[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Data Science (2e)",
    "section": "",
    "text": "환영합니다\n이 웹사이트는 “R for Data Science” (R을 활용한 데이터 과학) 제2판을 위한 곳입니다. 이 책은 R을 사용하여 데이터 과학을 수행하는 방법을 알려줍니다. 데이터를 R로 가져오고, 가장 유용한 구조로 만들고, 변형하고, 시각화하는 방법을 배우게 됩니다.\n이 책에서 데이터 과학을 위한 실습 기술을 찾을 수 있습니다. 화학자가 시험관을 세척하고 실험실을 비축하는 법을 배우는 것처럼, 데이터를 정제하고 도표를 그리는 법, 그리고 그 외의 많은 것들을 배우게 될 것입니다. 이것들은 데이터 과학이 가능하게 하는 기술들이며, 여기에서 R로 이러한 각각의 작업을 수행하기 위한 모범 사례를 찾을 수 있습니다. 시간을 절약하기 위해 그래픽 문법(grammar of graphics), 문학적 프로그래밍(literate programming), 재현 가능한 연구(reproducible research)를 사용하는 방법을 배우게 됩니다. 또한 데이터를 랭글링(wrangling), 시각화 및 탐색할 때 발견을 촉진하기 위해 인지 자원을 관리하는 방법도 배우게 됩니다.\n이 웹사이트는 CC BY-NC-ND 3.0 라이선스에 따라 언제나 무료로 제공됩니다. 책의 실물 사본을 원하시면 Amazon에서 주문할 수 있습니다. 이 책을 무료로 읽는 것에 감사하며 보답하고 싶다면, Kākāpō Recovery에 기부해 주세요. (R4DS 표지에 등장하는) 카카포(kākāpō)는 뉴질랜드 자생의 심각한 멸종 위기 앵무새로, 단 244마리만 남아 있습니다.\n다른 언어를 사용하신다면, 무료로 이용 가능한 1판 번역본에 관심이 있으실 수 있습니다:\n\n스페인어\n이탈리아어\n터키어\n포르투갈어\n\n그리고 2판 번역본:\n\n스페인어\n\n책의 연습문제에 대한 제안 답안은 https://mine-cetinkaya-rundel.github.io/r4ds-solutions에서 찾을 수 있습니다.\nR4DS는 기여자 행동 강령(Contributor Code of Conduct)을 따릅니다. 이 책에 기여함으로써 귀하는 해당 약관을 준수하는 데 동의하는 것입니다.",
    "crumbs": [
      "환영합니다"
    ]
  },
  {
    "objectID": "preface-2e.html",
    "href": "preface-2e.html",
    "title": "제2판 서문",
    "section": "",
    "text": "“R for Data Science” 제2판에 오신 것을 환영합니다! 이번 판은 1판의 대대적인 개정판으로, 더 이상 유용하지 않다고 생각되는 내용을 삭제하고, 1판에 포함했으면 좋았을 내용을 추가했으며, 전반적으로 텍스트와 코드를 업데이트하여 모범 사례의 변화를 반영했습니다. 또한 새로운 공저자를 맞이하게 되어 매우 기쁩니다. 저명한 데이터 과학 교육자이자 Posit(구 RStudio)의 동료인 Mine Çetinkaya-Rundel입니다.\n가장 큰 변화를 간략하게 요약하면 다음과 같습니다:\n\n책의 첫 번째 파트 이름을 “전체 게임(Whole game)”으로 변경했습니다. 이 섹션의 목표는 세부 사항으로 들어가기 전에 데이터 과학의 “전체 게임”에 대한 대략적인 세부 사항을 제공하는 것입니다.\n책의 두 번째 파트는 “시각화(Visualize)”입니다. 이 파트에서는 1판에 비해 데이터 시각화 도구와 모범 사례를 더 깊이 있게 다룹니다. 모든 세부 사항을 얻을 수 있는 가장 좋은 곳은 여전히 ggplot2 책이지만, 이제 R4DS에서도 가장 중요한 기법들을 더 많이 다룹니다.\n책의 세 번째 파트는 이제 “변형(Transform)”이라고 부르며, 숫자, 논리 벡터, 결측값에 대한 새로운 장들이 추가되었습니다. 이 내용들은 이전에 데이터 변형 장의 일부였으나, 모든 세부 사항을 다루기 위해 더 많은 지면이 필요했습니다.\n책의 네 번째 파트는 “가져오기(Import)”입니다. 평면 텍스트 파일을 읽는 것을 넘어 스프레드시트 작업, 데이터베이스에서 데이터 추출, 빅 데이터 작업, 계층적 데이터의 직사각형화(rectangling), 웹사이트에서 데이터 스크래핑 등을 다루는 새로운 장들로 구성되어 있습니다.\n“프로그램(Program)” 파트는 유지되지만, 함수 작성과 반복의 가장 중요한 부분에 초점을 맞추기 위해 처음부터 끝까지 다시 작성되었습니다. 함수 작성에는 이제 tidyverse 함수를 감싸는(wrapping) 방법(tidy evaluation의 어려움을 다루는 것)에 대한 세부 사항이 포함되는데, 지난 몇 년 동안 이 작업이 훨씬 쉬워지고 중요해졌기 때문입니다. 야생의 R 코드에서 자주 볼 수 있는 중요한 기본(base) R 함수들에 대한 새로운 장을 추가했습니다.\n모델링 파트는 삭제되었습니다. 모델링을 제대로 다루기에 충분한 지면이 없었고, 이제 훨씬 더 좋은 리소스들이 있습니다. 일반적으로 tidymodels 패키지를 사용하고, Max Kuhn과 Julia Silge가 쓴 Tidy Modeling with R을 읽는 것을 추천합니다.\n“소통(Communicate)” 파트는 유지되지만, R Markdown 대신 Quarto를 다루도록 철저히 업데이트되었습니다. 이 책의 이번 판은 Quarto로 작성되었으며, 이는 분명 미래의 도구입니다.",
    "crumbs": [
      "제2판 서문"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "소개",
    "section": "",
    "text": "무엇을 배우게 되나요\n데이터 과학은 원시 데이터를 이해, 통찰력, 지식으로 변환할 수 있게 해주는 흥미로운 분야입니다. “R for Data Science”의 목표는 데이터를 효율적이고 재현 가능하게 과학적으로 다루는 데 필요한 R의 가장 중요한 도구들을 배우고, 그 과정에서 재미도 느낄 수 있도록 돕는 것입니다 😃. 이 책을 다 읽고 나면, R의 장점들을 활용하여 다양한 데이터 과학 과제를 해결할 수 있는 도구를 갖추게 될 것입니다.\n데이터 과학은 방대한 분야이며, 책 한 권으로 모든 것을 마스터할 수는 없습니다. 이 책은 가장 중요한 도구들에 대한 탄탄한 기초를 제공하고, 필요할 때 더 많은 것을 배울 수 있는 리소스를 찾을 수 있는 지식을 제공하는 것을 목표로 합니다. 우리가 생각하는 일반적인 데이터 과학 프로젝트의 단계는 Figure 1 과 같습니다.\nFigure 1: 우리의 데이터 과학 프로세스 모델에서는 데이터 가져오기(import)와 정리(tidy)로 시작합니다. 다음으로 변형(transform), 시각화(visualize), 모델링(model)의 반복적인 주기를 통해 데이터를 이해합니다. 마지막으로 결과를 다른 사람들에게 소통(communicate)하며 프로세스를 마칩니다.\n먼저, 데이터를 R로 가져와야(import) 합니다. 이는 일반적으로 파일, 데이터베이스, 또는 웹 애플리케이션 프로그래밍 인터페이스(API)에 저장된 데이터를 가져와 R의 데이터 프레임으로 로드하는 것을 의미합니다. 데이터를 R로 가져오지 못하면 데이터 과학을 할 수 없습니다!\n데이터를 가져온 후에는 정리(tidy) 하는 것이 좋습니다. 데이터를 정리한다는 것은 데이터의 의미와 저장 방식이 일치하도록 일관된 형태로 저장하는 것을 의미합니다. 간단히 말해, 데이터가 깔끔하면(tidy) 각 열은 변수이고 각 행은 관측값입니다. 깔끔한(tidy) 데이터가 중요한 이유는 일관된 구조를 통해 데이터를 다양한 함수에 맞게 억지로 끼워 맞추는 대신 데이터에 대한 질문에 답하는 데 노력을 집중할 수 있게 해주기 때문입니다.\n깔끔한 데이터를 확보했다면, 일반적인 다음 단계는 변형(transform) 입니다. 변형에는 관심 있는 관측값(예: 특정 도시의 모든 사람 또는 작년의 모든 데이터)으로 좁히거나, 기존 변수의 함수로 새로운 변수를 생성하거나(예: 거리와 시간으로 속도 계산), 요약 통계량(예: 개수 또는 평균)을 계산하는 것이 포함됩니다. 정리와 변형을 합쳐서 랭글링(wrangling) 이라고 부르는데, 데이터를 작업하기 자연스러운 형태로 만드는 것이 종종 싸움처럼 느껴지기 때문입니다!\n필요한 변수를 갖춘 깔끔한 데이터가 준비되었다면, 지식 생성의 두 가지 주요 엔진은 시각화와 모델링입니다. 이들은 상호 보완적인 장단점을 가지고 있으므로, 실제 데이터 분석에서는 이 둘 사이를 여러 번 반복하게 됩니다.\n시각화(Visualization) 는 근본적으로 인간적인 활동입니다. 좋은 시각화는 예상치 못한 것을 보여주거나 데이터에 대한 새로운 질문을 제기합니다. 또한 좋은 시각화는 잘못된 질문을 하고 있다거나 다른 데이터를 수집해야 한다는 힌트를 줄 수도 있습니다. 시각화는 놀라움을 줄 수 있지만, 해석하는 데 사람이 필요하기 때문에 확장성이 그리 좋지는 않습니다.\n모델(Model) 은 시각화를 보완하는 도구입니다. 질문을 충분히 구체화했다면 모델을 사용하여 답을 얻을 수 있습니다. 모델은 근본적으로 수학적 또는 계산적 도구이므로 일반적으로 확장성이 좋습니다. 그렇지 않더라도, 더 많은 두뇌를 사는 것보다 더 많은 컴퓨터를 사는 것이 보통 더 저렴합니다! 하지만 모든 모델은 가정을 전제로 하며, 그 본질상 모델은 자신의 가정에 대해 의문을 제기할 수 없습니다. 즉, 모델은 근본적으로 여러분을 놀라게 할 수 없습니다.\n데이터 과학의 마지막 단계는 소통(communication) 으로, 모든 데이터 분석 프로젝트에서 절대적으로 중요한 부분입니다. 모델과 시각화가 데이터를 이해하는 데 아무리 큰 도움을 주었더라도, 그 결과를 다른 사람에게 전달할 수 없다면 의미가 없습니다.\n이 모든 도구를 감싸고 있는 것은 프로그래밍(programming) 입니다. 프로그래밍은 데이터 과학 프로젝트의 거의 모든 부분에서 사용하는 교차적인 도구입니다. 성공적인 데이터 과학자가 되기 위해 전문 프로그래머가 될 필요는 없지만, 프로그래밍을 더 배우는 것은 가치가 있습니다. 더 나은 프로그래머가 되면 반복적인 작업을 자동화하고 새로운 문제를 더 쉽게 해결할 수 있기 때문입니다.\n모든 데이터 과학 프로젝트에서 이 도구들을 사용하게 되지만, 대부분의 프로젝트에서는 이것만으로는 충분하지 않습니다. 대략 80/20 법칙이 적용됩니다. 이 책에서 배우는 도구들로 프로젝트의 약 80%를 해결할 수 있지만, 나머지 20%를 해결하려면 다른 도구들이 필요합니다. 책 전반에 걸쳐 더 배울 수 있는 리소스를 안내해 드릴 것입니다.",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "intro.html#이-책의-구성",
    "href": "intro.html#이-책의-구성",
    "title": "소개",
    "section": "이 책의 구성",
    "text": "이 책의 구성\n앞서 설명한 데이터 과학 도구들은 분석에서 사용하는 순서에 따라 대략적으로 구성되어 있습니다(물론 여러 번 반복하게 되겠지만요). 하지만 저희 경험상 데이터 가져오기와 정리를 먼저 배우는 것은 최선의 방법이 아닙니다. 왜냐하면 80%의 시간 동안은 일상적이고 지루하며, 나머지 20%의 시간 동안은 이상하고 답답하기 때문입니다. 새로운 주제를 배우기에 좋은 시작점이 아닙니다! 대신, 이미 가져와서 정리된 데이터의 시각화와 변형부터 시작하겠습니다. 그렇게 하면 나중에 직접 데이터를 가져와서 정리할 때, 그 고통이 노력할 가치가 있다는 것을 알기 때문에 동기를 유지할 수 있습니다.\n각 장 내에서는 일관된 패턴을 따르려고 노력합니다. 큰 그림을 볼 수 있도록 동기 부여가 되는 예제로 시작한 다음, 세부 사항으로 들어갑니다. 책의 각 섹션에는 배운 내용을 연습할 수 있는 연습문제들이 짝을 이루고 있습니다. 연습문제를 건너뛰고 싶은 유혹이 들 수 있지만, 실제 문제로 연습하는 것보다 더 좋은 학습 방법은 없습니다.",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "intro.html#배우지-않을-내용",
    "href": "intro.html#배우지-않을-내용",
    "title": "소개",
    "section": "배우지 않을 내용",
    "text": "배우지 않을 내용\n이 책에서 다루지 않는 몇 가지 중요한 주제가 있습니다. 우리는 가능한 한 빨리 시작하고 실행할 수 있도록 필수적인 것에 무자비하게 집중하는 것이 중요하다고 믿습니다. 즉, 이 책은 모든 중요한 주제를 다룰 수는 없습니다.\n모델링\n모델링은 데이터 과학에서 매우 중요하지만 큰 주제이며, 안타깝게도 여기서는 그에 걸맞은 분량을 할애할 공간이 없습니다. 모델링에 대해 더 배우고 싶다면 동료 Max Kuhn과 Julia Silge가 쓴 Tidy Modeling with R을 강력히 추천합니다. 이 책은 tidymodels 패키지 제품군을 가르쳐 주는데, 이름에서 짐작할 수 있듯이 이 책에서 사용하는 tidyverse 패키지들과 많은 관례를 공유합니다.\n빅 데이터\n이 책은 자랑스럽게 그리고 주로 작은 인메모리(in-memory) 데이터셋에 초점을 맞춥니다. 작은 데이터를 다뤄본 경험이 없으면 빅 데이터를 다룰 수 없기 때문에 이것이 올바른 시작점입니다. 이 책의 대부분에서 배우는 도구들은 수백 메가바이트의 데이터를 쉽게 처리할 수 있으며, 조금만 주의를 기울이면 일반적으로 몇 기가바이트의 데이터도 작업할 수 있습니다. 또한 빅 데이터를 저장하는 데 자주 사용되는 데이터베이스와 파켓(parquet) 파일에서 데이터를 가져오는 방법도 보여드릴 것입니다. 전체 데이터셋을 가지고 작업할 수 없을 수도 있지만, 관심 있는 질문에 답하기 위해서는 부분집합이나 샘플만 있으면 되므로 문제되지 않습니다.\n만약 일상적으로 더 큰 데이터(예: 10–100 GB)를 다룬다면, data.table에 대해 더 배우는 것을 추천합니다. 여기서는 가르치지 않는데, tidyverse와는 다른 인터페이스를 사용하고 다른 관례를 배워야 하기 때문입니다. 하지만 믿을 수 없을 정도로 빠르며, 큰 데이터를 다룬다면 성능상의 이점이 학습에 투자할 가치가 있습니다.\n파이썬, 줄리아, 그리고 친구들\n이 책에서는 파이썬(Python), 줄리아(Julia) 또는 데이터 과학에 유용한 다른 프로그래밍 언어에 대해 배우지 않습니다. 이 도구들이 나빠서가 아닙니다. 그렇지 않습니다! 실제로 대부분의 데이터 과학 팀은 여러 언어를 섞어서 사용하며, 종종 적어도 R과 파이썬을 함께 사용합니다. 하지만 우리는 한 번에 하나의 도구를 마스터하는 것이 가장 좋다고 굳게 믿으며, R은 시작하기에 훌륭한 곳입니다.",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "intro.html#선수-지식",
    "href": "intro.html#선수-지식",
    "title": "소개",
    "section": "선수 지식",
    "text": "선수 지식\n이 책을 최대한 활용하기 위해 여러분이 이미 알고 있다고 가정한 몇 가지가 있습니다. 일반적으로 수치적인 이해도가 있어야 하며, 기본적인 프로그래밍 경험이 있다면 도움이 됩니다. 프로그래밍을 한 번도 해본 적이 없다면, Garrett이 쓴 Hands on Programming with R이 이 책의 훌륭한 보조 교재가 될 것입니다.\n이 책의 코드를 실행하려면 네 가지가 필요합니다: R, RStudio, tidyverse라고 불리는 R 패키지 모음, 그리고 몇 가지 다른 패키지들입니다. 패키지는 재현 가능한 R 코드의 기본 단위입니다. 패키지에는 재사용 가능한 함수, 사용법을 설명하는 문서, 그리고 샘플 데이터가 포함되어 있습니다.\nR\nR을 다운로드하려면 CRAN(Comprehensive R Archive Network), https://cloud.r-project.org에 접속하세요. 새로운 R의 메이저 버전은 1년에 한 번 나오며, 마이너 릴리스는 1년에 2-3회 있습니다. 정기적으로 업데이트하는 것이 좋습니다. 업그레이드는 다소 번거로울 수 있으며, 특히 모든 패키지를 다시 설치해야 하는 메이저 버전의 경우 더욱 그렇지만, 미루면 더 나빠질 뿐입니다. 이 책에서는 R 4.2.0 이상을 권장합니다.\nRStudio\nRStudio는 R 프로그래밍을 위한 통합 개발 환경(IDE)으로, https://posit.co/download/rstudio-desktop/에서 다운로드할 수 있습니다. RStudio는 일 년에 몇 번 업데이트되며, 새 버전이 나오면 자동으로 알려주므로 다시 확인할 필요가 없습니다. 최신 기능을 활용하기 위해 정기적으로 업그레이드하는 것이 좋습니다. 이 책을 위해서는 최소 RStudio 2022.02.0 버전이 필요합니다.\nRStudio를 시작하면(Figure 2), 인터페이스에 두 가지 주요 영역, 즉 콘솔(console) 창과 출력(output) 창이 보일 것입니다. 지금은 콘솔 창에 R 코드를 입력하고 엔터를 눌러 실행한다는 것만 알면 됩니다. 진행하면서 더 배우게 될 것입니다.1\n\n\n\n\n\n\n\nFigure 2: RStudio IDE에는 두 가지 주요 영역이 있습니다. 왼쪽의 콘솔 창에 R 코드를 입력하고, 오른쪽의 출력 창에서 플롯을 확인하세요.\n\n\n\n\ntidyverse\n몇 가지 R 패키지도 설치해야 합니다. R 패키지는 기본 R의 기능을 확장하는 함수, 데이터, 문서의 모음입니다. 패키지 사용은 R을 성공적으로 사용하는 데 있어 핵심입니다. 이 책에서 배우게 될 대부분의 패키지는 소위 tidyverse의 일부입니다. tidyverse의 모든 패키지는 데이터와 R 프로그래밍에 대한 공통된 철학을 공유하며 함께 작동하도록 설계되었습니다.\n코드 한 줄로 전체 tidyverse를 설치할 수 있습니다:\n\ninstall.packages(\"tidyverse\")\n\n컴퓨터의 콘솔에 해당 코드를 입력하고 엔터를 눌러 실행하세요. R이 CRAN에서 패키지를 다운로드하여 컴퓨터에 설치합니다.\n패키지를 library()로 로드하기 전까지는 패키지의 함수, 객체 또는 도움말 파일을 사용할 수 없습니다. 패키지를 설치한 후에는 library() 함수를 사용하여 로드할 수 있습니다:\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.6\n#&gt; ✔ forcats   1.0.1     ✔ stringr   1.6.0\n#&gt; ✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n#&gt; ✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.2.0     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n이것은 tidyverse가 9개의 패키지(dplyr, forcats, ggplot2, lubridate, purrr, readr, stringr, tibble, tidyr)를 로드한다고 알려줍니다. 이들은 거의 모든 분석에서 사용하기 때문에 tidyverse의 핵심(core) 으로 간주됩니다.\ntidyverse의 패키지들은 꽤 자주 변경됩니다. tidyverse_update()를 실행하여 업데이트가 있는지 확인할 수 있습니다.\n그 외 패키지들\n다른 도메인의 문제를 해결하거나 다른 기본 원칙으로 설계되었기 때문에 tidyverse에 포함되지 않은 훌륭한 패키지들이 많이 있습니다. 그렇다고 해서 더 좋거나 나쁜 것은 아니며, 단지 다를 뿐입니다. 즉, tidyverse의 보완재는 지저분한(messy) verse가 아니라 상호 연관된 패키지들의 다른 많은 우주들입니다. R로 더 많은 데이터 과학 프로젝트를 수행함에 따라 새로운 패키지와 데이터를 생각하는 새로운 방식을 배우게 될 것입니다.\n이 책에서는 tidyverse 외부의 많은 패키지를 사용할 것입니다. 예를 들어, R을 배우는 과정에서 작업할 흥미로운 데이터셋을 제공하기 때문에 다음 패키지들을 사용할 것입니다:\n\ninstall.packages(\n  c(\"arrow\", \"babynames\", \"curl\", \"duckdb\", \"gapminder\", \n    \"ggrepel\", \"ggridges\", \"ggthemes\", \"hexbin\", \"janitor\", \"Lahman\", \n    \"leaflet\", \"maps\", \"nycflights13\", \"openxlsx\", \"palmerpenguins\", \n    \"repurrrsive\", \"tidymodels\", \"writexl\")\n  )\n\n또한 일회성 예제를 위해 다른 패키지들도 선택적으로 사용할 것입니다. 지금 당장 설치할 필요는 없지만, 다음과 같은 오류가 보일 때를 기억하세요:\n\nlibrary(ggrepel)\n#&gt; Error in library(ggrepel) : there is no package called ‘ggrepel’\n\n패키지를 설치하려면 install.packages(\"ggrepel\")을 실행해야 합니다.",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "intro.html#r-코드-실행하기",
    "href": "intro.html#r-코드-실행하기",
    "title": "소개",
    "section": "R 코드 실행하기",
    "text": "R 코드 실행하기\n이전 섹션에서는 R 코드를 실행하는 몇 가지 예제를 보여주었습니다. 책에 있는 코드는 다음과 같습니다:\n\n1 + 2\n#&gt; [1] 3\n\n동일한 코드를 로컬 콘솔에서 실행하면 다음과 같이 보일 것입니다:\n&gt; 1 + 2\n[1] 3\n두 가지 주요 차이점이 있습니다. 콘솔에서는 프롬프트(prompt) 라고 불리는 &gt; 뒤에 입력하지만, 책에서는 프롬프트를 보여주지 않습니다. 책에서는 출력이 #&gt;로 주석 처리되어 있지만, 콘솔에서는 코드 바로 뒤에 나타납니다. 이 두 가지 차이점 덕분에 전자책으로 작업하는 경우 책에서 코드를 쉽게 복사하여 콘솔에 붙여넣을 수 있습니다.\n책 전반에 걸쳐 코드를 지칭할 때 일관된 규칙을 사용합니다:\n\n함수는 sum() 또는 mean()과 같이 코드 글꼴로 표시되고 뒤에 괄호가 붙습니다.\n데이터나 함수 인자와 같은 다른 R 객체는 flights나 x와 같이 괄호 없이 코드 글꼴로 표시됩니다.\n때때로 객체가 어떤 패키지에서 왔는지 명확히 하기 위해 dplyr::mutate() 또는 nycflights13::flights와 같이 패키지 이름 뒤에 콜론 두 개를 사용합니다. 이 또한 유효한 R 코드입니다.",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "intro.html#감사의-말",
    "href": "intro.html#감사의-말",
    "title": "소개",
    "section": "감사의 말",
    "text": "감사의 말\n이 책은 Hadley, Mine, Garrett만의 결과물이 아니라 R 커뮤니티의 많은 사람들과 (대면 및 온라인으로) 나눈 수많은 대화의 결과입니다. 여러분 모두와 나눈 모든 대화에 진심으로 감사드립니다. 정말 고맙습니다!\n이 책은 공개적으로 작성되었으며, 많은 분들이 풀 리퀘스트(pull request)를 통해 기여해 주셨습니다. GitHub 풀 리퀘스트를 통해 개선에 기여해 주신 259명의 모든 분들께 특별한 감사를 전합니다(사용자명 알파벳 순): @a-rosenberg, Tim Becker (@a2800276), Abinash Satapathy (@Abinashbunty), Adam Gruer (@adam-gruer), adi pradhan (@adidoit), A. s. (@Adrianzo), Aep Hidyatuloh (@aephidayatuloh), Andrea Gilardi (@agila5), Ajay Deonarine (@ajay-d), @AlanFeder, Daihe Sui (@alansuidaihe), @alberto-agudo, @AlbertRapp, @aleloi, pete (@alonzi), Alex (@ALShum), Andrew M. (@amacfarland), Andrew Landgraf (@andland), @andyhuynh92, Angela Li (@angela-li), Antti Rask (@AnttiRask), LOU Xun (@aquarhead), @ariespirgel, @august-18, Michael Henry (@aviast), Azza Ahmed (@azzaea), Steven Moran (@bambooforest), Brian G. Barkley (@BarkleyBG), Mara Averick (@batpigandme), Oluwafemi OYEDELE (@BB1464), Brent Brewington (@bbrewington), Bill Behrman (@behrman), Ben Herbertson (@benherbertson), Ben Marwick (@benmarwick), Ben Steinberg (@bensteinberg), Benjamin Yeh (@bentyeh), Betul Turkoglu (@betulturkoglu), Brandon Greenwell (@bgreenwell), Bianca Peterson (@BinxiePeterson), Birger Niklas (@BirgerNi), Brett Klamer (@bklamer), @boardtc, Christian (@c-hoh), Caddy (@caddycarine), Camille V Leonard (@camillevleonard), @canovasjm, Cedric Batailler (@cedricbatailler), Christina Wei (@christina-wei), Christian Mongeau (@chrMongeau), Cooper Morris (@coopermor), Colin Gillespie (@csgillespie), Rademeyer Vermaak (@csrvermaak), Chloe Thierstein (@cthierst), Chris Saunders (@ctsa), Abhinav Singh (@curious-abhinav), Curtis Alexander (@curtisalexander), Christian G. Warden (@cwarden), Charlotte Wickham (@cwickham), Kenny Darrell (@darrkj), David Kane (@davidkane9), David (@davidrsch), David Rubinger (@davidrubinger), David Clark (@DDClark), Derwin McGeary (@derwinmcgeary), Daniel Gromer (@dgromer), @Divider85, @djbirke, Danielle Navarro (@djnavarro), Russell Shean (@DOH-RPS1303), Zhuoer Dong (@dongzhuoer), Devin Pastoor (@dpastoor), @DSGeoff, Devarshi Thakkar (@dthakkar09), Julian During (@duju211), Dylan Cashman (@dylancashman), Dirk Eddelbuettel (@eddelbuettel), Edwin Thoen (@EdwinTh), Ahmed El-Gabbas (@elgabbas), Henry Webel (@enryH), Ercan Karadas (@ercan7), Eric Kitaif (@EricKit), Eric Watt (@ericwatt), Erik Erhardt (@erikerhardt), Etienne B. Racine (@etiennebr), Everett Robinson (@evjrob), @fellennert, Flemming Miguel (@flemmingmiguel), Floris Vanderhaeghe (@florisvdh), @funkybluehen, @gabrivera, Garrick Aden-Buie (@gadenbuie), Peter Ganong (@ganong123), Gerome Meyer (@GeroVanMi), Gleb Ebert (@gl-eb), Josh Goldberg (@GoldbergData), bahadir cankardes (@gridgrad), Gustav W Delius (@gustavdelius), Hao Chen (@hao-trivago), Harris McGehee (@harrismcgehee), @hendrikweisser, Hengni Cai (@hengnicai), Iain (@Iain-S), Ian Sealy (@iansealy), Ian Lyttle (@ijlyttle), Ivan Krukov (@ivan-krukov), Jacob Kaplan (@jacobkap), Jazz Weisman (@jazzlw), John Blischak (@jdblischak), John D. Storey (@jdstorey), Gregory Jefferis (@jefferis), Jeffrey Stevens (@JeffreyRStevens), 蒋雨蒙 (@JeldorPKU), Jennifer (Jenny) Bryan (@jennybc), Jen Ren (@jenren), Jeroen Janssens (@jeroenjanssens), @jeromecholewa, Janet Wesner (@jilmun), Jim Hester (@jimhester), JJ Chen (@jjchern), Jacek Kolacz (@jkolacz), Joanne Jang (@joannejang), @johannes4998, John Sears (@johnsears), @jonathanflint, Jon Calder (@jonmcalder), Jonathan Page (@jonpage), Jon Harmon (@jonthegeek), JooYoung Seo (@jooyoungseo), Justinas Petuchovas (@jpetuchovas), Jordan (@jrdnbradford), Jeffrey Arnold (@jrnold), Jose Roberto Ayala Solares (@jroberayalas), Joyce Robbins (@jtr13), @juandering, Julia Stewart Lowndes (@jules32), Sonja (@kaetschap), Kara Woo (@karawoo), Katrin Leinweber (@katrinleinweber), Karandeep Singh (@kdpsingh), Kevin Perese (@kevinxperese), Kevin Ferris (@kferris10), Kirill Sevastyanenko (@kirillseva), Jonathan Kitt (@KittJonathan), @koalabearski, Kirill Müller (@krlmlr), Rafał Kucharski (@kucharsky), Kevin Wright (@kwstat), Noah Landesberg (@landesbergn), Lawrence Wu (@lawwu), @lindbrook, Luke W Johnston (@lwjohnst86), Kara de la Marck (@MarckK), Kunal Marwaha (@marwahaha), Matan Hakim (@matanhakim), Matthias Liew (@MatthiasLiew), Matt Wittbrodt (@MattWittbrodt), Mauro Lepore (@maurolepore), Mark Beveridge (@mbeveridge), @mcewenkhundi, mcsnowface, PhD (@mcsnowface), Matt Herman (@mfherman), Michael Boerman (@michaelboerman), Mitsuo Shiota (@mitsuoxv), Matthew Hendrickson (@mjhendrickson), @MJMarshall, Misty Knight-Finley (@mkfin7), Mohammed Hamdy (@mmhamdy), Maxim Nazarov (@mnazarov), Maria Paula Caldas (@mpaulacaldas), Mustafa Ascha (@mustafaascha), Nelson Areal (@nareal), Nate Olson (@nate-d-olson), Nathanael (@nateaff), @nattalides, Ned Western (@NedJWestern), Nick Clark (@nickclark1000), @nickelas, Nirmal Patel (@nirmalpatel), Nischal Shrestha (@nischalshrestha), Nicholas Tierney (@njtierney), Jakub Nowosad (@Nowosad), Nick Pullen (@nstjhp), @olivier6088, Olivier Cailloux (@oliviercailloux), Robin Penfold (@p0bs), Pablo E. Garcia (@pabloedug), Paul Adamson (@padamson), Penelope Y (@penelopeysm), Peter Hurford (@peterhurford), Peter Baumgartner (@petzi53), Patrick Kennedy (@pkq), Pooya Taherkhani (@pooyataher), Y. Yu (@PursuitOfDataScience), Radu Grosu (@radugrosu), Ranae Dietzel (@Ranae), Ralph Straumann (@rastrau), Rayna M Harris (@raynamharris), @ReeceGoding, Robin Gertenbach (@rgertenbach), Jajo (@RIngyao), Riva Quiroga (@rivaquiroga), Richard Knight (@RJHKnight), Richard Zijdeman (@rlzijdeman), @robertchu03, Robin Kohrs (@RobinKohrs), Robin (@Robinlovelace), Emily Robinson (@robinsones), Rob Tenorio (@robtenorio), Rod Mazloomi (@RodAli), Rohan Alexander (@RohanAlexander), Romero Morais (@RomeroBarata), Albert Y. Kim (@rudeboybert), Saghir (@saghirb), Hojjat Salmasian (@salmasian), Jonas (@sauercrowd), Vebash Naidoo (@sciencificity), Seamus McKinsey (@seamus-mckinsey), @seanpwilliams, Luke Smith (@seasmith), Matthew Sedaghatfar (@sedaghatfar), Sebastian Kraus (@sekR4), Sam Firke (@sfirke), Shannon Ellis (@ShanEllis), @shoili, Christian Heinrich (@Shurakai), S’busiso Mkhondwane (@sibusiso16), SM Raiyyan (@sm-raiyyan), Jakob Krigovsky (@sonicdoe), Stephan Koenig (@stephan-koenig), Stephen Balogun (@stephenbalogun), Steven M. Mortimer (@StevenMMortimer), Stéphane Guillou (@stragu), Sulgi Kim (@sulgik), Sergiusz Bleja (@svenski), Tal Galili (@talgalili), Alec Fisher (@Taurenamo), Todd Gerarden (@tgerarden), Tom Godfrey (@thomasggodfrey), Tim Broderick (@timbroderick), Tim Waterhouse (@timwaterhouse), TJ Mahr (@tjmahr), Thomas Klebel (@tklebel), Tom Prior (@tomjamesprior), Terence Teo (@tteo), @twgardner2, Ulrik Lyngs (@ulyngs), Shinya Uryu (@uribo), Martin Van der Linden (@vanderlindenma), Walter Somerville (@waltersom), @werkstattcodes, Will Beasley (@wibeasley), Yihui Xie (@yihui), Yiming (Paul) Li (@yimingli), @yingxingwu, Hiroaki Yutani (@yutannihilation), Yu Yu Aung (@yuyu-aung), Zach Bogart (@zachbogart), @zeal626, Zeki Akyol (@zekiakyol).",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "intro.html#판권",
    "href": "intro.html#판권",
    "title": "소개",
    "section": "판권",
    "text": "판권\n이 책의 온라인 버전은 https://r4ds.hadley.nz에서 이용할 수 있습니다. 실물 책이 재인쇄되는 사이에도 계속 발전할 것입니다. 책의 소스는 https://github.com/hadley/r4ds에서 확인할 수 있습니다. 이 책은 텍스트와 실행 가능한 코드를 결합한 책을 쉽게 쓸 수 있게 해주는 Quarto로 제작되었습니다.",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "소개",
    "section": "",
    "text": "RStudio의 모든 기능에 대한 포괄적인 개요를 보려면 https://docs.posit.co/ide/user의 RStudio 사용자 가이드를 참조하세요.↩︎",
    "crumbs": [
      "소개"
    ]
  },
  {
    "objectID": "whole-game.html",
    "href": "whole-game.html",
    "title": "전체 게임",
    "section": "",
    "text": "이 파트의 목표는 Figure 1 에서 보여주는 것처럼 데이터 과학의 주요 도구인 가져오기(importing), 정리(tidying), 변형(transforming), 시각화(visualizing) 에 대한 빠른 개요를 제공하는 것입니다. 데이터 과학의 “전체 게임”을 보여주어 간단하지만 실제 데이터셋을 다룰 수 있을 만큼의 주요 조각들을 충분히 제공하고자 합니다. 책의 뒷부분에서는 이러한 각 주제를 더 깊이 있게 다루어, 여러분이 해결할 수 있는 데이터 과학 과제의 범위를 넓힐 것입니다.\n\n\n\n\n\n\n\nFigure 1: 이 섹션에서는 데이터를 가져오고, 정리하고, 변형하고, 시각화하는 방법을 배웁니다.\n\n\n\n\n네 개의 장에서 데이터 과학 도구에 초점을 맞춥니다:\n\n시각화는 R 프로그래밍을 시작하기에 좋은 곳입니다. 보상이 매우 분명하기 때문입니다. 데이터를 이해하는 데 도움이 되는 우아하고 유익한 플롯을 만들 수 있습니다. 1  데이터 시각화 에서는 시각화에 뛰어들어 ggplot2 플롯의 기본 구조와 데이터를 플롯으로 바꾸는 강력한 기법들을 배웁니다.\n시각화만으로는 충분하지 않은 경우가 많으므로, 3  데이터 변형 에서는 중요한 변수를 선택하고, 주요 관측값을 필터링하고, 새로운 변수를 생성하고, 요약을 계산할 수 있는 핵심 동사들을 배웁니다.\n5  데이터 정리 에서는 변형, 시각화, 모델링을 더 쉽게 만들어주는 일관된 데이터 저장 방식인 ’깔끔한 데이터(tidy data)’에 대해 배웁니다. 기본 원칙과 데이터를 깔끔한 형태로 만드는 방법을 배우게 됩니다.\n데이터를 변형하고 시각화하기 전에 먼저 데이터를 R로 가져와야 합니다. 7  데이터 가져오기 에서는 .csv 파일을 R로 가져오는 기본 사항을 배웁니다.\n\n이 장들 사이에는 R 워크플로우에 초점을 맞춘 다른 네 개의 장이 자리 잡고 있습니다. 2  워크플로우: 기초, 4  워크플로우: 코드 스타일, 6  워크플로우: 스크립트와 프로젝트 에서는 R 코드를 작성하고 구성하기 위한 좋은 워크플로우 관행을 배웁니다. 이것들은 실제 프로젝트를 다룰 때 체계적으로 유지할 수 있는 도구를 제공하므로 장기적으로 성공할 수 있는 기반을 마련해 줄 것입니다. 마지막으로, 8  워크플로우: 도움 받기 에서는 도움을 받고 계속 학습하는 방법을 알려줍니다.",
    "crumbs": [
      "전체 게임"
    ]
  },
  {
    "objectID": "data-visualize.html",
    "href": "data-visualize.html",
    "title": "1  데이터 시각화",
    "section": "",
    "text": "1.1 소개\nR에는 그래프를 만들기 위한 여러 시스템이 있지만, ggplot2는 가장 우아하고 다재다능한 시스템 중 하나입니다. ggplot2는 그래프를 설명하고 구축하기 위한 일관된 시스템인 그래픽 문법(grammar of graphics) 을 구현합니다. ggplot2를 사용하면 하나의 시스템을 배워서 여러 곳에 적용함으로써 더 많은 일을 더 빠르게 할 수 있습니다.\n이 장에서는 ggplot2를 사용하여 데이터를 시각화하는 방법을 알려줍니다. 간단한 산점도를 만드는 것으로 시작하여 ggplot2의 기본 구성 요소인 심미적 매핑(aesthetic mappings)과 기하학적 객체(geometric objects)를 소개하는 데 사용합니다. 그런 다음 단일 변수의 분포를 시각화하는 방법과 두 개 이상의 변수 간의 관계를 시각화하는 방법을 안내합니다. 마지막으로 플롯을 저장하는 방법과 문제 해결 팁으로 마무리합니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#소개",
    "href": "data-visualize.html#소개",
    "title": "1  데이터 시각화",
    "section": "",
    "text": "“단순한 그래프는 다른 어떤 장치보다 더 많은 정보를 데이터 분석가의 마음에 전달해 왔다.” — John Tukey\n\n\n\n\n1.1.1 선수 지식\n이 장은 tidyverse의 핵심 패키지 중 하나인 ggplot2에 중점을 둡니다. 이 장에서 사용되는 데이터셋, 도움말 페이지, 함수에 액세스하려면 다음을 실행하여 tidyverse를 로드하세요:\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.6\n#&gt; ✔ forcats   1.0.1     ✔ stringr   1.6.0\n#&gt; ✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n#&gt; ✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.2.0     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n이 한 줄의 코드는 핵심 tidyverse를 로드합니다. 이는 거의 모든 데이터 분석에서 사용하게 될 패키지들입니다. 또한 tidyverse의 어떤 함수가 기본(base) R(또는 로드했을 수 있는 다른 패키지)의 함수와 충돌하는지 알려줍니다1.\n이 코드를 실행했는데 there is no package called 'tidyverse'라는 오류 메시지가 나타나면 먼저 설치한 다음 library()를 다시 실행해야 합니다.\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n패키지는 한 번만 설치하면 되지만, 새로운 세션을 시작할 때마다 로드해야 합니다.\ntidyverse 외에도 팔머 군도(Palmer Archipelago)의 세 섬에 있는 펭귄의 신체 치수 데이터가 포함된 penguins 데이터셋이 있는 palmerpenguins 패키지와 색맹에 안전한 색상 팔레트를 제공하는 ggthemes 패키지도 사용할 것입니다.\n\nlibrary(palmerpenguins)\n#&gt; \n#&gt; Attaching package: 'palmerpenguins'\n#&gt; The following objects are masked from 'package:datasets':\n#&gt; \n#&gt;     penguins, penguins_raw\nlibrary(ggthemes)\n#&gt; Warning: package 'ggthemes' was built under R version 4.5.2",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#첫-걸음",
    "href": "data-visualize.html#첫-걸음",
    "title": "1  데이터 시각화",
    "section": "\n1.2 첫 걸음",
    "text": "1.2 첫 걸음\n지느러미(flipper)가 더 긴 펭귄이 지느러미가 짧은 펭귄보다 무게가 더 많이 나갈까요? 아니면 적게 나갈까요? 이미 답을 알고 계실지 모르지만, 답을 정확하게 만들어 보세요. 지느러미 길이와 체중(body mass) 사이의 관계는 어떤 모습일까요? 양의 관계일까요? 음의 관계일까요? 선형일까요? 비선형일까요? 관계가 펭귄의 종(species)에 따라 달라질까요? 펭귄이 사는 섬에 따라서는 어떨까요? 이러한 질문에 답하는 데 사용할 수 있는 시각화를 만들어 봅시다.\n\n1.2.1 penguins 데이터 프레임\npalmerpenguins에 있는 penguins 데이터 프레임(일명 palmerpenguins::penguins)을 사용하여 해당 질문에 대한 답을 테스트할 수 있습니다. 데이터 프레임은 변수(열)와 관측값(행)의 직사각형 모음입니다. penguins에는 Kristen Gorman 박사와 Palmer Station, Antarctica LTER2가 수집하고 제공한 344개의 관측값이 포함되어 있습니다.\n논의를 더 쉽게 하기 위해 몇 가지 용어를 정의해 봅시다:\n\n변수(variable) 는 측정할 수 있는 수량, 품질 또는 속성입니다.\n값(value) 은 변수를 측정할 때의 상태입니다. 변수의 값은 측정할 때마다 달라질 수 있습니다.\n관측값(observation) 은 유사한 조건에서 수행된 측정값의 집합입니다(보통 하나의 관측값에 있는 모든 측정은 동시에 동일한 대상에 대해 수행됩니다). 관측값은 여러 값을 포함하며, 각 값은 서로 다른 변수와 연관됩니다. 때때로 관측값을 데이터 포인트라고 부르기도 합니다.\n표 형식 데이터(Tabular data) 는 각 값이 변수 및 관측값과 연관된 값들의 집합입니다. 각 값이 고유한 “셀”에 배치되고, 각 변수가 고유한 열에, 각 관측값이 고유한 행에 배치되면 표 형식 데이터는 깔끔(tidy) 합니다.\n\n이 맥락에서 변수는 모든 펭귄의 속성을 나타내며, 관측값은 단일 펭귄의 모든 속성을 나타냅니다.\n콘솔에 데이터 프레임의 이름을 입력하면 R이 그 내용의 미리보기를 출력합니다. 미리보기 상단에 tibble이라고 표시된 것을 주목하세요. tidyverse에서는 곧 더 자세히 배우게 될 티블(tibble) 이라는 특별한 데이터 프레임을 사용합니다.\n\npenguins\n#&gt; # A tibble: 344 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 338 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt;\n\n이 데이터 프레임에는 8개의 열이 포함되어 있습니다. 모든 변수와 각 변수의 처음 몇 개의 관측값을 볼 수 있는 다른 뷰를 보려면 glimpse()를 사용하세요. 또는 RStudio를 사용 중이라면 View(penguins)를 실행하여 대화형 데이터 뷰어를 여세요.\n\nglimpse(penguins)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, A…\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torge…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.…\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.…\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, …\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 347…\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, m…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2…\n\npenguins의 변수 중 일부는 다음과 같습니다:\n\nspecies: 펭귄의 종 (Adelie, Chinstrap, 또는 Gentoo).\nflipper_length_mm: 펭귄의 지느러미 길이 (밀리미터 단위).\nbody_mass_g: 펭귄의 체중 (그램 단위).\n\npenguins에 대해 더 자세히 알아보려면 ?penguins를 실행하여 도움말 페이지를 여세요.\n\n1.2.2 최종 목표\n이 장의 최종 목표는 펭귄의 종을 고려하여 지느러미 길이와 체중 사이의 관계를 보여주는 다음 시각화를 재현하는 것입니다.\n\n\n\n\n\n\n\n\n\n1.2.3 ggplot 만들기\n단계별로 이 플롯을 재현해 봅시다.\nggplot2에서는 ggplot() 함수로 플롯을 시작하여 플롯 객체를 정의한 다음 여기에 레이어(layer) 를 추가합니다. ggplot()의 첫 번째 인수는 그래프에 사용할 데이터셋이므로 ggplot(data = penguins)는 penguins 데이터를 표시할 준비가 된 빈 그래프를 생성하지만, 아직 시각화 방법을 알려주지 않았으므로 지금은 비어 있습니다. 이것은 별로 흥미롭지 않은 플롯이지만, 플롯의 나머지 레이어를 그릴 빈 캔버스와 같다고 생각할 수 있습니다.\n\nggplot(data = penguins)\n\n\n\n\n\n\n\n다음으로, 데이터의 정보가 시각적으로 어떻게 표현될지 ggplot()에 알려줘야 합니다. ggplot() 함수의 mapping 인수는 데이터셋의 변수가 플롯의 시각적 속성(심미성, aesthetics)에 매핑되는 방식을 정의합니다. mapping 인수는 항상 aes() 함수 내에 정의되며, aes()의 x와 y 인수는 x축과 y축에 매핑할 변수를 지정합니다. 지금은 지느러미 길이를 x 심미성에, 체중을 y 심미성에만 매핑하겠습니다. ggplot2는 data 인수, 이 경우 penguins에서 매핑된 변수를 찾습니다.\n다음 플롯은 이러한 매핑을 추가한 결과를 보여줍니다.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n)\n\n\n\n\n\n\n\n이제 빈 캔버스에 더 많은 구조가 생겼습니다. 지느러미 길이가 표시될 위치(x축)와 체중이 표시될 위치(y축)가 명확해졌습니다. 하지만 펭귄 자체는 아직 플롯에 없습니다. 이는 데이터 프레임의 관측값을 플롯에 어떻게 표현할지 코드에서 아직 명시하지 않았기 때문입니다.\n그렇게 하려면 지옴(geom) 을 정의해야 합니다. 지옴은 플롯이 데이터를 나타내는 데 사용하는 기하학적 객체입니다. 이러한 기하학적 객체는 ggplot2에서 geom_으로 시작하는 함수로 사용할 수 있습니다. 사람들은 종종 플롯이 사용하는 지옴의 유형으로 플롯을 설명합니다. 예를 들어, 막대 차트는 막대 지옴(geom_bar())을 사용하고, 선 차트는 선 지옴(geom_line())을 사용하며, 상자 그림은 상자 그림 지옴(geom_boxplot())을 사용하고, 산점도는 점 지옴(geom_point())을 사용하는 식입니다.\ngeom_point() 함수는 플롯에 점 레이어를 추가하여 산점도를 만듭니다. ggplot2에는 각각 플롯에 다른 유형의 레이어를 추가하는 많은 지옴 함수가 함께 제공됩니다. 책 전체, 특히 Chapter 9 에서 다양한 지옴을 배우게 될 것입니다.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n이제 우리가 “산점도”라고 생각하는 것과 비슷한 것이 생겼습니다. 아직 “최종 목표” 플롯과는 일치하지 않지만, 이 플롯을 사용하여 우리의 탐색 동기가 되었던 질문에 답하기 시작할 수 있습니다. “지느러미 길이와 체중 사이의 관계는 어떤 모습인가?” 관계는 양의 관계(지느러미 길이가 증가함에 따라 체중도 증가함)로 보이고, 꽤 선형적이며(점들이 곡선보다는 선 주위에 모여 있음), 중간 정도로 강합니다(선 주위에 산포가 너무 많지 않음). 지느러미가 더 긴 펭귄은 일반적으로 체중 면에서 더 큽니다.\n이 플롯에 레이어를 더 추가하기 전에 잠시 멈추고 우리가 받은 경고 메시지를 검토해 봅시다:\n\nRemoved 2 rows containing missing values (geom_point()). (결측값이 포함된 2개의 행이 제거되었습니다 (geom_point()).)\n\n이 메시지가 표시되는 이유는 데이터셋에 체중 및/또는 지느러미 길이 값이 누락된 펭귄이 두 마리 있는데, ggplot2는 이 두 값 없이 플롯에 이들을 표현할 방법이 없기 때문입니다. R과 마찬가지로 ggplot2는 결측값이 조용히 사라져서는 안 된다는 철학을 따릅니다. 이 유형의 경고는 실제 데이터로 작업할 때 가장 흔하게 볼 수 있는 경고 중 하나일 것입니다. 결측값은 매우 흔한 문제이며 책 전체, 특히 Chapter 18 에서 더 자세히 배우게 될 것입니다. 이 장의 나머지 플롯에서는 우리가 만드는 모든 플롯 옆에 이 경고가 출력되지 않도록 숨길 것입니다.\n\n1.2.4 심미성과 레이어 추가\n산점도는 두 수치형 변수 간의 관계를 표시하는 데 유용하지만, 두 변수 사이의 명백한 관계에 대해 항상 회의적인 태도를 취하고 이 명백한 관계를 설명하거나 성격을 바꾸는 다른 변수가 있을 수 있는지 묻는 것이 좋습니다. 예를 들어, 지느러미 길이와 체중 사이의 관계가 종에 따라 다를까요? 종을 플롯에 통합하여 이것이 변수들 간의 명백한 관계에 대한 추가적인 통찰력을 드러내는지 확인해 봅시다. 종을 다른 색상의 점으로 표현하여 이를 수행할 것입니다.\n이를 달성하기 위해 심미성을 수정해야 할까요, 아니면 지옴을 수정해야 할까요? “심미적 매핑, aes() 내부”라고 추측했다면 이미 ggplot2로 데이터 시각화를 만드는 요령을 터득한 것입니다! 그렇지 않더라도 걱정하지 마세요. 책 전체에 걸쳐 더 많은 ggplot을 만들고 만들면서 직관을 확인할 기회가 훨씬 더 많을 것입니다.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point()\n\n\n\n\n\n\n\n범주형 변수가 심미성에 매핑되면 ggplot2는 자동으로 변수의 각 고유 수준(세 종 각각)에 심미성의 고유 값(여기서는 고유 색상)을 할당하는데, 이 과정을 스케일링(scaling) 이라고 합니다. 또한 ggplot2는 어떤 값이 어떤 수준에 해당하는지 설명하는 범례를 추가합니다.\n이제 레이어를 하나 더 추가해 봅시다: 체중과 지느러미 길이 사이의 관계를 보여주는 매끄러운 곡선입니다. 진행하기 전에 위의 코드를 다시 참조하고 기존 플롯에 이것을 어떻게 추가할 수 있을지 생각해 보세요.\n이것은 데이터를 나타내는 새로운 기하학적 객체이므로 점 지옴 위에 레이어로 새로운 지옴인 geom_smooth()를 추가할 것입니다. 그리고 method = \"lm\"을 사용하여 선형 모형(linear model)에 기반한 최적 적합선을 그리도록 지정할 것입니다.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n성공적으로 선을 추가했지만, 이 플롯은 각 펭귄 종에 대해 별도의 선이 있는 것이 아니라 전체 데이터셋에 대해 하나의 선만 있는 Section 1.2.2 의 플롯과 같아 보이지 않습니다.\n심미적 매핑이 ggplot()에서 전역(global) 수준으로 정의되면 플롯의 후속 지옴 레이어 각각에 전달됩니다. 그러나 ggplot2의 각 지옴 함수는 mapping 인수를 취할 수 있으며, 이를 통해 전역 수준에서 상속된 것에 추가되는 로컬(local) 수준의 심미적 매핑을 허용합니다. 점은 종에 따라 색상을 지정하고 싶지만 선은 분리하고 싶지 않으므로 geom_point()에만 color = species를 지정해야 합니다.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n짠! 우리의 최종 목표와 매우 비슷해 보이는 것이 생겼지만, 아직 완벽하지는 않습니다. 여전히 각 펭귄 종에 대해 다른 모양을 사용하고 레이블을 개선해야 합니다.\n색맹이나 기타 색각 차이로 인해 사람들이 색을 다르게 인식하므로 플롯에서 색상만 사용하여 정보를 표현하는 것은 일반적으로 좋은 생각이 아닙니다. 따라서 색상 외에도 species를 shape 심미성에 매핑할 수 있습니다.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n범례가 점의 다른 모양도 반영하도록 자동으로 업데이트된다는 점에 유의하세요.\n그리고 마지막으로, 새로운 레이어에서 labs() 함수를 사용하여 플롯의 레이블을 개선할 수 있습니다. labs()의 인수 중 일부는 설명이 필요 없을 수 있습니다: title은 제목을 추가하고 subtitle은 플롯에 부제를 추가합니다. 다른 인수들은 심미적 매핑과 일치합니다. x는 x축 레이블, y는 y축 레이블, color와 shape는 범례의 레이블을 정의합니다. 또한 ggthemes 패키지의 scale_color_colorblind() 함수를 사용하여 색맹에 안전하도록 색상 팔레트를 개선할 수 있습니다.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Body mass and flipper length\",\n    subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Flipper length (mm)\", y = \"Body mass (g)\",\n    color = \"Species\", shape = \"Species\"\n  ) +\n  scale_color_colorblind()\n\n\n\n\n\n\n\n드디어 우리의 “최종 목표”와 완벽하게 일치하는 플롯을 갖게 되었습니다!\n\n1.2.5 연습문제\n\npenguins에는 몇 개의 행이 있습니까? 열은 몇 개입니까?\npenguins 데이터 프레임의 bill_depth_mm 변수는 무엇을 설명합니까? ?penguins 도움말을 읽고 확인하세요.\nbill_depth_mm 대 bill_length_mm의 산점도를 만드세요. 즉, y축에 bill_depth_mm, x축에 bill_length_mm가 있는 산점도를 만드세요. 이 두 변수 사이의 관계를 설명하세요.\nspecies 대 bill_depth_mm의 산점도를 만들면 어떻게 됩니까? 더 나은 지옴 선택은 무엇일까요?\n\n다음이 오류를 발생시키는 이유는 무엇이며 어떻게 수정하겠습니까?\n\nggplot(data = penguins) + \n  geom_point()\n\n\ngeom_point()에서 na.rm 인수는 무엇을 합니까? 인수의 기본값은 무엇입니까? 이 인수를 TRUE로 설정하여 성공적으로 사용하는 산점도를 만드세요.\n이전 연습문제에서 만든 플롯에 다음 캡션을 추가하세요: “Data come from the palmerpenguins package.” 힌트: labs() 문서를 살펴보세요.\n\n다음 시각화를 재현하세요. bill_depth_mm은 어떤 심미성에 매핑되어야 합니까? 그리고 전역 수준에서 매핑되어야 할까요, 아니면 지옴 수준에서 매핑되어야 할까요?\n\n\n\n\n\n\n\n\n\n\n이 코드를 머릿속으로 실행하고 출력이 어떻게 보일지 예측해 보세요. 그런 다음 R에서 코드를 실행하고 예측을 확인하세요.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = island)\n) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n이 두 그래프는 다르게 보일까요? 왜 그렇습니까/그렇지 않습니까?\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point() +\n  geom_smooth()\n\nggplot() +\n  geom_point(\n    data = penguins,\n    mapping = aes(x = flipper_length_mm, y = body_mass_g)\n  ) +\n  geom_smooth(\n    data = penguins,\n    mapping = aes(x = flipper_length_mm, y = body_mass_g)\n  )",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggplot2-calls",
    "href": "data-visualize.html#sec-ggplot2-calls",
    "title": "1  데이터 시각화",
    "section": "\n1.3 ggplot2 호출",
    "text": "1.3 ggplot2 호출\n이러한 소개 섹션에서 벗어나면서 ggplot2 코드를 더 간결하게 표현하는 방법으로 전환할 것입니다. 지금까지 우리는 매우 명시적이었으며, 이는 배울 때 도움이 됩니다:\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n\n일반적으로 함수의 처음 한두 인수는 매우 중요해서 외워두는 것이 좋습니다. ggplot()의 처음 두 인수는 data와 mapping이며, 책의 나머지 부분에서는 이 이름들을 제공하지 않을 것입니다. 이렇게 하면 타이핑을 줄이고, 추가 텍스트의 양을 줄여서 플롯 간의 차이점을 더 쉽게 볼 수 있습니다. 이것은 Chapter 25 에서 다시 다룰 정말 중요한 프로그래밍 고려 사항입니다.\n이전 플롯을 더 간결하게 다시 작성하면 다음과 같습니다:\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()\n\n나중에 파이프 |&gt;에 대해 배우게 될 텐데, 이를 사용하면 다음과 같이 플롯을 만들 수 있습니다:\n\npenguins |&gt; \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#분포-시각화",
    "href": "data-visualize.html#분포-시각화",
    "title": "1  데이터 시각화",
    "section": "\n1.4 분포 시각화",
    "text": "1.4 분포 시각화\n변수의 분포를 시각화하는 방법은 변수의 유형(범주형 또는 수치형)에 따라 다릅니다.\n\n1.4.1 범주형 변수\n변수가 작은 집합의 값 중 하나만 취할 수 있는 경우 범주형(categorical) 입니다. 범주형 변수의 분포를 조사하려면 막대 차트를 사용할 수 있습니다. 막대의 높이는 각 x 값에서 얼마나 많은 관측값이 발생했는지 보여줍니다.\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\n\n\n\n위의 펭귄 species와 같이 순서가 없는 수준을 가진 범주형 변수의 막대 플롯에서는 빈도에 따라 막대를 재정렬하는 것이 바람직한 경우가 많습니다. 그렇게 하려면 변수를 팩터(R이 범주형 데이터를 처리하는 방식)로 변환한 다음 해당 팩터의 수준을 재정렬해야 합니다.\n\nggplot(penguins, aes(x = fct_infreq(species))) +\n  geom_bar()\n\n\n\n\n\n\n\nChapter 16 에서 팩터와 팩터를 다루는 함수(위에 표시된 fct_infreq() 등)에 대해 더 자세히 배우게 될 것입니다.\n\n1.4.2 수치형 변수\n변수가 광범위한 수치 값을 취할 수 있고 그 값으로 더하기, 빼기 또는 평균을 구하는 것이 합리적이라면 수치형(numerical) (또는 양적)입니다. 수치형 변수는 연속적이거나 이산적일 수 있습니다.\n연속형 변수의 분포에 흔히 사용되는 시각화 중 하나는 히스토그램입니다.\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 200)\n\n\n\n\n\n\n\n히스토그램은 x축을 등간격의 구간(bin)으로 나눈 다음 막대의 높이를 사용하여 각 구간에 속하는 관측값의 수를 표시합니다. 위의 그래프에서 가장 높은 막대는 39개의 관측값이 3,500에서 3,700그램 사이의 body_mass_g 값을 가짐을 보여주며, 이는 막대의 왼쪽과 오른쪽 가장자리입니다.\nbinwidth 인수를 사용하여 히스토그램의 간격 너비를 설정할 수 있으며, 이는 x 변수의 단위로 측정됩니다. 히스토그램으로 작업할 때는 항상 다양한 구간 너비를 탐색해야 합니다. 구간 너비가 다르면 다른 패턴이 드러날 수 있기 때문입니다. 아래 플롯에서 구간 너비 20은 너무 좁아서 막대가 너무 많아져 분포의 모양을 파악하기 어렵습니다. 마찬가지로 구간 너비 2,000은 너무 커서 모든 데이터가 단 3개의 막대로 묶여 버려, 역시 분포의 모양을 파악하기 어렵게 만듭니다. 구간 너비 200은 합리적인 균형을 제공합니다.\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 20)\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 2000)\n\n\n\n\n\n\n\n\n\n\n수치형 변수의 분포에 대한 대안적인 시각화는 밀도 플롯(density plot)입니다. 밀도 플롯은 히스토그램을 부드럽게 만든 버전이며, 특히 근본적으로 매끄러운 분포에서 나온 연속형 데이터에 실용적인 대안입니다. geom_density()가 밀도를 어떻게 추정하는지에 대해서는 자세히 설명하지 않겠지만(함수 문서에서 자세한 내용을 읽을 수 있습니다), 유추를 통해 밀도 곡선이 어떻게 그려지는지 설명해 보겠습니다. 나무 블록으로 만든 히스토그램을 상상해 보세요. 그런 다음 익힌 스파게티 면을 그 위에 떨어뜨린다고 상상해 보세요. 블록 위에 늘어진 스파게티가 취하는 모양을 밀도 곡선의 모양이라고 생각할 수 있습니다. 히스토그램보다 세부 사항은 적게 보여주지만 분포의 모양, 특히 최빈값과 왜도(skewness)와 관련하여 빠르게 파악하기 쉽게 해줍니다.\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_density()\n#&gt; Warning: Removed 2 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\n\n1.4.3 연습문제\n\npenguins의 species에 대한 막대 플롯을 만드는데, species를 y 심미성에 할당하세요. 이 플롯은 어떻게 다릅니까?\n\n다음 두 플롯은 어떻게 다릅니까? 막대의 색상을 변경하는 데 color와 fill 중 어떤 심미성이 더 유용합니까?\n\nggplot(penguins, aes(x = species)) +\n  geom_bar(color = \"red\")\n\nggplot(penguins, aes(x = species)) +\n  geom_bar(fill = \"red\")\n\n\ngeom_histogram()에서 bins 인수는 무엇을 합니까?\ntidyverse 패키지를 로드할 때 사용할 수 있는 diamonds 데이터셋의 carat 변수에 대한 히스토그램을 만드세요. 다양한 구간 너비로 실험해 보세요. 어떤 구간 너비가 가장 흥미로운 패턴을 보여줍니까?",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#관계-시각화",
    "href": "data-visualize.html#관계-시각화",
    "title": "1  데이터 시각화",
    "section": "\n1.5 관계 시각화",
    "text": "1.5 관계 시각화\n관계를 시각화하려면 플롯의 심미성에 매핑된 변수가 적어도 두 개 있어야 합니다. 다음 섹션에서는 두 개 이상의 변수 간의 관계를 시각화하는 데 일반적으로 사용되는 플롯과 이를 생성하는 데 사용되는 지옴에 대해 배울 것입니다.\n\n1.5.1 수치형 변수와 범주형 변수\n수치형 변수와 범주형 변수 간의 관계를 시각화하기 위해 나란히 놓인 상자 그림(side-by-side box plots)을 사용할 수 있습니다. 상자 그림(boxplot) 은 분포를 설명하는 위치 측도(백분위수)에 대한 일종의 시각적 속기입니다. 잠재적인 이상치(outliers)를 식별하는 데도 유용합니다. Figure 1.1 에 표시된 것처럼 각 상자 그림은 다음으로 구성됩니다:\n\n데이터의 중간 절반의 범위, 즉 사분위수 범위(IQR)로 알려진 거리를 나타내는 상자로, 분포의 25번째 백분위수에서 75번째 백분위수까지 뻗어 있습니다. 상자 가운데에는 분포의 중앙값, 즉 50번째 백분위수를 표시하는 선이 있습니다. 이 세 선은 분포의 퍼짐 정도와 분포가 중앙값을 중심으로 대칭인지 아니면 한쪽으로 치우쳐 있는지에 대한 감을 줍니다.\n상자의 가장자리에서 1.5배의 IQR보다 더 멀리 떨어진 관측값을 표시하는 시각적 점들입니다. 이러한 이상 점들은 특이하므로 개별적으로 플롯됩니다.\n상자의 각 끝에서 뻗어 나와 분포에서 이상치가 아닌 가장 먼 지점까지 가는 선(또는 수염)입니다.\n\n\n\n\n\n\n\n\nFigure 1.1: 상자 그림이 생성되는 방식을 묘사한 다이어그램.\n\n\n\n\ngeom_boxplot()을 사용하여 종별 체중 분포를 살펴봅시다:\n\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n대안으로 geom_density()를 사용하여 밀도 플롯을 만들 수 있습니다.\n\nggplot(penguins, aes(x = body_mass_g, color = species)) +\n  geom_density(linewidth = 0.75)\n\n\n\n\n\n\n\n배경에 비해 좀 더 눈에 띄게 만들기 위해 linewidth 인수를 사용하여 선의 두께를 사용자 지정했습니다.\n또한 species를 color와 fill 심미성 모두에 매핑하고 alpha 심미성을 사용하여 채워진 밀도 곡선에 투명도를 추가할 수 있습니다. 이 심미성은 0(완전 투명)에서 1(완전 불투명) 사이의 값을 취합니다. 다음 플롯에서는 0.5로 설정 되어 있습니다.\n\nggplot(penguins, aes(x = body_mass_g, color = species, fill = species)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n여기서 사용한 용어에 유의하세요:\n\n시각적 속성이 변수의 값에 따라 달라지게 하려면 변수를 심미성에 매핑 합니다.\n그렇지 않은 경우 심미성의 값을 설정 합니다.\n\n1.5.2 두 개의 범주형 변수\n누적 막대 플롯을 사용하여 두 범주형 변수 간의 관계를 시각화할 수 있습니다. 예를 들어, 다음 두 개의 누적 막대 플롯은 모두 island와 species 간의 관계를 표시하거나, 구체적으로 각 섬 내에서 species의 분포를 시각화합니다.\n첫 번째 플롯은 각 섬에 있는 각 펭귄 종의 빈도를 보여줍니다. 빈도 플롯은 각 섬에 같은 수의 Adelie가 있음을 보여줍니다. 하지만 각 섬 내의 백분율 균형에 대한 좋은 감은 얻을 수 없습니다.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar()\n\n\n\n\n\n\n\n지옴에서 position = \"fill\"을 설정하여 생성된 상대 빈도 플롯인 두 번째 플롯은 섬 전체의 펭귄 수가 동일하지 않은 영향을 받지 않으므로 섬 전체의 종 분포를 비교하는 데 더 유용합니다. 이 플롯을 사용하면 Gentoo 펭귄은 모두 Biscoe 섬에 살고 해당 섬 펭귄의 약 75%를 차지하며, Chinstrap은 모두 Dream 섬에 살고 해당 섬 펭귄의 약 50%를 차지하며, Adelie는 세 섬 모두에 살고 Torgersen 섬 펭귄의 전체를 차지한다는 것을 알 수 있습니다.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n이러한 막대 차트를 만들 때 막대로 구분될 변수를 x 심미성에 매핑하고, 막대 내부의 색상을 변경할 변수를 fill 심미성에 매핑합니다. 불행히도 ggplot2는 y축에 기본적으로 \"count\"라고 레이블을 지정하지만, 이는 y축 레이블을 \"proportion\"으로 지정하는 labs() 레이어를 추가하여 재정의할 수 있는 부분입니다.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  labs(y = \"proportion\")\n\n\n\n\n\n\n\n\n1.5.3 두 개의 수치형 변수\n지금까지 두 수치형 변수 간의 관계를 시각화하기 위해 산점도(geom_point()로 생성)와 매끄러운 곡선(geom_smooth()로 생성)에 대해 배웠습니다. 산점도는 아마도 두 수치형 변수 간의 관계를 시각화하는 데 가장 일반적으로 사용되는 플롯일 것입니다.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\n\n\n\n\n\n\n1.5.4 세 개 이상의 변수\nSection 1.2.4 에서 보았듯이, 추가 심미성에 변수를 매핑하여 플롯에 더 많은 변수를 통합할 수 있습니다. 예를 들어, 다음 산점도에서 점의 색상은 종을 나타내고 점의 모양은 섬을 나타냅니다.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = island))\n\n\n\n\n\n\n\n그러나 플롯에 심미적 매핑을 너무 많이 추가하면 어수선해지고 이해하기 어려워집니다. 특히 범주형 변수에 유용한 또 다른 방법은 플롯을 패싯(facets), 즉 데이터의 각 하위 집합을 표시하는 하위 플롯으로 나누는 것입니다.\n단일 변수로 플롯을 패싯하려면 facet_wrap()을 사용하세요. facet_wrap()의 첫 번째 인수는 공식(formula)3으로, ~ 뒤에 변수 이름을 붙여 생성합니다. facet_wrap()에 전달하는 변수는 범주형이어야 합니다.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species)) +\n  facet_wrap(~island)\n\n\n\n\n\n\n\nChapter 9 에서 변수의 분포와 변수 간의 관계를 시각화하기 위한 다른 많은 지옴에 대해 배울 것입니다.\n\n1.5.5 연습문제\n\nggplot2 패키지에 번들로 제공되는 mpg 데이터 프레임에는 38개의 자동차 모델에 대해 미국 환경 보호국이 수집한 234개의 관측값이 포함되어 있습니다. mpg의 어떤 변수가 범주형입니까? 어떤 변수가 수치형입니까? (힌트: 데이터셋에 대한 문서를 읽으려면 ?mpg를 입력하세요.) mpg를 실행할 때 이 정보를 어떻게 볼 수 있습니까?\nmpg 데이터 프레임을 사용하여 hwy 대 displ의 산점도를 만드세요. 다음으로, 세 번째 수치형 변수를 color에 매핑하고, 그 다음엔 size에, 그 다음엔 color와 size 모두에, 그 다음엔 shape에 매핑하세요. 이러한 심미성은 범주형 변수와 수치형 변수에 대해 어떻게 다르게 작동합니까?\nhwy 대 displ의 산점도에서 세 번째 변수를 linewidth에 매핑하면 어떻게 됩니까?\n동일한 변수를 여러 심미성에 매핑하면 어떻게 됩니까?\nbill_depth_mm 대 bill_length_mm의 산점도를 만들고 species로 점의 색을 지정하세요. 종별로 색상을 추가하면 이 두 변수 간의 관계에 대해 무엇이 드러납니까? species로 패싯하는 것은 어떻습니까?\n\n다음이 두 개의 별도 범례를 생성하는 이유는 무엇입니까? 두 범례를 결합하려면 어떻게 수정해야 합니까?\n\nggplot(\n  data = penguins,\n  mapping = aes(\n    x = bill_length_mm, y = bill_depth_mm, \n    color = species, shape = species\n  )\n) +\n  geom_point() +\n  labs(color = \"Species\")\n\n\n\n다음 두 개의 누적 막대 플롯을 만드세요. 첫 번째 플롯으로 어떤 질문에 답할 수 있습니까? 두 번째 플롯으로 어떤 질문에 답할 수 있습니까?\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\")\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar(position = \"fill\")",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggsave",
    "href": "data-visualize.html#sec-ggsave",
    "title": "1  데이터 시각화",
    "section": "\n1.6 플롯 저장하기",
    "text": "1.6 플롯 저장하기\n플롯을 만든 후에는 다른 곳에서 사용할 수 있도록 이미지로 저장하여 R에서 내보내고 싶을 수 있습니다. 그것이 ggsave()의 역할이며, 가장 최근에 생성된 플롯을 디스크에 저장합니다:\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\nggsave(filename = \"penguin-plot.png\")\n\n이렇게 하면 플롯이 작업 디렉터리에 저장되는데, 작업 디렉터리라는 개념은 Chapter 6 에서 더 자세히 배울 것입니다.\nwidth와 height를 지정하지 않으면 현재 플롯 장치의 치수에서 가져옵니다. 재현 가능한 코드를 위해서는 지정하는 것이 좋습니다. 설명서에서 ggsave()에 대해 더 자세히 알아볼 수 있습니다.\n그러나 일반적으로는 코드와 산문을 섞어서 작성하고 플롯을 자동으로 포함할 수 있는 재현 가능한 저작 시스템인 Quarto를 사용하여 최종 보고서를 작성하는 것을 권장합니다. Quarto에 대해서는 Chapter 28 에서 더 자세히 배울 것입니다.\n\n1.6.1 연습문제\n\n\n다음 코드 줄을 실행하세요. 두 플롯 중 어느 것이 mpg-plot.png로 저장됩니까? 그 이유는 무엇입니까?\n\nggplot(mpg, aes(x = class)) +\n  geom_bar()\nggplot(mpg, aes(x = cty, y = hwy)) +\n  geom_point()\nggsave(\"mpg-plot.png\")\n\n\n위의 코드에서 플롯을 PNG 대신 PDF로 저장하려면 무엇을 변경해야 합니까? ggsave()에서 어떤 유형의 이미지 파일이 작동하는지 어떻게 알 수 있습니까?",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#일반적인-문제",
    "href": "data-visualize.html#일반적인-문제",
    "title": "1  데이터 시각화",
    "section": "\n1.7 일반적인 문제",
    "text": "1.7 일반적인 문제\nR 코드를 실행하기 시작하면 문제에 부딪힐 가능성이 큽니다. 걱정하지 마세요. 누구에게나 일어나는 일입니다. 우리 모두 수년 동안 R 코드를 작성해 왔지만, 매일 첫 시도에 작동하지 않는 코드를 여전히 작성합니다!\n실행 중인 코드를 책의 코드와 주의 깊게 비교하는 것으로 시작하세요. R은 매우 까다로워서 문자가 잘못된 위치에 있으면 큰 차이가 날 수 있습니다. 모든 (가 )와 짝이 맞는지, 모든 \"가 다른 \"와 짝이 맞는지 확인하세요. 때로는 코드를 실행해도 아무 일도 일어나지 않을 수 있습니다. 콘솔 왼쪽을 확인하세요. +가 보이면 R이 완전한 표현식을 입력하지 않았다고 생각하고 완료하기를 기다리고 있다는 의미입니다. 이 경우 일반적으로 ESCAPE를 눌러 현재 명령 처리를 중단하고 처음부터 다시 시작하는 것이 쉽습니다.\nggplot2 그래픽을 만들 때 흔히 발생하는 문제 중 하나는 +를 잘못된 위치에 두는 것입니다. +는 줄의 시작이 아니라 끝에 와야 합니다. 즉, 실수로 다음과 같이 코드를 작성하지 않았는지 확인하세요:\n\nggplot(data = mpg) \n+ geom_point(mapping = aes(x = displ, y = hwy))\n\n여전히 막힌다면 도움말을 시도해 보세요. 콘솔에서 ?function_name을 실행하거나 RStudio에서 함수 이름을 강조 표시하고 F1을 눌러 모든 R 함수에 대한 도움말을 얻을 수 있습니다. 도움말이 별로 도움이 되지 않는 것 같더라도 걱정하지 마세요. 대신 예제로 건너뛰어 시도하려는 것과 일치하는 코드를 찾아보세요.\n그래도 해결되지 않으면 오류 메시지를 주의 깊게 읽으세요. 때로는 답이 거기에 묻혀 있을 수 있습니다! 하지만 R을 처음 접하는 경우 답이 오류 메시지에 있더라도 아직 이해하는 방법을 모를 수 있습니다. 또 다른 훌륭한 도구는 Google입니다. 오류 메시지를 구글링해 보세요. 다른 누군가가 같은 문제를 겪었고 온라인에서 도움을 받았을 가능성이 큽니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#요약",
    "href": "data-visualize.html#요약",
    "title": "1  데이터 시각화",
    "section": "\n1.8 요약",
    "text": "1.8 요약\n이 장에서는 ggplot2를 사용한 데이터 시각화의 기본 사항을 배웠습니다. 우리는 ggplot2를 뒷받침하는 기본 아이디어인 시각화는 데이터의 변수에서 위치, 색상, 크기 및 모양과 같은 심미적 속성으로의 매핑이라는 것으로 시작했습니다. 그런 다음 레이어별로 플롯의 복잡성을 높이고 표현을 개선하는 것에 대해 배웠습니다. 또한 추가 심미적 매핑을 활용하거나 패싯을 사용하여 플롯을 작은 다중으로 분할함으로써 단일 변수의 분포를 시각화하고 두 개 이상의 변수 간의 관계를 시각화하는 데 일반적으로 사용되는 플롯에 대해 배웠습니다.\n이 책 전체에서 시각화를 계속해서 사용할 것이며, 필요에 따라 새로운 기술을 소개하고 Chapter 9 부터 Chapter 11 까지 ggplot2로 시각화를 만드는 것에 대해 더 깊이 다룰 것입니다.\n시각화의 기초를 익혔으므로 다음 장에서는 기어를 조금 바꿔서 실용적인 워크플로우 조언을 제공할 것입니다. 이 책의 이 파트 전반에 걸쳐 데이터 과학 도구와 함께 워크플로우 조언을 섞어서 제공하는 이유는 R 코드의 양이 늘어남에 따라 체계적으로 유지하는 데 도움이 되기 때문입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#footnotes",
    "href": "data-visualize.html#footnotes",
    "title": "1  데이터 시각화",
    "section": "",
    "text": "conflicted 패키지를 사용하여 해당 메시지를 없애고 충돌 해결을 필요할 때 강제하도록 할 수 있습니다. 이는 더 많은 패키지를 로드할수록 중요해집니다. conflicted에 대한 자세한 내용은 https://conflicted.r-lib.org에서 확인할 수 있습니다.↩︎\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.↩︎\n여기서 “공식”은 “방정식”의 동의어가 아니라 ~로 생성된 것의 이름입니다.↩︎",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>데이터 시각화</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html",
    "href": "workflow-basics.html",
    "title": "2  워크플로우: 기초",
    "section": "",
    "text": "2.1 코딩 기초\n이제 R 코드를 실행하는 경험을 조금 해보셨을 겁니다. 자세한 내용은 많이 알려드리지 않았지만, 기본은 확실히 파악하셨거나, 아니면 좌절해서 이 책을 던져버렸을 수도 있겠네요! R 프로그래밍을 시작할 때 좌절하는 것은 자연스러운 일입니다. R은 구두점에 매우 엄격해서 문자 하나만 틀려도 불평을 쏟아내기 때문입니다. 하지만 조금 좌절할 것을 예상해야 하지만, 이러한 경험은 일반적이고 일시적이라는 점에 위안을 삼으세요. 누구에게나 일어나는 일이며, 극복하는 유일한 방법은 계속 시도하는 것입니다.\n더 진행하기 전에, R 코드를 실행하는 탄탄한 기초를 갖추었는지, 그리고 가장 유용한 RStudio 기능 중 일부를 알고 있는지 확인해 봅시다.\n가능한 한 빨리 플롯을 그리게 하기 위해 생략했던 몇 가지 기초를 검토해 봅시다. R을 사용하여 기본적인 수학 계산을 할 수 있습니다:\n1 / 200 * 30\n#&gt; [1] 0.15\n(59 + 73 + 2) / 3\n#&gt; [1] 44.66667\nsin(pi / 2)\n#&gt; [1] 1\n할당 연산자 &lt;-를 사용하여 새 객체를 만들 수 있습니다:\nx &lt;- 3 * 4\nx의 값은 출력되지 않고 저장만 된다는 점에 유의하세요. 값을 보려면 콘솔에 x를 입력하세요.\nc()를 사용하여 여러 요소를 벡터로 결합(combine) 할 수 있습니다:\nprimes &lt;- c(2, 3, 5, 7, 11, 13)\n그리고 벡터에 대한 기본 산술 연산은 벡터의 모든 요소에 적용됩니다:\nprimes * 2\n#&gt; [1]  4  6 10 14 22 26\nprimes - 1\n#&gt; [1]  1  2  4  6 10 12\n객체를 생성하는 모든 R 구문, 즉 할당(assignment) 구문은 동일한 형식을 갖습니다:\nobject_name &lt;- value\n이 코드를 읽을 때는 머릿속으로 “객체 이름이 값을 얻는다(gets)”라고 말하세요.\n많은 할당을 하게 될 텐데, &lt;-는 타이핑하기 귀찮습니다. RStudio의 키보드 단축키인 Alt + - (빼기 기호)를 사용하면 시간을 절약할 수 있습니다. RStudio가 자동으로 &lt;- 주위에 공백을 넣는데, 이는 좋은 코드 서식 관행입니다. 코드는 좋은 날에도 읽기 끔찍할 수 있으니, 눈을쉬게해주고 공백을 사용하세요.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>워크플로우: 기초</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#주석",
    "href": "workflow-basics.html#주석",
    "title": "2  워크플로우: 기초",
    "section": "\n2.2 주석",
    "text": "2.2 주석\nR은 해당 줄의 # 뒤에 있는 모든 텍스트를 무시합니다. 이를 통해 주석(comments), 즉 R은 무시하지만 다른 사람은 읽을 수 있는 텍스트를 작성할 수 있습니다. 때때로 코드에서 무슨 일이 일어나고 있는지 설명하는 주석을 예제에 포함할 것입니다.\n주석은 다음 코드가 수행하는 작업을 간략하게 설명하는 데 도움이 될 수 있습니다.\n\n# 소수 벡터 생성\nprimes &lt;- c(2, 3, 5, 7, 11, 13)\n\n# 소수에 2를 곱함\nprimes * 2\n#&gt; [1]  4  6 10 14 22 26\n\n이런 짧은 코드 조각의 경우, 코드 한 줄 한 줄마다 주석을 남길 필요는 없을 수 있습니다. 하지만 작성하는 코드가 더 복잡해짐에 따라, 주석은 여러분(과 여러분의 협업자)이 코드에서 수행된 작업을 파악하는 데 많은 시간을 절약해 줄 수 있습니다.\n주석을 사용하여 코드의 방법이나 무엇이 아니라 이유를 설명하세요. 코드의 무엇과 방법은, 비록 지루할지라도 주의 깊게 읽으면 항상 파악할 수 있습니다. 모든 단계를 주석에 설명하고 나중에 코드를 변경하면, 주석도 업데이트해야 한다는 것을 기억해야 합니다. 그렇지 않으면 나중에 코드로 돌아왔을 때 혼란스러울 것입니다.\n어떤 일이 왜 수행되었는지 파악하는 것은 불가능하지는 않더라도 훨씬 더 어렵습니다. 예를 들어, geom_smooth()에는 곡선의 부드러움을 제어하는 span이라는 인수가 있으며, 값이 클수록 더 부드러운 곡선이 생성됩니다. span 값을 기본값 0.75에서 0.9로 변경하기로 결정했다고 가정해 봅시다. 미래의 독자가 무엇이 일어나고 있는지 이해하기는 쉽지만, 주석에 생각을 적어두지 않으면 아무도 왜 기본값을 변경했는지 이해하지 못할 것입니다.\n데이터 분석 코드의 경우, 주석을 사용하여 전반적인 공격 계획을 설명하고 중요한 통찰력을 발견했을 때 기록하세요. 코드 자체에서 이러한 지식을 다시 포착할 수 있는 방법은 없습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>워크플로우: 기초</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#sec-whats-in-a-name",
    "href": "workflow-basics.html#sec-whats-in-a-name",
    "title": "2  워크플로우: 기초",
    "section": "\n2.3 이름에는 무엇이 들어 있나요?",
    "text": "2.3 이름에는 무엇이 들어 있나요?\n객체 이름은 문자로 시작해야 하며 문자, 숫자, _, .만 포함할 수 있습니다. 객체 이름이 서술적이기를 원하므로 여러 단어에 대한 규칙을 채택해야 합니다. 소문자 단어를 _로 구분하는 스네이크 케이스(snake_case) 를 권장합니다.\n\ni_use_snake_case\notherPeopleUseCamelCase\nsome.people.use.periods\nAnd_aFew.People_RENOUNCEconvention\n\n코드 스타일을 논의할 때 Chapter 4 에서 이름에 대해 다시 다룰 것입니다.\n객체 이름을 입력하여 객체를 검사할 수 있습니다:\n\nx\n#&gt; [1] 12\n\n또 다른 할당을 해봅시다:\n\nthis_is_a_really_long_name &lt;- 2.5\n\n이 객체를 검사하려면 RStudio의 자동 완성 기능을 사용해 보세요. “this”를 입력하고 TAB을 누른 다음, 고유한 접두사가 될 때까지 문자를 추가하고 엔터를 누르세요.\n실수를 했고 this_is_a_really_long_name의 값이 2.5가 아니라 3.5여야 한다고 가정해 봅시다. 또 다른 키보드 단축키를 사용하여 수정할 수 있습니다. 예를 들어 ↑를 눌러 마지막으로 입력한 명령을 불러와 편집할 수 있습니다. 또는 “this”를 입력한 다음 Cmd/Ctrl + ↑를 눌러 해당 문자로 시작하는 입력한 모든 명령을 나열합니다. 화살표 키를 사용하여 탐색한 다음 엔터를 눌러 명령을 다시 입력하세요. 2.5를 3.5로 변경하고 다시 실행하세요.\n또 다른 할당을 해봅시다:\n\nr_rocks &lt;- 2^3\n\n검사해 봅시다:\n\nr_rock\n#&gt; Error: object 'r_rock' not found\nR_rocks\n#&gt; Error: object 'R_rocks' not found\n\n이것은 여러분과 R 사이의 암시적 계약을 보여줍니다. R은 지루한 계산을 대신 해주지만, 그 대가로 여러분은 지시사항을 완전히 정확하게 전달해야 합니다. 그렇지 않으면 찾고 있는 객체를 찾을 수 없다는 오류가 발생할 가능성이 큽니다. 오타는 중요합니다. R은 여러분의 마음을 읽고 “r_rock을 입력했을 때 아마 r_rocks를 의미했을 거야”라고 말할 수 없습니다. 대소문자는 중요합니다. 마찬가지로 R은 여러분의 마음을 읽고 “R_rocks를 입력했을 때 아마 r_rocks를 의미했을 거야”라고 말할 수 없습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>워크플로우: 기초</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#함수-호출",
    "href": "workflow-basics.html#함수-호출",
    "title": "2  워크플로우: 기초",
    "section": "\n2.4 함수 호출",
    "text": "2.4 함수 호출\nR에는 다음과 같이 호출되는 방대한 내장 함수 모음이 있습니다:\n\nfunction_name(argument1 = value1, argument2 = value2, ...)\n\n숫자의 정규 시퀀스(sequences) 를 만드는 seq()를 사용해 보고, RStudio의 더 유용한 기능을 알아봅시다. se를 입력하고 TAB을 누르세요. 팝업에 가능한 완성 목록이 표시됩니다. 더 입력(q)하여 명확히 하거나 ↑/↓ 화살표를 사용하여 선택하여 seq()를 지정하세요. 함수의 인수와 목적을 상기시켜주는 팝업 도구 설명을 주목하세요. 더 많은 도움이 필요하면 F1을 눌러 오른쪽 아래 창의 도움말 탭에서 모든 세부 정보를 확인하세요.\n원하는 함수를 선택했으면 TAB을 다시 누르세요. RStudio가 짝이 맞는 여는 괄호(()와 닫는 괄호())를 추가해 줍니다. 첫 번째 인수의 이름인 from을 입력하고 1로 설정하세요. 그런 다음 두 번째 인수의 이름인 to를 입력하고 10으로 설정하세요. 마지막으로 엔터를 치세요.\n\nseq(from = 1, to = 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\n우리는 종종 함수 호출에서 처음 몇 개의 인수 이름을 생략하므로, 다음과 같이 다시 쓸 수 있습니다:\n\nseq(1, 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\n다음 코드를 입력하고 RStudio가 짝이 맞는 따옴표로 비슷한 도움을 제공한다는 것을 확인하세요:\n\nx &lt;- \"hello world\"\n\n따옴표와 괄호는 항상 쌍으로 와야 합니다. RStudio가 최선을 다해 도와주지만, 여전히 엉망이 되어 불일치가 발생할 수 있습니다. 이 경우 R은 연속 문자 “+”를 보여줍니다:\n&gt; x &lt;- \"hello\n+\n+는 R이 더 많은 입력을 기다리고 있음을 알려줍니다. 아직 완료되지 않았다고 생각하는 것입니다. 일반적으로 이는 \"나 ) 중 하나를 잊어버렸음을 의미합니다. 누락된 쌍을 추가하거나 ESCAPE를 눌러 표현식을 중단하고 다시 시도하세요.\n오른쪽 상단 창의 환경 탭에는 생성한 모든 객체가 표시됩니다:",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>워크플로우: 기초</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#연습문제",
    "href": "workflow-basics.html#연습문제",
    "title": "2  워크플로우: 기초",
    "section": "\n2.5 연습문제",
    "text": "2.5 연습문제\n\n\n이 코드가 작동하지 않는 이유는 무엇입니까?\n\nmy_variable &lt;- 10\nmy_varıable\n#&gt; Error: object 'my_varıable' not found\n\n주의 깊게 보세요! (무의미한 연습처럼 보일 수 있지만, 아주 작은 차이도 알아차리도록 뇌를 훈련하는 것은 프로그래밍할 때 큰 도움이 될 것입니다.)\n\n\n다음 R 명령을 각각 올바르게 실행되도록 수정하세요:\n\nlibary(todyverse)\n\nggplot(dTA = mpg) + \n  geom_point(maping = aes(x = displ y = hwy)) +\n  geom_smooth(method = \"lm)\n\n\nOption + Shift + K / Alt + Shift + K를 누르세요. 어떤 일이 일어납니까? 메뉴를 사용하여 같은 곳으로 이동하려면 어떻게 해야 합니까?\n\nSection 1.6 의 연습문제를 다시 살펴봅시다. 다음 코드 줄을 실행하세요. 두 플롯 중 어느 것이 mpg-plot.png로 저장됩니까? 그 이유는 무엇입니까?\n\nmy_bar_plot &lt;- ggplot(mpg, aes(x = class)) +\n  geom_bar()\nmy_scatter_plot &lt;- ggplot(mpg, aes(x = cty, y = hwy)) +\n  geom_point()\nggsave(filename = \"mpg-plot.png\", plot = my_bar_plot)",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>워크플로우: 기초</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#요약",
    "href": "workflow-basics.html#요약",
    "title": "2  워크플로우: 기초",
    "section": "\n2.6 요약",
    "text": "2.6 요약\n이제 R 코드가 작동하는 방식에 대해 조금 더 배웠고, 나중에 다시 볼 때 코드를 이해하는 데 도움이 되는 몇 가지 팁을 배웠습니다. 다음 장에서는 중요한 변수 선택, 관심 있는 행 필터링, 요약 통계 계산 등 데이터를 변형하는 데 도움이 되는 tidyverse 패키지인 dplyr에 대해 가르쳐 데이터 과학 여정을 계속할 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>워크플로우: 기초</span>"
    ]
  },
  {
    "objectID": "data-transform.html",
    "href": "data-transform.html",
    "title": "3  데이터 변형",
    "section": "",
    "text": "3.1 소개\n시각화는 통찰력을 생성하는 데 중요한 도구이지만, 원하는 그래프를 만드는 데 필요한 정확한 형태로 데이터를 얻는 경우는 드뭅니다. 종종 데이터로 질문에 답하기 위해 새로운 변수나 요약을 생성해야 하거나, 데이터를 다루기 조금 더 쉽게 만들기 위해 변수의 이름을 바꾸거나 관측값의 순서를 변경하고 싶을 수도 있습니다. 이 장에서는 dplyr 패키지와 2013년 뉴욕시에서 출발한 항공편에 대한 새로운 데이터셋을 사용하여 데이터 변형을 소개하며 그 모든 작업(그리고 그 이상!)을 수행하는 방법을 배울 것입니다.\n이 장의 목표는 데이터 프레임을 변형하기 위한 모든 주요 도구에 대한 개요를 제공하는 것입니다. 데이터 프레임의 행과 열에서 작동하는 함수로 시작한 다음, 동사들을 결합하는 데 사용하는 중요한 도구인 파이프에 대해 더 이야기하기 위해 다시 돌아올 것입니다. 그런 다음 그룹으로 작업하는 기능을 소개할 것입니다. 이 장은 이러한 함수들이 실제로 작동하는 것을 보여주는 사례 연구로 마무리할 것입니다. 이후 장에서는 특정 유형의 데이터(예: 숫자, 문자열, 날짜)를 파고들기 시작하면서 함수들에 대해 더 자세히 다룰 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#소개",
    "href": "data-transform.html#소개",
    "title": "3  데이터 변형",
    "section": "",
    "text": "3.1.1 선수 지식\n이 장에서는 tidyverse의 또 다른 핵심 멤버인 dplyr 패키지에 초점을 맞출 것입니다. nycflights13 패키지의 데이터를 사용하여 핵심 아이디어를 설명하고 데이터를 이해하는 데 도움이 되도록 ggplot2를 사용할 것입니다.\n\nlibrary(nycflights13)\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.6\n#&gt; ✔ forcats   1.0.1     ✔ stringr   1.6.0\n#&gt; ✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n#&gt; ✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.2.0     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntidyverse를 로드할 때 출력되는 충돌 메시지에 주의하세요. 이 메시지는 dplyr이 기본(base) R의 일부 함수를 덮어쓴다고 알려줍니다. dplyr을 로드한 후 이러한 함수의 기본 버전을 사용하려면 전체 이름인 stats::filter()와 stats::lag()를 사용해야 합니다. 지금까지는 함수가 어떤 패키지에서 왔는지 거의 무시했는데, 대개는 중요하지 않기 때문입니다. 하지만 패키지를 알면 도움말을 찾고 관련 함수를 찾는 데 도움이 될 수 있으므로, 함수가 어떤 패키지에서 왔는지 정확히 해야 할 때는 R과 동일한 구문인 packagename::functionname()을 사용할 것입니다.\n\n3.1.2 nycflights13\n기본적인 dplyr 동사를 탐색하기 위해 nycflights13::flights를 사용할 것입니다. 이 데이터셋에는 2013년 뉴욕시에서 출발한 모든 336,776개의 항공편이 포함되어 있습니다. 데이터는 미국 교통통계국(Bureau of Transportation Statistics)에서 가져왔으며 ?flights에 문서화되어 있습니다.\n\nflights\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nflights는 티블(tibble)로, 몇 가지 일반적인 문제를 피하기 위해 tidyverse에서 사용하는 특별한 유형의 데이터 프레임입니다. 티블과 데이터 프레임의 가장 중요한 차이점은 티블이 출력되는 방식입니다. 티블은 대규모 데이터셋을 위해 설계되었으므로 처음 몇 개의 행과 한 화면에 맞는 열만 보여줍니다. 모든 것을 볼 수 있는 몇 가지 옵션이 있습니다. RStudio를 사용하는 경우 가장 편리한 방법은 아마도 View(flights)일 텐데, 이는 대화형으로 스크롤 및 필터링이 가능한 뷰를 엽니다. 그렇지 않으면 print(flights, width = Inf)를 사용하여 모든 열을 표시하거나 glimpse()를 사용할 수 있습니다:\n\nglimpse(flights)\n#&gt; Rows: 336,776\n#&gt; Columns: 19\n#&gt; $ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n#&gt; $ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 55…\n#&gt; $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 60…\n#&gt; $ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2,…\n#&gt; $ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 8…\n#&gt; $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 8…\n#&gt; $ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7,…\n#&gt; $ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\"…\n#&gt; $ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301…\n#&gt; $ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N…\n#&gt; $ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LG…\n#&gt; $ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IA…\n#&gt; $ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149…\n#&gt; $ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 73…\n#&gt; $ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6…\n#&gt; $ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59…\n#&gt; $ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-0…\n\n두 보기 모두 변수 이름 뒤에 각 변수의 유형을 알려주는 약어가 옵니다. &lt;int&gt;는 정수(integer)의 줄임말이고, &lt;dbl&gt;은 배정밀도 실수(double, 일명 실수)의 줄임말이며, &lt;chr&gt;은 문자(character, 일명 문자열), &lt;dttm&gt;은 날짜-시간(date-time)입니다. 열에 대해 수행할 수 있는 작업은 “유형”에 크게 의존하기 때문에 이것들은 중요합니다.\n\n3.1.3 dplyr 기초\n여러분은 데이터 조작 과제의 대다수를 해결할 수 있게 해주는 주요 dplyr 동사(함수)를 배우게 될 것입니다. 하지만 개별적인 차이점을 논의하기 전에 공통점을 언급할 가치가 있습니다:\n\n첫 번째 인수는 항상 데이터 프레임입니다.\n후속 인수는 일반적으로 변수 이름(따옴표 없이)을 사용하여 작업할 열을 설명합니다.\n출력은 항상 새로운 데이터 프레임입니다.\n\n각 동사는 한 가지 일을 잘 수행하므로 복잡한 문제를 해결하려면 일반적으로 여러 동사를 결합해야 하며, 파이프 |&gt;를 사용하여 그렇게 할 것입니다. Section 3.4 에서 파이프에 대해 더 논의하겠지만, 간단히 말해 파이프는 왼쪽에 있는 것을 오른쪽의 함수로 전달하므로 x |&gt; f(y)는 f(x, y)와 동일하고 x |&gt; f(y) |&gt; g(z)는 g(f(x, y), z)와 동일합니다. 파이프를 발음하는 가장 쉬운 방법은 “then(그 다음)”입니다. 덕분에 아직 세부 사항을 배우지 않았더라도 다음 코드의 의미를 파악할 수 있습니다:\n\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\ndplyr의 동사는 작업 대상에 따라 행(rows), 열(columns), 그룹(groups), 테이블(tables) 의 네 그룹으로 구성됩니다. 다음 섹션에서는 행, 열, 그룹에 대한 가장 중요한 동사를 배울 것입니다. 그런 다음 Chapter 19 에서 테이블에서 작동하는 조인(join) 동사에 대해 다시 이야기할 것입니다. 시작해 봅시다!",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#행",
    "href": "data-transform.html#행",
    "title": "3  데이터 변형",
    "section": "\n3.2 행",
    "text": "3.2 행\n데이터셋의 행에서 작동하는 가장 중요한 동사는 순서를 변경하지 않고 어떤 행이 존재하는지를 변경하는 filter()와 어떤 행이 존재하는지를 변경하지 않고 행의 순서를 변경하는 arrange()입니다. 두 함수 모두 행에만 영향을 미치며 열은 변경되지 않습니다. 또한 고유한 값을 가진 행을 찾는 distinct()에 대해서도 논의할 것입니다. arrange() 및 filter()와 달리 선택적으로 열을 수정할 수도 있습니다.\n\n3.2.1 filter()\n\nfilter()를 사용하면 열의 값에 따라 행을 유지할 수 있습니다1. 첫 번째 인수는 데이터 프레임입니다. 두 번째 및 후속 인수는 행을 유지하기 위해 참이어야 하는 조건입니다. 예를 들어, 120분(2시간) 이상 늦게 출발한 모든 항공편을 찾을 수 있습니다:\n\nflights |&gt; \n  filter(dep_delay &gt; 120)\n#&gt; # A tibble: 9,723 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      848           1835       853     1001           1950\n#&gt; 2  2013     1     1      957            733       144     1056            853\n#&gt; 3  2013     1     1     1114            900       134     1447           1222\n#&gt; 4  2013     1     1     1540           1338       122     2020           1825\n#&gt; 5  2013     1     1     1815           1325       290     2120           1542\n#&gt; 6  2013     1     1     1842           1422       260     1958           1535\n#&gt; # ℹ 9,717 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n&gt;(초과) 외에도 &gt;=(이상), &lt;(미만), &lt;=(이하), ==(같음), !=(같지 않음)를 사용할 수 있습니다. 또한 & 또는 ,를 사용하여 “그리고(and)”(두 조건 모두 확인)를 나타내거나 |를 사용하여 “또는(or)”(둘 중 하나 확인)을 나타내어 조건을 결합할 수도 있습니다:\n\n# 1월 1일에 출발한 항공편\nflights |&gt; \n  filter(month == 1 & day == 1)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# 1월 또는 2월에 출발한 항공편\nflights |&gt; \n  filter(month == 1 | month == 2)\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n|와 ==를 결합할 때 유용한 단축키가 있습니다: %in%. 변수가 오른쪽 값 중 하나와 같으면 행을 유지합니다:\n\n# 1월 또는 2월에 출발한 항공편을 선택하는 더 짧은 방법\nflights |&gt; \n  filter(month %in% c(1, 2))\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nChapter 12 에서 이러한 비교 및 논리 연산자에 대해 더 자세히 다시 다룰 것입니다.\nfilter()를 실행하면 dplyr은 필터링 작업을 실행하여 새 데이터 프레임을 생성한 다음 출력합니다. dplyr 함수는 입력을 절대 수정하지 않으므로 기존 flights 데이터셋을 수정하지 않습니다. 결과를 저장하려면 할당 연산자 &lt;-를 사용해야 합니다:\n\njan1 &lt;- flights |&gt; \n  filter(month == 1 & day == 1)\n\n\n3.2.2 일반적인 실수\nR을 처음 시작할 때 가장 저지르기 쉬운 실수는 동일성(equality)을 테스트할 때 == 대신 =를 사용하는 것입니다. filter()는 이런 일이 발생하면 알려줍니다:\n\nflights |&gt; \n  filter(month = 1)\n#&gt; Error in `filter()`:\n#&gt; ! We detected a named input.\n#&gt; ℹ This usually means that you've used `=` instead of `==`.\n#&gt; ℹ Did you mean `month == 1`?\n\n또 다른 실수는 영어에서처럼 “또는(or)” 문장을 작성하는 것입니다:\n\nflights |&gt; \n  filter(month == 1 | 2)\n\n이것은 오류를 발생시키지 않는다는 의미에서 “작동”하지만, |가 먼저 조건 month == 1을 확인한 다음 조건 2를 확인하는데, 이는 확인할 합리적인 조건이 아니므로 원하는 작업을 수행하지 않습니다. 여기서 무슨 일이 일어나고 있는지와 그 이유에 대해서는 Section 12.3.2 에서 더 자세히 배울 것입니다.\n\n3.2.3 arrange()\n\narrange()는 열의 값을 기준으로 행의 순서를 변경합니다. 데이터 프레임과 정렬 기준으로 삼을 일련의 열 이름(또는 더 복잡한 표현식)을 취합니다. 둘 이상의 열 이름을 제공하면 추가 열 각각이 이전 열 값의 동점(ties)을 깨는 데 사용됩니다. 예를 들어, 다음 코드는 4개의 열에 걸쳐 있는 출발 시간을 기준으로 정렬합니다. 가장 빠른 연도를 먼저 얻은 다음, 같은 연도 내에서 가장 빠른 달 등을 얻습니다.\n\nflights |&gt; \n  arrange(year, month, day, dep_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\narrange() 내부의 열에 desc()를 사용하여 내림차순(큰 것부터 작은 것 순)으로 해당 열을 기준으로 데이터 프레임을 재정렬할 수 있습니다. 예를 들어, 이 코드는 가장 많이 지연된 항공편부터 가장 적게 지연된 항공편 순으로 정렬합니다:\n\nflights |&gt; \n  arrange(desc(dep_delay))\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     9      641            900      1301     1242           1530\n#&gt; 2  2013     6    15     1432           1935      1137     1607           2120\n#&gt; 3  2013     1    10     1121           1635      1126     1239           1810\n#&gt; 4  2013     9    20     1139           1845      1014     1457           2210\n#&gt; 5  2013     7    22      845           1600      1005     1044           1815\n#&gt; 6  2013     4    10     1100           1900       960     1342           2211\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n행의 수는 변경되지 않았습니다. 데이터를 정렬하기만 했고 필터링하지는 않았습니다.\n\n3.2.4 distinct()\n\ndistinct()는 데이터셋에서 모든 고유한 행을 찾으므로 기술적으로는 주로 행에서 작동합니다. 그러나 대부분의 경우 일부 변수의 고유한 조합을 원할 것이므로 선택적으로 열 이름을 제공할 수도 있습니다:\n\n# 중복 행이 있는 경우 제거\nflights |&gt; \n  distinct()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# 모든 고유한 출발지 및 도착지 쌍 찾기\nflights |&gt; \n  distinct(origin, dest)\n#&gt; # A tibble: 224 × 2\n#&gt;   origin dest \n#&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 EWR    IAH  \n#&gt; 2 LGA    IAH  \n#&gt; 3 JFK    MIA  \n#&gt; 4 JFK    BQN  \n#&gt; 5 LGA    ATL  \n#&gt; 6 EWR    ORD  \n#&gt; # ℹ 218 more rows\n\n또는 고유한 행을 필터링할 때 다른 열을 유지하려면 .keep_all = TRUE 옵션을 사용할 수 있습니다.\n\nflights |&gt; \n  distinct(origin, dest, .keep_all = TRUE)\n#&gt; # A tibble: 224 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 218 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n이 모든 고유한 항공편이 1월 1일인 것은 우연이 아닙니다. distinct()는 데이터셋에서 고유한 행의 첫 번째 발생을 찾고 나머지는 버리기 때문입니다.\n대신 발생 횟수를 찾으려면 distinct()를 count()로 바꾸는 것이 좋습니다. sort = TRUE 인수를 사용하면 발생 횟수의 내림차순으로 정렬할 수 있습니다. count에 대해서는 Section 13.3 에서 더 자세히 배울 것입니다.\n\nflights |&gt;\n  count(origin, dest, sort = TRUE)\n#&gt; # A tibble: 224 × 3\n#&gt;   origin dest      n\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 JFK    LAX   11262\n#&gt; 2 LGA    ATL   10263\n#&gt; 3 LGA    ORD    8857\n#&gt; 4 JFK    SFO    8204\n#&gt; 5 LGA    CLT    6168\n#&gt; 6 EWR    ORD    6100\n#&gt; # ℹ 218 more rows\n\n\n3.2.5 연습문제\n\n\n각 조건에 대해 단일 파이프라인에서 조건을 충족하는 모든 항공편을 찾으세요:\n\n도착 지연이 2시간 이상이었다\n휴스턴(IAH 또는 HOU)으로 비행했다\n유나이티드(United), 아메리칸(American), 또는 델타(Delta) 항공에 의해 운항되었다\n여름(7월, 8월, 9월)에 출발했다\n2시간 이상 늦게 도착했지만 늦게 출발하지 않았다\n적어도 1시간 지연되었지만 비행 중 30분 이상 만회했다\n\n\n출발 지연이 가장 긴 항공편을 찾으려면 flights를 정렬하세요. 아침에 가장 일찍 떠난 항공편을 찾으세요.\n가장 빠른 항공편을 찾으려면 flights를 정렬하세요. (힌트: 함수 내부에 수학 계산을 포함해 보세요.)\n2013년의 모든 날에 항공편이 있었습니까?\n어떤 항공편이 가장 먼 거리를 이동했습니까? 어떤 것이 가장 짧은 거리를 이동했습니까?\nfilter()와 arrange()를 모두 사용하는 경우 어떤 순서로 사용하는지가 중요합니까? 왜 그렇습니까/그렇지 않습니까? 결과와 함수가 수행해야 할 작업량에 대해 생각해보세요.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#열",
    "href": "data-transform.html#열",
    "title": "3  데이터 변형",
    "section": "\n3.3 열",
    "text": "3.3 열\n행을 변경하지 않고 열에 영향을 미치는 4가지 중요한 동사가 있습니다. mutate()는 기존 열에서 파생된 새 열을 생성하고, select()는 존재하는 열을 변경하고, rename()은 열의 이름을 변경하고, relocate()는 열의 위치를 변경합니다.\n\n3.3.1 mutate()\n\nmutate()의 역할은 기존 열에서 계산된 새 열을 추가하는 것입니다. 변형(transform) 장에서는 다양한 유형의 변수를 조작하는 데 사용할 수 있는 다양한 함수 세트를 배우게 될 것입니다. 지금은 지연된 항공편이 공중에서 얼마나 많은 시간을 만회했는지(gain)와 시간당 마일 단위의 속도(speed)를 계산할 수 있는 기본 대수학을 고수할 것입니다:\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60\n  )\n#&gt; # A tibble: 336,776 × 21\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n기본적으로 mutate()는 데이터셋의 오른쪽에 새 열을 추가하므로 여기서 무슨 일이 일어나고 있는지 보기가 어렵습니다. 대신 .before 인수를 사용하여 변수를 왼쪽에 추가할 수 있습니다2:\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60,\n    .before = 1\n  )\n#&gt; # A tibble: 336,776 × 21\n#&gt;    gain speed  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    -9  370.  2013     1     1      517            515         2      830\n#&gt; 2   -16  374.  2013     1     1      533            529         4      850\n#&gt; 3   -31  408.  2013     1     1      542            540         2      923\n#&gt; 4    17  517.  2013     1     1      544            545        -1     1004\n#&gt; 5    19  394.  2013     1     1      554            600        -6      812\n#&gt; 6   -16  288.  2013     1     1      554            558        -4      740\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\n.은 .before가 함수에 대한 인수이지 우리가 생성하는 세 번째 새 변수의 이름이 아님을 나타냅니다. .after를 사용하여 변수 뒤에 추가할 수도 있으며, .before와 .after 모두에서 위치 대신 변수 이름을 사용할 수 있습니다. 예를 들어, day 뒤에 새 변수를 추가할 수 있습니다:\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60,\n    .after = day\n  )\n\n또는 .keep 인수로 유지되는 변수를 제어할 수 있습니다. 특히 유용한 인수는 \"used\"로, mutate() 단계에 포함되거나 생성된 열만 유지하도록 지정합니다. 예를 들어, 다음 출력에는 dep_delay, arr_delay, air_time, gain, hours, gain_per_hour 변수만 포함됩니다.\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    hours = air_time / 60,\n    gain_per_hour = gain / hours,\n    .keep = \"used\"\n  )\n\n위 계산의 결과를 flights에 다시 할당하지 않았기 때문에 새 변수 gain, hours, gain_per_hour는 출력만 되고 데이터 프레임에 저장되지 않는다는 점에 유의하세요. 나중에 사용할 수 있도록 데이터 프레임에서 사용할 수 있게 하려면 결과를 flights에 다시 할당하여 원본 데이터 프레임을 훨씬 더 많은 변수로 덮어쓸지, 아니면 새 객체에 할당할지 신중하게 생각해야 합니다. 종종 정답은 내용을 나타내도록 정보가 풍부하게 이름 지어진 새 객체(예: delay_gain)이지만, flights를 덮어쓰는 데에는 타당한 이유가 있을 수도 있습니다.\n\n3.3.2 select()\n\n수백 개 또는 수천 개의 변수가 있는 데이터셋을 얻는 것은 드문 일이 아닙니다. 이 상황에서 첫 번째 과제는 종종 관심 있는 변수에만 집중하는 것입니다. select()를 사용하면 변수 이름을 기반으로 한 작업을 사용하여 유용한 부분집합을 빠르게 확대할 수 있습니다:\n\n\n이름으로 열 선택:\n\nflights |&gt; \n  select(year, month, day)\n\n\n\nyear와 day 사이의 모든 열 선택(포함):\n\nflights |&gt; \n  select(year:day)\n\n\n\nyear에서 day까지의 열을 제외한 모든 열 선택(포함):\n\nflights |&gt; \n  select(!year:day)\n\n역사적으로 이 작업은 ! 대신 -로 수행되었으므로 야생에서 볼 가능성이 높습니다. 이 두 연산자는 같은 목적을 수행하지만 동작에 미묘한 차이가 있습니다. !는 “not”으로 읽히고 & 및 |와 잘 결합되므로 사용하는 것이 좋습니다.\n\n\n문자인 모든 열 선택:\n\nflights |&gt; \n  select(where(is.character))\n\n\n\nselect() 내에서 사용할 수 있는 몇 가지 도우미 함수가 있습니다:\n\n\nstarts_with(\"abc\"): “abc”로 시작하는 이름과 일치합니다.\n\nends_with(\"xyz\"): “xyz”로 끝나는 이름과 일치합니다.\n\ncontains(\"ijk\"): “ijk”를 포함하는 이름과 일치합니다.\n\nnum_range(\"x\", 1:3): x1, x2, x3와 일치합니다.\n\n자세한 내용은 ?select를 참조하세요. 정규 표현식(Chapter 15 의 주제)을 알고 나면 matches()를 사용하여 패턴과 일치하는 변수를 선택할 수도 있습니다.\nselect()할 때 =를 사용하여 변수의 이름을 바꿀 수 있습니다. 새 이름은 =의 왼쪽에 나타나고 이전 변수는 오른쪽에 나타납니다:\n\nflights |&gt; \n  select(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 1\n#&gt;   tail_num\n#&gt;   &lt;chr&gt;   \n#&gt; 1 N14228  \n#&gt; 2 N24211  \n#&gt; 3 N619AA  \n#&gt; 4 N804JB  \n#&gt; 5 N668DN  \n#&gt; 6 N39463  \n#&gt; # ℹ 336,770 more rows\n\n\n3.3.3 rename()\n\n기존 변수를 모두 유지하고 몇 가지 이름만 바꾸고 싶다면 select() 대신 rename()을 사용할 수 있습니다:\n\nflights |&gt; \n  rename(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n일관성 없이 명명된 열이 많아 모두 수동으로 수정하기 고통스럽다면 유용한 자동 정리를 제공하는 janitor::clean_names()를 확인해 보세요.\n\n3.3.4 relocate()\n\n변수를 이동하려면 relocate()를 사용하세요. 관련 변수를 함께 모으거나 중요한 변수를 앞으로 이동하고 싶을 수 있습니다. 기본적으로 relocate()는 변수를 앞으로 이동합니다:\n\nflights |&gt; \n  relocate(time_hour, air_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;   time_hour           air_time  year month   day dep_time sched_dep_time\n#&gt;   &lt;dttm&gt;                 &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n#&gt; 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n#&gt; 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n#&gt; 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n#&gt; 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n#&gt; 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, …\n\nmutate()에서처럼 .before 및 .after 인수를 사용하여 어디에 둘지 지정할 수도 있습니다:\n\nflights |&gt; \n  relocate(year:dep_time, .after = time_hour)\nflights |&gt; \n  relocate(starts_with(\"arr\"), .before = dep_time)\n\n\n3.3.5 연습문제\n\ndep_time, sched_dep_time, dep_delay를 비교하세요. 이 세 숫자가 어떻게 관련될 것이라고 예상합니까?\nflights에서 dep_time, dep_delay, arr_time, arr_delay를 선택할 수 있는 가능한 많은 방법을 브레인스토밍하세요.\nselect() 호출에서 동일한 변수의 이름을 여러 번 지정하면 어떻게 됩니까?\n\nany_of() 함수는 무엇을 합니까? 이 벡터와 함께 사용할 때 왜 도움이 될 수 있습니까?\n\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\n\n\n다음 코드를 실행한 결과가 놀랍습니까? select 도우미는 기본적으로 대소문자를 어떻게 처리합니까? 그 기본값을 어떻게 변경할 수 있습니까?\n\nflights |&gt; select(contains(\"TIME\"))\n\n\n측정 단위를 나타내기 위해 air_time을 air_time_min으로 이름을 바꾸고 데이터 프레임의 맨 앞으로 이동하세요.\n\n다음이 작동하지 않는 이유는 무엇이며 오류는 무엇을 의미합니까?\n\nflights |&gt; \n  select(tailnum) |&gt; \n  arrange(arr_delay)\n#&gt; Error in `arrange()`:\n#&gt; ℹ In argument: `..1 = arr_delay`.\n#&gt; Caused by error:\n#&gt; ! object 'arr_delay' not found",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-the-pipe",
    "href": "data-transform.html#sec-the-pipe",
    "title": "3  데이터 변형",
    "section": "\n3.4 파이프",
    "text": "3.4 파이프\n위에서 파이프의 간단한 예를 보여주었지만, 진정한 힘은 여러 동사를 결합하기 시작할 때 나타납니다. 예를 들어, 휴스턴의 IAH 공항으로 가는 가장 빠른 항공편을 찾고 싶다고 상상해 보세요. filter(), mutate(), select(), arrange()를 결합해야 합니다:\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  mutate(speed = distance / air_time * 60) |&gt; \n  select(year:day, dep_time, carrier, flight, speed) |&gt; \n  arrange(desc(speed))\n#&gt; # A tibble: 7,198 × 7\n#&gt;    year month   day dep_time carrier flight speed\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n#&gt; 1  2013     7     9      707 UA         226  522.\n#&gt; 2  2013     8    27     1850 UA        1128  521.\n#&gt; 3  2013     8    28      902 UA        1711  519.\n#&gt; 4  2013     8    28     2122 UA        1022  519.\n#&gt; 5  2013     6    11     1628 UA        1178  515.\n#&gt; 6  2013     8    27     1017 UA         333  515.\n#&gt; # ℹ 7,192 more rows\n\n이 파이프라인에는 4단계가 있지만 동사가 각 줄의 시작 부분에 오기 때문에 훑어보기 쉽습니다. flights 데이터로 시작한 다음 필터링하고, 변형하고, 선택하고, 정렬합니다.\n파이프가 없었다면 어떻게 되었을까요? 각 함수 호출을 이전 호출 안에 중첩할 수 있습니다:\n\narrange(\n  select(\n    mutate(\n      filter(\n        flights, \n        dest == \"IAH\"\n      ),\n      speed = distance / air_time * 60\n    ),\n    year:day, dep_time, carrier, flight, speed\n  ),\n  desc(speed)\n)\n\n또는 중간 객체를 많이 사용할 수도 있습니다:\n\nflights1 &lt;- filter(flights, dest == \"IAH\")\nflights2 &lt;- mutate(flights1, speed = distance / air_time * 60)\nflights3 &lt;- select(flights2, year:day, dep_time, carrier, flight, speed)\narrange(flights3, desc(speed))\n\n두 형식 모두 때와 장소가 있지만 파이프는 일반적으로 쓰기 쉽고 읽기 쉬운 데이터 분석 코드를 생성합니다.\n코드에 파이프를 추가하려면 내장 키보드 단축키인 Ctrl/Cmd + Shift + M을 사용하는 것이 좋습니다. Figure 3.1 에 표시된 대로 %&gt;% 대신 |&gt;를 사용하려면 RStudio 옵션을 하나 변경해야 합니다. %&gt;%에 대해서는 잠시 후에 자세히 설명하겠습니다.\n\n\n\n\n\n\n\nFigure 3.1: |&gt;를 삽입하려면 “Use native pipe operator” 옵션이 선택되어 있는지 확인하세요.\n\n\n\n\n\n\n\n\n\n\nNotemagrittr\n\n\n\n한동안 tidyverse를 사용해 왔다면 magrittr 패키지에서 제공하는 %&gt;% 파이프에 익숙할 수 있습니다. magrittr 패키지는 핵심 tidyverse에 포함되어 있으므로 tidyverse를 로드할 때마다 %&gt;%를 사용할 수 있습니다:\n\nlibrary(tidyverse)\n\nmtcars %&gt;% \n  group_by(cyl) %&gt;%\n  summarize(n = n())\n\n간단한 경우 |&gt;와 %&gt;%는 동일하게 작동합니다. 그렇다면 왜 기본(base) 파이프를 권장할까요? 첫째, 기본 R의 일부이므로 tidyverse를 사용하지 않을 때도 항상 사용할 수 있습니다. 둘째, |&gt;는 %&gt;%보다 훨씬 간단합니다. 2014년에 %&gt;%가 발명된 후 2021년 R 4.1.0에 |&gt;가 포함되기까지의 시간 동안 우리는 파이프에 대해 더 잘 이해하게 되었습니다. 이를 통해 기본 구현에서 자주 사용되지 않고 덜 중요한 기능을 버릴 수 있었습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#그룹",
    "href": "data-transform.html#그룹",
    "title": "3  데이터 변형",
    "section": "\n3.5 그룹",
    "text": "3.5 그룹\n지금까지 행과 열을 다루는 함수에 대해 배웠습니다. dplyr은 그룹으로 작업하는 기능을 추가하면 훨씬 더 강력해집니다. 이 섹션에서는 가장 중요한 함수인 group_by(), summarize() 및 슬라이스 함수 제품군에 초점을 맞출 것입니다.\n\n3.5.1 group_by()\n\ngroup_by()를 사용하여 데이터셋을 분석에 의미 있는 그룹으로 나누세요:\n\nflights |&gt; \n  group_by(month)\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   month [12]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\ngroup_by()는 데이터를 변경하지 않지만, 출력을 자세히 살펴보면 출력이 월별로 “그룹화”되었음을 나타내는 것을 알 수 있습니다(Groups: month [12]). 즉, 후속 작업은 이제 “월별로” 작동합니다. group_by()는 이 그룹화된 기능(클래스라고 함)을 데이터 프레임에 추가하여 데이터에 적용되는 후속 동사의 동작을 변경합니다.\n\n3.5.2 summarize()\n\n가장 중요한 그룹화된 작업은 요약(summary)으로, 단일 요약 통계를 계산하는 데 사용되는 경우 데이터 프레임을 각 그룹에 대해 단일 행을 갖도록 축소합니다. dplyr에서 이 작업은 summarize()3에 의해 수행되며, 다음 예제는 월별 평균 출발 지연을 계산합니다:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay)\n  )\n#&gt; # A tibble: 12 × 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1        NA\n#&gt; 2     2        NA\n#&gt; 3     3        NA\n#&gt; 4     4        NA\n#&gt; 5     5        NA\n#&gt; 6     6        NA\n#&gt; # ℹ 6 more rows\n\n어라! 무언가 잘못되었고, 모든 결과가 R의 결측값 기호인 NA(“N-A”라고 발음)입니다. 이것은 관측된 일부 항공편의 지연 열에 누락된 데이터가 있기 때문에 발생했으며, 해당 값을 포함하여 평균을 계산했을 때 NA 결과가 나왔습니다. Chapter 18 에서 결측값에 대해 자세히 다시 다루겠지만, 지금은 mean() 함수에 na.rm 인수를 TRUE로 설정하여 모든 결측값을 무시하도록 지시할 것입니다:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 12 × 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1      10.0\n#&gt; 2     2      10.8\n#&gt; 3     3      13.2\n#&gt; 4     4      13.9\n#&gt; 5     5      13.0\n#&gt; 6     6      20.8\n#&gt; # ℹ 6 more rows\n\nsummarize()에 대한 단일 호출로 원하는 만큼의 요약을 생성할 수 있습니다. 다가오는 장에서 다양한 유용한 요약을 배우겠지만, 매우 유용한 요약 중 하나는 각 그룹의 행 수를 반환하는 n()입니다:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    n = n()\n  )\n#&gt; # A tibble: 12 × 3\n#&gt;   month avg_delay     n\n#&gt;   &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1     1      10.0 27004\n#&gt; 2     2      10.8 24951\n#&gt; 3     3      13.2 28834\n#&gt; 4     4      13.9 28330\n#&gt; 5     5      13.0 28796\n#&gt; 6     6      20.8 28243\n#&gt; # ℹ 6 more rows\n\n평균과 개수는 데이터 과학에서 놀랍도록 많은 것을 얻게 해줍니다!\n\n3.5.3 slice_ 함수들\n각 그룹 내에서 특정 행을 추출할 수 있는 5가지 편리한 함수가 있습니다:\n\n\ndf |&gt; slice_head(n = 1)은 각 그룹에서 첫 번째 행을 가져옵니다.\n\ndf |&gt; slice_tail(n = 1)은 각 그룹에서 마지막 행을 가져옵니다.\n\ndf |&gt; slice_min(x, n = 1)은 x 열의 값이 가장 작은 행을 가져옵니다.\n\ndf |&gt; slice_max(x, n = 1)은 x 열의 값이 가장 큰 행을 가져옵니다.\n\ndf |&gt; slice_sample(n = 1)은 임의의 행 하나를 가져옵니다.\n\nn을 변경하여 둘 이상의 행을 선택하거나 n = 대신 prop = 0.1을 사용하여 각 그룹에서 (예를 들어) 10%의 행을 선택할 수 있습니다. 예를 들어, 다음 코드는 각 목적지에 도착했을 때 가장 많이 지연된 항공편을 찾습니다:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  slice_max(arr_delay, n = 1) |&gt;\n  relocate(dest)\n#&gt; # A tibble: 108 × 19\n#&gt; # Groups:   dest [105]\n#&gt;   dest   year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 ABQ    2013     7    22     2145           2007        98      132\n#&gt; 2 ACK    2013     7    23     1139            800       219     1250\n#&gt; 3 ALB    2013     1    25      123           2000       323      229\n#&gt; 4 ANC    2013     8    17     1740           1625        75     2042\n#&gt; 5 ATL    2013     7    22     2257            759       898      121\n#&gt; 6 AUS    2013     7    10     2056           1505       351     2347\n#&gt; # ℹ 102 more rows\n#&gt; # ℹ 11 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\n목적지는 105개인데 여기서는 108개의 행을 얻습니다. 무슨 일일까요? slice_min()과 slice_max()는 동점 값을 유지하므로 n = 1은 가장 높은 값을 가진 모든 행을 제공하라는 의미입니다. 그룹당 정확히 하나의 행을 원하면 with_ties = FALSE를 설정할 수 있습니다.\n이것은 summarize()로 최대 지연을 계산하는 것과 유사하지만, 단일 요약 통계 대신 전체 해당 행(또는 동점이 있는 경우 행들)을 얻습니다.\n\n3.5.4 여러 변수로 그룹화하기\n하나 이상의 변수를 사용하여 그룹을 만들 수 있습니다. 예를 들어 각 날짜에 대한 그룹을 만들 수 있습니다.\n\ndaily &lt;- flights |&gt;  \n  group_by(year, month, day)\ndaily\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n둘 이상의 변수로 그룹화된 티블을 요약하면 각 요약이 마지막 그룹을 벗겨냅니다. 지나고 보니 이것은 이 기능을 작동시키는 좋은 방법이 아니었지만, 기존 코드를 깨지 않고 변경하기는 어렵습니다. 무슨 일이 일어나고 있는지 명확하게 하기 위해 dplyr은 이 동작을 변경하는 방법을 알려주는 메시지를 표시합니다:\n\ndaily_flights &lt;- daily |&gt; \n  summarize(n = n())\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n\n이 동작에 만족하면 메시지를 억제하기 위해 명시적으로 요청할 수 있습니다:\n\ndaily_flights &lt;- daily |&gt; \n  summarize(\n    n = n(), \n    .groups = \"drop_last\"\n  )\n\n또는 다른 값을 설정하여 기본 동작을 변경하세요. 예: 모든 그룹화를 삭제하려면 \"drop\", 동일한 그룹을 보존하려면 \"keep\".\n\n3.5.5 그룹화 해제하기\nsummarize()를 사용하지 않고 데이터 프레임에서 그룹화를 제거하고 싶을 수도 있습니다. ungroup()으로 이 작업을 수행할 수 있습니다.\n\ndaily |&gt; \n  ungroup()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n이제 그룹화되지 않은 데이터 프레임을 요약할 때 어떤 일이 발생하는지 봅시다.\n\ndaily |&gt; \n  ungroup() |&gt;\n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n  )\n#&gt; # A tibble: 1 × 2\n#&gt;   avg_delay flights\n#&gt;       &lt;dbl&gt;   &lt;int&gt;\n#&gt; 1      12.6  336776\n\ndplyr은 그룹화되지 않은 데이터 프레임의 모든 행을 하나의 그룹에 속하는 것으로 취급하기 때문에 단일 행을 반환합니다.\n\n3.5.6 .by\n\ndplyr 1.1.0에는 작업별 그룹화를 위한 새로운 실험적 구문인 .by 인수가 포함되어 있습니다. group_by()와 ungroup()이 사라지는 것은 아니지만 이제 .by 인수를 사용하여 단일 작업 내에서 그룹화할 수도 있습니다:\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = month\n  )\n\n또는 여러 변수로 그룹화하려면:\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = c(origin, dest)\n  )\n\n.by는 모든 동사와 함께 작동하며 작업이 완료되었을 때 그룹화 메시지를 억제하기 위해 .groups 인수를 사용하거나 ungroup()을 사용할 필요가 없다는 장점이 있습니다.\n우리가 책을 썼을 때 이 구문이 매우 새로운 것이었기 때문에 이 장에서는 이 구문에 집중하지 않았습니다. 우리는 이것이 많은 가능성을 가지고 있고 꽤 인기가 있을 것 같다고 생각하기 때문에 언급하고 싶었습니다. dplyr 1.1.0 블로그 게시물에서 자세한 내용을 확인할 수 있습니다.\n\n3.5.7 연습문제\n\n평균 지연 시간이 가장 나쁜 항공사는 어디입니까? 도전 과제: 나쁜 공항 대 나쁜 항공사의 영향을 풀 수 있습니까? 왜 그렇습니까/그렇지 않습니까? (힌트: flights |&gt; group_by(carrier, dest) |&gt; summarize(n())을 생각해보세요)\n각 목적지로 출발할 때 가장 많이 지연된 항공편을 찾으세요.\n지연은 하루 동안 어떻게 변합니까? 플롯으로 답을 설명하세요.\nslice_min()과 친구들에게 음수 n을 제공하면 어떻게 됩니까?\n방금 배운 dplyr 동사 측면에서 count()가 수행하는 작업을 설명하세요. count()에 대한 sort 인수는 무엇을 합니까?\n\n다음과 같은 작은 데이터 프레임이 있다고 가정해 봅시다:\n\ndf &lt;- tibble(\n  x = 1:5,\n  y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\n  z = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\n\n\n\n출력이 어떻게 보일지 생각나는 대로 적은 다음 맞았는지 확인하고 group_by()가 무엇을 하는지 설명하세요.\n\ndf |&gt;\n  group_by(y)\n\n\n\n출력이 어떻게 보일지 생각나는 대로 적은 다음 맞았는지 확인하고 arrange()가 무엇을 하는지 설명하세요. 또한 (a) 부분의 group_by()와 어떻게 다른지 언급하세요.\n\ndf |&gt;\n  arrange(y)\n\n\n\n출력이 어떻게 보일지 생각나는 대로 적은 다음 맞았는지 확인하고 파이프라인이 무엇을 하는지 설명하세요.\n\ndf |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\n출력이 어떻게 보일지 생각나는 대로 적은 다음 맞았는지 확인하고 파이프라인이 무엇을 하는지 설명하세요. 그런 다음 메시지가 무엇을 말하는지 언급하세요.\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\n출력이 어떻게 보일지 생각나는 대로 적은 다음 맞았는지 확인하고 파이프라인이 무엇을 하는지 설명하세요. 출력이 (d) 부분의 출력과 어떻게 다릅니까?\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\n\n\n출력이 어떻게 보일지 생각나는 대로 적은 다음 맞았는지 확인하고 각 파이프라인이 무엇을 하는지 설명하세요. 두 파이프라인의 출력은 어떻게 다릅니까?\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  mutate(mean_x = mean(x))",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-sample-size",
    "href": "data-transform.html#sec-sample-size",
    "title": "3  데이터 변형",
    "section": "\n3.6 사례 연구: 집계 및 표본 크기",
    "text": "3.6 사례 연구: 집계 및 표본 크기\n집계를 수행할 때마다 항상 개수(n())를 포함하는 것이 좋습니다. 그렇게 하면 매우 적은 양의 데이터에 근거하여 결론을 내리지 않도록 할 수 있습니다. Lahman 패키지의 야구 데이터를 사용하여 이를 보여줄 것입니다. 구체적으로 선수가 안타를 친 횟수(H) 대 공을 인플레이(in play)하려고 시도한 횟수(AB)의 비율을 비교할 것입니다:\n\nbatters &lt;- Lahman::Batting |&gt; \n  group_by(playerID) |&gt; \n  summarize(\n    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),\n    n = sum(AB, na.rm = TRUE)\n  )\nbatters\n#&gt; # A tibble: 20,985 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 aardsda01      0          4\n#&gt; 2 aaronha01      0.305  12364\n#&gt; 3 aaronto01      0.229    944\n#&gt; 4 aasedo01       0          5\n#&gt; 5 abadan01       0.0952    21\n#&gt; 6 abadfe01       0.111      9\n#&gt; # ℹ 20,979 more rows\n\n타자의 기량(타율 performance로 측정) 대 공을 칠 기회(타수 n으로 측정)를 플롯하면 두 가지 패턴이 나타납니다:\n\n타석 수가 적은 선수들 사이에서 performance의 변동이 더 큽니다. 이 플롯의 모양은 매우 특징적입니다. 평균(또는 기타 요약 통계) 대 그룹 크기를 플롯할 때마다 표본 크기가 커짐에 따라 변동이 감소하는 것을 볼 수 있습니다4.\n기량(performance)과 공을 칠 기회(n) 사이에는 양의 상관관계가 있습니다. 팀은 최고의 타자에게 공을 칠 기회를 가장 많이 주고 싶어하기 때문입니다.\n\n\nbatters |&gt; \n  filter(n &gt; 100) |&gt; \n  ggplot(aes(x = n, y = performance)) +\n  geom_point(alpha = 1 / 10) + \n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\nggplot2와 dplyr을 결합하는 편리한 패턴을 주목하세요. 데이터셋 처리를 위한 |&gt;에서 플롯에 레이어를 추가하기 위한 +로 전환해야 한다는 점만 기억하면 됩니다.\n이것은 순위 매기기에도 중요한 의미를 갖습니다. desc(performance)로 순진하게 정렬하면 타율이 가장 좋은 사람들은 분명히 공을 인플레이하려고 시도한 횟수가 매우 적고 우연히 안타를 친 사람들이며, 반드시 가장 숙련된 선수는 아닙니다:\n\nbatters |&gt; \n  arrange(desc(performance))\n#&gt; # A tibble: 20,985 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 abramge01           1     1\n#&gt; 2 alberan01           1     1\n#&gt; 3 banisje01           1     1\n#&gt; 4 bartocl01           1     1\n#&gt; 5 bassdo01            1     1\n#&gt; 6 birasst01           1     2\n#&gt; # ℹ 20,979 more rows\n\n이 문제에 대한 좋은 설명과 해결 방법은 http://varianceexplained.org/r/empirical_bayes_baseball/ 및 https://www.evanmiller.org/how-not-to-sort-by-average-rating.html에서 찾을 수 있습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#요약",
    "href": "data-transform.html#요약",
    "title": "3  데이터 변형",
    "section": "\n3.7 요약",
    "text": "3.7 요약\n이 장에서는 dplyr이 데이터 프레임 작업을 위해 제공하는 도구에 대해 배웠습니다. 도구는 대략 세 가지 범주로 분류됩니다: 행을 조작하는 도구(filter() 및 arrange() 등), 열을 조작하는 도구(select() 및 mutate() 등), 그룹을 조작하는 도구(group_by() 및 summarize() 등). 이 장에서는 이러한 “전체 데이터 프레임” 도구에 중점을 두었지만 개별 변수로 무엇을 할 수 있는지에 대해서는 아직 많이 배우지 않았습니다. 각 장에서 특정 유형의 변수에 대한 도구를 제공하는 책의 변형(Transform) 파트에서 다시 다룰 것입니다.\n다음 장에서는 워크플로우로 다시 돌아가 코드 스타일의 중요성과 코드를 잘 정리하여 자신과 다른 사람들이 읽고 이해하기 쉽게 만드는 방법에 대해 논의할 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "data-transform.html#footnotes",
    "href": "data-transform.html#footnotes",
    "title": "3  데이터 변형",
    "section": "",
    "text": "나중에 위치에 따라 행을 선택할 수 있는 slice_*() 제품군에 대해 배울 것입니다.↩︎\nRStudio에서 열이 많은 데이터셋을 보는 가장 쉬운 방법은 View()임을 기억하세요.↩︎\n영국식 영어를 선호하는 경우 summarise()도 가능합니다.↩︎\n*쿨럭* 대수의 법칙 *쿨럭*.↩︎",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 변형</span>"
    ]
  },
  {
    "objectID": "workflow-style.html",
    "href": "workflow-style.html",
    "title": "4  워크플로우: 코드 스타일",
    "section": "",
    "text": "4.1 이름\n좋은 코딩 스타일은 올바른 문장 부호와 같습니다: 없어도 어떻게든 할 수는 있지만, 그것이있으면확실히읽기가더쉬워집니다. 이제 막 시작한 프로그래머라도 코드 스타일에 신경 쓰는 것이 좋습니다. 일관된 스타일을 사용하면 다른 사람(미래의 자신 포함!)이 작업을 더 쉽게 읽을 수 있으며, 다른 사람에게 도움을 받아야 할 때 특히 중요합니다. 이 장에서는 이 책 전체에서 사용되는 tidyverse 스타일 가이드의 가장 중요한 요점을 소개합니다.\n코드를 스타일링하는 것은 처음에는 약간 지루하게 느껴질 수 있지만, 연습하면 곧 제2의 천성이 될 것입니다. 또한 Lorenz Walthert가 만든 styler 패키지처럼 기존 코드를 빠르게 다시 스타일링할 수 있는 훌륭한 도구도 있습니다. install.packages(\"styler\")로 설치한 후 사용하는 쉬운 방법은 RStudio의 명령 팔레트(command palette) 를 통하는 것입니다. 명령 팔레트를 사용하면 내장된 RStudio 명령과 패키지에서 제공하는 많은 애드인을 사용할 수 있습니다. Cmd/Ctrl + Shift + P를 눌러 팔레트를 연 다음 “styler”를 입력하여 styler가 제공하는 모든 단축키를 확인하세요. Figure 4.1 는 결과를 보여줍니다.\n이 장의 코드 예제에는 tidyverse 및 nycflights13 패키지를 사용합니다.\nSection 2.3 에서 이름에 대해 간략하게 이야기했습니다. 변수 이름(&lt;-로 생성된 변수와 mutate()로 생성된 변수)은 소문자, 숫자, _만 사용해야 한다는 것을 기억하세요. 이름 내에서 단어를 구분하려면 _를 사용하세요.\n# 권장:\nshort_flights &lt;- flights |&gt; filter(air_time &lt; 60)\n\n# 피해야 할 것:\nSHORTFLIGHTS &lt;- flights |&gt; filter(air_time &lt; 60)\n일반적인 경험 법칙으로, 입력하기 빠른 간결한 이름보다는 이해하기 쉬운 길고 서술적인 이름을 선호하는 것이 좋습니다. 짧은 이름은 코드를 작성할 때 상대적으로 적은 시간을 절약하지만(특히 자동 완성이 입력을 완료하는 데 도움이 되기 때문에), 오래된 코드로 돌아와서 암호 같은 약어를 파악해야 할 때는 많은 시간이 걸릴 수 있습니다.\n관련된 것들에 대해 여러 이름이 있는 경우 일관성을 유지하도록 최선을 다하세요. 이전 관례를 잊어버리면 불일치가 발생하기 쉬우므로 돌아가서 이름을 바꿔야 하더라도 기분 나빠하지 마세요. 일반적으로 주제에 대한 변형인 변수가 여러 개 있는 경우, 자동 완성은 변수의 시작 부분에서 가장 잘 작동하므로 공통 접미사보다는 공통 접두사를 부여하는 것이 좋습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#공백",
    "href": "workflow-style.html#공백",
    "title": "4  워크플로우: 코드 스타일",
    "section": "\n4.2 공백",
    "text": "4.2 공백\n^를 제외한 수학 연산자(즉, +, -, ==, &lt;, …)의 양쪽과 할당 연산자(&lt;-) 주위에 공백을 넣으세요.\n\n# 권장\nz &lt;- (a + b)^2 / d\n\n# 피해야 할 것\nz&lt;-( a + b ) ^ 2/d\n\n일반적인 함수 호출의 경우 괄호 안이나 밖에 공백을 넣지 마세요. 표준 영어에서와 마찬가지로 항상 쉼표 뒤에 공백을 넣으세요.\n\n# 권장\nmean(x, na.rm = TRUE)\n\n# 피해야 할 것\nmean (x ,na.rm=TRUE)\n\n정렬을 개선하는 경우 공백을 추가해도 괜찮습니다. 예를 들어 mutate()에서 여러 변수를 생성하는 경우 모든 =가 일렬로 정렬되도록 공백을 추가하고 싶을 수 있습니다.1 이렇게 하면 코드를 훑어보기가 더 쉬워집니다.\n\nflights |&gt; \n  mutate(\n    speed      = distance / air_time,\n    dep_hour   = dep_time %/% 100,\n    dep_minute = dep_time %%  100\n  )",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#sec-pipes",
    "href": "workflow-style.html#sec-pipes",
    "title": "4  워크플로우: 코드 스타일",
    "section": "\n4.3 파이프",
    "text": "4.3 파이프\n|&gt; 앞에는 항상 공백이 있어야 하며 일반적으로 줄의 마지막에 와야 합니다. 이렇게 하면 새로운 단계를 추가하고, 기존 단계를 재정렬하고, 단계 내의 요소를 수정하고, 왼쪽의 동사를 훑어보며 전체적인 흐름(10,000피트 뷰)을 파악하기가 더 쉬워집니다.\n\n# 권장 \nflights |&gt;  \n  filter(!is.na(arr_delay), !is.na(tailnum)) |&gt; \n  count(dest)\n\n# 피해야 할 것\nflights|&gt;filter(!is.na(arr_delay), !is.na(tailnum))|&gt;count(dest)\n\n파이핑하는 함수에 명명된 인수(예: mutate() 또는 summarize())가 있는 경우 각 인수를 새 줄에 넣으세요. 함수에 명명된 인수가 없는 경우(예: select() 또는 filter()), 맞지 않는 경우가 아니라면 모든 것을 한 줄에 유지하세요. 맞지 않는 경우에는 각 인수를 별도의 줄에 넣어야 합니다.\n\n# 권장\nflights |&gt;  \n  group_by(tailnum) |&gt; \n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\n# 피해야 할 것\nflights |&gt;\n  group_by(\n    tailnum\n  ) |&gt; \n  summarize(delay = mean(arr_delay, na.rm = TRUE), n = n())\n\n파이프라인의 첫 번째 단계 후에는 각 줄을 두 칸 들여쓰기하세요. RStudio는 |&gt; 뒤에 줄바꿈을 하면 자동으로 공백을 넣어줍니다. 각 인수를 별도의 줄에 넣는 경우 추가로 두 칸 더 들여쓰기하세요. )가 별도의 줄에 있고 함수 이름의 수평 위치와 일치하도록 들여쓰기가 해제되어 있는지 확인하세요.\n\n# 권장 \nflights |&gt;  \n  group_by(tailnum) |&gt; \n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\n# 피해야 할 것\nflights|&gt;\n  group_by(tailnum) |&gt; \n  summarize(\n             delay = mean(arr_delay, na.rm = TRUE), \n             n = n()\n           )\n\n# 피해야 할 것\nflights|&gt;\n  group_by(tailnum) |&gt; \n  summarize(\n  delay = mean(arr_delay, na.rm = TRUE), \n  n = n()\n  )\n\n파이프라인이 한 줄에 쉽게 들어가는 경우 이러한 규칙 중 일부를 어겨도 괜찮습니다. 하지만 우리의 집단적인 경험에 따르면 짧은 스니펫이 길어지는 경우가 흔하므로 일반적으로 필요한 모든 수직 공간으로 시작하는 것이 장기적으로 시간을 절약할 수 있습니다.\n\n# 이것은 한 줄에 간결하게 들어갑니다\ndf |&gt; mutate(y = x + 1)\n\n# 이것은 4배나 많은 줄을 차지하지만, \n# 나중에 더 많은 변수와 단계로 쉽게 확장할 수 있습니다\ndf |&gt; \n  mutate(\n    y = x + 1\n  )\n\n마지막으로 10-15줄보다 긴 매우 긴 파이프를 작성하는 것을 경계하세요. 더 작은 하위 작업으로 나누고 각 작업에 유익한 이름을 지정하세요. 이름은 독자에게 무슨 일이 일어나고 있는지 알려주고 중간 결과가 예상대로인지 확인하기 쉽게 해줍니다. 유익한 이름을 지정할 수 있을 때는 항상 유익한 이름을 지정해야 합니다. 예를 들어 피벗(pivoting)이나 요약(summarizing) 후와 같이 데이터의 구조를 근본적으로 변경할 때가 그렇습니다. 처음부터 올바르게 할 것이라고 기대하지 마세요! 이는 좋은 이름을 얻을 수 있는 중간 상태가 있는 경우 긴 파이프라인을 분할하는 것을 의미합니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#ggplot2",
    "href": "workflow-style.html#ggplot2",
    "title": "4  워크플로우: 코드 스타일",
    "section": "\n4.4 ggplot2",
    "text": "4.4 ggplot2\n파이프에 적용되는 동일한 기본 규칙이 ggplot2에도 적용됩니다. +를 |&gt;와 같은 방식으로 취급하면 됩니다.\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE)\n  ) |&gt; \n  ggplot(aes(x = month, y = delay)) +\n  geom_point() + \n  geom_line()\n\n다시 말하지만, 함수의 모든 인수를 한 줄에 넣을 수 없는 경우 각 인수를 별도의 줄에 넣으세요:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(\n    distance = mean(distance),\n    speed = mean(distance / air_time, na.rm = TRUE)\n  ) |&gt; \n  ggplot(aes(x = distance, y = speed)) +\n  geom_smooth(\n    method = \"loess\",\n    span = 0.5,\n    se = FALSE, \n    color = \"white\", \n    linewidth = 4\n  ) +\n  geom_point()\n\n|&gt;에서 +로 전환되는 부분을 주의하세요. 이 전환이 필요하지 않았으면 좋겠지만, 안타깝게도 ggplot2는 파이프가 발견되기 전에 작성되었습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#섹션-주석",
    "href": "workflow-style.html#섹션-주석",
    "title": "4  워크플로우: 코드 스타일",
    "section": "\n4.5 섹션 주석",
    "text": "4.5 섹션 주석\n스크립트가 길어지면 섹션(sectioning) 주석을 사용하여 파일을 관리하기 쉬운 조각으로 나눌 수 있습니다:\n\n# Load data --------------------------------------\n\n# Plot data --------------------------------------\n\nRStudio는 이러한 헤더를 생성하는 키보드 단축키(Cmd/Ctrl + Shift + R)를 제공하며, Figure 4.2 에 표시된 것처럼 편집기 왼쪽 하단의 코드 탐색 드롭다운에 표시합니다.\n\n\n\n\n\n\n\nFigure 4.2: 스크립트에 섹션 주석을 추가한 후 스크립트 편집기 왼쪽 하단의 코드 탐색 도구를 사용하여 해당 섹션으로 쉽게 이동할 수 있습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#연습문제",
    "href": "workflow-style.html#연습문제",
    "title": "4  워크플로우: 코드 스타일",
    "section": "\n4.6 연습문제",
    "text": "4.6 연습문제\n\n\n위의 지침에 따라 다음 파이프라인의 스타일을 다시 지정하세요.\n\nflights|&gt;filter(dest==\"IAH\")|&gt;group_by(year,month,day)|&gt;summarize(n=n(),\ndelay=mean(arr_delay,na.rm=TRUE))|&gt;filter(n&gt;10)\n\nflights|&gt;filter(carrier==\"UA\",dest%in%c(\"IAH\",\"HOU\"),sched_dep_time&gt;\n0900,sched_arr_time&lt;2000)|&gt;group_by(flight)|&gt;summarize(delay=mean(\narr_delay,na.rm=TRUE),cancelled=sum(is.na(arr_delay)),n=n())|&gt;filter(n&gt;10)",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#요약",
    "href": "workflow-style.html#요약",
    "title": "4  워크플로우: 코드 스타일",
    "section": "\n4.7 요약",
    "text": "4.7 요약\n이 장에서는 코드 스타일의 가장 중요한 원칙을 배웠습니다. 처음에는 임의의 규칙 집합처럼 느껴질 수 있지만(실제로 그렇습니다!) 시간이 지나면서 더 많은 코드를 작성하고 더 많은 사람과 코드를 공유하면 일관된 스타일이 얼마나 중요한지 알게 될 것입니다. 그리고 styler 패키지를 잊지 마세요. 스타일이 좋지 않은 코드의 품질을 빠르게 개선할 수 있는 좋은 방법입니다.\n다음 장에서는 다시 데이터 과학 도구로 돌아가 깔끔한 데이터(tidy data)에 대해 배웁니다. 깔끔한 데이터는 tidyverse 전체에서 사용되는 데이터 프레임을 구성하는 일관된 방법입니다. 이러한 일관성은 삶을 더 쉽게 만듭니다. 깔끔한 데이터가 있으면 대부분의 tidyverse 함수와 잘 작동하기 때문입니다. 물론 인생은 결코 쉽지 않으며, 야생에서 만나는 대부분의 데이터셋은 이미 깔끔하지 않을 것입니다. 그래서 우리는 tidyr 패키지를 사용하여 깔끔하지 않은 데이터를 정리하는 방법도 가르칠 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#footnotes",
    "href": "workflow-style.html#footnotes",
    "title": "4  워크플로우: 코드 스타일",
    "section": "",
    "text": "dep_time은 HMM 또는 HHMM 형식이므로 정수 나눗셈(%/%)을 사용하여 시간을 얻고 나머지(모듈로라고도 함, %%)를 사용하여 분을 얻습니다.↩︎",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>워크플로우: 코드 스타일</span>"
    ]
  },
  {
    "objectID": "data-tidy.html",
    "href": "data-tidy.html",
    "title": "5  데이터 정리",
    "section": "",
    "text": "5.1 소개\n이 장에서는 깔끔한 데이터(tidy data) 라는 시스템을 사용하여 R에서 데이터를 일관되게 구성하는 방법을 배울 것입니다. 데이터를 이 형식으로 만드는 데는 초기에 약간의 작업이 필요하지만, 그 작업은 장기적으로 성과를 냅니다. 일단 깔끔한 데이터와 tidyverse의 패키지에서 제공하는 깔끔한 도구를 갖추면, 한 표현에서 다른 표현으로 데이터를 뭉개는 데(munging) 훨씬 적은 시간을 소비하게 되어, 관심 있는 데이터 질문에 더 많은 시간을 할애할 수 있습니다.\n이 장에서는 먼저 깔끔한 데이터의 정의를 배우고 간단한 장난감 데이터셋에 적용되는 것을 볼 것입니다. 그런 다음 데이터 정리에 사용할 주요 도구인 피벗(pivoting)에 대해 자세히 알아볼 것입니다. 피벗을 사용하면 값을 변경하지 않고도 데이터의 형태를 변경할 수 있습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터 정리</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#소개",
    "href": "data-tidy.html#소개",
    "title": "5  데이터 정리",
    "section": "",
    "text": "“행복한 가정은 모두 비슷하고, 불행한 가정은 모두 저마다의 이유로 불행하다.” — 레프 톨스토이\n\n\n“깔끔한(tidy) 데이터셋은 모두 비슷하지만, 지저분한(messy) 데이터셋은 모두 저마다의 방식으로 지저분하다.” — 해들리 위컴\n\n\n\n\n5.1.1 선수 지식\n이 장에서는 지저분한 데이터셋을 정리하는 데 도움이 되는 많은 도구를 제공하는 패키지인 tidyr에 초점을 맞출 것입니다. tidyr은 핵심 tidyverse의 멤버입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\n\n이 장부터는 library(tidyverse)의 로드 메시지를 숨깁니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터 정리</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-tidy-data",
    "href": "data-tidy.html#sec-tidy-data",
    "title": "5  데이터 정리",
    "section": "\n5.2 깔끔한 데이터(Tidy data)",
    "text": "5.2 깔끔한 데이터(Tidy data)\n동일한 기본 데이터를 여러 가지 방식으로 표현할 수 있습니다. 아래 예제는 동일한 데이터를 세 가지 다른 방식으로 구성한 것을 보여줍니다. 각 데이터셋은 네 가지 변수인 국가(country), 연도(year), 인구(population), 결핵(TB) 사례(cases) 수에 대해 동일한 값을 보여주지만, 각 데이터셋은 값을 다른 방식으로 구성합니다.\n\ntable1\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\ntable2\n#&gt; # A tibble: 12 × 4\n#&gt;   country      year type           count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999 cases            745\n#&gt; 2 Afghanistan  1999 population  19987071\n#&gt; 3 Afghanistan  2000 cases           2666\n#&gt; 4 Afghanistan  2000 population  20595360\n#&gt; 5 Brazil       1999 cases          37737\n#&gt; 6 Brazil       1999 population 172006362\n#&gt; # ℹ 6 more rows\n\ntable3\n#&gt; # A tibble: 6 × 3\n#&gt;   country      year rate             \n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n#&gt; 1 Afghanistan  1999 745/19987071     \n#&gt; 2 Afghanistan  2000 2666/20595360    \n#&gt; 3 Brazil       1999 37737/172006362  \n#&gt; 4 Brazil       2000 80488/174504898  \n#&gt; 5 China        1999 212258/1272915272\n#&gt; 6 China        2000 213766/1280428583\n\n이것들은 모두 동일한 기본 데이터의 표현이지만 사용하기에 똑같이 쉽지는 않습니다. 그중 하나인 table1은 깔끔하기(tidy) 때문에 tidyverse 내에서 작업하기가 훨씬 쉬울 것입니다.\n데이터셋을 깔끔하게 만드는 세 가지 상호 관련된 규칙이 있습니다:\n\n각 변수는 하나의 열(column)이어야 하고, 각 열은 하나의 변수여야 합니다.\n각 관측값은 하나의 행(row)이어야 하고, 각 행은 하나의 관측값이어야 합니다.\n각 값은 하나의 셀(cell)이어야 하고, 각 셀은 하나의 값이어야 합니다.\n\nFigure 5.1 는 규칙을 시각적으로 보여줍니다.\n\n\n\n\n\n\n\nFigure 5.1: 다음 세 가지 규칙이 데이터셋을 깔끔하게 만듭니다: 변수는 열이고, 관측값은 행이며, 값은 셀입니다.\n\n\n\n\n왜 데이터가 깔끔한지 확인해야 할까요? 두 가지 주요 이점이 있습니다:\n\n데이터를 저장하는 일관된 방식을 선택하는 것에는 일반적인 이점이 있습니다. 일관된 데이터 구조가 있으면 근본적인 통일성이 있기 때문에 그와 함께 작동하는 도구를 배우기가 더 쉽습니다.\n변수를 열에 배치하는 것에는 구체적인 이점이 있는데, 이를 통해 R의 벡터화된 특성이 빛을 발할 수 있기 때문입니다. Section 3.3.1 와 Section 3.5.2 에서 배웠듯이 대부분의 내장 R 함수는 값의 벡터와 함께 작동합니다. 따라서 깔끔한 데이터를 변형하는 것이 특히 자연스럽게 느껴집니다.\n\ndplyr, ggplot2 및 tidyverse의 다른 모든 패키지는 깔끔한 데이터와 함께 작동하도록 설계되었습니다. 다음은 table1로 작업하는 방법을 보여주는 몇 가지 작은 예입니다.\n\n# 10,000명당 비율 계산\ntable1 |&gt;\n  mutate(rate = cases / population * 10000)\n#&gt; # A tibble: 6 × 5\n#&gt;   country      year  cases population  rate\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071 0.373\n#&gt; 2 Afghanistan  2000   2666   20595360 1.29 \n#&gt; 3 Brazil       1999  37737  172006362 2.19 \n#&gt; 4 Brazil       2000  80488  174504898 4.61 \n#&gt; 5 China        1999 212258 1272915272 1.67 \n#&gt; 6 China        2000 213766 1280428583 1.67\n\n# 연도별 총 사례 수 계산\ntable1 |&gt; \n  group_by(year) |&gt; \n  summarize(total_cases = sum(cases))\n#&gt; # A tibble: 2 × 2\n#&gt;    year total_cases\n#&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1  1999      250740\n#&gt; 2  2000      296920\n\n# 시간 경과에 따른 변화 시각화\nggplot(table1, aes(x = year, y = cases)) +\n  geom_line(aes(group = country), color = \"grey50\") +\n  geom_point(aes(color = country, shape = country)) +\n  scale_x_continuous(breaks = c(1999, 2000)) # x-axis breaks at 1999 and 2000\n\n\n\n\n\n\n\n\n5.2.1 연습문제\n\n각 샘플 테이블에 대해 각 관측값과 각 열이 무엇을 나타내는지 설명하세요.\n\ntable2와 table3에 대한 rate를 계산하는 데 사용할 프로세스를 스케치하세요. 네 가지 작업을 수행해야 합니다:\n\n국가별 연도별 결핵 사례 수를 추출합니다.\n일치하는 국가별 연도별 인구를 추출합니다.\n사례를 인구로 나누고 10000을 곱합니다.\n적절한 위치에 다시 저장합니다.\n\n이러한 작업을 실제로 수행하는 데 필요한 모든 함수를 아직 배우지는 않았지만 필요한 변형에 대해 생각할 수는 있어야 합니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터 정리</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-pivoting",
    "href": "data-tidy.html#sec-pivoting",
    "title": "5  데이터 정리",
    "section": "\n5.3 데이터 길게 늘리기",
    "text": "5.3 데이터 길게 늘리기\n깔끔한 데이터의 원칙이 너무 뻔해 보여서 깔끔하지 않은 데이터셋을 만날 일이 있을지 궁금할 수도 있습니다. 하지만 불행히도 대부분의 실제 데이터는 깔끔하지 않습니다. 두 가지 주요 이유가 있습니다:\n\n데이터는 종종 분석 이외의 목표를 용이하게 하기 위해 구성됩니다. 예를 들어, 분석이 아닌 데이터 입력을 쉽게 하기 위해 데이터가 구조화되는 것이 일반적입니다.\n대부분의 사람들은 깔끔한 데이터의 원칙에 익숙하지 않으며, 데이터를 다루는 데 많은 시간을 보내지 않는 한 스스로 도출하기 어렵습니다.\n\n즉, 대부분의 실제 분석에는 최소한 약간의 정리가 필요합니다. 근본적인 변수와 관측값이 무엇인지 파악하는 것으로 시작할 것입니다. 때로는 쉽지만, 다른 경우에는 데이터를 처음 생성한 사람들과 상의해야 할 수도 있습니다. 다음으로, 변수는 열에 있고 관측값은 행에 있는 깔끔한 형태로 데이터를 피벗(pivot) 합니다.\ntidyr은 데이터를 피벗하기 위한 두 가지 함수인 pivot_longer()와 pivot_wider()를 제공합니다. 가장 일반적인 경우이기 때문에 pivot_longer()부터 시작하겠습니다. 몇 가지 예제를 살펴보겠습니다.\n\n5.3.1 열 이름에 있는 데이터\nbillboard 데이터셋은 2000년 노래의 빌보드 순위를 기록합니다:\n\nbillboard\n#&gt; # A tibble: 317 × 79\n#&gt;   artist       track               date.entered   wk1   wk2   wk3   wk4   wk5\n#&gt;   &lt;chr&gt;        &lt;chr&gt;               &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac        Baby Don't Cry (Ke… 2000-02-26      87    82    72    77    87\n#&gt; 2 2Ge+her      The Hardest Part O… 2000-09-02      91    87    92    NA    NA\n#&gt; 3 3 Doors Down Kryptonite          2000-04-08      81    70    68    67    66\n#&gt; 4 3 Doors Down Loser               2000-10-21      76    76    72    69    67\n#&gt; 5 504 Boyz     Wobble Wobble       2000-04-15      57    34    25    17    17\n#&gt; 6 98^0         Give Me Just One N… 2000-08-19      51    39    34    26    26\n#&gt; # ℹ 311 more rows\n#&gt; # ℹ 71 more variables: wk6 &lt;dbl&gt;, wk7 &lt;dbl&gt;, wk8 &lt;dbl&gt;, wk9 &lt;dbl&gt;, …\n\n이 데이터셋에서 각 관측값은 노래입니다. 처음 세 열(artist, track, date.entered)은 노래를 설명하는 변수입니다. 그 다음에는 매주 노래의 순위를 설명하는 76개의 열(wk1-wk76)이 있습니다1. 여기서 열 이름은 하나의 변수(week)이고 셀 값은 다른 변수(rank)입니다.\n이 데이터를 정리하기 위해 pivot_longer()를 사용할 것입니다:\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\"\n  )\n#&gt; # A tibble: 24,092 × 5\n#&gt;    artist track                   date.entered week   rank\n#&gt;    &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt;  1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt;  2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt;  3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt;  4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt;  5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt;  6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt;  7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n#&gt;  8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n#&gt;  9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n#&gt; 10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n#&gt; # ℹ 24,082 more rows\n\n데이터 뒤에는 세 가지 주요 인수가 있습니다:\n\n\ncols는 피벗해야 하는 열, 즉 변수가 아닌 열을 지정합니다. 이 인수는 select()와 동일한 구문을 사용하므로 여기서는 !c(artist, track, date.entered) 또는 starts_with(\"wk\")를 사용할 수 있습니다.\n\nnames_to는 열 이름에 저장된 변수의 이름을 지정하며, 우리는 그 변수의 이름을 week라고 지었습니다.\n\nvalues_to는 셀 값에 저장된 변수의 이름을 지정하며, 우리는 그 변수의 이름을 rank라고 지었습니다.\n\n코드에서 \"week\"와 \"rank\"는 인용부호로 묶여 있는데, 이는 우리가 생성하는 새 변수이며 pivot_longer() 호출을 실행할 때 데이터에 아직 존재하지 않기 때문입니다.\n이제 결과로 나온 더 긴 데이터 프레임에 주의를 돌려봅시다. 노래가 76주 미만 동안 상위 100위 안에 있으면 어떻게 될까요? 2 Pac의 “Baby Don’t Cry”를 예로 들어보겠습니다. 위의 출력은 이 노래가 7주 동안만 상위 100위 안에 있었고 나머지 모든 주는 결측값으로 채워져 있음을 시사합니다. 이러한 NA는 실제로 알 수 없는 관측값을 나타내는 것이 아니라 데이터셋의 구조에 의해 강제로 존재하게 된 것이므로2, values_drop_na = TRUE를 설정하여 pivot_longer()에 제거하도록 요청할 수 있습니다:\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  )\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered week   rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt; # ℹ 5,301 more rows\n\n이제 행 수가 훨씬 줄어들어 NA가 있는 많은 행이 삭제되었음을 나타냅니다.\n또한 노래가 76주 이상 상위 100위 안에 있으면 어떻게 되는지 궁금할 수도 있습니다. 이 데이터에서는 알 수 없지만 추가 열 wk77, wk78, …이 데이터셋에 추가될 것이라고 추측할 수 있습니다.\n이 데이터는 이제 깔끔하지만, mutate()와 readr::parse_number()를 사용하여 week의 값을 문자열에서 숫자로 변환하면 향후 계산을 조금 더 쉽게 만들 수 있습니다. parse_number()는 다른 모든 텍스트를 무시하고 문자열에서 첫 번째 숫자를 추출하는 편리한 함수입니다.\n\nbillboard_longer &lt;- billboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  ) |&gt; \n  mutate(\n    week = parse_number(week)\n  )\nbillboard_longer\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered  week  rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26       1    87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26       2    82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26       3    72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26       4    77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26       5    87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26       6    94\n#&gt; # ℹ 5,301 more rows\n\n이제 모든 주 번호가 하나의 변수에 있고 모든 순위 값이 다른 변수에 있으므로 시간 경과에 따른 노래 순위 변화를 시각화하기에 좋은 위치에 있습니다. 코드는 아래와 같고 결과는 Figure 5.2 에 있습니다. 20주 이상 상위 100위 안에 머무르는 노래가 거의 없음을 알 수 있습니다.\n\nbillboard_longer |&gt; \n  ggplot(aes(x = week, y = rank, group = track)) + \n  geom_line(alpha = 0.25) + \n  scale_y_reverse()\n\n\n\n\n\n\nFigure 5.2: 시간 경과에 따른 노래 순위 변화를 보여주는 선 플롯.\n\n\n\n\n\n5.3.2 피벗은 어떻게 작동하나요?\n이제 피벗을 사용하여 데이터의 모양을 바꾸는 방법을 보았으므로, 피벗이 데이터에 어떤 작업을 수행하는지에 대한 직관을 얻기 위해 시간을 조금 투자해 봅시다. 무슨 일이 일어나고 있는지 보기 쉽도록 아주 간단한 데이터셋으로 시작하겠습니다. id가 A, B, C인 세 명의 환자가 있고 각 환자에 대해 두 번의 혈압 측정을 한다고 가정해 봅시다. 작은 티블을 손으로 구성하는 편리한 함수인 tribble()로 데이터를 만들 것입니다:\n\ndf &lt;- tribble(\n  ~id,  ~bp1, ~bp2,\n   \"A\",  100,  120,\n   \"B\",  140,  115,\n   \"C\",  120,  125\n)\n\n우리는 새 데이터셋이 세 가지 변수인 id(이미 존재함), measurement(열 이름), value(셀 값)를 갖기를 원합니다. 이를 달성하려면 df를 더 길게 피벗해야 합니다:\n\ndf |&gt; \n  pivot_longer(\n    cols = bp1:bp2,\n    names_to = \"measurement\",\n    values_to = \"value\"\n  )\n#&gt; # A tibble: 6 × 3\n#&gt;   id    measurement value\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 A     bp1           100\n#&gt; 2 A     bp2           120\n#&gt; 3 B     bp1           140\n#&gt; 4 B     bp2           115\n#&gt; 5 C     bp1           120\n#&gt; 6 C     bp2           125\n\n형태 변경(reshaping)은 어떻게 작동할까요? 열별로 생각하면 더 쉽게 알 수 있습니다. Figure 5.3 에 표시된 것처럼 원본 데이터셋에서 이미 변수였던 열(id)의 값은 피벗되는 각 열에 대해 한 번씩 반복되어야 합니다.\n\n\n\n\n\n\n\nFigure 5.3: 이미 변수인 열은 피벗되는 각 열에 대해 한 번씩 반복되어야 합니다.\n\n\n\n\n열 이름은 Figure 5.4 에 표시된 것처럼 names_to에 의해 정의된 이름의 새 변수에서 값이 됩니다. 원본 데이터셋의 각 행에 대해 한 번씩 반복되어야 합니다.\n\n\n\n\n\n\n\nFigure 5.4: 피벗된 열의 열 이름은 새 열의 값이 됩니다. 값은 원본 데이터셋의 각 행에 대해 한 번씩 반복되어야 합니다.\n\n\n\n\n셀 값 또한 values_to에 의해 정의된 이름을 가진 새 변수의 값이 됩니다. 행별로 풀립니다. Figure 5.5 는 프로세스를 보여줍니다.\n\n\n\n\n\n\n\nFigure 5.5: 값의 수는 보존되지만(반복되지 않음) 행별로 풀립니다.\n\n\n\n\n\n5.3.3 열 이름에 많은 변수가 있는 경우\n열 이름에 여러 정보가 섞여 있어 이를 별도의 새 변수에 저장하고 싶을 때 더 어려운 상황이 발생합니다. 예를 들어 위에서 본 table1과 친구들의 소스인 who2 데이터셋을 가져와 보겠습니다:\n\nwho2\n#&gt; # A tibble: 7,240 × 58\n#&gt;   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980       NA        NA        NA        NA        NA\n#&gt; 2 Afghanistan  1981       NA        NA        NA        NA        NA\n#&gt; 3 Afghanistan  1982       NA        NA        NA        NA        NA\n#&gt; 4 Afghanistan  1983       NA        NA        NA        NA        NA\n#&gt; 5 Afghanistan  1984       NA        NA        NA        NA        NA\n#&gt; 6 Afghanistan  1985       NA        NA        NA        NA        NA\n#&gt; # ℹ 7,234 more rows\n#&gt; # ℹ 51 more variables: sp_m_5564 &lt;dbl&gt;, sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, …\n\n세계보건기구(WHO)에서 수집한 이 데이터셋은 결핵 진단에 대한 정보를 기록합니다. 이미 변수이고 해석하기 쉬운 두 개의 열 country와 year가 있습니다. 그 뒤에는 sp_m_014, ep_m_4554, rel_m_3544와 같은 56개의 열이 있습니다. 이 열들을 충분히 오래 쳐다보면 패턴이 있음을 알 수 있습니다. 각 열 이름은 _로 구분된 세 부분으로 구성됩니다. 첫 번째 부분인 sp/rel/ep는 진단에 사용된 방법을 설명하고, 두 번째 부분인 m/f는 성별(gender, 이 데이터셋에서는 이진 변수로 코딩됨)이며, 세 번째 부분인 014/1524/2534/3544/4554/5564/65는 나이(age) 범위(예: 014는 0-14세를 나타냄)입니다.\n따라서 이 경우 who2에는 6가지 정보가 기록되어 있습니다: 국가와 연도(이미 열임), 진단 방법, 성별 범주, 연령대 범주(다른 열 이름에 포함됨), 해당 범주의 환자 수(셀 값). 이 6가지 정보를 6개의 별도 열로 구성하기 위해 names_to에 열 이름 벡터를 사용하고, 원래 변수 이름을 조각으로 나누기 위한 지시자로 names_sep을 사용하며, values_to에 열 이름을 사용하여 pivot_longer()를 씁니다:\n\nwho2 |&gt; \n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"), \n    names_sep = \"_\",\n    values_to = \"count\"\n  )\n#&gt; # A tibble: 405,440 × 6\n#&gt;   country      year diagnosis gender age   count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980 sp        m      014      NA\n#&gt; 2 Afghanistan  1980 sp        m      1524     NA\n#&gt; 3 Afghanistan  1980 sp        m      2534     NA\n#&gt; 4 Afghanistan  1980 sp        m      3544     NA\n#&gt; 5 Afghanistan  1980 sp        m      4554     NA\n#&gt; 6 Afghanistan  1980 sp        m      5564     NA\n#&gt; # ℹ 405,434 more rows\n\nnames_sep의 대안은 names_pattern으로, Chapter 15 에서 정규 표현식에 대해 배우고 나면 더 복잡한 명명 시나리오에서 변수를 추출하는 데 사용할 수 있습니다.\n개념적으로 이것은 이미 본 더 간단한 경우의 작은 변형일 뿐입니다. Figure 5.6 는 기본 아이디어를 보여줍니다. 이제 열 이름이 단일 열로 피벗되는 대신 여러 열로 피벗됩니다. 두 단계(먼저 피벗한 다음 분리)로 일어난다고 상상할 수 있지만 내부적으로는 더 빠르기 때문에 단일 단계로 일어납니다.\n\n\n\n\n\n\n\nFigure 5.6: 이름에 여러 정보가 있는 열을 피벗한다는 것은 각 열 이름이 이제 여러 출력 열의 값을 채운다는 것을 의미합니다.\n\n\n\n\n\n5.3.4 열 헤더의 데이터 및 변수 이름\n복잡성의 다음 단계는 열 이름에 변수 값과 변수 이름이 섞여 있는 경우입니다. 예를 들어 household 데이터셋을 가져와 보겠습니다:\n\nhousehold\n#&gt; # A tibble: 5 × 5\n#&gt;   family dob_child1 dob_child2 name_child1 name_child2\n#&gt;    &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      \n#&gt; 1      1 1998-11-26 2000-01-29 Susan       Jose       \n#&gt; 2      2 1996-06-22 NA         Mark        &lt;NA&gt;       \n#&gt; 3      3 2002-07-11 2004-04-05 Sam         Seth       \n#&gt; 4      4 2004-10-10 2009-08-27 Craig       Khai       \n#&gt; 5      5 2000-12-05 2005-02-28 Parker      Gracie\n\n이 데이터셋에는 최대 두 자녀의 이름과 생년월일이 있는 다섯 가족에 대한 데이터가 포함되어 있습니다. 이 데이터셋의 새로운 과제는 열 이름에 두 변수(dob, name)의 이름과 다른 변수(child, 값은 1 또는 2)의 값이 포함되어 있다는 것입니다. 이 문제를 해결하려면 다시 names_to에 벡터를 제공해야 하지만 이번에는 특수 \".value\" 센티넬(sentinel)을 사용합니다. 이것은 변수의 이름이 아니라 pivot_longer()에 다른 작업을 수행하도록 지시하는 고유한 값입니다. 이는 일반적인 values_to 인수를 재정의하여 피벗된 열 이름의 첫 번째 구성 요소를 출력의 변수 이름으로 사용합니다.\n\nhousehold |&gt; \n  pivot_longer(\n    cols = !family, \n    names_to = c(\".value\", \"child\"), \n    names_sep = \"_\", \n    values_drop_na = TRUE\n  )\n#&gt; # A tibble: 9 × 4\n#&gt;   family child  dob        name \n#&gt;    &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;\n#&gt; 1      1 child1 1998-11-26 Susan\n#&gt; 2      1 child2 2000-01-29 Jose \n#&gt; 3      2 child1 1996-06-22 Mark \n#&gt; 4      3 child1 2002-07-11 Sam  \n#&gt; 5      3 child2 2004-04-05 Seth \n#&gt; 6      4 child1 2004-10-10 Craig\n#&gt; # ℹ 3 more rows\n\n입력의 형태로 인해 명시적인 결측 변수(예: 자녀가 한 명뿐인 가족의 경우)가 강제로 생성되므로 다시 values_drop_na = TRUE를 사용합니다.\nFigure 5.7 는 더 간단한 예제로 기본 아이디어를 보여줍니다. names_to에 \".value\"를 사용하면 입력의 열 이름이 출력의 값과 변수 이름 모두에 기여합니다.\n\n\n\n\n\n\n\nFigure 5.7: names_to = c(\".value\", \"num\")으로 피벗하면 열 이름이 두 구성 요소로 분할됩니다. 첫 번째 부분은 출력 열 이름(x 또는 y)을 결정하고 두 번째 부분은 num 열의 값을 결정합니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터 정리</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#데이터-넓게-만들기",
    "href": "data-tidy.html#데이터-넓게-만들기",
    "title": "5  데이터 정리",
    "section": "\n5.4 데이터 넓게 만들기",
    "text": "5.4 데이터 넓게 만들기\n지금까지 값이 열 이름에 들어가 있는 일반적인 문제를 해결하기 위해 pivot_longer()를 사용했습니다. 다음으로 열을 늘리고 행을 줄여 데이터셋을 더 넓게 만들고 하나의 관측값이 여러 행에 걸쳐 있을 때 도움이 되는 pivot_wider()로 피벗(하하)해 보겠습니다. 이것은 야생에서 덜 흔하게 발생하는 것 같지만 정부 데이터를 다룰 때 많이 나타나는 것 같습니다.\n환자 경험에 대한 데이터를 수집하는 메디케어 및 메디케이드 서비스 센터(Centers of Medicare and Medicaid services)의 데이터셋인 cms_patient_experience를 살펴보는 것으로 시작하겠습니다:\n\ncms_patient_experience\n#&gt; # A tibble: 500 × 5\n#&gt;   org_pac_id org_nm                     measure_cd   measure_title   prf_rate\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                      &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_1  CAHPS for MIPS…       63\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_2  CAHPS for MIPS…       87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_3  CAHPS for MIPS…       86\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_5  CAHPS for MIPS…       57\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_8  CAHPS for MIPS…       85\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_12 CAHPS for MIPS…       24\n#&gt; # ℹ 494 more rows\n\n연구의 핵심 단위는 조직이지만, 각 조직은 6개 행에 걸쳐 있으며 각 행은 조사 조직에서 수행된 측정 하나에 해당합니다. distinct()를 사용하여 measure_cd와 measure_title의 전체 값 집합을 볼 수 있습니다:\n\ncms_patient_experience |&gt; \n  distinct(measure_cd, measure_title)\n#&gt; # A tibble: 6 × 2\n#&gt;   measure_cd   measure_title                                                 \n#&gt;   &lt;chr&gt;        &lt;chr&gt;                                                         \n#&gt; 1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and In…\n#&gt; 2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate            \n#&gt; 3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider              \n#&gt; 4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education            \n#&gt; 5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff        \n#&gt; 6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources\n\n이 두 열 중 어느 것도 특별히 좋은 변수 이름이 되지 않습니다. measure_cd는 변수의 의미를 암시하지 않으며 measure_title은 공백이 포함된 긴 문장입니다. 지금은 measure_cd를 새 열 이름의 소스로 사용하겠지만, 실제 분석에서는 짧고 의미 있는 자체 변수 이름을 만들고 싶을 수 있습니다.\npivot_wider()는 pivot_longer()와 반대되는 인터페이스를 가지고 있습니다. 새 열 이름을 선택하는 대신 값(values_from)과 열 이름(names_from)을 정의하는 기존 열을 제공해야 합니다:\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n#&gt; # A tibble: 500 × 9\n#&gt;   org_pac_id org_nm                   measure_title   CAHPS_GRP_1 CAHPS_GRP_2\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                    &lt;chr&gt;                 &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          63          NA\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; # ℹ 494 more rows\n#&gt; # ℹ 4 more variables: CAHPS_GRP_3 &lt;dbl&gt;, CAHPS_GRP_5 &lt;dbl&gt;, …\n\n출력이 아주 맞아 보이지는 않습니다. 여전히 각 조직에 대해 여러 행이 있는 것 같습니다. 그 이유는 pivot_wider()에 어떤 열(들)이 각 행을 고유하게 식별하는 값을 가지고 있는지 알려줘야 하기 때문입니다. 이 경우 \"org\"로 시작하는 변수들입니다:\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    id_cols = starts_with(\"org\"),\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n#&gt; # A tibble: 95 × 8\n#&gt;   org_pac_id org_nm           CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICA…          63          87          86          57\n#&gt; 2 0446162697 ASSOCIATION OF …          59          85          83          63\n#&gt; 3 0547164295 BEAVER MEDICAL …          49          NA          75          44\n#&gt; 4 0749333730 CAPE PHYSICIANS…          67          84          85          65\n#&gt; 5 0840104360 ALLIANCE PHYSIC…          66          87          87          64\n#&gt; 6 0840109864 REX HOSPITAL INC          73          87          84          67\n#&gt; # ℹ 89 more rows\n#&gt; # ℹ 2 more variables: CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\n이것이 우리가 찾고 있는 출력을 제공합니다.\n\n5.4.1 pivot_wider()는 어떻게 작동하나요?\npivot_wider()가 어떻게 작동하는지 이해하기 위해 다시 아주 간단한 데이터셋으로 시작해 봅시다. 이번에는 id가 A와 B인 두 명의 환자가 있고 환자 A에 대해 세 번, 환자 B에 대해 두 번의 혈압 측정이 있습니다:\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"B\",        \"bp1\",    140,\n  \"B\",        \"bp2\",    115, \n  \"A\",        \"bp2\",    120,\n  \"A\",        \"bp3\",    105\n)\n\nvalue 열에서 값을 가져오고 measurement 열에서 이름을 가져올 것입니다:\n\ndf |&gt; \n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   id      bp1   bp2   bp3\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A       100   120   105\n#&gt; 2 B       140   115    NA\n\n프로세스를 시작하기 위해 pivot_wider()는 먼저 행과 열에 무엇이 들어갈지 파악해야 합니다. 새 열 이름은 measurement의 고유 값이 될 것입니다.\n\ndf |&gt; \n  distinct(measurement) |&gt; \n  pull()\n#&gt; [1] \"bp1\" \"bp2\" \"bp3\"\n\n기본적으로 출력의 행은 새 이름이나 값에 들어가지 않는 모든 변수에 의해 결정됩니다. 이것들을 id_cols라고 합니다. 여기에는 열이 하나만 있지만 일반적으로는 얼마든지 있을 수 있습니다.\n\ndf |&gt; \n  select(!measurement & !value) |&gt; \n  distinct()\n#&gt; # A tibble: 2 × 1\n#&gt;   id   \n#&gt;   &lt;chr&gt;\n#&gt; 1 A    \n#&gt; 2 B\n\n그런 다음 pivot_wider()는 이 결과들을 결합하여 빈 데이터 프레임을 생성합니다:\n\ndf |&gt; \n  select(!measurement & !value) |&gt; \n  distinct() |&gt; \n  mutate(x = NA, y = NA, z = NA)\n#&gt; # A tibble: 2 × 4\n#&gt;   id    x     y     z    \n#&gt;   &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 A     NA    NA    NA   \n#&gt; 2 B     NA    NA    NA\n\n그런 다음 입력의 데이터를 사용하여 모든 결측값을 채웁니다. 이 경우 환자 B에 대한 세 번째 혈압 측정이 없으므로 출력의 모든 셀에 해당하는 입력 값이 있는 것은 아니며 해당 셀은 결측 상태로 유지됩니다. Chapter 18 에서 pivot_wider()가 결측값을 “만들” 수 있다는 이 아이디어를 다시 다룰 것입니다.\n또한 입력에 출력의 한 셀에 해당하는 여러 행이 있는 경우 어떻게 되는지 궁금할 수 있습니다. 아래 예제에는 id “A”와 measurement “bp1”에 해당하는 두 개의 행이 있습니다:\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"A\",        \"bp1\",    102,\n  \"A\",        \"bp2\",    120,\n  \"B\",        \"bp1\",    140, \n  \"B\",        \"bp2\",    115\n)\n\n이것을 피벗하려고 시도하면 리스트 열(list-columns)이 포함된 출력을 얻게 되는데, 이에 대해서는 Chapter 23 에서 더 자세히 배울 것입니다:\n\ndf |&gt;\n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n#&gt; Warning: Values from `value` are not uniquely identified; output will contain\n#&gt; list-cols.\n#&gt; • Use `values_fn = list` to suppress this warning.\n#&gt; • Use `values_fn = {summary_fun}` to summarise duplicates.\n#&gt; • Use the following dplyr code to identify duplicates.\n#&gt;   {data} |&gt;\n#&gt;   dplyr::summarise(n = dplyr::n(), .by = c(id, measurement)) |&gt;\n#&gt;   dplyr::filter(n &gt; 1L)\n#&gt; # A tibble: 2 × 3\n#&gt;   id    bp1       bp2      \n#&gt;   &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n#&gt; 2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\n아직 이런 종류의 데이터를 다루는 방법을 모르기 때문에 경고의 힌트를 따라 문제가 어디에 있는지 파악하고 싶을 것입니다:\n\ndf |&gt; \n  group_by(id, measurement) |&gt; \n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 × 3\n#&gt;   id    measurement     n\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 A     bp1             2\n\n데이터에 무엇이 잘못되었는지 파악하고 근본적인 손상을 복구하거나 그룹화 및 요약 기술을 사용하여 행과 열 값의 각 조합에 단일 행만 있도록 하는 것은 여러분의 몫입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터 정리</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#요약",
    "href": "data-tidy.html#요약",
    "title": "5  데이터 정리",
    "section": "\n5.5 요약",
    "text": "5.5 요약\n이 장에서는 깔끔한 데이터, 즉 변수는 열에 있고 관측값은 행에 있는 데이터에 대해 배웠습니다. 깔끔한 데이터는 대부분의 함수가 이해하는 일관된 구조이기 때문에 tidyverse에서 작업하기가 더 쉬우며, 주된 과제는 어떤 구조로 받든 데이터를 깔끔한 형식으로 변환하는 것입니다. 이를 위해 깔끔하지 않은 많은 데이터셋을 정리할 수 있는 pivot_longer()와 pivot_wider()에 대해 배웠습니다. 여기서 제시한 예제는 vignette(\"pivot\", package = \"tidyr\")에서 선택한 것이므로 이 장에서 도움이 되지 않는 문제에 직면하면 해당 비네트가 다음에 시도해 볼 수 있는 좋은 장소입니다.\n또 다른 과제는 주어진 데이터셋에 대해 더 긴 버전이나 더 넓은 버전 중 하나를 “깔끔한” 것이라고 라벨링하는 것이 불가능할 수 있다는 것입니다. 이는 부분적으로 깔끔한 데이터에 대한 우리의 정의를 반영하는 것인데, 우리는 깔끔한 데이터가 각 열에 하나의 변수를 갖는다고 말했지만 실제로 변수가 무엇인지는 정의하지 않았습니다(그리고 그렇게 하기는 놀라울 정도로 어렵습니다). 실용적으로 생각해서 분석을 가장 쉽게 만드는 것이 변수라고 말하는 것은 전적으로 괜찮습니다. 따라서 계산을 수행하는 방법을 알아내는 데 막힌다면 데이터 구성을 바꾸는 것을 고려해 보세요. 필요에 따라 어지럽히고(untidy), 변형하고, 다시 정리하는(re-tidy) 것을 두려워하지 마세요!\n이 장을 즐겼고 기본 이론에 대해 더 알고 싶다면 Journal of Statistical Software에 게시된 Tidy Data 논문에서 역사와 이론적 토대에 대해 자세히 알아볼 수 있습니다.\n이제 상당한 양의 R 코드를 작성하고 있으므로 코드를 파일과 디렉터리로 구성하는 것에 대해 더 배울 때입니다. 다음 장에서는 스크립트와 프로젝트의 이점과 삶을 더 쉽게 만들기 위해 제공하는 많은 도구 중 일부에 대해 모두 배울 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터 정리</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#footnotes",
    "href": "data-tidy.html#footnotes",
    "title": "5  데이터 정리",
    "section": "",
    "text": "노래는 2000년 어느 시점에 상위 100위 안에 들었다면 포함되며, 등장 후 최대 72주 동안 추적됩니다.↩︎\nChapter 18 에서 이 아이디어를 다시 다룰 것입니다.↩︎",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터 정리</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html",
    "href": "workflow-scripts.html",
    "title": "6  워크플로우: 스크립트와 프로젝트",
    "section": "",
    "text": "6.1 스크립트\n이 장에서는 코드를 구성하는 두 가지 필수 도구인 스크립트와 프로젝트에 대해 소개합니다.\n지금까지는 콘솔을 사용하여 코드를 실행했습니다. 콘솔은 시작하기에 좋은 곳이지만, 더 복잡한 ggplot2 그래픽과 더 긴 dplyr 파이프라인을 만들다 보면 금방 비좁게 느껴질 것입니다. 작업할 공간을 더 확보하려면 스크립트 편집기를 사용하세요. File(파일) 메뉴를 클릭하고 New File(새 파일)을 선택한 다음 R script(R 스크립트)를 선택하거나 키보드 단축키 Cmd/Ctrl + Shift + N을 사용하여 엽니다. 이제 Figure 6.1 처럼 네 개의 창이 보일 것입니다. 스크립트 편집기는 코드를 실험해 보기에 아주 좋은 곳입니다. 무언가를 변경하고 싶을 때 전체를 다시 입력할 필요 없이 스크립트를 편집하고 다시 실행하기만 하면 됩니다. 그리고 작동하고 원하는 대로 수행하는 코드를 작성하고 나면 나중에 쉽게 다시 볼 수 있도록 스크립트 파일로 저장할 수 있습니다.\nFigure 6.1: 스크립트 편집기를 열면 IDE의 왼쪽 상단에 새 창이 추가됩니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>워크플로우: 스크립트와 프로젝트</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#스크립트",
    "href": "workflow-scripts.html#스크립트",
    "title": "6  워크플로우: 스크립트와 프로젝트",
    "section": "",
    "text": "6.1.1 코드 실행하기\n스크립트 편집기는 복잡한 ggplot2 플롯이나 긴 dplyr 조작 시퀀스를 구축하기에 훌륭한 장소입니다. 스크립트 편집기를 효과적으로 사용하는 열쇠는 가장 중요한 키보드 단축키 중 하나인 Cmd/Ctrl + Enter를 외우는 것입니다. 이 단축키는 콘솔에서 현재 R 표현식을 실행합니다. 예를 들어 아래 코드를 보세요.\n\nlibrary(dplyr)\nlibrary(nycflights13)\n\nnot_cancelled &lt;- flights |&gt; \n  filter(!is.na(dep_delay))█, !is.na(arr_delay))\n\nnot_cancelled |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(mean = mean(dep_delay))\n\n커서가 █에 있을 때 Cmd/Ctrl + Enter를 누르면 not_cancelled를 생성하는 전체 명령이 실행됩니다. 또한 커서가 다음 문(not_cancelled |&gt;로 시작하는 부분)으로 이동합니다. 따라서 Cmd/Ctrl + Enter를 반복해서 눌러 전체 스크립트를 쉽게 단계별로 실행할 수 있습니다.\n코드를 표현식별로 실행하는 대신 Cmd/Ctrl + Shift + S로 전체 스크립트를 한 번에 실행할 수도 있습니다. 이 작업을 정기적으로 수행하는 것은 코드의 모든 중요한 부분을 스크립트에 캡처했는지 확인하는 좋은 방법입니다.\n항상 필요한 패키지로 스크립트를 시작하는 것이 좋습니다. 그렇게 하면 코드를 다른 사람과 공유할 때 설치해야 할 패키지를 쉽게 알 수 있습니다. 하지만 공유하는 스크립트에 install.packages()를 절대 포함해서는 안 됩니다. 상대방이 주의하지 않으면 컴퓨터의 무언가를 변경할 수 있는 스크립트를 건네주는 것은 배려심 없는 행동입니다!\n앞으로 나올 장들을 진행할 때 스크립트 편집기에서 시작하여 키보드 단축키를 연습하는 것을 강력히 추천합니다. 시간이 지나면 이런 방식으로 콘솔에 코드를 보내는 것이 너무 자연스러워져서 생각조차 하지 않게 될 것입니다.\n\n6.1.2 RStudio 진단\n스크립트 편집기에서 RStudio는 구문 오류를 빨간색 물결선과 사이드바의 X 표시로 강조 표시합니다:\n\n\n\n\n\n\n\n\nX 표시 위에 마우스를 올리면 문제가 무엇인지 확인할 수 있습니다:\n\n\n\n\n\n\n\n\nRStudio는 잠재적인 문제에 대해서도 알려줍니다:\n\n\n\n\n\n\n\n\n\n6.1.3 저장 및 이름 지정\nRStudio는 종료할 때 스크립트 편집기의 내용을 자동으로 저장하고 다시 열 때 자동으로 다시 로드합니다. 그럼에도 불구하고 Untitled1, Untitled2, Untitled3 등을 피하고 대신 스크립트를 저장하고 유익한 이름을 지정하는 것이 좋습니다.\n파일 이름을 code.R이나 myscript.R로 짓고 싶은 유혹이 들 수 있지만, 파일 이름을 선택하기 전에 조금 더 깊이 생각해야 합니다. 파일 이름 지정에 대한 세 가지 중요한 원칙은 다음과 같습니다:\n\n파일 이름은 기계가 읽을 수 있어야 합니다: 공백, 기호 및 특수 문자를 피하세요. 파일을 구별하기 위해 대소문자 구분에 의존하지 마세요.\n파일 이름은 사람이 읽을 수 있어야 합니다: 파일 내용을 설명하는 파일 이름을 사용하세요.\n파일 이름은 기본 정렬과 잘 어울려야 합니다: 알파벳순 정렬이 사용 순서대로 배치되도록 파일 이름을 숫자로 시작하세요.\n\n예를 들어 프로젝트 폴더에 다음 파일들이 있다고 가정해 봅시다.\nalternative model.R\ncode for exploratory analysis.r\nfinalreport.qmd\nFinalReport.qmd\nfig 1.png\nFigure_02.png\nmodel_first_try.R\nrun-first.r\ntemp.txt\n여기에는 다양한 문제가 있습니다: 어떤 파일을 먼저 실행해야 하는지 찾기 어렵고, 파일 이름에 공백이 포함되어 있으며, 이름은 같지만 대소문자가 다른 두 파일(finalreport 대 FinalReport1)이 있고, 일부 이름은 내용(run-first 및 temp)을 설명하지 않습니다.\n동일한 파일 세트의 이름을 지정하고 구성하는 더 좋은 방법은 다음과 같습니다:\n01-load-data.R\n02-exploratory-analysis.R\n03-model-approach-1.R\n04-model-approach-2.R\nfig-01.png\nfig-02.png\nreport-2022-03-20.qmd\nreport-2022-04-02.qmd\nreport-draft-notes.txt\n주요 스크립트에 번호를 매기면 실행 순서가 분명해지고 일관된 명명 체계를 사용하면 변경되는 내용을 쉽게 파악할 수 있습니다. 또한 그림에는 유사하게 라벨이 지정되어 있고, 보고서는 파일 이름에 포함된 날짜로 구분되며, temp는 내용을 더 잘 설명하기 위해 report-draft-notes로 이름이 변경되었습니다. 디렉터리에 파일이 많은 경우 구성을 한 단계 더 발전시켜 다른 유형의 파일(스크립트, 그림 등)을 다른 디렉터리에 배치하는 것이 좋습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>워크플로우: 스크립트와 프로젝트</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#프로젝트",
    "href": "workflow-scripts.html#프로젝트",
    "title": "6  워크플로우: 스크립트와 프로젝트",
    "section": "\n6.2 프로젝트",
    "text": "6.2 프로젝트\n언젠가 여러분은 R을 종료하고 다른 일을 하러 갔다가 나중에 분석으로 돌아와야 할 것입니다. 언젠가 여러분은 여러 분석을 동시에 수행하게 되어 그것들을 분리하고 싶을 것입니다. 언젠가 여러분은 외부 세계에서 데이터를 R로 가져오고 R의 수치 결과와 그림을 다시 세상 밖으로 보내야 할 것입니다.\n이러한 실제 상황을 처리하려면 두 가지 결정을 내려야 합니다:\n\n진실의 원천(source of truth)은 무엇입니까? 일어난 일에 대한 지속적인 기록으로 무엇을 저장하시겠습니까?\n분석은 어디에 있습니까?\n\n\n6.2.1 진실의 원천은 무엇입니까?\n초보자에게는 현재 환경(Environment)에 분석 전체에서 생성한 모든 객체가 포함되어 있다고 믿는 것이 괜찮습니다. 하지만 더 큰 프로젝트에서 작업하거나 다른 사람과 협업하기 쉽게 하려면 진실의 원천은 R 스크립트여야 합니다. R 스크립트(및 데이터 파일)를 사용하면 환경을 다시 만들 수 있습니다. 환경만으로는 R 스크립트를 다시 만들기가 훨씬 더 어렵습니다. 기억을 더듬어 많은 코드를 다시 입력해야 하거나(도중에 필연적으로 실수를 하게 됨) R 기록을 주의 깊게 파헤쳐야 합니다.\nR 스크립트를 분석의 진실의 원천으로 유지하는 데 도움이 되도록 RStudio가 세션 간에 작업 공간(workspace)을 보존하지 않도록 지시하는 것을 강력히 권장합니다. usethis::use_blank_slate()2를 실행하거나 Figure 6.2 에 표시된 옵션을 모방하여 이 작업을 수행할 수 있습니다. 이렇게 하면 RStudio를 다시 시작할 때 지난번에 실행한 코드를 더 이상 기억하지 못하고 생성한 객체나 읽은 데이터셋을 사용할 수 없게 되므로 단기적인 고통을 겪게 될 것입니다. 하지만 이 단기적인 고통은 코드에 모든 중요한 절차를 캡처하도록 강제하므로 장기적인 고통을 덜어줍니다. 중요한 계산 결과를 환경에만 저장하고 코드에는 계산 자체를 저장하지 않았다는 사실을 3개월 후에 발견하는 것보다 더 나쁜 것은 없습니다.\n\n\n\n\n\n\n\nFigure 6.2: 항상 깨끗한 상태로 RStudio 세션을 시작하려면 RStudio 옵션에서 이 옵션들을 복사하세요.\n\n\n\n\n편집기에서 코드의 중요한 부분을 캡처했는지 확인하기 위해 함께 작동하는 훌륭한 키보드 단축키 쌍이 있습니다:\n\nCmd/Ctrl + Shift + 0/F10을 눌러 R을 다시 시작합니다.\nCmd/Ctrl + Shift + S를 눌러 현재 스크립트를 다시 실행합니다.\n\n우리는 집단적으로 일주일에 수백 번 이 패턴을 사용합니다.\n또는 키보드 단축키를 사용하지 않는 경우 Session(세션) &gt; Restart R(R 다시 시작)로 이동한 다음 현재 스크립트를 강조 표시하고 다시 실행할 수 있습니다.\n\n\n\n\n\n\nNoteRStudio 서버\n\n\n\nRStudio 서버를 사용하는 경우 기본적으로 R 세션이 다시 시작되지 않습니다. RStudio 서버 탭을 닫으면 R을 닫는 것처럼 느껴질 수 있지만 실제로는 서버가 백그라운드에서 계속 실행합니다. 다음에 돌아올 때는 떠났던 곳과 정확히 같은 곳에 있게 됩니다. 따라서 깨끗한 상태에서 시작할 수 있도록 R을 정기적으로 다시 시작하는 것이 훨씬 더 중요합니다.\n\n\n\n6.2.2 분석은 어디에 있습니까?\nR에는 작업 디렉터리(working directory) 라는 강력한 개념이 있습니다. 이곳은 R이 로드하도록 요청한 파일을 찾고 저장하도록 요청한 파일을 두는 곳입니다. RStudio는 콘솔 상단에 현재 작업 디렉터리를 표시합니다:\n\n\n\n\n\n\n\n\n그리고 getwd()를 실행하여 R 코드에서 이를 출력할 수 있습니다:\n\ngetwd()\n#&gt; [1] \"/Users/hadley/Documents/r4ds\"\n\n이 R 세션에서 현재 작업 디렉터리(“홈”이라고 생각하세요)는 hadley의 Documents 폴더 안에 있는 r4ds라는 하위 폴더에 있습니다. 이 코드는 여러분의 컴퓨터가 Hadley와 다른 디렉터리 구조를 가지고 있기 때문에 실행할 때 다른 결과를 반환할 것입니다!\n초보 R 사용자라면 작업 디렉터리를 홈 디렉터리, 문서 디렉터리 또는 컴퓨터의 다른 이상한 디렉터리로 두어도 괜찮습니다. 하지만 여러분은 이 책을 몇 장이나 읽었고 더 이상 초보자가 아닙니다. 이제 곧 프로젝트를 디렉터리로 구성하고 프로젝트에서 작업할 때 R의 작업 디렉터리를 관련 디렉터리로 설정하도록 발전해야 합니다.\nR 내에서 작업 디렉터리를 설정할 수 있지만 우리는 권장하지 않습니다:\n\nsetwd(\"/path/to/my/CoolProject\")\n\n더 좋은 방법이 있습니다; 전문가처럼 R 작업을 관리할 수 있는 길로 안내하는 방법입니다. 그 방법은 RStudio 프로젝트입니다.\n\n6.2.3 RStudio 프로젝트\n주어진 프로젝트와 관련된 모든 파일(입력 데이터, R 스크립트, 분석 결과 및 그림)을 한 디렉터리에 함께 보관하는 것은 매우 현명하고 일반적인 관행이므로 RStudio는 프로젝트를 통해 이에 대한 지원을 내장했습니다. 이 책의 나머지 부분을 진행하는 동안 사용할 프로젝트를 만들어 보겠습니다. File(파일) &gt; New Project(새 프로젝트)를 클릭한 다음 Figure 6.3 에 표시된 단계를 따르세요.\n\n\n\n\n\n\n\nFigure 6.3: 새 프로젝트를 만들려면: (상단) 먼저 New Directory를 클릭한 다음, (중간) New Project를 클릭하고, (하단) 디렉터리(프로젝트) 이름을 입력하고 홈으로 사용할 적절한 하위 디렉터리를 선택한 다음 Create Project를 클릭합니다.\n\n\n\n\n프로젝트 이름을 r4ds라고 짓고 프로젝트를 어느 하위 디렉터리에 넣을지 신중하게 생각하세요. 합리적인 곳에 저장하지 않으면 나중에 찾기 어려울 것입니다!\n이 프로세스가 완료되면 이 책만을 위한 새로운 RStudio 프로젝트를 얻게 됩니다. 프로젝트의 “홈”이 현재 작업 디렉터리인지 확인하세요:\n\ngetwd()\n#&gt; [1] \"/Users/hadley/Documents/r4ds\"\n\n이제 스크립트 편집기에 다음 명령을 입력하고 파일을 “diamonds.R”이라고 저장하세요. 그런 다음 “data”라는 새 폴더를 만드세요. RStudio의 파일 창에서 “New Folder(새 폴더)” 버튼을 클릭하여 이 작업을 수행할 수 있습니다. 마지막으로 전체 스크립트를 실행하여 프로젝트 디렉터리에 PNG 및 CSV 파일을 저장하세요. 세부 사항에 대해서는 걱정하지 마세요. 나중에 책에서 배우게 될 것입니다.\n\nlibrary(tidyverse)\n\nggplot(diamonds, aes(x = carat, y = price)) + \n  geom_hex()\nggsave(\"diamonds.png\")\n\nwrite_csv(diamonds, \"data/diamonds.csv\")\n\nRStudio를 종료하세요. 프로젝트와 연결된 폴더를 검사해 보세요 — .Rproj 파일이 보일 것입니다. 해당 파일을 더블 클릭하여 프로젝트를 다시 여세요. 중단했던 곳으로 돌아온 것을 알 수 있습니다. 동일한 작업 디렉터리와 명령 기록이 있고 작업 중이던 모든 파일이 여전히 열려 있습니다. 하지만 위의 지시를 따랐으므로 완전히 새로운 환경을 갖게 되어 깨끗한 상태에서 시작하는 것이 보장됩니다.\n좋아하는 OS별 방법으로 컴퓨터에서 diamonds.png를 검색하면 PNG뿐만 아니라(당연하지만) 그것을 만든 스크립트(diamonds.R)도 찾을 수 있습니다. 이것은 엄청난 승리입니다! 언젠가 여러분은 그림을 다시 만들거나 어디서 왔는지 이해하고 싶을 것입니다. 마우스나 클립보드가 아니라 R 코드로 그림을 파일에 엄격하게 저장하면 옛날 작업을 쉽게 재현할 수 있습니다!\n\n6.2.4 상대 경로와 절대 경로\n프로젝트 내부에 들어가면 절대 경로가 아닌 상대 경로만 사용해야 합니다. 차이점은 무엇일까요? A relative path is relative to the working directory, i.e. the project’s home. When Hadley wrote data/diamonds.csv above it was a shortcut for /Users/hadley/Documents/r4ds/data/diamonds.csv. But importantly, if Mine ran this code on her computer, it would point to /Users/Mine/Documents/r4ds/data/diamonds.csv. This is why relative paths are important: they’ll work regardless of where the R project folder ends up.\n절대 경로는 작업 디렉터리에 관계없이 같은 곳을 가리킵니다. 운영 체제에 따라 모양이 약간 다릅니다. Windows에서는 드라이브 문자(예: C:)나 두 개의 백슬래시(예: \\servername)로 시작하고 Mac/Linux에서는 슬래시 “/”(예: /users/hadley)로 시작합니다. 스크립트에서 절대 경로를 절대 사용해서는 안 됩니다. 공유를 방해하기 때문입니다. 다른 누구도 여러분과 정확히 같은 디렉터리 구성을 가지고 있지 않을 것입니다.\n운영 체제 간에는 또 다른 중요한 차이점이 있습니다: 경로의 구성 요소를 구분하는 방법입니다. Mac과 Linux는 슬래시(예: data/diamonds.csv)를 사용하고 Windows는 백슬래시(예: data\\diamonds.csv)를 사용합니다. R은 두 가지 유형 모두에서 작동할 수 있지만(현재 어떤 플랫폼을 사용하든 상관없이), 안타깝게도 백슬래시는 R에 특별한 의미가 있으며 경로에 단일 백슬래시를 얻으려면 백슬래시를 두 번 입력해야 합니다! 이것은 삶을 좌절스럽게 만들므로 항상 슬래시가 있는 Linux/Mac 스타일을 사용하는 것이 좋습니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>워크플로우: 스크립트와 프로젝트</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#연습문제",
    "href": "workflow-scripts.html#연습문제",
    "title": "6  워크플로우: 스크립트와 프로젝트",
    "section": "\n6.3 연습문제",
    "text": "6.3 연습문제\n\nRStudio 팁 트위터 계정(https://twitter.com/rstudiotips)으로 이동하여 흥미로워 보이는 팁 하나를 찾으세요. 사용 연습을 해보세요!\nRStudio 진단은 또 어떤 일반적인 실수를 보고합니까? https://support.posit.co/hc/en-us/articles/205753617-Code-Diagnostics를 읽고 확인하세요.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>워크플로우: 스크립트와 프로젝트</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#요약",
    "href": "workflow-scripts.html#요약",
    "title": "6  워크플로우: 스크립트와 프로젝트",
    "section": "\n6.4 요약",
    "text": "6.4 요약\n이 장에서는 스크립트(파일)와 프로젝트(디렉터리)로 R 코드를 구성하는 방법을 배웠습니다. 코드 스타일과 마찬가지로 처음에는 바쁜 일처럼 느껴질 수 있습니다. 하지만 여러 프로젝트에 걸쳐 더 많은 코드가 쌓이면, 초기에 약간의 조직화가 나중에 얼마나 많은 시간을 절약해 줄 수 있는지 알게 될 것입니다.\n요약하자면, 스크립트와 프로젝트는 미래에 큰 도움이 될 견고한 워크플로우를 제공합니다:\n\n각 데이터 분석 프로젝트마다 하나의 RStudio 프로젝트를 만드세요.\n프로젝트에 스크립트(유익한 이름으로)를 저장하고, 편집하고, 부분적으로 또는 전체적으로 실행하세요. 스크립트에 모든 것을 캡처했는지 확인하기 위해 R을 자주 다시 시작하세요.\n절대 경로가 아닌 상대 경로만 사용하세요.\n\n그러면 필요한 모든 것이 한 곳에 있고 작업 중인 다른 모든 프로젝트와 깔끔하게 분리됩니다.\n지금까지 우리는 R 패키지 안에 번들로 제공되는 데이터셋으로 작업했습니다. 이렇게 하면 미리 준비된 데이터로 연습하기가 더 쉽지만, 당연히 여러분의 데이터는 이런 방식으로 사용할 수 없을 것입니다. 따라서 다음 장에서는 readr 패키지를 사용하여 디스크에서 R 세션으로 데이터를 로드하는 방법을 배울 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>워크플로우: 스크립트와 프로젝트</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#footnotes",
    "href": "workflow-scripts.html#footnotes",
    "title": "6  워크플로우: 스크립트와 프로젝트",
    "section": "",
    "text": "이름에 “final”을 사용하여 운명을 시험하는 것은 말할 것도 없고요 😆 만화 Piled Higher and Deeper에는 이것에 대한 재미있는 스트립이 있습니다.↩︎\nusethis가 설치되어 있지 않다면 install.packages(\"usethis\")로 설치할 수 있습니다.↩︎",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>워크플로우: 스크립트와 프로젝트</span>"
    ]
  },
  {
    "objectID": "data-import.html",
    "href": "data-import.html",
    "title": "7  데이터 가져오기",
    "section": "",
    "text": "7.1 소개\nR 패키지에서 제공하는 데이터로 작업하는 것은 데이터 과학 도구를 배우는 좋은 방법이지만, 언젠가는 배운 내용을 자신의 데이터에 적용하고 싶을 것입니다. 이 장에서는 데이터 파일을 R로 읽어오는 기본 사항을 배웁니다.\n구체적으로 이 장에서는 일반 텍스트 사각형 파일(plain-text rectangular files)을 읽는 데 중점을 둘 것입니다. 열 이름, 유형, 결측 데이터와 같은 기능을 처리하기 위한 실용적인 조언으로 시작하겠습니다. 그런 다음 한 번에 여러 파일에서 데이터를 읽고 R에서 파일로 데이터를 쓰는 방법에 대해 배울 것입니다. 마지막으로 R에서 데이터 프레임을 직접 만드는 방법을 배울 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#소개",
    "href": "data-import.html#소개",
    "title": "7  데이터 가져오기",
    "section": "",
    "text": "7.1.1 선수 지식\n이 장에서는 핵심 tidyverse의 일부인 readr 패키지를 사용하여 R에서 플랫 파일(flat files)을 로드하는 방법을 배웁니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#파일에서-데이터-읽기",
    "href": "data-import.html#파일에서-데이터-읽기",
    "title": "7  데이터 가져오기",
    "section": "\n7.2 파일에서 데이터 읽기",
    "text": "7.2 파일에서 데이터 읽기\n먼저 가장 일반적인 사각형 데이터 파일 유형인 CSV(comma-separated values, 쉼표로 구분된 값)에 초점을 맞출 것입니다. 간단한 CSV 파일의 모습은 다음과 같습니다. 일반적으로 헤더 행이라고 하는 첫 번째 행은 열 이름을 제공하고 다음 6개 행은 데이터를 제공합니다. 열은 쉼표로 구분(또는 구분자로 사용)됩니다.\n\nStudent ID,Full Name,favourite.food,mealPlan,AGE\n1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4\n2,Barclay Lynn,French fries,Lunch only,5\n3,Jayendra Lyne,N/A,Breakfast and lunch,7\n4,Leon Rossini,Anchovies,Lunch only,\n5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five\n6,Güvenç Attila,Ice cream,Lunch only,6\n\nTable 7.1 은 동일한 데이터를 표로 나타낸 것입니다.\n\n\n\nTable 7.1: students.csv 파일의 데이터를 표로 나타낸 것.\n\n\n\n\n\n\n\n\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\n\n1\nSunil Huffmann\nStrawberry yoghurt\nLunch only\n4\n\n\n2\nBarclay Lynn\nFrench fries\nLunch only\n5\n\n\n3\nJayendra Lyne\nN/A\nBreakfast and lunch\n7\n\n\n4\nLeon Rossini\nAnchovies\nLunch only\nNA\n\n\n5\nChidiegwu Dunkel\nPizza\nBreakfast and lunch\nfive\n\n\n6\nGüvenç Attila\nIce cream\nLunch only\n6\n\n\n\n\n\n\n\n\nread_csv()를 사용하여 이 파일을 R로 읽을 수 있습니다. 첫 번째 인수가 가장 중요합니다. 파일의 경로(path)입니다. 경로는 파일의 주소라고 생각할 수 있습니다. 파일 이름은 students.csv이고 data 폴더에 있습니다.\n\nstudents &lt;- read_csv(\"data/students.csv\")\n#&gt; Rows: 6 Columns: 5\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr (4): Full Name, favourite.food, mealPlan, AGE\n#&gt; dbl (1): Student ID\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n위의 코드는 프로젝트의 data 폴더에 students.csv 파일이 있는 경우 작동합니다. https://pos.it/r4ds-students-csv에서 students.csv 파일을 다운로드하거나 다음을 사용하여 해당 URL에서 직접 읽을 수 있습니다:\n\nstudents &lt;- read_csv(\"https://pos.it/r4ds-students-csv\")\n\nread_csv()를 실행하면 데이터의 행과 열 수, 사용된 구분자, 열 사양(열에 포함된 데이터 유형별로 구성된 열 이름)을 알려주는 메시지가 출력됩니다. 또한 전체 열 사양을 검색하는 방법과 이 메시지를 끄는 방법에 대한 정보도 출력합니다. 이 메시지는 readr의 필수적인 부분이며 Section 7.3 에서 다시 다룰 것입니다.\n\n7.2.1 실용적인 조언\n데이터를 읽은 후 첫 번째 단계는 일반적으로 나머지 분석에서 작업하기 쉽도록 데이터를 어떤 식으로든 변형하는 것입니다. 그 점을 염두에 두고 students 데이터를 다시 살펴봅시다.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\nfavourite.food 열에는 많은 음식 항목이 있고 그 다음 문자열 N/A가 있는데, 이는 R이 “사용할 수 없음(not available)”으로 인식하는 실제 NA였어야 합니다. 이것은 na 인수를 사용하여 해결할 수 있는 문제입니다. 기본적으로 read_csv()는 이 데이터셋의 빈 문자열(\"\")만 NA로 인식하지만, 문자열 \"N/A\"도 인식하도록 하고 싶습니다.\n\nstudents &lt;- read_csv(\"data/students.csv\", na = c(\"N/A\", \"\"))\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\nStudent ID와 Full Name 열이 역따옴표(backticks)로 둘러싸여 있는 것을 눈치챘을 수도 있습니다. 공백이 포함되어 있어 변수 이름에 대한 R의 일반적인 규칙을 위반하기 때문입니다. 이를 비구문적(non-syntactic) 이름이라고 합니다. 이러한 변수를 참조하려면 역따옴표 `로 감싸야 합니다:\n\nstudents |&gt; \n  rename(\n    student_id = `Student ID`,\n    full_name = `Full Name`\n  )\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite.food     mealPlan            AGE  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n대안적인 접근 방식은 janitor::clean_names()를 사용하여 몇 가지 휴리스틱을 사용해 모든 이름을 한 번에 스네이크 케이스(snake case)로 바꾸는 것입니다1.\n\nstudents |&gt; janitor::clean_names()\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n데이터를 읽은 후의 또 다른 일반적인 작업은 변수 유형을 고려하는 것입니다. 예를 들어 meal_plan은 가능한 값 집합이 알려진 범주형 변수이며, R에서는 팩터(factor)로 표현되어야 합니다:\n\nstudents |&gt;\n  janitor::clean_names() |&gt;\n  mutate(meal_plan = factor(meal_plan))\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\nmeal_plan 변수의 값은 그대로 유지되었지만 변수 이름 아래에 표시된 변수 유형이 문자(&lt;chr&gt;)에서 팩터(&lt;fct&gt;)로 변경되었습니다. 팩터에 대해서는 Chapter 16 에서 더 자세히 배울 것입니다.\n이 데이터를 분석하기 전에 아마도 age 열을 수정하고 싶을 것입니다. 현재 age는 관측값 중 하나가 숫자 5 대신 five로 입력되어 있기 때문에 문자 변수입니다. 이 문제를 해결하는 세부 사항은 Chapter 20 에서 논의합니다.\n\nstudents &lt;- students |&gt;\n  janitor::clean_names() |&gt;\n  mutate(\n    meal_plan = factor(meal_plan),\n    age = parse_number(if_else(age == \"five\", \"5\", age))\n  )\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n여기서 새로운 함수는 if_else()로, 세 가지 인수가 있습니다. 첫 번째 인수 test는 논리형 벡터여야 합니다. 결과는 test가 TRUE일 때 두 번째 인수 yes의 값을, FALSE일 때 세 번째 인수 no의 값을 포함합니다. 여기서는 age가 문자열 \"five\"이면 \"5\"로 만들고, 그렇지 않으면 age 그대로 두라고 말하고 있습니다. if_else()와 논리형 벡터에 대해서는 Chapter 12 에서 더 자세히 배울 것입니다.\n\n7.2.2 기타 인수\n언급해야 할 다른 중요한 인수가 몇 가지 있는데, 편리한 트릭을 먼저 보여드리면 시연하기가 더 쉬울 것입니다. read_csv()는 CSV 파일처럼 만들고 서식을 지정한 텍스트 문자열을 읽을 수 있습니다:\n\nread_csv(\n  \"a,b,c\n  1,2,3\n  4,5,6\"\n)\n#&gt; # A tibble: 2 × 3\n#&gt;       a     b     c\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\n일반적으로 read_csv()는 데이터의 첫 번째 줄을 열 이름으로 사용하는데, 이는 매우 일반적인 관례입니다. 하지만 파일 상단에 몇 줄의 메타데이터가 포함되는 경우도 드물지 않습니다. skip = n을 사용하여 처음 n 줄을 건너뛰거나 comment = \"#\"을 사용하여 (예를 들어) #로 시작하는 모든 줄을 삭제할 수 있습니다:\n\nread_csv(\n  \"메타데이터 첫 번째 줄\n  메타데이터 두 번째 줄\n  x,y,z\n  1,2,3\",\n  skip = 2\n)\n#&gt; # A tibble: 1 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\nread_csv(\n  \"# 건너뛰고 싶은 주석\n  x,y,z\n  1,2,3\",\n  comment = \"#\"\n)\n#&gt; # A tibble: 1 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\n다른 경우에는 데이터에 열 이름이 없을 수도 있습니다. col_names = FALSE를 사용하여 read_csv()에 첫 번째 행을 헤더로 처리하지 말고 대신 X1에서 Xn까지 순차적으로 레이블을 지정하도록 지시할 수 있습니다:\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = FALSE\n)\n#&gt; # A tibble: 2 × 3\n#&gt;      X1    X2    X3\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\n또는 col_names에 문자 벡터를 전달하여 열 이름으로 사용할 수 있습니다:\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = c(\"x\", \"y\", \"z\")\n)\n#&gt; # A tibble: 2 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\n이러한 인수들은 실제로 마주칠 대부분의 CSV 파일을 읽는 데 알아야 할 전부입니다. (나머지는 .csv 파일을 주의 깊게 검사하고 read_csv()의 다른 많은 인수에 대한 설명서를 읽어야 합니다.)\n\n7.2.3 기타 파일 유형\nread_csv()를 마스터하면 readr의 다른 기능을 사용하는 것은 간단합니다. 어떤 기능을 사용해야 하는지 알면 됩니다:\n\nread_csv2()는 세미콜론으로 구분된 파일을 읽습니다. 이들은 필드를 구분하는 데 , 대신 ;을 사용하며 소수점 표시에 ,를 사용하는 국가에서 일반적입니다.\nread_tsv()는 탭으로 구분된 파일을 읽습니다.\nread_delim()은 구분자가 있는 파일을 읽으며, 지정하지 않으면 구분자를 자동으로 추측하려고 시도합니다.\nread_fwf()는 고정 너비 파일을 읽습니다. fwf_widths()로 너비로 필드를 지정하거나 fwf_positions()로 위치로 필드를 지정할 수 있습니다.\nread_table()은 열이 공백으로 구분되는 고정 너비 파일의 일반적인 변형을 읽습니다.\nread_log()는 Apache 스타일의 로그 파일을 읽습니다.\n\n7.2.4 연습문제\n\n필드가 “|”로 구분된 파일을 읽으려면 어떤 함수를 사용하겠습니까?\nfile, skip, comment 외에 read_csv()와 read_tsv()가 공통적으로 갖는 다른 인수는 무엇입니까?\nread_fwf()의 가장 중요한 인수는 무엇입니까?\n\n때때로 CSV 파일의 문자열에 쉼표가 포함되어 있습니다. 문제를 일으키지 않으려면 \" 또는 '와 같은 인용 문자로 둘러싸야 합니다. 기본적으로 read_csv()는 인용 문자가 \"일 것이라고 가정합니다. 다음 텍스트를 데이터 프레임으로 읽으려면 read_csv()의 어떤 인수를 지정해야 합니까?\n\n\"x,y\\n1,'a,b'\"\n\n\n\n다음 인라인 CSV 파일 각각에 무엇이 잘못되었는지 식별하세요. 코드를 실행하면 어떻게 됩니까?\n\nread_csv(\"a,b\\n1,2,3\\n4,5,6\")\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\nread_csv(\"a,b\\n\\\"1\")\nread_csv(\"a,b\\n1,2\\na,b\")\nread_csv(\"a;b\\n1;3\")\n\n\n\n다음 데이터 프레임에서 비구문적 이름을 참조하는 연습을 하세요:\n\n\n1이라는 변수 추출하기.\n\n1 대 2의 산점도 그리기.\n\n2를 1로 나눈 3이라는 새 열 만들기.\n열 이름을 one, two, three로 바꾸기.\n\n\nannoying &lt;- tibble(\n  `1` = 1:10,\n  `2` = `1` * 2 + rnorm(length(`1`))\n)",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-col-types",
    "href": "data-import.html#sec-col-types",
    "title": "7  데이터 가져오기",
    "section": "\n7.3 열 유형 제어",
    "text": "7.3 열 유형 제어\nCSV 파일에는 각 변수의 유형(즉, 논리형인지, 숫자인지, 문자열인지 등)에 대한 정보가 포함되어 있지 않으므로 readr은 유형을 추측하려고 시도합니다. 이 섹션에서는 추측 프로세스가 작동하는 방식, 실패를 유발하는 몇 가지 일반적인 문제를 해결하는 방법, 필요한 경우 열 유형을 직접 제공하는 방법에 대해 설명합니다. 마지막으로 readr이 치명적으로 실패하고 파일 구조에 대한 더 많은 통찰력이 필요한 경우 유용한 몇 가지 일반적인 전략을 언급할 것입니다.\n\n7.3.1 유형 추측\nreadr은 휴리스틱을 사용하여 열 유형을 파악합니다. 각 열에 대해 첫 번째 행에서 마지막 행까지 균등하게 간격을 둔 1,000개 행2의 값을 가져오며 결측값은 무시합니다. 그런 다음 다음 질문을 통해 작업합니다:\n\n\nF, T, FALSE, TRUE만 포함합니까(대소문자 무시)? 그렇다면 논리형입니다.\n숫자만 포함합니까(예: 1, -4.5, 5e6, Inf)? 그렇다면 숫자입니다.\nISO8601 표준과 일치합니까? 그렇다면 날짜 또는 날짜-시간입니다. (Section 17.2 에서 날짜-시간에 대해 더 자세히 다시 다룰 것입니다).\n그렇지 않으면 문자열이어야 합니다.\n\n이 간단한 예제에서 해당 동작을 실제로 볼 수 있습니다:\n\nread_csv(\n  \"\\n  logical,numeric,date,string\n  TRUE,1,2021-01-15,abc\n  false,4.5,2021-02-15,def\n  T,Inf,2021-02-16,ghi\n\")\n#&gt; # A tibble: 3 × 4\n#&gt;   logical numeric date       string\n#&gt;   &lt;lgl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt; \n#&gt; 1 TRUE        1   2021-01-15 abc   \n#&gt; 2 FALSE       4.5 2021-02-15 def   \n#&gt; 3 TRUE      Inf   2021-02-16 ghi\n\n이 휴리스틱은 깨끗한 데이터셋이 있는 경우 잘 작동하지만, 실제로는 기이하고 아름다운 실패들을 마주하게 될 것입니다.\n\n7.3.2 결측값, 열 유형 및 문제\n열 감지가 실패하는 가장 일반적인 방법은 열에 예기치 않은 값이 포함되어 있어 더 구체적인 유형 대신 문자 열을 얻는 것입니다. 가장 일반적인 원인 중 하나는 readr이 예상하는 NA가 아닌 다른 것으로 기록된 결측값입니다.\n이 간단한 1열 CSV 파일을 예로 들어보겠습니다:\n\nsimple_csv &lt;- \"\n  x\n  10\n  .\n  20\n  30\"\n\n추가 인수 없이 읽으면 x는 문자 열이 됩니다:\n\nread_csv(simple_csv)\n#&gt; # A tibble: 4 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 10   \n#&gt; 2 .    \n#&gt; 3 20   \n#&gt; 4 30\n\n이 아주 작은 경우에는 결측값 .를 쉽게 볼 수 있습니다. 하지만 수천 개의 행이 있고 그 사이에 .로 표시된 결측값이 몇 개만 흩어져 있다면 어떻게 될까요? 한 가지 접근 방식은 readr에 x가 숫자 열이라고 알린 다음 어디에서 실패하는지 확인하는 것입니다. CSV 파일의 열 이름과 이름이 일치하는 명명된 리스트를 취하는 col_types 인수로 그렇게 할 수 있습니다:\n\ndf &lt;- read_csv(\n  simple_csv, \n  col_types = list(x = col_double())\n)\n#&gt; Warning: One or more parsing issues, call `problems()` on your data frame for\n#&gt; details, e.g.:\n#&gt;   dat &lt;- vroom(...)\n#&gt;   problems(dat)\n\n이제 read_csv()는 문제가 있었다고 보고하고 problems()를 통해 더 많은 정보를 얻을 수 있다고 알려줍니다:\n\nproblems(df)\n#&gt; # A tibble: 1 × 5\n#&gt;     row   col expected actual file                                           \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;                                          \n#&gt; 1     3     1 a double .      /private/var/folders/qc/wsq_wkqn6c37nz9rfqqpvp…\n\n이것은 3행 1열에 문제가 있었는데 readr은 double을 예상했지만 .을 얻었음을 알려줍니다. 이는 이 데이터셋이 결측값에 .을 사용한다는 것을 시사합니다. 그래서 na = \".\"을 설정하면 자동 추측이 성공하여 우리가 원하는 숫자 열을 얻게 됩니다:\n\nread_csv(simple_csv, na = \".\")\n#&gt; # A tibble: 4 × 1\n#&gt;       x\n#&gt;   &lt;dbl&gt;\n#&gt; 1    10\n#&gt; 2    NA\n#&gt; 3    20\n#&gt; 4    30\n\n\n7.3.3 열 유형\nreadr은 사용자가 사용할 수 있는 총 9가지 열 유형을 제공합니다:\n\n\ncol_logical() 및 col_double()은 논리형 및 실수를 읽습니다. readr이 일반적으로 추측하므로 상대적으로 거의 필요하지 않습니다(위와 같은 경우 제외).\n\ncol_integer()는 정수를 읽습니다. 이 책에서는 정수와 double이 기능적으로 동일하기 때문에 거의 구별하지 않지만, 정수가 double의 절반 메모리를 차지하므로 명시적으로 정수를 읽는 것이 가끔 유용할 수 있습니다.\n\ncol_character()는 문자열을 읽습니다. 숫자 식별자, 즉 객체를 식별하지만 수학 연산을 적용하는 것이 의미가 없는 긴 숫자 시리즈인 열이 있을 때 명시적으로 지정하는 데 유용할 수 있습니다. 예로는 전화번호, 주민등록번호, 신용카드 번호 등이 있습니다.\n\ncol_factor(), col_date(), col_datetime()은 각각 팩터, 날짜, 날짜-시간을 생성합니다. Chapter 16 및 Chapter 17 에서 해당 데이터 유형에 도달했을 때 자세히 배울 것입니다.\n\ncol_number()는 숫자가 아닌 구성 요소를 무시하는 관대한 숫자 파서이며 통화에 특히 유용합니다. Chapter 13 에서 자세히 배울 것입니다.\n\ncol_skip()은 열을 건너뛰어 결과에 포함되지 않도록 합니다. 이는 대용량 CSV 파일이 있고 일부 열만 사용하려는 경우 데이터 읽기 속도를 높이는 데 유용할 수 있습니다.\n\nlist()에서 cols()로 전환하고 .default를 지정하여 유형을 추측하는 기본 휴리스틱을 재정의하는 것도 가능합니다:\n\nanother_csv &lt;- \"\nx,y,z\n1,2,3\"\n\nread_csv(\n  another_csv, \n  col_types = cols(.default = col_character())\n)\n#&gt; # A tibble: 1 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     2     3\n\n또 다른 유용한 도우미는 지정한 열만 읽어들이는 cols_only()입니다:\n\nread_csv(\n  another_csv,\n  col_types = cols_only(x = col_character())\n)\n#&gt; # A tibble: 1 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-readr-directory",
    "href": "data-import.html#sec-readr-directory",
    "title": "7  데이터 가져오기",
    "section": "\n7.4 여러 파일에서 데이터 읽기",
    "text": "7.4 여러 파일에서 데이터 읽기\n때로는 데이터가 단일 파일에 포함되어 있는 대신 여러 파일로 나뉘어 있습니다. 예를 들어, 여러 달의 판매 데이터가 있고 각 달의 데이터가 별도 파일(01-sales.csv(1월), 02-sales.csv(2월), 03-sales.csv(3월))에 있을 수 있습니다. read_csv()를 사용하면 이 데이터를 한 번에 읽어서 단일 데이터 프레임에 서로 쌓을 수 있습니다.\n\nsales_files &lt;- c(\"data/01-sales.csv\", \"data/02-sales.csv\", \"data/03-sales.csv\")\nread_csv(sales_files, id = \"file\")\n#&gt; # A tibble: 19 × 6\n#&gt;   file              month    year brand  item     n\n#&gt;   &lt;chr&gt;             &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 data/01-sales.csv January  2019     1  1234     3\n#&gt; 2 data/01-sales.csv January  2019     1  8721     9\n#&gt; 3 data/01-sales.csv January  2019     1  1822     2\n#&gt; 4 data/01-sales.csv January  2019     2  3333     1\n#&gt; 5 data/01-sales.csv January  2019     2  2156     9\n#&gt; 6 data/01-sales.csv January  2019     2  3987     6\n#&gt; # ℹ 13 more rows\n\n다시 말하지만, 위의 코드는 프로젝트의 data 폴더에 CSV 파일이 있는 경우 작동합니다. https://pos.it/r4ds-01-sales, https://pos.it/r4ds-02-sales, https://pos.it/r4ds-03-sales에서 이 파일들을 다운로드하거나 다음을 사용하여 직접 읽을 수 있습니다:\n\nsales_files &lt;- c(\n  \"https://pos.it/r4ds-01-sales\",\n  \"https://pos.it/r4ds-02-sales\",\n  \"https://pos.it/r4ds-03-sales\"\n)\nread_csv(sales_files, id = \"file\")\n\nid 인수는 데이터가 어떤 파일에서 왔는지 식별하는 file이라는 새 열을 결과 데이터 프레임에 추가합니다. 이는 읽어들이는 파일에 관측값을 원래 소스로 추적하는 데 도움이 되는 식별 열이 없는 경우 특히 유용합니다.\n읽고 싶은 파일이 많으면 이름을 목록으로 작성하는 것이 번거로울 수 있습니다. 대신 기본 list.files() 함수를 사용하여 파일 이름의 패턴을 일치시켜 파일을 찾을 수 있습니다. Chapter 15 에서 이러한 패턴에 대해 더 자세히 배울 것입니다.\n\nsales_files &lt;- list.files(\"data\", pattern = \"sales\\\\.csv$\", full.names = TRUE)\nsales_files\n#&gt; [1] \"data/01-sales.csv\" \"data/02-sales.csv\" \"data/03-sales.csv\"",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-writing-to-a-file",
    "href": "data-import.html#sec-writing-to-a-file",
    "title": "7  데이터 가져오기",
    "section": "\n7.5 파일에 쓰기",
    "text": "7.5 파일에 쓰기\nreadr에는 데이터를 디스크에 다시 쓰는 두 가지 유용한 함수인 write_csv()와 write_tsv()도 함께 제공됩니다. 이 함수의 가장 중요한 인수는 x(저장할 데이터 프레임)와 file(저장할 위치)입니다. 또한 na로 결측값을 어떻게 쓸지 지정할 수 있고, 기존 파일에 append(추가)하고 싶은지 지정할 수 있습니다.\n\nwrite_csv(students, \"students.csv\")\n\n이제 그 csv 파일을 다시 읽어 봅시다. CSV에 저장할 때 방금 설정한 변수 유형 정보가 손실된다는 점에 유의하세요. 일반 텍스트 파일에서 다시 읽기 시작하기 때문입니다:\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\nwrite_csv(students, \"students-2.csv\")\nread_csv(\"students-2.csv\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n이로 인해 CSV는 중간 결과를 캐싱하는 데 약간 신뢰할 수 없습니다. 로드할 때마다 열 사양을 다시 생성해야 하기 때문입니다. 두 가지 주요 대안이 있습니다:\n\n\nwrite_rds()와 read_rds()는 기본 함수인 readRDS()와 saveRDS()를 감싸는 균일한 래퍼입니다. 이들은 RDS라는 R의 사용자 정의 이진 형식으로 데이터를 저장합니다. 즉, 객체를 다시 로드할 때 저장한 것과 정확히 같은 R 객체를 로드하게 됩니다.\n\nwrite_rds(students, \"students.rds\")\nread_rds(\"students.rds\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\narrow 패키지를 사용하면 프로그래밍 언어 간에 공유할 수 있는 빠른 이진 파일 형식인 parquet 파일을 읽고 쓸 수 있습니다. Chapter 22 에서 arrow에 대해 더 깊이 다룰 것입니다.\n\nlibrary(arrow)\nwrite_parquet(students, \"students.parquet\")\nread_parquet(\"students.parquet\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    NA                 Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\nParquet는 RDS보다 훨씬 빠르고 R 외부에서 사용할 수 있는 경향이 있지만 arrow 패키지가 필요합니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#데이터-입력",
    "href": "data-import.html#데이터-입력",
    "title": "7  데이터 가져오기",
    "section": "\n7.6 데이터 입력",
    "text": "7.6 데이터 입력\n때로는 R 스크립트에서 약간의 데이터 입력을 수행하여 “손으로” 티블을 조립해야 할 수도 있습니다. 이를 수행하는 데 도움이 되는 두 가지 유용한 함수가 있는데, 티블을 열별로 배치할지 행별로 배치할지에 따라 다릅니다. tibble()은 열별로 작동합니다:\n\ntibble(\n  x = c(1, 2, 5), \n  y = c(\"h\", \"m\", \"g\"),\n  z = c(0.08, 0.83, 0.60)\n)\n#&gt; # A tibble: 3 × 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6\n\n열별로 데이터를 배치하면 행이 어떻게 관련되어 있는지 보기 어려울 수 있으므로 대안은 transposed tibble(전치된 티블)의 줄임말인 tribble()로, 데이터를 행별로 배치할 수 있습니다. tribble()은 코드 내 데이터 입력에 맞춤화되어 있습니다: 열 머리글은 ~로 시작하고 항목은 쉼표로 구분됩니다. 이를 통해 읽기 쉬운 형식으로 소량의 데이터를 배치할 수 있습니다:\n\ntribble(\n  ~x, ~y, ~z,\n  1, \"h\", 0.08,\n  2, \"m\", 0.83,\n  5, \"g\", 0.60\n)\n#&gt; # A tibble: 3 × 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#요약",
    "href": "data-import.html#요약",
    "title": "7  데이터 가져오기",
    "section": "\n7.7 요약",
    "text": "7.7 요약\n이 장에서는 read_csv()로 CSV 파일을 로드하는 방법과 tibble() 및 tribble()로 직접 데이터를 입력하는 방법을 배웠습니다. csv 파일이 작동하는 방식, 발생할 수 있는 문제, 극복 방법에 대해 배웠습니다. 이 책에서 데이터 가져오기에 대해 몇 번 더 다룰 것입니다: Chapter 20 에서는 Excel 및 Google Sheets에서, Chapter 21 에서는 데이터베이스에서 데이터를 로드하는 방법을, Chapter 22 에서는 parquet 파일에서, Chapter 23 에서는 JSON에서, Chapter 24 에서는 웹사이트에서 데이터를 로드하는 방법을 보여줄 것입니다.\n이 책의 이 섹션은 거의 끝났지만 다뤄야 할 중요한 마지막 주제가 하나 있습니다: 도움을 받는 방법입니다. 따라서 다음 장에서는 도움을 찾을 수 있는 좋은 곳, 좋은 도움을 받을 가능성을 극대화하기 위해 reprex(재현 가능한 예제)를 만드는 방법, R의 세계를 따라잡기 위한 몇 가지 일반적인 조언을 배울 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "data-import.html#footnotes",
    "href": "data-import.html#footnotes",
    "title": "7  데이터 가져오기",
    "section": "",
    "text": "janitor 패키지는 tidyverse의 일부는 아니지만 편리한 데이터 정리 기능을 제공하며 |&gt;를 사용하는 데이터 파이프라인 내에서 잘 작동합니다.↩︎\nguess_max 인수로 기본값 1000을 재정의할 수 있습니다.↩︎",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>데이터 가져오기</span>"
    ]
  },
  {
    "objectID": "workflow-help.html",
    "href": "workflow-help.html",
    "title": "8  워크플로우: 도움 받기",
    "section": "",
    "text": "8.1 구글(Google)은 여러분의 친구입니다\n이 책은 섬이 아닙니다. R을 마스터할 수 있게 해주는 단 하나의 리소스는 없습니다. 이 책에서 설명하는 기법을 자신의 데이터에 적용하기 시작하면 곧 우리가 대답하지 않은 질문들을 발견하게 될 것입니다. 이 섹션에서는 도움을 받고 계속 학습하는 데 도움이 되는 몇 가지 팁을 설명합니다.\n막히면 구글에서 시작하세요. 일반적으로 쿼리에 “R”을 추가하는 것만으로도 관련 결과로 제한하기에 충분합니다. 검색이 유용하지 않다면 R 관련 결과가 없다는 의미일 때가 많습니다. 또한 “tidyverse”나 “ggplot2”와 같은 패키지 이름을 추가하면 결과를 더 익숙한 코드로 좁히는 데 도움이 됩니다. 예를 들어 “how to make a boxplot in R(R에서 상자 그림 그리는 법)” 대 “how to make a boxplot in R with ggplot2(R에서 ggplot2로 상자 그림 그리는 법)”. 구글은 오류 메시지에 대해 특히 유용합니다. 오류 메시지가 나타나고 무슨 뜻인지 전혀 모르겠다면 구글에 검색해 보세요! 과거에 다른 누군가가 그것 때문에 혼란스러워했을 가능성이 높으며 웹 어딘가에 도움이 있을 것입니다. (오류 메시지가 영어가 아닌 경우 Sys.setenv(LANGUAGE = \"en\")을 실행하고 코드를 다시 실행하세요. 영어 오류 메시지에 대한 도움말을 찾을 가능성이 더 높습니다.)\n구글이 도움이 되지 않으면 Stack Overflow를 시도해 보세요. R을 사용하는 질문과 답변으로 검색을 제한하기 위해 [R]을 포함하여 기존 답변을 검색하는 데 시간을 조금 할애하는 것으로 시작하세요.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>워크플로우: 도움 받기</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#reprex-만들기",
    "href": "workflow-help.html#reprex-만들기",
    "title": "8  워크플로우: 도움 받기",
    "section": "\n8.2 reprex 만들기",
    "text": "8.2 reprex 만들기\n구글링으로 유용한 정보를 찾지 못했다면 reprex, 즉 최소한의 재현 가능한 예제(minimal reproducible example)를 준비하는 것이 정말 좋은 생각입니다. 좋은 reprex는 다른 사람들이 여러분을 돕기 쉽게 만들고, 종종 만드는 과정에서 스스로 문제를 파악하게 되기도 합니다. reprex를 만드는 데는 두 가지 부분이 있습니다:\n\n먼저 코드를 재현 가능하게 만들어야 합니다. 즉, 모든 것을 캡처해야 합니다. 즉, library() 호출을 포함하고 필요한 모든 객체를 생성해야 합니다. 이 작업을 수행했는지 확인하는 가장 쉬운 방법은 reprex 패키지를 사용하는 것입니다.\n둘째, 최소한으로 만들어야 합니다. 문제와 직접 관련이 없는 모든 것을 제거하세요. 여기에는 일반적으로 실제 상황에서 직면하고 있는 것보다 훨씬 작고 간단한 R 객체를 만들거나 내장 데이터를 사용하는 것이 포함됩니다.\n\n일이 많은 것처럼 들립니다! 그럴 수 있지만, 큰 보상이 있습니다:\n\n80%의 경우, 훌륭한 reprex를 만들면 문제의 원인이 드러납니다. 자급자족적이고 최소한의 예제를 작성하는 과정에서 자신의 질문에 답할 수 있게 되는 경우가 놀라울 정도로 많습니다.\n나머지 20%의 경우, 다른 사람들이 쉽게 실행해 볼 수 있는 방식으로 문제의 본질을 캡처하게 됩니다. 이것은 도움을 받을 가능성을 상당히 높여줍니다!\n\n손으로 reprex를 만들 때는 실수로 무언가를 놓치기 쉬우며, 이는 코드가 다른 사람의 컴퓨터에서 실행되지 않을 수 있음을 의미합니다. tidyverse의 일부로 설치되는 reprex 패키지를 사용하여 이 문제를 피하세요. 이 코드를 클립보드에 복사한다고 가정해 보겠습니다(또는 RStudio Server나 Cloud에서 선택):\n\ny &lt;- 1:4\nmean(y)\n\n그런 다음 기본 출력이 GitHub용으로 포맷된 reprex()를 호출하세요:\nreprex::reprex()\nRStudio의 뷰어(RStudio에 있는 경우)나 기본 브라우저에 깔끔하게 렌더링된 HTML 미리보기가 표시됩니다. reprex는 자동으로 클립보드에 복사됩니다(RStudio Server 또는 Cloud에서는 직접 복사해야 함):\n``` r\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n```\n이 텍스트는 마크다운(Markdown)이라는 특별한 방식으로 포맷되어 있으며, StackOverflow나 Github 같은 사이트에 붙여넣으면 자동으로 코드처럼 보이게 렌더링됩니다. 다음은 해당 마크다운이 GitHub에서 렌더링된 모습입니다:\n\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n\n누구나 이것을 즉시 복사, 붙여넣기 및 실행할 수 있습니다.\n예제를 재현 가능하게 만들려면 필수 패키지, 데이터, 코드의 세 가지를 포함해야 합니다.\n\n패키지는 스크립트 상단에 로드하여 예제에 필요한 패키지를 쉽게 확인할 수 있어야 합니다. 지금은 각 패키지의 최신 버전을 사용하고 있는지 확인할 좋은 시기입니다. 패키지를 설치하거나 마지막으로 업데이트한 이후 수정된 버그를 발견했을 수도 있습니다. tidyverse 패키지의 경우 가장 쉬운 확인 방법은 tidyverse_update()를 실행하는 것입니다.\n\n데이터를 포함하는 가장 쉬운 방법은 dput()을 사용하여 데이터를 다시 생성하는 데 필요한 R 코드를 생성하는 것입니다. 예를 들어 R에서 mtcars 데이터셋을 다시 생성하려면 다음 단계를 수행하세요:\n\nR에서 dput(mtcars) 실행\n출력 복사\nreprex에서 mtcars &lt;-를 입력한 다음 붙여넣기.\n\n문제를 여전히 드러내는 가장 작은 데이터 하위 집합을 사용해 보세요.\n\n\n다른 사람들이 코드를 쉽게 읽을 수 있도록 시간을 조금 투자하세요:\n\n공백을 사용하고 변수 이름이 간결하면서도 유익한지 확인하세요.\n주석을 사용하여 문제가 어디에 있는지 나타내세요.\n문제와 관련이 없는 모든 것을 제거하도록 최선을 다하세요.\n\n코드가 짧을수록 이해하기 쉽고 수정하기 쉽습니다.\n\n\n새로운 R 세션을 시작하고 스크립트를 복사하여 붙여넣어 실제로 재현 가능한 예제를 만들었는지 확인하며 마무리하세요.\nreprex를 만드는 것은 사소한 일이 아니며, 좋고 정말로 최소한의 reprex를 만드는 법을 배우려면 연습이 필요할 것입니다. 그러나 코드를 포함하여 질문하는 법을 배우고 재현 가능하게 만드는 데 시간을 투자하는 것은 R을 배우고 마스터함에 따라 계속해서 성과를 거둘 것입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>워크플로우: 도움 받기</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#자신에게-투자하기",
    "href": "workflow-help.html#자신에게-투자하기",
    "title": "8  워크플로우: 도움 받기",
    "section": "\n8.3 자신에게 투자하기",
    "text": "8.3 자신에게 투자하기\n문제가 발생하기 전에 문제를 해결할 수 있도록 스스로를 준비하는 데에도 시간을 할애해야 합니다. 매일 R을 배우는 데 약간의 시간을 투자하면 장기적으로 큰 보상을 받을 것입니다. 한 가지 방법은 tidyverse 블로그에서 tidyverse 팀이 무엇을 하고 있는지 팔로우하는 것입니다. R 커뮤니티를 더 광범위하게 따라잡으려면 R Weekly를 읽는 것을 추천합니다. 매주 R 커뮤니티에서 가장 흥미로운 뉴스를 집계하는 커뮤니티의 노력입니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>워크플로우: 도움 받기</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#요약",
    "href": "workflow-help.html#요약",
    "title": "8  워크플로우: 도움 받기",
    "section": "\n8.4 요약",
    "text": "8.4 요약\n이 장으로 책의 ‘전체 게임(Whole Game)’ 파트가 마무리됩니다. 이제 시각화, 변형, 정리, 가져오기 등 데이터 과학 프로세스의 가장 중요한 부분들을 보았습니다. 이제 전체 프로세스에 대한 전체적인 시각을 갖게 되었으므로 작은 조각들의 세부 사항으로 들어가기 시작할 것입니다.\n책의 다음 파트인 ’시각화(Visualize)’에서는 그래픽 문법과 ggplot2로 데이터 시각화를 만드는 것에 대해 더 깊이 파고들고, 지금까지 배운 도구를 사용하여 탐색적 데이터 분석을 수행하는 방법을 보여주며, 소통을 위한 플롯을 만드는 모범 사례를 소개합니다.",
    "crumbs": [
      "전체 게임",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>워크플로우: 도움 받기</span>"
    ]
  },
  {
    "objectID": "visualize.html",
    "href": "visualize.html",
    "title": "시각화 (Visualize)",
    "section": "",
    "text": "책의 첫 번째 파트를 읽고 난 후, 여러분은 데이터 과학을 수행하기 위한 가장 중요한 도구들을 (적어도 표면적으로는) 이해하게 되었습니다. 이제 세부 사항으로 깊이 들어갈 때입니다. 책의 이 파트에서는 데이터 시각화에 대해 더 깊이 있게 배울 것입니다.\n\n\n\n\n\n\n\nFigure 1: 데이터 시각화는 종종 데이터 탐색의 첫 번째 단계입니다.\n\n\n\n\n각 장은 데이터 시각화를 생성하는 한두 가지 측면을 다룹니다.\n\n9  레이어(Layers) 에서는 레이어드 그래픽 문법(layered grammar of graphics)에 대해 배웁니다.\n10  탐색적 데이터 분석(Exploratory data analysis) 에서는 시각화를 호기심 및 회의주의와 결합하여 데이터에 대한 흥미로운 질문을 던지고 답하는 방법을 배웁니다.\n마지막으로 11  소통(Communication) 에서는 탐색적 그래픽을 가져와 이를 발전시켜 설명적 그래픽으로 바꾸는 방법을 배웁니다. 설명적 그래픽은 분석을 처음 접하는 사람이 무슨 일이 일어나고 있는지 가능한 한 쉽고 빠르게 이해할 수 있도록 돕는 그래픽입니다.\n\n이 세 장은 여러분을 시각화의 세계로 안내하지만, 배워야 할 것이 훨씬 더 많습니다. 더 배우기에 가장 좋은 곳은 ggplot2 책인 ggplot2: Elegant graphics for data analysis입니다. 이 책은 기저 이론을 훨씬 더 깊이 있게 다루며, 실질적인 문제를 해결하기 위해 개별 조각들을 결합하는 더 많은 예제를 담고 있습니다. 또 다른 훌륭한 리소스는 ggplot2 확장 갤러리 https://exts.ggplot2.tidyverse.org/gallery/입니다. 이 사이트에는 새로운 지옴(geoms)과 스케일(scales)로 ggplot2를 확장하는 많은 패키지들이 나열되어 있습니다. ggplot2로 하기에 어려워 보이는 작업을 하려 할 때 시작하기 좋은 곳입니다.",
    "crumbs": [
      "시각화 (Visualize)"
    ]
  },
  {
    "objectID": "layers.html",
    "href": "layers.html",
    "title": "9  레이어(Layers)",
    "section": "",
    "text": "9.1 소개\nChapter 1 에서 산점도, 막대 차트, 상자 그림을 만드는 방법 그 이상을 배웠습니다. ggplot2로 어떤 유형의 플롯이든 만드는 데 사용할 수 있는 기초를 배웠습니다.\n이 장에서는 레이어드 그래픽 문법(layered grammar of graphics)에 대해 배우면서 그 기초를 확장할 것입니다. 심미적 매핑, 기하학적 객체, 패싯에 대해 더 깊이 파고드는 것으로 시작하겠습니다. 그런 다음 플롯을 생성할 때 ggplot2가 내부적으로 수행하는 통계적 변환에 대해 배울 것입니다. 이러한 변환은 막대 플롯의 막대 높이나 상자 그림의 중앙값과 같이 플롯할 새 값을 계산하는 데 사용됩니다. 또한 플롯에 지옴이 표시되는 방식을 수정하는 위치 조정(position adjustments)에 대해서도 배울 것입니다. 마지막으로 좌표계를 간략하게 소개할 것입니다.\n이러한 각 레이어에 대한 모든 단일 함수와 옵션을 다루지는 않겠지만, ggplot2가 제공하는 가장 중요하고 일반적으로 사용되는 기능을 안내하고 ggplot2를 확장하는 패키지를 소개할 것입니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#소개",
    "href": "layers.html#소개",
    "title": "9  레이어(Layers)",
    "section": "",
    "text": "9.1.1 선수 지식\n이 장은 ggplot2에 중점을 둡니다. 이 장에서 사용되는 데이터셋, 도움말 페이지, 함수에 액세스하려면 다음 코드를 실행하여 tidyverse를 로드하세요:\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#심미적-매핑",
    "href": "layers.html#심미적-매핑",
    "title": "9  레이어(Layers)",
    "section": "\n9.2 심미적 매핑",
    "text": "9.2 심미적 매핑\n\n“그림의 가장 큰 가치는 우리가 결코 볼 것이라고 예상하지 못했던 것을 알아차리게 할 때이다.” — 존 튜키(John Tukey)\n\nggplot2 패키지와 함께 제공되는 mpg 데이터 프레임에는 38개의 자동차 모델에 대한 234개의 관측값이 포함되어 있음을 기억하세요.\n\nmpg\n#&gt; # A tibble: 234 × 11\n#&gt;   manufacturer model displ  year   cyl trans      drv     cty   hwy fl   \n#&gt;   &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n#&gt; 1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p    \n#&gt; 2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p    \n#&gt; 3 audi         a4      2    2008     4 manual(m6) f        20    31 p    \n#&gt; 4 audi         a4      2    2008     4 auto(av)   f        21    30 p    \n#&gt; 5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p    \n#&gt; 6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p    \n#&gt; # ℹ 228 more rows\n#&gt; # ℹ 1 more variable: class &lt;chr&gt;\n\nmpg의 변수 중 일부는 다음과 같습니다:\n\ndispl: 자동차의 엔진 크기(리터 단위). 수치형 변수입니다.\nhwy: 고속도로에서의 자동차 연비(갤런당 마일, mpg). 연비가 낮은 자동차는 연비가 높은 자동차보다 같은 거리를 이동할 때 더 많은 연료를 소비합니다. 수치형 변수입니다.\nclass: 자동차 유형. 범주형 변수입니다.\n\n다양한 자동차 class에 대해 displ과 hwy 사이의 관계를 시각화하는 것으로 시작해 봅시다. 수치형 변수를 x와 y 심미성에 매핑하고 범주형 변수를 color나 shape 같은 심미성에 매핑하는 산점도로 이를 수행할 수 있습니다.\n# 왼쪽\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point()\n\n# 오른쪽\nggplot(mpg, aes(x = displ, y = hwy, shape = class)) +\n  geom_point()\n#&gt; Warning: The shape palette can deal with a maximum of 6 discrete values because more\n#&gt; than 6 becomes difficult to discriminate\n#&gt; ℹ you have requested 7 values. Consider specifying shapes manually if you\n#&gt;   need that many of them.\n#&gt; Warning: Removed 62 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nclass가 shape에 매핑될 때 두 가지 경고가 발생합니다:\n\n1: The shape palette can deal with a maximum of 6 discrete values because more than 6 becomes difficult to discriminate; you have 7. Consider specifying shapes manually if you must have them. (모양 팔레트는 최대 6개의 이산 값을 처리할 수 있습니다. 6개 이상은 구별하기 어렵기 때문입니다. 7개가 있습니다. 꼭 필요하다면 모양을 수동으로 지정하는 것을 고려하세요.)\n2: Removed 62 rows containing missing values (geom_point()). (결측값이 포함된 62개 행이 제거되었습니다 (geom_point()).)\n\n기본적으로 ggplot2는 한 번에 6개의 모양만 사용하므로 모양 심미성을 사용할 때 추가 그룹은 플롯되지 않습니다. 두 번째 경고는 이와 관련이 있습니다. 데이터셋에 62대의 SUV가 있는데 플롯되지 않았습니다.\n마찬가지로 class를 점의 크기와 투명도를 제어하는 size 또는 alpha 심미성에 매핑할 수도 있습니다.\n# 왼쪽\nggplot(mpg, aes(x = displ, y = hwy, size = class)) +\n  geom_point()\n#&gt; Warning: Using size for a discrete variable is not advised.\n\n# 오른쪽\nggplot(mpg, aes(x = displ, y = hwy, alpha = class)) +\n  geom_point()\n#&gt; Warning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n이 두 가지 모두 경고를 발생시킵니다:\n\nUsing alpha for a discrete variable is not advised. (이산 변수에 알파를 사용하는 것은 권장되지 않습니다.)\n\n순서가 없는 이산(범주형) 변수(class)를 순서가 있는 심미성(size 또는 alpha)에 매핑하는 것은 일반적으로 좋은 생각이 아닙니다. 사실 존재하지 않는 순위를 암시하기 때문입니다.\n심미성을 매핑하면 나머지는 ggplot2가 처리합니다. 심미성에 사용할 합리적인 척도(scale)를 선택하고 수준과 값 사이의 매핑을 설명하는 범례를 구성합니다. x와 y 심미성의 경우 ggplot2는 범례를 만들지 않고 눈금 표시와 레이블이 있는 축 선을 만듭니다. 축 선은 범례와 동일한 정보를 제공합니다. 위치와 값 사이의 매핑을 설명합니다.\n변수 매핑에 의존하여 모양을 결정하는 대신 지옴 함수의 인수(aes() 외부)로 지옴의 시각적 속성을 수동으로 설정할 수도 있습니다. 예를 들어 플롯의 모든 점을 파란색으로 만들 수 있습니다:\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(color = \"blue\")\n\n\n\n\n\n\n\n여기서 색상은 변수에 대한 정보를 전달하지 않고 플롯의 모양만 변경합니다. 해당 심미성에 맞는 값을 선택해야 합니다:\n\n문자열로 된 색상 이름, 예: color = \"blue\"\n\nmm 단위의 점 크기, 예: size = 1\n\n숫자로 된 점 모양, 예: shape = 1, Figure 9.1 에 표시된 대로.\n\n\n\n\n\n\n\n\nFigure 9.1: R에는 숫자로 식별되는 26개의 내장 모양이 있습니다. 일부 중복되어 보이는 것이 있습니다. 예를 들어 0, 15, 22는 모두 정사각형입니다. 차이점은 color와 fill 심미성의 상호 작용에서 비롯됩니다. 빈 모양(0–14)은 color에 의해 결정되는 테두리가 있습니다. 꽉 찬 모양(15–20)은 color로 채워집니다. 채워진 모양(21–25)은 color의 테두리가 있고 fill로 채워집니다. 모양은 유사한 모양을 서로 옆에 유지하도록 배열되어 있습니다.\n\n\n\n\n지금까지 점 지옴을 사용할 때 산점도에서 매핑하거나 설정할 수 있는 심미성에 대해 논의했습니다. https://ggplot2.tidyverse.org/articles/ggplot2-specs.html의 심미적 사양 비네트에서 가능한 모든 심미적 매핑에 대해 자세히 알아볼 수 있습니다.\n플롯에 사용할 수 있는 특정 심미성은 데이터를 나타내는 데 사용하는 지옴에 따라 다릅니다. 다음 섹션에서는 지옴에 대해 더 깊이 파고들 것입니다.\n\n9.2.1 연습문제\n\nhwy 대 displ의 산점도를 만드는데, 점들을 분홍색으로 채워진 삼각형으로 만드세요.\n\n다음 코드가 파란색 점이 있는 플롯을 생성하지 않은 이유는 무엇입니까?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = \"blue\"))\n\n\nstroke 심미성은 무엇을 합니까? 어떤 모양과 함께 작동합니까? (힌트: ?geom_point를 사용하세요)\naes(color = displ &lt; 5)와 같이 변수 이름이 아닌 다른 것에 심미성을 매핑하면 어떻게 됩니까? 참고로 x와 y도 지정해야 합니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#sec-geometric-objects",
    "href": "layers.html#sec-geometric-objects",
    "title": "9  레이어(Layers)",
    "section": "\n9.3 기하학적 객체(Geometric objects)",
    "text": "9.3 기하학적 객체(Geometric objects)\n이 두 플롯은 어떻게 유사합니까?\n\n\n\n\n\n\n\n\n\n\n두 플롯 모두 동일한 x 변수, 동일한 y 변수를 포함하며 동일한 데이터를 설명합니다. 하지만 플롯은 동일하지 않습니다. 각 플롯은 데이터를 나타내기 위해 다른 기하학적 객체, 지옴(geom)을 사용합니다. 왼쪽 플롯은 점 지옴을 사용하고 오른쪽 플롯은 데이터에 적합된 매끄러운 선인 매끄러운(smooth) 지옴을 사용합니다.\n플롯의 지옴을 변경하려면 ggplot()에 추가하는 지옴 함수를 변경하세요. 예를 들어 위의 플롯을 만들기 위해 다음 코드를 사용할 수 있습니다:\n\n# 왼쪽\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n# 오른쪽\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_smooth()\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nggplot2의 모든 지옴 함수는 지옴 레이어에서 로컬로 정의되거나 ggplot() 레이어에서 전역적으로 정의된 mapping 인수를 취합니다. 그러나 모든 심미성이 모든 지옴과 작동하는 것은 아닙니다. 점의 모양을 설정할 수는 있지만 선의 “모양”을 설정할 수는 없습니다. 시도하면 ggplot2는 해당 심미적 매핑을 조용히 무시합니다. 반면에 선의 선형(linetype)을 설정할 수 있습니다. geom_smooth()는 선형에 매핑한 변수의 각 고유 값에 대해 다른 선형을 가진 다른 선을 그립니다.\n# 왼쪽\nggplot(mpg, aes(x = displ, y = hwy, shape = drv)) + \n  geom_smooth()\n\n# 오른쪽\nggplot(mpg, aes(x = displ, y = hwy, linetype = drv)) + \n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n여기서 geom_smooth()는 자동차의 구동 방식을 설명하는 drv 값에 따라 자동차를 세 개의 선으로 분리합니다. 한 선은 4 값을 가진 모든 점을 설명하고, 한 선은 f 값을 가진 모든 점을 설명하며, 한 선은 r 값을 가진 모든 점을 설명합니다. 여기서 4는 4륜 구동, f는 전륜 구동, r은 후륜 구동을 나타냅니다.\n이것이 이상하게 들린다면 원시 데이터 위에 선을 겹쳐 놓고 drv에 따라 모든 것을 색칠하면 더 명확하게 만들 수 있습니다.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) + \n  geom_point() +\n  geom_smooth(aes(linetype = drv))\n\n\n\n\n\n\n\n이 플롯에는 동일한 그래프에 두 개의 지옴이 포함되어 있음을 주목하세요.\ngeom_smooth()와 같은 많은 지옴은 단일 기하학적 객체를 사용하여 여러 행의 데이터를 표시합니다. 이러한 지옴의 경우 group 심미성을 범주형 변수로 설정하여 여러 객체를 그릴 수 있습니다. ggplot2는 그룹화 변수의 각 고유 값에 대해 별도의 객체를 그립니다. 실제로 ggplot2는 심미성을 이산 변수에 매핑할 때마다( linetype 예제와 같이) 이러한 지옴에 대해 데이터를 자동으로 그룹화합니다. group 심미성 자체는 지옴에 범례나 구별되는 특징을 추가하지 않기 때문에 이 기능에 의존하는 것이 편리합니다.\n# 왼쪽\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth()\n\n# 가운데\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(group = drv))\n\n# 오른쪽\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n매핑을 지옴 함수에 넣으면 ggplot2는 이를 해당 레이어에 대한 로컬 매핑으로 취급합니다. 이 매핑을 사용하여 해당 레이어에 대해서만 전역 매핑을 확장하거나 덮어씁니다. 이를 통해 다른 레이어에 다른 심미성을 표시할 수 있습니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(aes(color = class)) + \n  geom_smooth()\n\n\n\n\n\n\n\n동일한 아이디어를 사용하여 각 레이어에 대해 다른 data를 지정할 수 있습니다. 여기서는 빨간 점과 열린 원을 사용하여 2인승 자동차를 강조 표시합니다. geom_point()의 로컬 데이터 인수는 해당 레이어에 대해서만 ggplot()의 전역 데이터 인수를 덮어씁니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    color = \"red\"\n  ) +\n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    shape = \"circle open\", size = 3, color = \"red\"\n  )\n\n\n\n\n\n\n\n지옴은 ggplot2의 기본 구성 요소입니다. 지옴을 변경하여 플롯의 모양을 완전히 바꿀 수 있으며, 서로 다른 지옴은 데이터의 서로 다른 특징을 드러낼 수 있습니다. 예를 들어 아래의 히스토그램과 밀도 플롯은 고속도로 마일리지의 분포가 이봉형이고 오른쪽으로 치우쳐 있음을 보여주는 반면, 상자 그림은 두 개의 잠재적인 이상치를 보여줍니다.\n# 왼쪽\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram(binwidth = 2)\n\n# 가운데\nggplot(mpg, aes(x = hwy)) +\n  geom_density()\n\n# 오른쪽\nggplot(mpg, aes(x = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2는 40개 이상의 지옴을 제공하지만 이것이 만들 수 있는 모든 가능한 플롯을 커버하는 것은 아닙니다. 다른 지옴이 필요한 경우 먼저 확장 패키지를 살펴보고 다른 누군가가 이미 구현했는지 확인하는 것이 좋습니다(샘플링은 https://exts.ggplot2.tidyverse.org/gallery/ 참조). 예를 들어 ggridges 패키지(https://wilkelab.org/ggridges)는 릿지라인(ridgeline) 플롯을 만드는 데 유용하며, 이는 범주형 변수의 여러 수준에 대해 수치형 변수의 밀도를 시각화하는 데 유용할 수 있습니다. 다음 플롯에서는 새 지옴(geom_density_ridges())을 사용했을 뿐만 아니라 동일한 변수를 여러 심미성(drv를 y, fill, color에)에 매핑하고 심미성(alpha = 0.5)을 설정하여 밀도 곡선을 투명하게 만들었습니다.\n\nlibrary(ggridges)\n\nggplot(mpg, aes(x = hwy, y = drv, fill = drv, color = drv)) +\n  geom_density_ridges(alpha = 0.5, show.legend = FALSE)\n#&gt; Picking joint bandwidth of 1.28\n\n\n\n\n\n\n\nggplot2가 제공하는 모든 지옴과 패키지의 모든 함수에 대한 포괄적인 개요를 얻을 수 있는 가장 좋은 곳은 참조 페이지입니다: https://ggplot2.tidyverse.org/reference. 단일 지옴에 대해 더 자세히 알아보려면 도움말을 사용하세요(예: ?geom_smooth).\n\n9.3.1 연습문제\n\n선 차트를 그리기 위해 어떤 지옴을 사용하겠습니까? 상자 그림은? 히스토그램은? 영역 차트는?\n\n이 장의 앞부분에서 설명 없이 show.legend를 사용했습니다:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\n여기서 show.legend = FALSE는 무엇을 합니까? 제거하면 어떻게 됩니까? 앞에서 왜 이것을 사용했다고 생각합니까?\n\ngeom_smooth()의 se 인수는 무엇을 합니까?\n\n다음 그래프를 생성하는 데 필요한 R 코드를 다시 작성하세요. 플롯에서 범주형 변수가 사용되는 곳은 drv입니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#패싯facets",
    "href": "layers.html#패싯facets",
    "title": "9  레이어(Layers)",
    "section": "\n9.4 패싯(Facets)",
    "text": "9.4 패싯(Facets)\nChapter 1 에서 범주형 변수를 기반으로 데이터의 한 부분집합을 각각 표시하는 하위 플롯으로 플롯을 분할하는 facet_wrap()을 사용한 패싯에 대해 배웠습니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_wrap(~cyl)\n\n\n\n\n\n\n\n두 변수의 조합으로 플롯을 패싯하려면 facet_wrap()에서 facet_grid()로 전환하세요. facet_grid()의 첫 번째 인수도 공식이지만, 이제는 양면 공식인 rows ~ cols입니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl)\n\n\n\n\n\n\n\n기본적으로 각 패싯은 x축과 y축에 대해 동일한 척도와 범위를 공유합니다. 이는 패싯 간에 데이터를 비교할 때 유용하지만 각 패싯 내의 관계를 더 잘 시각화하고 싶을 때는 제한적일 수 있습니다. 패싯 함수의 scales 인수를 \"free_x\"로 설정하면 열 전체에서 x축의 척도를 다르게 할 수 있고, \"free_y\"는 행 전체에서 y축의 척도를 다르게 할 수 있으며, \"free\"는 둘 다 허용합니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl, scales = \"free\")\n\n\n\n\n\n\n\n\n9.4.1 연습문제\n\n연속형 변수로 패싯하면 어떻게 됩니까?\n\n위의 facet_grid(drv ~ cyl)가 있는 플롯의 빈 셀은 무엇을 의미합니까? 다음 코드를 실행하세요. 결과 플롯과 어떤 관련이 있습니까?\n\nggplot(mpg) + \n  geom_point(aes(x = drv, y = cyl))\n\n\n\n다음 코드는 어떤 플롯을 만듭니까? .은 무엇을 합니까?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)\n\n\n\n이 섹션의 첫 번째 패싯 플롯을 가져오세요:\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ cyl, nrow = 2)\n\n색상 심미성 대신 패싯을 사용할 때의 장점은 무엇입니까? 단점은 무엇입니까? 더 큰 데이터셋이 있는 경우 균형이 어떻게 바뀔 수 있습니까?\n\n?facet_wrap을 읽어보세요. nrow는 무엇을 합니까? ncol은 무엇을 합니까? 개별 패널의 레이아웃을 제어하는 다른 옵션은 무엇입니까? facet_grid()에는 왜 nrow와 ncol 인수가 없습니까?\n\n다음 플롯 중 구동 방식이 다른 자동차 간의 엔진 크기(displ)를 비교하기 더 쉬운 것은 무엇입니까? 이는 패싯 변수를 행이나 열에 배치할 때 무엇을 말해줍니까?\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(drv ~ .)\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() +\n  facet_grid(. ~ drv)\n\n\n\nfacet_grid() 대신 facet_wrap()을 사용하여 다음 플롯을 다시 만드세요. 패싯 레이블의 위치가 어떻게 바뀝니까?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#통계적-변환",
    "href": "layers.html#통계적-변환",
    "title": "9  레이어(Layers)",
    "section": "\n9.5 통계적 변환",
    "text": "9.5 통계적 변환\ngeom_bar() 또는 geom_col()로 그린 기본 막대 차트를 고려해 보세요. 다음 차트는 cut별로 그룹화된 diamonds 데이터셋의 다이아몬드 총 개수를 표시합니다. ggplot2 패키지에 있는 diamonds 데이터셋에는 각 다이아몬드의 price, carat, color, clarity, cut을 포함한 약 54,000개의 다이아몬드 정보가 포함되어 있습니다. 차트는 품질이 낮은 컷보다 품질이 높은 컷의 다이아몬드가 더 많이 사용 가능함을 보여줍니다.\n\nggplot(diamonds, aes(x = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\nx축에는 차트가 diamonds의 변수인 cut을 표시합니다. y축에는 개수(count)를 표시하지만 개수는 diamonds의 변수가 아닙니다! 개수는 어디에서 왔을까요? 산점도와 같은 많은 그래프는 데이터셋의 원시 값을 플롯합니다. 막대 차트와 같은 다른 그래프는 플롯할 새 값을 계산합니다:\n\n막대 차트, 히스토그램, 빈도 다각형은 데이터를 비닝(binning)한 다음 각 빈에 속하는 포인트 수인 빈 카운트를 플롯합니다.\n스무더(smoothers)는 데이터에 모델을 적합시킨 다음 모델의 예측을 플롯합니다.\n상자 그림은 분포의 5가지 요약 수치를 계산한 다음 그 요약을 특별히 포맷된 상자로 표시합니다.\n\n그래프에 대한 새 값을 계산하는 데 사용되는 알고리즘을 스탯(stat), 통계적 변환(statistical transformation)의 줄임말이라고 합니다. Figure 9.2 는 geom_bar()에서 이 프로세스가 작동하는 방식을 보여줍니다.\n\n\n\n\n\n\n\nFigure 9.2: 막대 차트를 만들 때는 먼저 원시 데이터로 시작한 다음, 각 막대의 관측값 수를 계산하기 위해 집계하고, 마지막으로 계산된 변수를 플롯 심미성에 매핑합니다.\n\n\n\n\nstat 인수의 기본값을 검사하여 지옴이 사용하는 스탯을 알 수 있습니다. 예를 들어 ?geom_bar는 stat의 기본값이 “count”임을 보여주며, 이는 geom_bar()가 stat_count()를 사용한다는 의미입니다. stat_count()는 geom_bar()와 같은 페이지에 문서화되어 있습니다. 아래로 스크롤하면 “Computed variables(계산된 변수)”라는 섹션에서 count와 prop라는 두 가지 새로운 변수를 계산한다고 설명합니다.\n모든 지옴에는 기본 스탯이 있고, 모든 스탯에는 기본 지옴이 있습니다. 즉, 일반적으로 기본 통계적 변환에 대해 걱정하지 않고 지옴을 사용할 수 있습니다. 그러나 스탯을 명시적으로 사용해야 하는 세 가지 이유가 있습니다:\n\n\n기본 스탯을 재정의하고 싶을 수 있습니다. 아래 코드에서는 geom_bar()의 스탯을 count(기본값)에서 identity로 변경합니다. 이렇게 하면 막대의 높이를 y 변수의 원시 값에 매핑할 수 있습니다.\n\ndiamonds |&gt;\n  count(cut) |&gt;\n  ggplot(aes(x = cut, y = n)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n변환된 변수에서 심미성으로의 기본 매핑을 재정의하고 싶을 수 있습니다. 예를 들어 개수보다는 비율의 막대 차트를 표시하고 싶을 수 있습니다:\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop), group = 1)) + \n  geom_bar()\n\n\n\n\n\n\n\n스탯에 의해 계산될 수 있는 변수를 찾으려면 geom_bar() 도움말에서 “computed variables”라는 제목의 섹션을 찾으세요.\n\n\n코드에서 통계적 변환에 더 큰 주의를 끌고 싶을 수 있습니다. 예를 들어 각 고유 x 값에 대한 y 값을 요약하는 stat_summary()를 사용하여 계산 중인 요약에 주의를 끌 수 있습니다:\n\nggplot(diamonds) + \n  stat_summary(\n    aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )\n\n\n\n\n\n\n\n\n\nggplot2는 사용할 수 있는 20개 이상의 스탯을 제공합니다. 각 스탯은 함수이므로 일반적인 방법(예: ?stat_bin)으로 도움말을 얻을 수 있습니다.\n\n9.5.1 연습문제\n\nstat_summary()와 관련된 기본 지옴은 무엇입니까? 스탯 함수 대신 지옴 함수를 사용하도록 이전 플롯을 어떻게 다시 작성할 수 있습니까?\ngeom_col()은 무엇을 합니까? geom_bar()와 어떻게 다릅니까?\n대부분의 지옴과 스탯은 거의 항상 함께 사용되는 쌍으로 제공됩니다. 모든 쌍의 목록을 만드세요. 공통점은 무엇입니까? (힌트: 문서를 읽어보세요.)\nstat_smooth()는 어떤 변수를 계산합니까? 어떤 인수가 동작을 제어합니까?\n\n비율 막대 차트에서 group = 1을 설정해야 했습니다. 이유는 무엇입니까? 즉, 이 두 그래프의 문제점은 무엇입니까?\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop))) + \n  geom_bar()\nggplot(diamonds, aes(x = cut, fill = color, y = after_stat(prop))) + \n  geom_bar()",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#위치-조정position-adjustments",
    "href": "layers.html#위치-조정position-adjustments",
    "title": "9  레이어(Layers)",
    "section": "\n9.6 위치 조정(Position adjustments)",
    "text": "9.6 위치 조정(Position adjustments)\n막대 차트와 관련된 마법이 하나 더 있습니다. color 심미성이나 더 유용하게는 fill 심미성을 사용하여 막대 차트에 색을 입힐 수 있습니다:\n# 왼쪽\nggplot(mpg, aes(x = drv, color = drv)) + \n  geom_bar()\n\n# 오른쪽\nggplot(mpg, aes(x = drv, fill = drv)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n채우기 심미성을 class와 같은 다른 변수에 매핑하면 어떻게 되는지 주목하세요. 막대가 자동으로 쌓입니다. 각 색상 사각형은 drv와 class의 조합을 나타냅니다.\n\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar()\n\n\n\n\n\n\n\n스태킹(stacking)은 position 인수에 의해 지정된 위치 조정을 사용하여 자동으로 수행됩니다. 누적 막대 차트를 원하지 않는 경우 \"identity\", \"dodge\", \"fill\"의 세 가지 다른 옵션 중 하나를 사용할 수 있습니다.\n\n\nposition = \"identity\"는 각 객체를 그래프 컨텍스트 내에서 떨어지는 위치에 정확하게 배치합니다. 이것은 막대가 겹치기 때문에 막대에는 별로 유용하지 않습니다. 그 겹침을 보려면 alpha를 작은 값으로 설정하여 막대를 약간 투명하게 만들거나 fill = NA를 설정하여 완전히 투명하게 만들어야 합니다.\n# 왼쪽\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(alpha = 1/5, position = \"identity\")\n\n# 오른쪽\nggplot(mpg, aes(x = drv, color = class)) + \n  geom_bar(fill = NA, position = \"identity\")\n\n\n\n\n\n\n\n\n\n\nidentity 위치 조정은 점과 같은 2D 지옴에 더 유용하며, 여기서는 기본값입니다.\n\nposition = \"fill\"은 스태킹처럼 작동하지만, 각 누적 막대 세트의 높이를 동일하게 만듭니다. 이렇게 하면 그룹 간의 비율을 비교하기가 더 쉽습니다.\n\nposition = \"dodge\"는 겹치는 객체를 서로 옆에 바로 배치합니다. 이렇게 하면 개별 값을 비교하기가 더 쉽습니다.\n# 왼쪽\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(position = \"fill\")\n\n# 오른쪽\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\n막대 차트에는 유용하지 않지만 산점도에는 매우 유용할 수 있는 다른 유형의 조정이 하나 있습니다. 첫 번째 산점도를 상기해 보세요. 데이터셋에 234개의 관측값이 있는데 플롯에는 126개의 점만 표시된다는 것을 눈치챘나요?\n\n\n\n\n\n\n\n\nhwy와 displ의 기본 값은 반올림되어 점이 그리드에 나타나고 많은 점이 서로 겹칩니다. 이 문제를 오버플로팅(overplotting) 이라고 합니다. 이러한 배열은 데이터의 분포를 보기 어렵게 만듭니다. 데이터 포인트가 그래프 전체에 균등하게 퍼져 있나요, 아니면 109개의 값을 포함하는 hwy와 displ의 특별한 조합이 하나 있나요?\n위치 조정을 “jitter”로 설정하여 이 그리딩을 피할 수 있습니다. position = \"jitter\"는 각 점에 약간의 무작위 노이즈를 추가합니다. 두 점이 같은 양의 무작위 노이즈를 받을 가능성이 없기 때문에 점들이 퍼집니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(position = \"jitter\")\n\n\n\n\n\n\n\n무작위성을 추가하는 것은 플롯을 개선하는 이상한 방법처럼 보일 수 있지만, 그래프를 작은 규모에서는 덜 정확하게 만들지만 큰 규모에서는 그래프를 더 잘 드러나게 만듭니다. 이것은 매우 유용한 작업이기 때문에 ggplot2에는 geom_point(position = \"jitter\")의 단축형인 geom_jitter()가 함께 제공됩니다.\n위치 조정에 대해 자세히 알아보려면 각 조정과 관련된 도움말 페이지를 찾아보세요: ?position_dodge, ?position_fill, ?position_identity, ?position_jitter, ?position_stack.\n\n9.6.1 연습문제\n\n\n다음 플롯의 문제점은 무엇입니까? 어떻게 개선할 수 있습니까?\n\nggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point()\n\n\n\n두 플롯의 차이점이 있다면 무엇입니까? 이유는 무엇입니까?\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point()\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(position = \"identity\")\n\n\ngeom_jitter()의 어떤 매개변수가 지터링의 양을 제어합니까?\ngeom_jitter()와 geom_count()를 비교하고 대조하세요.\ngeom_boxplot()의 기본 위치 조정은 무엇입니까? 그것을 보여주는 mpg 데이터셋의 시각화를 만드세요.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#좌표계",
    "href": "layers.html#좌표계",
    "title": "9  레이어(Layers)",
    "section": "\n9.7 좌표계",
    "text": "9.7 좌표계\n좌표계는 아마도 ggplot2에서 가장 복잡한 부분일 것입니다. 기본 좌표계는 x와 y 위치가 독립적으로 작용하여 각 점의 위치를 결정하는 데카르트 좌표계(Cartesian coordinate system)입니다. 가끔 도움이 되는 두 가지 다른 좌표계가 있습니다.\n\n\ncoord_quickmap()은 지리적 지도의 가로세로 비율(aspect ratio)을 올바르게 설정합니다. 이것은 ggplot2로 공간 데이터를 플롯하는 경우 매우 중요합니다. 이 책에서는 지도를 다룰 공간이 없지만 ggplot2: Elegant graphics for data analysis의 Maps 장에서 자세히 알아볼 수 있습니다.\nnz &lt;- map_data(\"nz\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\") +\n  coord_quickmap()\n\n\n\n\n\n\n\n\n\n\n\n\ncoord_polar()는 극좌표를 사용합니다. 극좌표는 막대 차트와 콕스콤(Coxcomb) 차트 사이의 흥미로운 연결을 보여줍니다.\nbar &lt;- ggplot(data = diamonds) + \n  geom_bar(\n    mapping = aes(x = clarity, fill = clarity), \n    show.legend = FALSE,\n    width = 1\n  ) + \n  theme(aspect.ratio = 1)\n\nbar + coord_flip()\nbar + coord_polar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.7.1 연습문제\n\ncoord_polar()를 사용하여 누적 막대 차트를 파이 차트로 바꾸세요.\ncoord_quickmap()과 coord_map()의 차이점은 무엇입니까?\n\n다음 플롯은 도시 및 고속도로 mpg 간의 관계에 대해 무엇을 말해줍니까? coord_fixed()가 중요한 이유는 무엇입니까? geom_abline()은 무엇을 합니까?\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +\n  geom_point() + \n  geom_abline() +\n  coord_fixed()",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#레이어드-그래픽-문법",
    "href": "layers.html#레이어드-그래픽-문법",
    "title": "9  레이어(Layers)",
    "section": "\n9.8 레이어드 그래픽 문법",
    "text": "9.8 레이어드 그래픽 문법\nSection 1.3 에서 배운 그래프 템플릿에 위치 조정, 스탯, 좌표계, 패싯을 추가하여 확장할 수 있습니다:\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(\n     mapping = aes(&lt;MAPPINGS&gt;),\n     stat = &lt;STAT&gt;, \n     position = &lt;POSITION&gt;\n  ) +\n  &lt;COORDINATE_FUNCTION&gt; +\n  &lt;FACET_FUNCTION&gt;\n우리의 새 템플릿은 템플릿에 나타나는 대괄호로 묶인 단어인 7개의 매개변수를 취합니다. 실제로는 그래프를 만들기 위해 7개의 매개변수를 모두 제공할 필요가 거의 없습니다. ggplot2가 데이터, 매핑, 지옴 함수를 제외한 모든 것에 대해 유용한 기본값을 제공하기 때문입니다.\n템플릿의 7개 매개변수는 플롯을 구축하기 위한 공식적인 시스템인 그래픽 문법을 구성합니다. 그래픽 문법은 데이터셋, 지옴, 매핑 세트, 스탯, 위치 조정, 좌표계, 패싯 방식, 테마의 조합으로 어떤 플롯이든 고유하게 설명할 수 있다는 통찰력에 기초합니다.\n이것이 어떻게 작동하는지 보려면 처음부터 기본 플롯을 구축하는 방법을 고려해 보세요: 데이터셋으로 시작한 다음 표시하려는 정보로 변환할 수 있습니다(스탯으로). 다음으로 변환된 데이터의 각 관측값을 나타낼 기하학적 객체를 선택할 수 있습니다. 그런 다음 지옴의 심미적 속성을 사용하여 데이터의 변수를 나타낼 수 있습니다. 각 변수의 값을 심미성의 수준에 매핑합니다. 이 단계들은 Figure 9.3 에 설명되어 있습니다. 그런 다음 지옴을 배치할 좌표계를 선택하고 객체의 위치(그 자체로 심미적 속성임)를 사용하여 x 및 y 변수의 값을 표시합니다.\n\n\n\n\n\n\n\nFigure 9.3: 원시 데이터에서 빈도 테이블로, 그리고 막대의 높이가 빈도를 나타내는 막대 플롯으로 가는 단계.\n\n\n\n\n이 시점에서 완전한 그래프를 갖게 되지만 좌표계 내에서 지옴의 위치를 추가로 조정하거나(위치 조정) 그래프를 하위 플롯으로 분할(패싯)할 수 있습니다. 또한 하나 이상의 추가 레이어를 추가하여 플롯을 확장할 수도 있습니다. 여기서 각 추가 레이어는 데이터셋, 지옴, 매핑 세트, 스탯, 위치 조정을 사용합니다.\n이 방법을 사용하여 상상하는 어떤 플롯이든 만들 수 있습니다. 즉, 이 장에서 배운 코드 템플릿을 사용하여 수십만 개의 고유한 플롯을 만들 수 있습니다.\nggplot2의 이론적 토대에 대해 더 알고 싶다면 ggplot2의 이론을 자세히 설명하는 과학 논문인 “The Layered Grammar of Graphics”를 읽어보는 것을 추천합니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "layers.html#요약",
    "href": "layers.html#요약",
    "title": "9  레이어(Layers)",
    "section": "\n9.9 요약",
    "text": "9.9 요약\n이 장에서는 간단한 플롯을 만들기 위한 심미성과 기하학, 플롯을 부분집합으로 나누기 위한 패싯, 지옴이 계산되는 방식을 이해하기 위한 통계, 지옴이 겹칠 수 있는 경우 위치의 세부 사항을 제어하기 위한 위치 조정, x와 y가 의미하는 바를 근본적으로 변경할 수 있는 좌표계로 시작하여 레이어드 그래픽 문법에 대해 배웠습니다. 아직 다루지 않은 레이어 중 하나는 테마이며, Section 11.5 에서 소개할 것입니다.\n전체 ggplot2 기능에 대한 개요를 얻을 수 있는 매우 유용한 두 가지 리소스는 ggplot2 치트시트(https://posit.co/resources/cheatsheets에서 찾을 수 있음)와 ggplot2 패키지 웹사이트(https://ggplot2.tidyverse.org)입니다.\n이 장에서 얻어야 할 중요한 교훈은 ggplot2에서 제공하지 않는 지옴이 필요하다고 느낄 때, 다른 누군가가 해당 지옴을 제공하는 ggplot2 확장 패키지를 만들어 이미 문제를 해결했는지 확인해 보는 것이 항상 좋은 생각이라는 것입니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>레이어(Layers)</span>"
    ]
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "",
    "text": "10.1 소개\n이 장에서는 시각화와 변형을 사용하여 체계적으로 데이터를 탐색하는 방법을 보여줄 것입니다. 이는 통계학자들이 탐색적 데이터 분석(exploratory data analysis), 줄여서 EDA라고 부르는 작업입니다. EDA는 반복적인 주기입니다. 여러분은:\nEDA는 엄격한 규칙이 있는 공식적인 프로세스가 아닙니다. 무엇보다 EDA는 마음가짐입니다. EDA의 초기 단계에서는 떠오르는 모든 아이디어를 자유롭게 조사해야 합니다. 이러한 아이디어 중 일부는 성공할 것이고 일부는 막다른 골목일 것입니다. 탐색이 계속됨에 따라 결국 작성하여 다른 사람들에게 전달하게 될 몇 가지 특히 생산적인 통찰력에 집중하게 될 것입니다.\nEDA는 주요 연구 질문이 쟁반에 담겨 제공되더라도 모든 데이터 분석의 중요한 부분입니다. 항상 데이터의 품질을 조사해야 하기 때문입니다. 데이터 정리는 EDA의 한 가지 적용일 뿐입니다. 데이터가 기대치를 충족하는지 여부에 대한 질문을 합니다. 데이터 정리를 하려면 EDA의 모든 도구인 시각화, 변형, 모델링을 배포해야 합니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#소개",
    "href": "EDA.html#소개",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "",
    "text": "데이터에 대한 질문을 생성합니다.\n데이터를 시각화, 변형, 모델링하여 답을 찾습니다.\n배운 내용을 사용하여 질문을 다듬거나 새로운 질문을 생성합니다.\n\n\n\n\n10.1.1 선수 지식\n이 장에서는 dplyr과 ggplot2에 대해 배운 내용을 결합하여 대화식으로 질문하고, 데이터로 답하고, 새로운 질문을 할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#질문",
    "href": "EDA.html#질문",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "\n10.2 질문",
    "text": "10.2 질문\n\n“일상적인 통계 질문은 없고, 의심스러운 통계 일상만 있다.” — 데이비드 콕스(Sir David Cox)\n\n\n“종종 모호한 올바른 질문에 대한 근사적인 답이 항상 정확하게 만들 수 있는 잘못된 질문에 대한 정확한 답보다 훨씬 낫다.” — 존 튜키(John Tukey)\n\nEDA 동안의 목표는 데이터에 대한 이해를 발전시키는 것입니다. 이를 수행하는 가장 쉬운 방법은 질문을 도구로 사용하여 조사를 안내하는 것입니다. 질문을 하면 질문은 데이터셋의 특정 부분에 주의를 집중시키고 어떤 그래프, 모델 또는 변형을 만들지 결정하는 데 도움이 됩니다.\nEDA는 근본적으로 창의적인 프로세스입니다. 그리고 대부분의 창의적인 프로세스와 마찬가지로 양질의 질문을 하는 열쇠는 다량의 질문을 생성하는 것입니다. 분석 시작 시점에 통찰력 있는 질문을 하는 것은 어렵습니다. 데이터셋에서 어떤 통찰력을 얻을 수 있는지 모르기 때문입니다. 반면에 새로운 질문을 할 때마다 데이터의 새로운 측면에 노출되고 발견을 할 가능성이 높아집니다. 각 질문에 대해 찾은 내용을 바탕으로 새로운 질문을 후속 조치하면 데이터의 가장 흥미로운 부분을 빠르게 파고들어 생각할 거리를 주는 일련의 질문을 개발할 수 있습니다.\n연구를 안내하기 위해 어떤 질문을 해야 하는지에 대한 규칙은 없습니다. 그러나 데이터 내에서 발견을 하기 위해 항상 유용한 두 가지 유형의 질문이 있습니다. 이 질문들을 대략적으로 다음과 같이 표현할 수 있습니다:\n\n변수 내에서 어떤 유형의 변동(variation)이 발생하는가?\n변수 간에 어떤 유형의 공변동(covariation)이 발생하는가?\n\n이 장의 나머지 부분에서는 이 두 가지 질문을 살펴볼 것입니다. 변동과 공변동이 무엇인지 설명하고 각 질문에 답하는 여러 가지 방법을 보여줄 것입니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#변동variation",
    "href": "EDA.html#변동variation",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "\n10.3 변동(Variation)",
    "text": "10.3 변동(Variation)\n변동은 측정할 때마다 변수의 값이 변하는 경향입니다. 실생활에서 변동을 쉽게 볼 수 있습니다. 연속형 변수를 두 번 측정하면 두 가지 다른 결과를 얻게 됩니다. 빛의 속도와 같이 일정한 양을 측정하더라도 마찬가지입니다. 각 측정에는 측정할 때마다 달라지는 소량의 오차가 포함됩니다. 다른 대상(예: 다른 사람들의 눈 색깔)이나 다른 시간(예: 다른 순간의 전자의 에너지 준위)에 걸쳐 측정하는 경우에도 변수가 달라질 수 있습니다. 모든 변수에는 고유한 변동 패턴이 있으며, 이는 동일한 관측값에 대한 측정 간에 그리고 관측값 전반에 걸쳐 어떻게 변하는지에 대한 흥미로운 정보를 드러낼 수 있습니다. 그 패턴을 이해하는 가장 좋은 방법은 변수 값의 분포를 시각화하는 것인데, 이는 Chapter 1 에서 배웠습니다.\ndiamonds 데이터셋에 있는 약 54,000개의 다이아몬드 무게(carat) 분포를 시각화하여 탐색을 시작하겠습니다. carat은 수치형 변수이므로 히스토그램을 사용할 수 있습니다:\n\nggplot(diamonds, aes(x = carat)) +\n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\n이제 변동을 시각화할 수 있으므로 플롯에서 무엇을 찾아야 할까요? 그리고 어떤 유형의 후속 질문을 해야 할까요? 아래에 그래프에서 찾을 수 있는 가장 유용한 유형의 정보 목록과 각 유형의 정보에 대한 몇 가지 후속 질문을 정리했습니다. 좋은 후속 질문을 하는 열쇠는 호기심(무엇을 더 배우고 싶은가?)과 회의주의(이것이 어떻게 오해를 불러일으킬 수 있는가?)에 의존하는 것입니다.\n\n10.3.1 전형적인 값\n막대 차트와 히스토그램 모두에서 키가 큰 막대는 변수의 일반적인 값을 보여주고 짧은 막대는 덜 일반적인 값을 보여줍니다. 막대가 없는 곳은 데이터에서 보이지 않는 값을 나타냅니다. 이 정보를 유용한 질문으로 바꾸려면 예상치 못한 것을 찾으세요:\n\n가장 흔한 값은 무엇입니까? 왜 그렇습니까?\n드문 값은 무엇입니까? 왜 그렇습니까? 그것이 당신의 기대와 일치합니까?\n특이한 패턴을 볼 수 있습니까? 무엇이 그것들을 설명할 수 있습니까?\n\n더 작은 다이아몬드에 대한 carat 분포를 살펴보겠습니다.\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt; 3)\n\nggplot(smaller, aes(x = carat)) +\n  geom_histogram(binwidth = 0.01)\n\n\n\n\n\n\n\n이 히스토그램은 몇 가지 흥미로운 질문을 제기합니다:\n\n왜 정수 캐럿과 일반적인 캐럿 분수에 더 많은 다이아몬드가 있습니까?\n왜 각 봉우리의 약간 오른쪽에는 다이아몬드가 더 많고 각 봉우리의 약간 왼쪽에는 더 적습니까?\n\n시각화는 또한 클러스터를 드러낼 수 있으며, 이는 데이터에 하위 그룹이 존재함을 시사합니다. 하위 그룹을 이해하려면 다음을 질문하세요:\n\n각 하위 그룹 내의 관측값은 서로 어떻게 유사합니까?\n별도의 클러스터에 있는 관측값은 서로 어떻게 다릅니까?\n클러스터를 어떻게 설명하거나 묘사할 수 있습니까?\n클러스터의 모양이 오해를 불러일으킬 수 있는 이유는 무엇입니까?\n\n이러한 질문 중 일부는 데이터로 답할 수 있는 반면 일부는 데이터에 대한 도메인 전문 지식이 필요합니다. 그 중 많은 질문은 변수 간의 관계를 탐색하도록 유도할 것입니다. 예를 들어 한 변수의 값이 다른 변수의 동작을 설명할 수 있는지 확인하는 것입니다. 곧 다루겠습니다.\n\n10.3.2 특이한 값\n이상치(Outliers)는 특이한 관측값입니다. 패턴에 맞지 않는 것처럼 보이는 데이터 포인트입니다. 때로는 이상치가 데이터 입력 오류이기도 하고, 때로는 단순히 이 데이터 수집에서 관찰된 극단적인 값이기도 하며, 다른 경우에는 중요한 새로운 발견을 암시하기도 합니다. 데이터가 많으면 히스토그램에서 이상치를 보기 어려울 때가 있습니다. 예를 들어 diamonds 데이터셋에서 y 변수의 분포를 가져와 보겠습니다. 이상치의 유일한 증거는 x축의 비정상적으로 넓은 한계입니다.\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\n일반적인 빈에는 너무 많은 관측값이 있어서 드문 빈은 매우 짧아 보기가 매우 어렵습니다(0을 뚫어지게 쳐다보면 뭔가 발견할 수도 있겠지만요). 특이한 값을 쉽게 볼 수 있도록 coord_cartesian()을 사용하여 y축의 작은 값으로 줌인해야 합니다:\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5) +\n  coord_cartesian(ylim = c(0, 50))\n\n\n\n\n\n\n\ncoord_cartesian()에는 x축을 줌인해야 할 때를 위한 xlim() 인수도 있습니다. ggplot2에는 xlim() 및 ylim() 함수도 있는데, 이는 약간 다르게 작동합니다. 한계를 벗어나는 데이터를 버립니다.\n이를 통해 0, ~30, ~60의 세 가지 특이한 값을 볼 수 있습니다. dplyr로 그것들을 뽑아냅니다:\n\nunusual &lt;- diamonds |&gt; \n  filter(y &lt; 3 | y &gt; 20) |&gt; \n  select(price, x, y, z) |&gt;\n  arrange(y)\nunusual\n#&gt; # A tibble: 9 × 4\n#&gt;   price     x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  5139  0      0    0   \n#&gt; 2  6381  0      0    0   \n#&gt; 3 12800  0      0    0   \n#&gt; 4 15686  0      0    0   \n#&gt; 5 18034  0      0    0   \n#&gt; 6  2130  0      0    0   \n#&gt; 7  2130  0      0    0   \n#&gt; 8  2075  5.15  31.8  5.12\n#&gt; 9 12210  8.09  58.9  8.06\n\ny 변수는 이 다이아몬드의 세 가지 치수 중 하나를 mm 단위로 측정합니다. 우리는 다이아몬드의 너비가 0mm일 수 없다는 것을 알고 있으므로 이 값들은 부정확해야 합니다. EDA를 수행함으로써 우리는 단순히 NA를 검색해서는 찾을 수 없었던 0으로 코딩된 결측 데이터를 발견했습니다. 앞으로는 오해의 소지가 있는 계산을 방지하기 위해 이 값들을 NA로 다시 코딩하는 것을 선택할 수 있습니다. 또한 32mm와 59mm의 측정값이 그럴듯하지 않다고 의심할 수도 있습니다. 그 다이아몬드들은 길이가 1인치가 넘지만 가격은 수십만 달러가 아니니까요!\n이상치를 포함하고 제외하고 분석을 반복하는 것은 좋은 습관입니다. 결과에 미치는 영향이 미미하고 왜 거기에 있는지 파악할 수 없다면 생략하고 넘어가는 것이 합리적입니다. 그러나 결과에 상당한 영향을 미치는 경우 정당한 이유 없이 삭제해서는 안 됩니다. 원인(예: 데이터 입력 오류)을 파악하고 보고서에 제거했음을 공개해야 합니다.\n\n10.3.3 연습문제\n\ndiamonds의 x, y, z 변수 각각의 분포를 탐색하세요. 무엇을 알게 되었습니까? 다이아몬드에 대해 생각하고 길이, 너비, 깊이인 치수를 어떻게 결정할 수 있을지 생각해 보세요.\nprice의 분포를 탐색하세요. 특이하거나 놀라운 것을 발견했습니까? (힌트: binwidth에 대해 신중하게 생각하고 다양한 값을 시도해 보세요.)\n0.99 캐럿인 다이아몬드는 몇 개입니까? 1 캐럿인 것은 몇 개입니까? 차이의 원인은 무엇이라고 생각합니까?\n히스토그램을 확대할 때 coord_cartesian() 대 xlim() 또는 ylim()을 비교하고 대조하세요. binwidth를 설정하지 않으면 어떻게 됩니까? 막대 절반만 보이도록 확대하려고 하면 어떻게 됩니까?",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#sec-unusual-values-eda",
    "href": "EDA.html#sec-unusual-values-eda",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "\n10.4 특이한 값",
    "text": "10.4 특이한 값\n데이터셋에서 특이한 값을 발견했고 나머지 분석으로 넘어가고 싶다면 두 가지 옵션이 있습니다.\n\n\n이상한 값이 있는 전체 행을 삭제합니다:\n\ndiamonds2 &lt;- diamonds |&gt; \n  filter(between(y, 3, 20))\n\n하나의 유효하지 않은 값이 해당 관측값의 다른 모든 값도 유효하지 않음을 의미하지는 않으므로 이 옵션은 권장하지 않습니다. 또한 품질이 낮은 데이터가 있는 경우 모든 변수에 이 접근 방식을 적용할 때쯤이면 데이터가 하나도 남지 않을 수 있습니다!\n\n\n대신 특이한 값을 결측값으로 바꾸는 것을 권장합니다. 가장 쉬운 방법은 mutate()를 사용하여 변수를 수정된 사본으로 바꾸는 것입니다. if_else() 함수를 사용하여 특이한 값을 NA로 바꿀 수 있습니다:\n\ndiamonds2 &lt;- diamonds |&gt; \n  mutate(y = if_else(y &lt; 3 | y &gt; 20, NA, y))\n\n\n\n결측값을 어디에 플롯해야 하는지 명확하지 않으므로 ggplot2는 플롯에 포함하지 않지만 제거되었다고 경고합니다:\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point()\n#&gt; Warning: Removed 9 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n경고를 억제하려면 na.rm = TRUE를 설정하세요:\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point(na.rm = TRUE)\n\n어떤 때는 결측값이 있는 관측값이 기록된 값이 있는 관측값과 어떻게 다른지 이해하고 싶을 때가 있습니다. 예를 들어 nycflights13::flights1에서 dep_time 변수의 결측값은 항공편이 취소되었음을 나타냅니다. 따라서 취소된 항공편과 취소되지 않은 항공편의 예정된 출발 시간을 비교하고 싶을 수 있습니다. is.na()를 사용하여 dep_time이 누락되었는지 확인하여 새 변수를 만듦으로써 이를 수행할 수 있습니다.\n\nnycflights13::flights |&gt; \n  mutate(\n    cancelled = is.na(dep_time),\n    sched_hour = sched_dep_time %/% 100,\n    sched_min = sched_dep_time %% 100,\n    sched_dep_time = sched_hour + (sched_min / 60)\n  ) |&gt; \n  ggplot(aes(x = sched_dep_time)) + \n  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)\n\n\n\n\n\n\n\n그러나 취소된 항공편보다 취소되지 않은 항공편이 훨씬 많기 때문에 이 플롯은 훌륭하지 않습니다. 다음 섹션에서는 이 비교를 개선하기 위한 몇 가지 기술을 살펴볼 것입니다.\n\n10.4.1 연습문제\n\n히스토그램에서 결측값은 어떻게 됩니까? 막대 차트에서 결측값은 어떻게 됩니까? 히스토그램과 막대 차트에서 결측값을 처리하는 방식에 차이가 있는 이유는 무엇입니까?\nmean()과 sum()에서 na.rm = TRUE는 무엇을 합니까?\n항공편이 취소되었는지 여부에 따라 색상으로 구분된 scheduled_dep_time의 빈도 플롯을 다시 만드세요. 또한 cancelled 변수로 패싯하세요. 취소된 항공편보다 취소되지 않은 항공편이 많은 효과를 완화하기 위해 패싯 함수의 scales 변수에 대해 다른 값을 실험해 보세요.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#공변동covariation",
    "href": "EDA.html#공변동covariation",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "\n10.5 공변동(Covariation)",
    "text": "10.5 공변동(Covariation)\n변동이 변수 내의 동작을 설명한다면, 공변동은 변수 간의 동작을 설명합니다. 공변동은 두 개 이상의 변수 값이 관련된 방식으로 함께 변하는 경향입니다. 공변동을 발견하는 가장 좋은 방법은 두 개 이상의 변수 간의 관계를 시각화하는 것입니다.\n\n10.5.1 범주형 변수와 수치형 변수\n예를 들어 geom_freqpoly()를 사용하여 다이아몬드의 가격이 품질(cut으로 측정)에 따라 어떻게 변하는지 살펴보겠습니다:\n\nggplot(diamonds, aes(x = price)) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\nggplot2는 cut이 데이터에서 순서형 팩터 변수로 정의되어 있기 때문에 cut에 대해 순서가 있는 색상 척도를 사용한다는 점에 유의하세요. 이것들에 대해서는 Section 16.6 에서 더 자세히 배울 것입니다.\ngeom_freqpoly()의 기본 모양은 여기서는 별로 유용하지 않습니다. 전체 개수에 의해 결정되는 높이가 cut마다 너무 다르기 때문에 분포 모양의 차이를 보기 어렵기 때문입니다.\n비교를 더 쉽게 하려면 y축에 표시되는 것을 바꿔야 합니다. 개수를 표시하는 대신, 각 빈도 다각형 아래의 면적이 1이 되도록 개수를 표준화한 밀도(density) 를 표시할 것입니다.\n\nggplot(diamonds, aes(x = price, y = after_stat(density))) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\n밀도를 y에 매핑하고 있지만 density는 diamonds 데이터셋의 변수가 아니므로 먼저 계산해야 합니다. 그렇게 하기 위해 after_stat() 함수를 사용합니다.\n이 플롯에는 다소 놀라운 점이 있습니다. (가장 낮은 품질인) Fair 다이아몬드의 평균 가격이 가장 높은 것 같습니다! 하지만 빈도 다각형은 해석하기가 조금 어려워서 그럴 수도 있습니다. 이 플롯에는 많은 내용이 들어 있습니다.\n이 관계를 탐색하기 위해 시각적으로 더 단순한 플롯은 나란히 놓인 상자 그림을 사용하는 것입니다.\n\nggplot(diamonds, aes(x = cut, y = price)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n분포에 대한 정보는 훨씬 적게 보이지만 상자 그림은 훨씬 더 간결하여 비교하기 쉽습니다(그리고 하나의 플롯에 더 많이 맞출 수 있습니다). 이는 더 좋은 품질의 다이아몬드가 일반적으로 더 저렴하다는 직관에 반하는 발견을 뒷받침합니다! 연습문제에서 그 이유를 알아내도록 도전하게 될 것입니다.\ncut은 순서형 팩터입니다. Fair는 Good보다 나쁘고, Good은 Very Good보다 나쁘고 등등입니다. 많은 범주형 변수에는 이러한 내재적 순서가 없으므로 더 유익한 디스플레이를 만들기 위해 순서를 변경하고 싶을 수 있습니다. 그렇게 하는 한 가지 방법은 fct_reorder()를 사용하는 것입니다. Section 16.4 에서 그 함수에 대해 더 자세히 배우겠지만, 매우 유용하기 때문에 여기서는 간단히 미리보기를 제공하고자 합니다. 예를 들어 mpg 데이터셋의 class 변수를 가져와 보겠습니다. 고속도로 연비가 클래스에 따라 어떻게 달라지는지 알고 싶을 수 있습니다:\n\nggplot(mpg, aes(x = class, y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n추세를 더 쉽게 볼 수 있도록 hwy의 중앙값을 기준으로 class를 재정렬할 수 있습니다:\n\nggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n변수 이름이 긴 경우 geom_boxplot()을 90도 뒤집으면 더 잘 작동합니다. x와 y 심미적 매핑을 교환하여 그렇게 할 수 있습니다.\n\nggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n10.5.1.1 연습문제\n\n취소된 항공편과 취소되지 않은 항공편의 출발 시간 시각화를 개선하기 위해 배운 내용을 사용하세요.\nEDA를 바탕으로 할 때 다이아몬드 가격을 예측하는 데 가장 중요한 것으로 보이는 diamonds 데이터셋의 변수는 무엇입니까? 그 변수는 컷과 어떤 상관관계가 있습니까? 그 두 관계의 조합이 왜 품질이 낮은 다이아몬드가 더 비싼 결과로 이어집니까?\nx와 y 변수를 교환하는 대신 수직 상자 그림에 새 레이어로 coord_flip()을 추가하여 수평 상자 그림을 만드세요. 변수를 교환하는 것과 비교하면 어떻습니까?\n상자 그림의 한 가지 문제점은 훨씬 더 작은 데이터셋 시대에 개발되었으며 엄청나게 많은 수의 “이상치 값”을 표시하는 경향이 있다는 것입니다. 이 문제를 해결하기 위한 한 가지 접근 방식은 letter value plot입니다. lvplot 패키지를 설치하고 geom_lv()를 사용하여 가격 대 컷의 분포를 표시해 보세요. 무엇을 알게 되었습니까? 플롯을 어떻게 해석합니까?\ngeom_violin(), 패싯된 geom_histogram(), 색상이 지정된 geom_freqpoly(), 색상이 지정된 geom_density()를 사용하여 diamonds 데이터셋의 다이아몬드 가격 대 범주형 변수의 시각화를 만드세요. 네 가지 플롯을 비교하고 대조하세요. 범주형 변수의 수준에 따라 수치형 변수의 분포를 시각화하는 각 방법의 장단점은 무엇입니까?\n작은 데이터셋이 있는 경우 때때로 geom_jitter()를 사용하여 오버플로팅을 방지하고 연속형 변수와 범주형 변수 간의 관계를 더 쉽게 확인하는 것이 유용합니다. ggbeeswarm 패키지는 geom_jitter()와 유사한 여러 메서드를 제공합니다. 그것들을 나열하고 각각이 무엇을 하는지 간략하게 설명하세요.\n\n10.5.2 두 개의 범주형 변수\n범주형 변수 간의 공변동을 시각화하려면 이러한 범주형 변수 수준의 각 조합에 대한 관측값 수를 세어야 합니다. 그렇게 하는 한 가지 방법은 내장된 geom_count()에 의존하는 것입니다:\n\nggplot(diamonds, aes(x = cut, y = color)) +\n  geom_count()\n\n\n\n\n\n\n\n플롯에 있는 각 원의 크기는 각 값 조합에서 얼마나 많은 관측값이 발생했는지를 나타냅니다. 공변동은 특정 x 값과 특정 y 값 사이의 강한 상관관계로 나타날 것입니다.\n이러한 변수 간의 관계를 탐색하기 위한 또 다른 접근 방식은 dplyr로 개수를 계산하는 것입니다:\n\ndiamonds |&gt; \n  count(color, cut)\n#&gt; # A tibble: 35 × 3\n#&gt;   color cut           n\n#&gt;   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt;\n#&gt; 1 D     Fair        163\n#&gt; 2 D     Good        662\n#&gt; 3 D     Very Good  1513\n#&gt; 4 D     Premium    1603\n#&gt; 5 D     Ideal      2834\n#&gt; 6 E     Fair        224\n#&gt; # ℹ 29 more rows\n\n그런 다음 geom_tile()과 채우기(fill) 심미성으로 시각화합니다:\n\ndiamonds |&gt; \n  count(color, cut) |&gt;  \n  ggplot(aes(x = color, y = cut)) +\n  geom_tile(aes(fill = n))\n\n\n\n\n\n\n\n범주형 변수에 순서가 없는 경우 흥미로운 패턴을 더 명확하게 드러내기 위해 seriation 패키지를 사용하여 행과 열을 동시에 재정렬할 수 있습니다. 더 큰 플롯의 경우 대화형 플롯을 생성하는 heatmaply 패키지를 사용해 볼 수 있습니다.\n\n10.5.2.1 연습문제\n\n색상 내의 컷 분포 또는 컷 내의 색상 분포를 더 명확하게 보여주기 위해 위의 카운트 데이터셋을 어떻게 재조정(rescale)할 수 있습니까?\n색상이 x 심미성에 매핑되고 cut이 fill 심미성에 매핑된 경우 분할 막대 차트로 어떤 다른 데이터 통찰력을 얻을 수 있습니까? 각 세그먼트에 속하는 개수를 계산하세요.\ngeom_tile()을 dplyr과 함께 사용하여 목적지 및 연중 월별로 평균 항공편 출발 지연이 어떻게 변하는지 탐색하세요. 플롯을 읽기 어렵게 만드는 것은 무엇입니까? 어떻게 개선할 수 있습니까?\n\n10.5.3 두 개의 수치형 변수\n두 수치형 변수 간의 공변동을 시각화하는 훌륭한 방법을 이미 보았습니다: geom_point()로 산점도를 그리는 것입니다. 점의 패턴으로 공변동을 볼 수 있습니다. 예를 들어 다이아몬드의 캐럿 크기와 가격 사이에 양의 관계를 볼 수 있습니다: 캐럿이 많은 다이아몬드일수록 가격이 높습니다. 관계는 지수적입니다.\n\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_point()\n\n\n\n\n\n\n\n(이 섹션에서는 3캐럿보다 작은 다이아몬드 대부분에 집중하기 위해 smaller 데이터셋을 사용할 것입니다)\n산점도는 데이터셋의 크기가 커질수록 덜 유용해집니다. 점들이 오버플로팅되기 시작하고 균일한 검은색 영역으로 쌓여 2차원 공간 전체의 데이터 밀도 차이를 판단하기 어렵게 만들고 추세를 파악하기 어렵게 만들기 때문입니다. 문제를 해결하는 한 가지 방법을 이미 보았습니다: alpha 심미성을 사용하여 투명도를 추가하는 것입니다.\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_point(alpha = 1 / 100)\n\n\n\n\n\n\n\n하지만 투명도를 사용하는 것은 매우 큰 데이터셋의 경우 어려울 수 있습니다. 또 다른 해결책은 빈(bin)을 사용하는 것입니다. 이전에는 geom_histogram()과 geom_freqpoly()를 사용하여 1차원에서 비닝했습니다. 이제 geom_bin2d()와 geom_hex()를 사용하여 2차원에서 비닝하는 방법을 배울 것입니다.\ngeom_bin2d()와 geom_hex()는 좌표 평면을 2D 빈으로 나누고 채우기 색상을 사용하여 각 빈에 얼마나 많은 포인트가 속하는지 표시합니다. geom_bin2d()는 직사각형 빈을 만듭니다. geom_hex()는 육각형 빈을 만듭니다. geom_hex()를 사용하려면 hexbin 패키지를 설치해야 합니다.\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_bin2d()\n#&gt; `stat_bin2d()` using `bins = 30`. Pick better value `binwidth`.\n\n# install.packages(\"hexbin\")\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_hex()\n\n\n\n\n\n\n\n\n\n\n또 다른 옵션은 하나의 연속형 변수를 범주형 변수처럼 작동하도록 비닝하는 것입니다. 그런 다음 배운 범주형 변수와 연속형 변수의 조합을 시각화하는 기술 중 하나를 사용할 수 있습니다. 예를 들어 carat을 비닝한 다음 각 그룹에 대해 상자 그림을 표시할 수 있습니다:\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_width(carat, 0.1)))\n#&gt; Warning: Orientation is not uniquely specified when both the x and y aesthetics are\n#&gt; continuous. Picking default orientation 'x'.\n\n\n\n\n\n\n\n위에서 사용된 cut_width(x, width)는 x를 너비가 width인 빈으로 나눕니다. 기본적으로 상자 그림은 관측값이 얼마나 많은지에 관계없이 대략 동일하게 보이므로(이상치 수 제외) 각 상자 그림이 다른 수의 포인트를 요약한다는 것을 알기 어렵습니다. 이를 보여주는 한 가지 방법은 varwidth = TRUE를 사용하여 상자 그림의 너비를 포인트 수에 비례하게 만드는 것입니다.\n\n10.5.3.1 연습문제\n\n조건부 분포를 상자 그림으로 요약하는 대신 빈도 다각형을 사용할 수 있습니다. cut_width() 대 cut_number()를 사용할 때 고려해야 할 사항은 무엇입니까? 그것이 carat과 price의 2D 분포 시각화에 어떤 영향을 미칩니까?\nprice로 파티션된 carat의 분포를 시각화하세요.\n매우 큰 다이아몬드의 가격 분포는 작은 다이아몬드와 어떻게 비교됩니까? 예상대로입니까, 아니면 놀랍습니까?\n배운 기술 중 두 가지를 결합하여 컷, 캐럿, 가격의 결합된 분포를 시각화하세요.\n\n2차원 플롯은 1차원 플롯에서는 보이지 않는 이상치를 드러냅니다. 예를 들어 다음 플롯의 일부 점은 특이한 x와 y 값 조합을 가지고 있어 x와 y 값을 개별적으로 조사했을 때는 정상으로 보일지라도 점들을 이상치로 만듭니다. 이 경우 비닝된 플롯보다 산점도가 더 나은 디스플레이인 이유는 무엇입니까?\n\ndiamonds |&gt; \n  filter(x &gt;= 4) |&gt; \n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))\n\n\n\ncut_width()로 동일한 너비의 상자를 만드는 대신 cut_number()로 대략 동일한 수의 포인트를 포함하는 상자를 만들 수 있습니다. 이 접근 방식의 장단점은 무엇입니까?\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_number(carat, 20)))",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#패턴과-모델",
    "href": "EDA.html#패턴과-모델",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "\n10.6 패턴과 모델",
    "text": "10.6 패턴과 모델\n두 변수 사이에 체계적인 관계가 존재하면 데이터에 패턴으로 나타날 것입니다. 패턴을 발견하면 자문해 보세요:\n\n이 패턴이 우연(즉, 무작위 확률) 때문일 수 있습니까?\n패턴이 암시하는 관계를 어떻게 설명할 수 있습니까?\n패턴이 암시하는 관계는 얼마나 강력합니까?\n어떤 다른 변수가 관계에 영향을 미칠 수 있습니까?\n데이터의 개별 하위 그룹을 보면 관계가 변합니까?\n\n데이터의 패턴은 관계에 대한 단서를 제공합니다. 즉, 공변동을 드러냅니다. 변동을 불확실성을 생성하는 현상으로 생각한다면, 공변동은 불확실성을 줄이는 현상입니다. 두 변수가 공변하면 한 변수의 값을 사용하여 두 번째 변수의 값을 더 잘 예측할 수 있습니다. 공변동이 인과 관계(특수한 경우) 때문이라면 한 변수의 값을 사용하여 두 번째 변수의 값을 제어할 수 있습니다.\n모델은 데이터에서 패턴을 추출하기 위한 도구입니다. 예를 들어 diamonds 데이터를 고려해 보세요. 컷과 가격의 관계를 이해하기 어려운데, 그 이유는 컷과 캐럿, 그리고 캐럿과 가격이 밀접하게 관련되어 있기 때문입니다. 모델을 사용하여 가격과 캐럿 간의 매우 강한 관계를 제거하여 남은 미묘함을 탐색할 수 있습니다. 다음 코드는 carat에서 price를 예측하는 모델을 적합시킨 다음 잔차(예측값과 실제 값의 차이)를 계산합니다. 잔차는 캐럿의 효과가 제거된 후의 다이아몬드 가격에 대한 뷰를 제공합니다. price와 carat의 원시 값을 사용하는 대신 먼저 로그 변환하고 로그 변환된 값에 모델을 적합시킨다는 점에 유의하세요. 그런 다음 잔차를 지수화하여 원시 가격의 척도로 되돌립니다.\n\nlibrary(tidymodels)\n#&gt; Warning: package 'broom' was built under R version 4.5.2\n#&gt; Warning: package 'infer' was built under R version 4.5.2\n#&gt; Warning: package 'parsnip' was built under R version 4.5.2\n\ndiamonds &lt;- diamonds |&gt;\n  mutate(\n    log_price = log(price),\n    log_carat = log(carat)\n  )\n\ndiamonds_fit &lt;- linear_reg() |&gt;\n  fit(log_price ~ log_carat, data = diamonds)\n\ndiamonds_aug &lt;- augment(diamonds_fit, new_data = diamonds) |&gt;\n  mutate(.resid = exp(.resid))\n\nggplot(diamonds_aug, aes(x = carat, y = .resid)) + \n  geom_point()\n\n\n\n\n\n\n\n캐럿과 가격 사이의 강한 관계를 제거하고 나면 컷과 가격 사이의 관계에서 예상되는 것을 볼 수 있습니다: 크기에 비해 품질이 좋은 다이아몬드가 더 비쌉니다.\n\nggplot(diamonds_aug, aes(x = cut, y = .resid)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n이 책에서는 모델링에 대해 논의하지 않는데, 모델이 무엇이고 어떻게 작동하는지 이해하는 것은 데이터 랭글링 및 프로그래밍 도구를 갖춘 후에 가장 쉽기 때문입니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#요약",
    "href": "EDA.html#요약",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "\n10.7 요약",
    "text": "10.7 요약\n이 장에서는 데이터 내의 변동을 이해하는 데 도움이 되는 다양한 도구를 배웠습니다. 한 번에 단일 변수와 한 쌍의 변수와 함께 작동하는 기술을 보았습니다. 데이터에 수십 또는 수백 개의 변수가 있는 경우 이것이 고통스럽게 제한적으로 보일 수 있지만, 이것들은 다른 모든 기술이 구축되는 기초입니다.\n다음 장에서는 결과를 소통하는 데 사용할 수 있는 도구에 초점을 맞출 것입니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "EDA.html#footnotes",
    "href": "EDA.html#footnotes",
    "title": "10  탐색적 데이터 분석(Exploratory data analysis)",
    "section": "",
    "text": "함수(또는 데이터셋)가 어디에서 왔는지 명시해야 할 때는 package::function() 또는 package::dataset이라는 특별한 형식을 사용한다는 것을 기억하세요.↩︎",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>탐색적 데이터 분석(Exploratory data analysis)</span>"
    ]
  },
  {
    "objectID": "communication.html",
    "href": "communication.html",
    "title": "11  소통(Communication)",
    "section": "",
    "text": "11.1 소개\nChapter 10 에서 탐색을 위한 도구로 플롯을 사용하는 방법을 배웠습니다. 탐색적 플롯을 만들 때는 보기 전에도 플롯에 어떤 변수가 표시될지 알고 있습니다. 각 플롯을 목적에 맞게 만들었고, 빠르게 살펴본 다음, 다음 플롯으로 넘어갈 수 있었습니다. 대부분의 분석 과정에서 수십 또는 수백 개의 플롯을 생성하게 되며, 그중 대부분은 즉시 버려집니다.\n이제 데이터를 이해했으므로 이해한 내용을 다른 사람들에게 소통해야 합니다. 청중은 아마도 여러분의 배경 지식을 공유하지 않을 것이며 데이터에 깊이 투자하지 않았을 것입니다. 다른 사람들이 데이터에 대한 좋은 멘탈 모델을 빠르게 구축하도록 돕기 위해 플롯을 가능한 한 설명이 필요 없도록 만드는 데 상당한 노력을 투자해야 합니다. 이 장에서는 ggplot2가 이를 위해 제공하는 도구 중 일부를 배울 것입니다.\n이 장은 좋은 그래픽을 만드는 데 필요한 도구에 중점을 둡니다. 우리는 여러분이 무엇을 원하는지 알고 있으며 단지 그것을 수행하는 방법만 알면 된다고 가정합니다. 이러한 이유로 이 장을 좋은 일반적인 시각화 책과 함께 보는 것을 강력히 추천합니다. 우리는 특히 알버트 카이로(Albert Cairo)의 The Truthful Art를 좋아합니다. 이 책은 시각화를 만드는 메커니즘을 가르치지는 않지만 대신 효과적인 그래픽을 만들기 위해 무엇을 생각해야 하는지에 초점을 맞춥니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#소개",
    "href": "communication.html#소개",
    "title": "11  소통(Communication)",
    "section": "",
    "text": "11.1.1 선수 지식\n이 장에서는 다시 한 번 ggplot2에 초점을 맞출 것입니다. 또한 데이터 조작을 위해 약간의 dplyr을 사용하고, 기본 breaks, 레이블, 변환 및 팔레트를 재정의하기 위해 scales를 사용하며, Kamil Slowikowski의 ggrepel(https://ggrepel.slowkow.com)과 Thomas Lin Pedersen의 patchwork(https://patchwork.data-imaginist.com)를 포함한 몇 가지 ggplot2 확장 패키지를 사용할 것입니다. 아직 패키지가 없다면 install.packages()로 설치해야 한다는 것을 잊지 마세요.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(patchwork)",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#레이블",
    "href": "communication.html#레이블",
    "title": "11  소통(Communication)",
    "section": "\n11.2 레이블",
    "text": "11.2 레이블\n탐색적 그래픽을 설명적 그래픽으로 바꿀 때 가장 먼저 시작하기 쉬운 곳은 좋은 레이블입니다. labs() 함수로 레이블을 추가합니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Engine displacement (L)\",\n    y = \"Highway fuel economy (mpg)\",\n    color = \"Car type\",\n    title = \"Fuel efficiency generally decreases with engine size\",\n    subtitle = \"Two seaters (sports cars) are an exception because of their light weight\",\n    caption = \"Data from fueleconomy.gov\"\n  )\n\n\n\n\n\n\n\n플롯 제목의 목적은 주요 결과를 요약하는 것입니다. “엔진 배기량 대 연비의 산점도”와 같이 플롯이 무엇인지만 설명하는 제목은 피하세요.\n텍스트를 더 추가해야 하는 경우 유용한 두 가지 레이블이 더 있습니다. subtitle은 제목 아래에 더 작은 글꼴로 추가 세부 정보를 추가하고 caption은 플롯 오른쪽 하단에 텍스트를 추가하며 종종 데이터의 출처를 설명하는 데 사용됩니다. labs()를 사용하여 축 및 범례 제목을 바꿀 수도 있습니다. 일반적으로 짧은 변수 이름을 더 자세한 설명으로 바꾸고 단위를 포함하는 것이 좋습니다.\n텍스트 문자열 대신 수식을 사용할 수 있습니다. \"\"를 quote()로 바꾸고 ?plotmath에서 사용 가능한 옵션에 대해 읽어보세요:\n\ndf &lt;- tibble(\n  x = 1:10,\n  y = cumsum(x^2)\n)\n\nggplot(df, aes(x, y)) +\n  geom_point() +\n  labs(\n    x = quote(x[i]),\n    y = quote(sum(x[i] ^ 2, i == 1, n))\n  )\n\n\n\n\n\n\n\n\n11.2.1 연습문제\n\n연비 데이터에 대해 사용자 정의된 title, subtitle, caption, x, y, color 레이블이 있는 하나의 플롯을 만드세요.\n\n연비 데이터를 사용하여 다음 플롯을 다시 만드세요. 점의 색상과 모양 모두 구동 방식 유형에 따라 달라집니다.\n\n\n\n\n\n\n\n\n\n지난달에 만든 탐색적 그래픽을 가져와 다른 사람들이 더 쉽게 이해할 수 있도록 유익한 제목을 추가하세요.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#주석annotations",
    "href": "communication.html#주석annotations",
    "title": "11  소통(Communication)",
    "section": "\n11.3 주석(Annotations)",
    "text": "11.3 주석(Annotations)\n플롯의 주요 구성 요소에 레이블을 지정하는 것 외에도 개별 관측값이나 관측값 그룹에 레이블을 지정하는 것이 유용한 경우가 많습니다. 사용할 수 있는 첫 번째 도구는 geom_text()입니다. geom_text()는 geom_point()와 유사하지만 추가 심미성인 label이 있습니다. 이것은 플롯에 텍스트 레이블을 추가할 수 있게 해줍니다.\n레이블의 소스는 두 가지가 있습니다. 첫째, 레이블을 제공하는 티블이 있을 수 있습니다. 다음 플롯에서는 각 구동 방식에서 엔진 크기가 가장 큰 자동차를 뽑아내어 정보를 label_info라는 새 데이터 프레임으로 저장합니다.\n\nlabel_info &lt;- mpg |&gt;\n  group_by(drv) |&gt;\n  arrange(desc(displ)) |&gt;\n  slice_head(n = 1) |&gt;\n  mutate(\n    drive_type = case_when(\n      drv == \"f\" ~ \"front-wheel drive\",\n      drv == \"r\" ~ \"rear-wheel drive\",\n      drv == \"4\" ~ \"4-wheel drive\"\n    )\n  ) |&gt;\n  select(displ, hwy, drv, drive_type)\n\nlabel_info\n#&gt; # A tibble: 3 × 4\n#&gt; # Groups:   drv [3]\n#&gt;   displ   hwy drv   drive_type       \n#&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;            \n#&gt; 1   6.5    17 4     4-wheel drive    \n#&gt; 2   5.3    25 f     front-wheel drive\n#&gt; 3   7      24 r     rear-wheel drive\n\n그런 다음 이 새 데이터 프레임을 사용하여 세 그룹에 직접 레이블을 지정하여 범례를 플롯에 직접 배치된 레이블로 바꿉니다. fontface 및 size 인수를 사용하여 텍스트 레이블의 모양을 사용자 정의할 수 있습니다. 플롯의 나머지 텍스트보다 크고 굵게 표시됩니다. (theme(legend.position = \"none\")은 모든 범례를 끕니다. 잠시 후에 더 자세히 이야기하겠습니다.)\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_text(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, hjust = \"right\", vjust = \"bottom\"\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nhjust(수평 정렬) 및 vjust(수직 정렬)를 사용하여 레이블의 정렬을 제어하는 것에 유의하세요.\n그러나 위에서 만든 주석이 달린 플롯은 레이블이 서로 겹치고 점과 겹치기 때문에 읽기 어렵습니다. ggprepel 패키지의 geom_label_repel() 함수를 사용하여 두 문제를 모두 해결할 수 있습니다. 이 유용한 패키지는 레이블이 겹치지 않도록 자동으로 조정합니다:\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_label_repel(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, nudge_y = 2\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n또한 ggrepel 패키지의 geom_text_repel()을 사용하여 플롯의 특정 점을 강조 표시하는 데 동일한 아이디어를 사용할 수 있습니다. 여기서 사용된 또 다른 편리한 기술에 주목하세요: 레이블이 지정된 점을 더욱 강조하기 위해 크고 빈 점 레이어를 추가했습니다.\n\npotential_outliers &lt;- mpg |&gt;\n  filter(hwy &gt; 40 | (hwy &gt; 20 & displ &gt; 5))\n  \nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_text_repel(data = potential_outliers, aes(label = model)) +\n  geom_point(data = potential_outliers, color = \"red\") +\n  geom_point(\n    data = potential_outliers,\n    color = \"red\", size = 3, shape = \"circle open\"\n  )\n\n\n\n\n\n\n\ngeom_text() 및 geom_label() 외에도 ggplot2에는 플롯에 주석을 추가하는 데 도움이 되는 다른 많은 지옴이 있다는 것을 기억하세요. 몇 가지 아이디어:\n\ngeom_hline() 및 geom_vline()을 사용하여 참조선을 추가하세요. 우리는 종종 두껍게(linewidth = 2) 흰색(color = white)으로 만들고 기본 데이터 레이어 아래에 그립니다. 그렇게 하면 데이터에서 주의를 뺏지 않으면서도 보기 쉽습니다.\ngeom_rect()를 사용하여 관심 지점 주위에 사각형을 그립니다. 사각형의 경계는 xmin, xmax, ymin, ymax 심미성에 의해 정의됩니다. 또는 ggforce 패키지, 구체적으로 geom_mark_hull()을 살펴보세요. 이를 통해 헐(hulls)로 점의 하위 집합에 주석을 달 수 있습니다.\ngeom_segment()와 arrow 인수를 사용하여 화살표로 점에 주의를 끕니다. x 및 y 심미성을 사용하여 시작 위치를 정의하고 xend 및 yend를 사용하여 끝 위치를 정의하세요.\n\n플롯에 주석을 추가하는 또 다른 편리한 함수는 annotate()입니다. 경험적으로 지옴은 일반적으로 데이터의 하위 집합을 강조 표시하는 데 유용한 반면 annotate()는 플롯에 하나 또는 소수의 주석 요소를 추가하는 데 유용합니다.\nannotate() 사용을 보여주기 위해 플롯에 추가할 텍스트를 만들어 보겠습니다. 텍스트가 조금 길기 때문에 stringr::str_wrap()을 사용하여 한 줄에 원하는 문자 수에 따라 자동으로 줄 바꿈을 추가합니다:\n\ntrend_text &lt;- \"Larger engine sizes tend to have lower fuel economy.\" |&gt;\n  str_wrap(width = 30)\ntrend_text\n#&gt; [1] \"Larger engine sizes tend to\\nhave lower fuel economy.\"\n\n그런 다음 두 개의 주석 레이어를 추가합니다. 하나는 레이블 지옴이고 다른 하나는 세그먼트 지옴입니다. 두 경우 모두 x 및 y 심미성은 주석이 시작될 위치를 정의하고 세그먼트 주석의 xend 및 yend 심미성은 세그먼트의 끝 위치를 정의합니다. 또한 세그먼트가 화살표로 스타일링되어 있음에 유의하세요.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  annotate(\n    geom = \"label\", x = 3.5, y = 38,\n    label = trend_text,\n    hjust = \"left\", color = \"red\"\n  ) +\n  annotate(\n    geom = \"segment\",\n    x = 3, y = 35, xend = 5, yend = 25, color = \"red\",\n    arrow = arrow(type = \"closed\")\n  )\n\n\n\n\n\n\n\n주석은 시각화의 주요 시사점과 흥미로운 특징을 전달하기 위한 강력한 도구입니다. 유일한 한계는 상상력(그리고 주석을 미적으로 즐겁게 배치하는 인내심)뿐입니다!\n\n11.3.1 연습문제\n\ngeom_text()와 무한 위치(infinite positions)를 사용하여 플롯의 네 모서리에 텍스트를 배치하세요.\nannotate()를 사용하여 티블을 생성하지 않고 마지막 플롯의 가운데에 점 지옴을 추가하세요. 점의 모양, 크기 또는 색상을 사용자 정의하세요.\ngeom_text()를 사용한 레이블은 패싯과 어떻게 상호 작용합니까? 단일 패싯에 레이블을 어떻게 추가할 수 있습니까? 각 패싯에 다른 레이블을 어떻게 넣을 수 있습니까? (힌트: geom_text()에 전달되는 데이터셋에 대해 생각해 보세요.)\ngeom_label()의 어떤 인수가 배경 상자의 모양을 제어합니까?\narrow()의 네 가지 인수는 무엇입니까? 어떻게 작동합니까? 가장 중요한 옵션을 보여주는 일련의 플롯을 만드세요.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#척도scales",
    "href": "communication.html#척도scales",
    "title": "11  소통(Communication)",
    "section": "\n11.4 척도(Scales)",
    "text": "11.4 척도(Scales)\n소통을 위해 플롯을 더 좋게 만드는 세 번째 방법은 척도를 조정하는 것입니다. 척도는 심미적 매핑이 시각적으로 나타나는 방식을 제어합니다.\n\n11.4.1 기본 척도\n일반적으로 ggplot2는 자동으로 척도를 추가합니다. 예를 들어 다음과 같이 입력할 때:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nggplot2는 뒤에서 자동으로 기본 척도를 추가합니다:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  scale_color_discrete()\n\n척도의 명명 체계에 유의하세요: scale_ 뒤에 심미성 이름, 그 다음 _, 그 다음 척도 이름이 옵니다. 기본 척도는 일치하는 변수 유형에 따라 이름이 지정됩니다: 연속형(continuous), 이산형(discrete), 날짜-시간(datetime) 또는 날짜(date). scale_x_continuous()는 displ의 숫자 값을 x축의 연속 숫자 라인에 놓고, scale_color_discrete()는 각 자동차 class에 대한 색상을 선택하는 식입니다. 아래에서 배우게 될 기본값이 아닌 척도가 많이 있습니다.\n기본 척도는 광범위한 입력에 대해 잘 수행되도록 신중하게 선택되었습니다. 그럼에도 불구하고 두 가지 이유로 기본값을 재정의하고 싶을 수 있습니다:\n\n기본 척도의 일부 매개변수를 조정하고 싶을 수 있습니다. 이를 통해 축의 나누기(breaks) 또는 범례의 키 레이블을 변경하는 것과 같은 작업을 수행할 수 있습니다.\n척도를 완전히 교체하고 완전히 다른 알고리즘을 사용하고 싶을 수 있습니다. 종종 데이터에 대해 더 많이 알고 있기 때문에 기본값보다 더 잘할 수 있습니다.\n\n11.4.2 축 눈금 및 범례 키\n집합적으로 축과 범례를 가이드(guides) 라고 합니다. 축은 x 및 y 심미성에 사용되고 범례는 다른 모든 것에 사용됩니다.\n축의 눈금과 범례의 키 모양에 영향을 미치는 두 가지 주요 인수는 breaks와 labels입니다. breaks는 눈금의 위치 또는 키와 관련된 값을 제어합니다. Labels는 각 눈금/키와 관련된 텍스트 레이블을 제어합니다. breaks의 가장 일반적인 용도는 기본 선택을 재정의하는 것입니다:\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(15, 40, by = 5)) \n\n\n\n\n\n\n\nlabels도 같은 방식으로 사용할 수 있지만(breaks와 길이가 같은 문자 벡터), NULL로 설정하여 레이블을 완전히 억제할 수도 있습니다. 이것은 지도나 절대 숫자를 공유할 수 없는 플롯을 게시하는 데 유용할 수 있습니다. breaks 및 labels를 사용하여 범례의 모양을 제어할 수도 있습니다. 범주형 변수의 이산 척도의 경우 labels는 기존 수준 이름과 원하는 레이블의 명명된 리스트일 수 있습니다.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_x_continuous(labels = NULL) +\n  scale_y_continuous(labels = NULL) +\n  scale_color_discrete(labels = c(\"4\" = \"4-wheel\", \"f\" = \"front\", \"r\" = \"rear\"))\n\n\n\n\n\n\n\nlabels 인수는 scales 패키지의 라벨링 함수와 결합하여 숫자를 통화, 백분율 등으로 포맷하는 데에도 유용합니다. 왼쪽 플롯은 달러 기호와 천 단위 구분 기호 쉼표를 추가하는 label_dollar()를 사용한 기본 라벨링을 보여줍니다. 오른쪽 플롯은 달러 값을 1,000으로 나누고 접미사 “K”(“천”을 의미)를 추가하고 사용자 정의 나누기를 추가하여 사용자 정의를 더 추가합니다. breaks는 데이터의 원래 척도에 있다는 점에 유의하세요.\n# 왼쪽\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(labels = label_dollar())\n\n# 오른쪽\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(\n    labels = label_dollar(scale = 1/1000, suffix = \"K\"), \n    breaks = seq(1000, 19000, by = 6000)\n  )\n\n\n\n\n\n\n\n\n\n\n또 다른 편리한 레이블 함수는 label_percent()입니다:\n\nggplot(diamonds, aes(x = cut, fill = clarity)) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(name = \"Percentage\", labels = label_percent())\n\n\n\n\n\n\n\nbreaks의 또 다른 용도는 데이터 포인트가 비교적 적고 관측값이 정확히 어디에서 발생하는지 강조하고 싶을 때입니다. 예를 들어 각 미국 대통령이 임기를 시작하고 마친 시기를 보여주는 이 플롯을 가져와 보겠습니다.\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_x_date(name = NULL, breaks = presidential$start, date_labels = \"'%y\")\n\n\n\n\n\n\n\nbreaks 인수에 대해 이 인수에 대한 심미적 매핑을 할 수 없기 때문에 presidential$start를 사용하여 벡터로 start 변수를 뽑아냈다는 점에 유의하세요. 또한 날짜 및 날짜 시간 척도에 대한 나누기 및 레이블 지정은 약간 다릅니다:\n\ndate_labels는 parse_datetime()과 같은 형식의 형식 사양을 취합니다.\ndate_breaks(여기에는 표시되지 않음)는 “2 days” 또는 “1 month”와 같은 문자열을 취합니다.\n\n11.4.3 범례 레이아웃\n축을 조정하기 위해 breaks와 labels를 가장 자주 사용할 것입니다. 둘 다 범례에도 작동하지만 더 많이 사용할 가능성이 있는 몇 가지 다른 기술이 있습니다.\n범례의 전체 위치를 제어하려면 theme() 설정을 사용해야 합니다. 이 장의 마지막 부분에서 테마에 대해 다시 다루겠지만, 간단히 말해 테마는 플롯의 데이터가 아닌 부분을 제어합니다. 테마 설정 legend.position은 범례가 그려지는 위치를 제어합니다:\nbase &lt;- ggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nbase + theme(legend.position = \"right\") # 기본값\nbase + theme(legend.position = \"left\")\nbase + \n  theme(legend.position = \"top\") +\n  guides(color = guide_legend(nrow = 3))\nbase + \n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n플롯이 짧고 넓으면 범례를 위나 아래에 놓고, 키가 크고 좁으면 범례를 왼쪽이나 오른쪽에 놓으세요. legend.position = \"none\"을 사용하여 범례 표시를 완전히 억제할 수도 있습니다.\n개별 범례의 표시를 제어하려면 guides()를 guide_legend() 또는 guide_colorbar()와 함께 사용하세요. 다음 예제는 두 가지 중요한 설정을 보여줍니다. nrow로 범례가 사용하는 행 수를 제어하고, 심미성 중 하나를 재정의하여 점을 더 크게 만듭니다. 이것은 플롯에 많은 점을 표시하기 위해 낮은 alpha를 사용한 경우에 특히 유용합니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2, override.aes = list(size = 4)))\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nguides()의 인수 이름이 labs()에서와 마찬가지로 심미성의 이름과 일치한다는 점에 유의하세요.\n\n11.4.4 척도 교체\n세부 사항을 조금만 조정하는 대신 척도를 완전히 교체할 수도 있습니다. 교체하고 싶을 가능성이 가장 높은 척도는 연속 위치 척도와 색상 척도의 두 가지 유형입니다. 다행히도 다른 모든 심미성에도 동일한 원칙이 적용되므로 위치와 색상을 마스터하면 다른 척도 교체를 빠르게 익힐 수 있습니다.\n변수의 변환을 플롯하는 것은 매우 유용합니다. 예를 들어 carat과 price를 로그 변환하면 그들 사이의 정확한 관계를 보기가 더 쉽습니다:\n# 왼쪽\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d()\n#&gt; `stat_bin2d()` using `bins = 30`. Pick better value `binwidth`.\n\n# 오른쪽\nggplot(diamonds, aes(x = log10(carat), y = log10(price))) +\n  geom_bin2d()\n#&gt; `stat_bin2d()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\n그러나 이 변환의 단점은 축이 이제 변환된 값으로 레이블이 지정되어 플롯을 해석하기 어렵다는 것입니다. 심미적 매핑에서 변환을 수행하는 대신 척도에서 수행할 수 있습니다. 축이 원래 데이터 척도로 레이블이 지정된다는 점을 제외하면 시각적으로 동일합니다.\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d() + \n  scale_x_log10() + \n  scale_y_log10()\n#&gt; `stat_bin2d()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n자주 사용자 정의되는 또 다른 척도는 색상입니다. 기본 범주형 척도는 색상환 주위에 균등하게 간격을 둔 색상을 선택합니다. 유용한 대안은 일반적인 유형의 색맹을 가진 사람들에게 더 잘 작동하도록 수동으로 조정된 ColorBrewer 척도입니다. 아래의 두 플롯은 비슷해 보이지만 빨간색과 녹색 음영의 차이가 충분하여 적록색맹이 있는 사람들도 오른쪽의 점을 구별할 수 있습니다.1\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv))\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n접근성을 개선하기 위한 더 간단한 기술을 잊지 마세요. 색상이 몇 개뿐인 경우 중복된 모양 매핑을 추가할 수 있습니다. 이렇게 하면 플롯을 흑백으로 해석할 수 있도록 하는 데에도 도움이 됩니다.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv, shape = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\nColorBrewer 척도는 https://colorbrewer2.org/에 온라인으로 문서화되어 있으며 Erich Neuwirth의 RColorBrewer 패키지를 통해 R에서 사용할 수 있습니다. Figure 11.1 는 모든 팔레트의 전체 목록을 보여줍니다. 순차적(위쪽) 및 발산(아래쪽) 팔레트는 범주형 값이 순서가 있거나 “중간”이 있는 경우 특히 유용합니다. 이는 cut()을 사용하여 연속형 변수를 범주형 변수로 만든 경우 자주 발생합니다.\n\n\n\n\n\n\n\nFigure 11.1: 모든 colorBrewer 척도.\n\n\n\n\n값과 색상 사이에 미리 정의된 매핑이 있는 경우 scale_color_manual()을 사용하세요. 예를 들어 대통령 정당을 색상에 매핑하는 경우 공화당은 빨간색, 민주당은 파란색이라는 표준 매핑을 사용하고 싶습니다. 이러한 색상을 할당하는 한 가지 접근 방식은 16진수 색상 코드를 사용하는 것입니다:\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id, color = party)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_color_manual(values = c(Republican = \"#E81B23\", Democratic = \"#00AEF3\"))\n\n\n\n\n\n\n\n연속적인 색상의 경우 내장된 scale_color_gradient() 또는 scale_fill_gradient()를 사용할 수 있습니다. 발산 척도가 있는 경우 scale_color_gradient2()를 사용할 수 있습니다. 이를 통해 예를 들어 양수 값과 음수 값에 다른 색상을 부여할 수 있습니다. 이는 평균 위 또는 아래의 점을 구별하려는 경우에도 때때로 유용합니다.\n또 다른 옵션은 viridis 색상 척도를 사용하는 것입니다. 디자이너인 Nathaniel Smith와 Stéfan van der Walt는 다양한 형태의 색맹을 가진 사람들이 인식할 수 있을 뿐만 아니라 색상과 흑백 모두에서 지각적으로 균일한 연속 색상 체계를 신중하게 맞춤화했습니다. 이 척도는 ggplot2에서 연속(c), 이산(d), 비닝된(b) 팔레트로 사용할 수 있습니다.\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  labs(title = \"Default, continuous\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_c() +\n  labs(title = \"Viridis, continuous\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_b() +\n  labs(title = \"Viridis, binned\", x = NULL, y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n모든 색상 척도에는 두 가지 종류가 있습니다: color 및 fill 심미성에 대해 각각 scale_color_*() 및 scale_fill_*()(색상 척도는 영국식 및 미국식 철자 모두 사용 가능).\n\n11.4.5 줌(Zooming)\n플롯 한계를 제어하는 세 가지 방법이 있습니다:\n\n플롯되는 데이터를 조정합니다.\n각 척도의 한계를 설정합니다.\n\ncoord_cartesian()에서 xlim 및 ylim을 설정합니다.\n\n일련의 플롯으로 이러한 옵션을 보여드리겠습니다. 왼쪽 플롯은 엔진 크기와 연비 사이의 관계를 보여주며 구동 방식 유형별로 색상이 지정되어 있습니다. 오른쪽 플롯은 동일한 변수를 보여주지만 플롯되는 데이터의 하위 집합을 만듭니다. 데이터의 하위 집합을 만들면 x 및 y 척도뿐만 아니라 매끄러운 곡선에도 영향을 미쳤습니다.\n# 왼쪽\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n# 오른쪽\nmpg |&gt;\n  filter(displ &gt;= 5 & displ &lt;= 6 & hwy &gt;= 10 & hwy &lt;= 25) |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n이것을 아래의 두 플롯과 비교해 봅시다. 왼쪽 플롯은 개별 척도에 limits를 설정하고 오른쪽 플롯은 coord_cartesian()에 설정합니다. 한계를 줄이는 것은 데이터를 부분집합화하는 것과 동일함을 알 수 있습니다. 따라서 플롯의 영역을 줌인하려면 일반적으로 coord_cartesian()을 사용하는 것이 가장 좋습니다.\n# 왼쪽\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  scale_x_continuous(limits = c(5, 6)) +\n  scale_y_continuous(limits = c(10, 25))\n\n# 오른쪽\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  coord_cartesian(xlim = c(5, 6), ylim = c(10, 25))\n\n\n\n\n\n\n\n\n\n\n반면에 개별 척도에 limits를 설정하는 것은 한계를 확장하려는 경우, 예를 들어 다른 플롯 간에 척도를 일치시키려는 경우에 일반적으로 더 유용합니다. 예를 들어 두 클래스의 자동차를 추출하여 별도로 플롯하는 경우 세 가지 척도(x축, y축, 색상 심미성) 모두 범위가 다르기 때문에 플롯을 비교하기 어렵습니다.\nsuv &lt;- mpg |&gt; filter(class == \"suv\")\ncompact &lt;- mpg |&gt; filter(class == \"compact\")\n\n# 왼쪽\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n# 오른쪽\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n이 문제를 극복하는 한 가지 방법은 전체 데이터의 limits로 척도를 훈련(training)하여 여러 플롯에서 척도를 공유하는 것입니다.\nx_scale &lt;- scale_x_continuous(limits = range(mpg$displ))\ny_scale &lt;- scale_y_continuous(limits = range(mpg$hwy))\ncol_scale &lt;- scale_color_discrete(limits = unique(mpg$drv))\n\n# 왼쪽\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n# 오른쪽\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n\n\n\n\n\n\n\n\n\n이 특별한 경우에는 단순히 패싯을 사용할 수 있었지만, 예를 들어 보고서의 여러 페이지에 플롯을 분산시키려는 경우와 같이 이 기술은 더 일반적으로 유용합니다.\n\n11.4.6 연습문제\n\n\n다음 코드가 기본 척도를 재정의하지 않는 이유는 무엇입니까?\n\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  scale_color_gradient(low = \"white\", high = \"red\") +\n  coord_fixed()\n\n\n모든 척도의 첫 번째 인수는 무엇입니까? labs()와 어떻게 비교됩니까?\n\n다음을 수행하여 대통령 임기 표시를 변경하세요:\n\n색상과 x축 나누기를 사용자 정의하는 두 가지 변형을 결합합니다.\ny축 표시를 개선합니다.\n각 임기에 대통령 이름으로 레이블을 지정합니다.\n유익한 플롯 레이블을 추가합니다.\n4년마다 나누기를 배치합니다(생각보다 까다롭습니다!).\n\n\n\n먼저 다음 플롯을 만드세요. 그런 다음 override.aes를 사용하여 코드를 수정하여 범례를 더 보기 쉽게 만드세요.\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_point(aes(color = cut), alpha = 1/20)",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#sec-themes",
    "href": "communication.html#sec-themes",
    "title": "11  소통(Communication)",
    "section": "\n11.5 테마(Themes)",
    "text": "11.5 테마(Themes)\n마지막으로 테마를 사용하여 플롯의 데이터가 아닌 요소를 사용자 정의할 수 있습니다:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme_bw()\n\n\n\n\n\n\n\nggplot2에는 Figure 11.2 에 표시된 8가지 테마가 포함되어 있으며 theme_gray()가 기본값입니다.2 제프리 아놀드(Jeffrey Arnold)의 ggthemes(https://jrnold.github.io/ggthemes)와 같은 추가 패키지에는 더 많은 테마가 포함되어 있습니다. 특정 회사나 저널 스타일을 일치시키려는 경우 자신만의 테마를 만들 수도 있습니다.\n\n\n\n\n\n\n\nFigure 11.2: ggplot2에 내장된 8가지 테마.\n\n\n\n\ny축에 사용되는 글꼴의 크기와 색상과 같은 각 테마의 개별 구성 요소를 제어하는 것도 가능합니다. legend.position이 범례가 그려지는 위치를 제어한다는 것을 이미 보았습니다. theme()으로 사용자 정의할 수 있는 범례의 다른 많은 측면이 있습니다. 예를 들어 아래 플롯에서는 범례의 방향을 변경하고 주위에 검은색 테두리를 넣습니다. 범례 상자 및 플롯 제목 요소의 사용자 정의는 element_*() 함수로 수행됩니다. 이러한 함수는 데이터가 아닌 구성 요소의 스타일을 지정합니다. 예를 들어 제목 텍스트는 element_text()의 face 인수에서 굵게 표시되고 범례 테두리 색상은 element_rect()의 color 인수에서 정의됩니다. 제목과 캡션의 위치를 제어하는 테마 요소는 각각 plot.title.position과 plot.caption.position입니다. 다음 플롯에서 이들은 플롯 패널(기본값) 대신 전체 플롯 영역에 정렬됨을 나타내기 위해 “plot”으로 설정됩니다. 제목 및 캡션 텍스트의 형식을 위한 배치 변경에 몇 가지 다른 유용한 theme() 구성 요소가 사용됩니다.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  labs(\n    title = \"Larger engine sizes tend to have lower fuel economy\",\n    caption = \"Source: https://fueleconomy.gov.\"\n  ) +\n  theme(\n    legend.position = c(0.6, 0.7),\n    legend.direction = \"horizontal\",\n    legend.box.background = element_rect(color = \"black\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.title.position = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.caption = element_text(hjust = 0)\n  )\n\n\n\n\n\n\n\n모든 theme() 구성 요소에 대한 개요는 ?theme 도움말을 참조하세요. ggplot2 책은 테마 지정에 대한 전체 세부 정보를 얻을 수 있는 훌륭한 장소이기도 합니다.\n\n11.5.1 연습문제\n\nggthemes 패키지에서 제공하는 테마를 선택하여 마지막으로 만든 플롯에 적용하세요.\n플롯의 축 레이블을 파란색과 굵게 만드세요.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#레이아웃layout",
    "href": "communication.html#레이아웃layout",
    "title": "11  소통(Communication)",
    "section": "\n11.6 레이아웃(Layout)",
    "text": "11.6 레이아웃(Layout)\n지금까지 단일 플롯을 만들고 수정하는 방법에 대해 이야기했습니다. 특정 방식으로 레이아웃하고 싶은 여러 플롯이 있다면 어떻게 해야 할까요? patchwork 패키지를 사용하면 별도의 플롯을 동일한 그래픽으로 결합할 수 있습니다. 이 장의 앞부분에서 이 패키지를 로드했습니다.\n두 플롯을 나란히 배치하려면 단순히 서로 더하면 됩니다. 먼저 플롯을 만들고 객체로 저장해야 합니다(다음 예제에서는 p1과 p2라고 함). 그런 다음 +로 나란히 배치합니다.\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"Plot 2\")\np1 + p2\n\n\n\n\n\n\n\n위의 코드 청크에서 patchwork 패키지의 새로운 함수를 사용하지 않았다는 점에 유의하는 것이 중요합니다. 대신 패키지가 + 연산자에 새로운 기능을 추가했습니다.\npatchwork로 복잡한 플롯 레이아웃을 만들 수도 있습니다. 다음에서 |는 p1과 p3를 나란히 배치하고 /는 p2를 다음 줄로 이동합니다.\n\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 3\")\n(p1 | p3) / p2\n\n\n\n\n\n\n\n또한 patchwork를 사용하면 여러 플롯의 범례를 하나의 공통 범례로 수집하고, 범례의 배치 및 플롯의 치수를 사용자 정의하고, 플롯에 공통 제목, 부제, 캡션 등을 추가할 수 있습니다. 아래에서 5개의 플롯을 만듭니다. 상자 그림과 산점도의 범례를 끄고 & theme(legend.position = \"top\")으로 밀도 플롯의 범례를 플롯 상단에 모았습니다. 여기서 일반적인 + 대신 & 연산자를 사용한 것에 주목하세요. 이는 개별 ggplot이 아니라 patchwork 플롯의 테마를 수정하기 때문입니다. 범례는 상단의 guide_area() 내부에 배치됩니다. 마지막으로 patchwork의 다양한 구성 요소 높이도 사용자 정의했습니다. 가이드는 높이가 1, 상자 그림은 3, 밀도 플롯은 2, 패싯된 산점도는 4입니다. Patchwork는 이 척도를 사용하여 플롯에 할당된 영역을 나누고 구성 요소를 그에 따라 배치합니다.\n\n#   처음 두 플롯은 나란히 놓인 상자 그림입니다. 3번과 4번 플롯은 밀도 \n#|   플롯입니다. 그리고 5번 플롯은 패싯된 산점도입니다.\n#   이러한 각 플롯은 구동 방식별로 색상이 지정된 지옴을 \n#|   보여주지만 패치워크된 플롯에는 플롯 위와 제목 아래에 모두 적용되는 \n#|   하나의 범례만 있습니다.\np1 &lt;- ggplot(mpg, aes(x = drv, y = cty, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"Plot 1\")\n\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"Plot 2\")\n\np3 &lt;- ggplot(mpg, aes(x = cty, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"Plot 3\")\n\np4 &lt;- ggplot(mpg, aes(x = hwy, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"Plot 4\")\n\np5 &lt;- ggplot(mpg, aes(x = cty, y = hwy, color = drv)) + \n  geom_point(show.legend = FALSE) + \n  facet_wrap(~drv) +\n  labs(title = \"Plot 5\")\n\n(guide_area() / (p1 + p2) / (p3 + p4) / p5) +\n  plot_annotation(\n    title = \"City and highway mileage for cars with different drive trains\",\n    caption = \"Source: https://fueleconomy.gov.\"\n  ) +\n  plot_layout(\n    guides = \"collect\",\n    heights = c(1, 3, 2, 4)\n    ) &\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\npatchwork로 여러 플롯을 결합하고 레이아웃하는 것에 대해 더 알고 싶다면 패키지 웹사이트의 가이드를 살펴보는 것을 추천합니다: https://patchwork.data-imaginist.com.\n\n11.6.1 연습문제\n\n\n다음 플롯 레이아웃에서 괄호를 생략하면 어떻게 됩니까? 왜 이런 일이 발생하는지 설명할 수 있습니까?\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"Plot 2\")\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 3\")\n\n(p1 | p2) / p3\n\n\n\n이전 연습문제의 세 플롯을 사용하여 다음 패치워크를 다시 만드세요.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#요약",
    "href": "communication.html#요약",
    "title": "11  소통(Communication)",
    "section": "\n11.7 요약",
    "text": "11.7 요약\n이 장에서는 제목, 부제, 캡션과 같은 플롯 레이블 추가, 기본 축 레이블 수정, 주석을 사용하여 플롯에 정보 텍스트를 추가하거나 특정 데이터 포인트를 강조 표시, 축 척도 사용자 정의, 플롯 테마 변경에 대해 배웠습니다. 또한 단순 및 복잡한 플롯 레이아웃을 모두 사용하여 여러 플롯을 단일 그래프로 결합하는 방법에 대해서도 배웠습니다.\n지금까지 다양한 유형의 플롯을 만드는 방법과 다양한 기술을 사용하여 사용자 정의하는 방법에 대해 배웠지만, ggplot2로 만들 수 있는 것의 겉만 핥았을 뿐입니다. ggplot2에 대한 포괄적인 이해를 얻으려면 ggplot2: Elegant Graphics for Data Analysis 책을 읽는 것을 추천합니다. 다른 유용한 리소스는 Winston Chang의 R Graphics Cookbook과 Claus Wilke의 Fundamentals of Data Visualization입니다.",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "communication.html#footnotes",
    "href": "communication.html#footnotes",
    "title": "11  소통(Communication)",
    "section": "",
    "text": "SimDaltonism과 같은 도구를 사용하여 색맹을 시뮬레이션하여 이 이미지를 테스트할 수 있습니다.↩︎\n많은 사람들이 기본 테마가 회색 배경인 이유를 궁금해합니다. 이것은 격자선을 여전히 볼 수 있게 하면서 데이터를 앞으로 내세우기 때문에 의도적인 선택이었습니다. 흰색 격자선이 보이지만(위치 판단에 상당히 도움이 되기 때문에 중요함) 시각적 영향이 적어 쉽게 무시할 수 있습니다. 회색 배경은 플롯에 텍스트와 유사한 인쇄 색상을 제공하여 그래픽이 밝은 흰색 배경으로 튀어나오지 않고 문서 흐름에 맞도록 합니다. 마지막으로 회색 배경은 플롯이 단일 시각적 개체로 인식되도록 하는 연속적인 색상 필드를 만듭니다.↩︎",
    "crumbs": [
      "시각화 (Visualize)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>소통(Communication)</span>"
    ]
  },
  {
    "objectID": "transform.html",
    "href": "transform.html",
    "title": "변형 (Transform)",
    "section": "",
    "text": "책의 두 번째 파트에서는 데이터 시각화를 깊이 있게 다루었습니다. 책의 이 파트에서는 데이터 프레임 내부에서 마주하게 될 가장 중요한 변수 유형에 대해 배우고, 이를 다루는 데 사용할 수 있는 도구들을 배울 것입니다.\n\n\n\n\n\n\n\nFigure 1: 데이터 변형 옵션은 관련된 데이터 유형에 따라 크게 달라지며, 이것이 책의 이 파트의 주제입니다.\n\n\n\n\n이 장들은 필요에 따라 읽을 수 있습니다. 순서에 상관없이 읽을 수 있도록 대부분 독립적으로 설계되었습니다.\n\n12  논리형 벡터 에서는 논리형 벡터에 대해 배웁니다. 논리형 벡터는 가장 단순한 유형의 벡터이지만 매우 강력합니다. 수치 비교를 통해 이를 생성하는 방법, 부울 대수를 사용하여 결합하는 방법, 요약에 사용하는 방법, 조건부 변형에 사용하는 방법을 배웁니다.\n13  숫자 에서는 데이터 과학의 원동력인 수치형 벡터를 위한 도구들을 깊이 있게 다룹니다. 개수 세기와 많은 중요한 변형 및 요약 함수에 대해 더 배우게 됩니다.\n14  문자열 에서는 문자열 작업을 위한 도구들을 제공합니다: 문자열을 자르고, 나누고, 다시 합치는 방법을 배웁니다. 이 장은 주로 stringr 패키지에 초점을 맞추지만, 문자열에서 데이터를 추출하는 데 전념하는 더 많은 tidyr 함수들도 배우게 됩니다.\n15  정규 표현식 (Regular expressions) 에서는 문자열 조작을 위한 강력한 도구인 정규 표현식을 소개합니다. 이 장을 통해 키보드 위를 고양이가 걸어간 것 같은 암호 같은 문자열에서 복잡한 문자열 패턴을 읽고 쓰는 수준으로 나아가게 될 것입니다.\n16  팩터(Factors) 에서는 R이 범주형 데이터를 저장하는 데 사용하는 데이터 유형인 팩터를 소개합니다. 변수가 가질 수 있는 가능한 값의 집합이 고정되어 있거나, 문자열의 알파벳 순서가 아닌 정렬을 사용하고 싶을 때 팩터를 사용합니다.\n17  날짜와 시간 에서는 날짜와 날짜-시간 작업을 위한 핵심 도구들을 제공합니다. 불행히도 날짜-시간에 대해 더 많이 배울수록 더 복잡해지는 것처럼 느껴지지만, lubridate 패키지의 도움을 받아 가장 일반적인 과제들을 극복하는 방법을 배우게 될 것입니다.\n18  결측값(Missing values) 에서는 결측값을 심층적으로 다룹니다. 이전에도 몇 번 부분적으로 논의했지만, 이제는 암시적 결측값과 명시적 결측값의 차이점, 그리고 왜 그리고 어떻게 이들 사이를 변환하는지 이해할 수 있도록 전체적으로 논의할 때입니다.\n19  조인(Joins) 에서는 두 개(또는 그 이상)의 데이터 프레임을 하나로 결합하는 도구들을 제공하며 이 파트를 마무리합니다. 조인을 배우면서 키(keys)의 개념과 씨름하고, 데이터셋의 각 행을 어떻게 식별할지 생각하게 될 것입니다.",
    "crumbs": [
      "변형 (Transform)"
    ]
  },
  {
    "objectID": "logicals.html",
    "href": "logicals.html",
    "title": "12  논리형 벡터",
    "section": "",
    "text": "12.1 소개\n이 장에서는 논리형 벡터(logical vectors)로 작업하는 도구를 배울 것입니다. 논리형 벡터는 각 요소가 TRUE, FALSE, NA의 세 가지 가능한 값 중 하나만 될 수 있기 때문에 가장 단순한 유형의 벡터입니다. 원시 데이터에서 논리형 벡터를 찾는 것은 상대적으로 드물지만, 거의 모든 분석 과정에서 논리형 벡터를 생성하고 조작하게 될 것입니다.\n숫자 비교를 통해 논리형 벡터를 만드는 가장 일반적인 방법에 대해 논의하는 것으로 시작하겠습니다. 그런 다음 부울 대수(Boolean algebra)를 사용하여 서로 다른 논리형 벡터를 결합하는 방법과 유용한 요약에 대해 배울 것입니다. 논리형 벡터로 구동되는 조건부 변경을 수행하기 위한 두 가지 유용한 함수인 if_else()와 case_when()으로 마무리할 것입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "logicals.html#소개",
    "href": "logicals.html#소개",
    "title": "12  논리형 벡터",
    "section": "",
    "text": "12.1.1 선수 지식\n이 장에서 배울 대부분의 함수는 기본(base) R에서 제공하므로 tidyverse가 필요하지 않지만, 데이터 프레임으로 작업하기 위해 mutate(), filter() 및 친구들을 사용할 수 있도록 tidyverse를 로드할 것입니다. 또한 nycflights13::flights 데이터셋에서 예제를 계속 가져올 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(nycflights13)\n\n그러나 더 많은 도구를 다루기 시작하면서 완벽한 실제 예제가 항상 있는 것은 아닙니다. 그래서 c()로 더미 데이터를 만들기 시작할 것입니다:\n\nx &lt;- c(1, 2, 3, 5, 7, 11, 13)\nx * 2\n#&gt; [1]  2  4  6 10 14 22 26\n\n이렇게 하면 데이터 문제에 어떻게 적용될 수 있는지 보기 어렵게 만드는 대신 개별 함수를 설명하기가 더 쉬워집니다. 자유 부동(free-floating) 벡터에 수행하는 모든 조작은 mutate() 및 친구들을 사용하여 데이터 프레임 내부의 변수에 수행할 수 있다는 점을 기억하세요.\n\ndf &lt;- tibble(x)\ndf |&gt; \n  mutate(y = x * 2)\n#&gt; # A tibble: 7 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2\n#&gt; 2     2     4\n#&gt; 3     3     6\n#&gt; 4     5    10\n#&gt; 5     7    14\n#&gt; 6    11    22\n#&gt; # ℹ 1 more row",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "logicals.html#비교",
    "href": "logicals.html#비교",
    "title": "12  논리형 벡터",
    "section": "\n12.2 비교",
    "text": "12.2 비교\n논리형 벡터를 만드는 매우 일반적인 방법은 &lt;, &lt;=, &gt;, &gt;=, !=, ==를 사용한 숫자 비교를 통하는 것입니다. 지금까지 우리는 주로 filter() 내에서 논리형 변수를 일시적으로 생성했습니다. 계산되고, 사용된 다음, 버려졌습니다. 예를 들어 다음 필터는 대략 제시간에 도착하는 모든 주간 출발 항공편을 찾습니다:\n\nflights |&gt; \n  filter(dep_time &gt; 600 & dep_time &lt; 2000 & abs(arr_delay) &lt; 20)\n#&gt; # A tibble: 172,286 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      601            600         1      844            850\n#&gt; 2  2013     1     1      602            610        -8      812            820\n#&gt; 3  2013     1     1      602            605        -3      821            805\n#&gt; 4  2013     1     1      606            610        -4      858            910\n#&gt; 5  2013     1     1      606            610        -4      837            845\n#&gt; 6  2013     1     1      607            607         0      858            915\n#&gt; # ℹ 172,280 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n이것이 단축키이며 mutate()로 기본 논리형 변수를 명시적으로 생성할 수 있다는 것을 아는 것이 유용합니다:\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 4\n#&gt;   dep_time arr_delay daytime approx_ontime\n#&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;lgl&gt;   &lt;lgl&gt;        \n#&gt; 1      517        11 FALSE   TRUE         \n#&gt; 2      533        20 FALSE   FALSE        \n#&gt; 3      542        33 FALSE   FALSE        \n#&gt; 4      544       -18 FALSE   TRUE         \n#&gt; 5      554       -25 FALSE   FALSE        \n#&gt; 6      554        12 FALSE   TRUE         \n#&gt; # ℹ 336,770 more rows\n\n중간 단계의 이름을 지정하면 코드를 읽고 각 단계가 올바르게 계산되었는지 확인하기가 더 쉽기 때문에 더 복잡한 로직에 특히 유용합니다.\n종합하면 초기 필터는 다음과 동일합니다:\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n  ) |&gt; \n  filter(daytime & approx_ontime)\n\n\n12.2.1 부동 소수점 비교\n숫자와 함께 ==를 사용할 때는 주의하세요. 예를 들어 이 벡터에는 숫자 1과 2가 포함된 것처럼 보입니다:\n\nx &lt;- c(1 / 49 * 49, sqrt(2) ^ 2)\nx\n#&gt; [1] 1 2\n\n하지만 동일성을 테스트하면 FALSE를 얻습니다:\n\nx == c(1, 2)\n#&gt; [1] FALSE FALSE\n\n무슨 일일까요? 컴퓨터는 고정된 소수점 자릿수로 숫자를 저장하므로 1/49 또는 sqrt(2)를 정확하게 표현할 방법이 없으며 후속 계산은 아주 약간 벗어나게 됩니다. digits1 인수로 print()를 호출하여 정확한 값을 볼 수 있습니다:\n\nprint(x, digits = 16)\n#&gt; [1] 0.9999999999999999 2.0000000000000004\n\nR이 왜 이 숫자를 반올림하는지 알 수 있습니다. 실제로는 예상한 것과 매우 가깝습니다.\n이제 ==가 실패하는 이유를 알았으니 어떻게 해야 할까요? 한 가지 옵션은 작은 차이를 무시하는 dplyr::near()를 사용하는 것입니다:\n\nnear(x, c(1, 2))\n#&gt; [1] TRUE TRUE\n\n\n12.2.2 결측값\n결측값은 알 수 없음을 나타내므로 “전염성”이 있습니다. 알 수 없는 값과 관련된 거의 모든 연산도 알 수 없게 됩니다:\n\nNA &gt; 5\n#&gt; [1] NA\n10 == NA\n#&gt; [1] NA\n\n가장 혼란스러운 결과는 이것입니다:\n\nNA == NA\n#&gt; [1] NA\n\n맥락을 조금 더 인위적으로 제공하면 이것이 왜 사실인지 이해하기 가장 쉽습니다:\n\n# 메리의 나이를 모릅니다\nage_mary &lt;- NA\n\n# 존의 나이를 모릅니다\nage_john &lt;- NA\n\n# 메리와 존은 동갑입니까?\nage_mary == age_john\n#&gt; [1] NA\n# 우리는 모릅니다!\n\n따라서 dep_time이 누락된 모든 항공편을 찾으려면 다음 코드는 작동하지 않습니다. dep_time == NA는 모든 단일 행에 대해 NA를 생성하고 filter()는 결측값을 자동으로 삭제하기 때문입니다:\n\nflights |&gt; \n  filter(dep_time == NA)\n#&gt; # A tibble: 0 × 19\n#&gt; # ℹ 19 variables: year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;, dep_time &lt;int&gt;,\n#&gt; #   sched_dep_time &lt;int&gt;, dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, …\n\n대신 새로운 도구인 is.na()가 필요합니다.\n\n12.2.3 is.na()\n\nis.na(x)는 모든 유형의 벡터와 작동하며 결측값에 대해서는 TRUE를 반환하고 그 외의 모든 것에 대해서는 FALSE를 반환합니다:\n\nis.na(c(TRUE, NA, FALSE))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(1, NA, 3))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(\"a\", NA, \"b\"))\n#&gt; [1] FALSE  TRUE FALSE\n\nis.na()를 사용하여 dep_time이 누락된 모든 행을 찾을 수 있습니다:\n\nflights |&gt; \n  filter(is.na(dep_time))\n#&gt; # A tibble: 8,255 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     2       NA           1540        NA       NA           1747\n#&gt; 6  2013     1     2       NA           1620        NA       NA           1746\n#&gt; # ℹ 8,249 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nis.na()는 arrange()에서도 유용할 수 있습니다. arrange()는 일반적으로 모든 결측값을 끝에 배치하지만 먼저 is.na()로 정렬하여 이 기본값을 재정의할 수 있습니다:\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(dep_time)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(desc(is.na(dep_time)), dep_time)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     1      517            515         2      830            819\n#&gt; 6  2013     1     1      533            529         4      850            830\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nChapter 18 에서 결측값을 더 깊이 다루기 위해 다시 돌아올 것입니다.\n\n12.2.4 연습문제\n\n\ndplyr::near()는 어떻게 작동합니까? 소스 코드를 보려면 near를 입력하세요. sqrt(2)^2는 2에 가깝습니까?\n\nmutate(), is.na(), count()를 함께 사용하여 dep_time, sched_dep_time, dep_delay의 결측값이 어떻게 연결되어 있는지 설명하세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "logicals.html#부울-대수boolean-algebra",
    "href": "logicals.html#부울-대수boolean-algebra",
    "title": "12  논리형 벡터",
    "section": "\n12.3 부울 대수(Boolean algebra)",
    "text": "12.3 부울 대수(Boolean algebra)\n여러 논리형 벡터가 있으면 부울 대수를 사용하여 결합할 수 있습니다. R에서 &는 “그리고(and)”, |는 “또는(or)”, !는 “아님(not)”, xor()는 배타적 또는(exclusive or)2입니다. 예를 들어 df |&gt; filter(!is.na(x))는 x가 누락되지 않은 모든 행을 찾고 df |&gt; filter(x &lt; -10 | x &gt; 0)은 x가 -10보다 작거나 0보다 큰 모든 행을 찾습니다. Figure 12.1 는 일반적으로 사용되는 부울 연산의 예와 작동 방식을 보여줍니다.\n\n\n\n\n\n\n\nFigure 12.1: 일반적으로 사용되는 부울 연산 세트. x는 왼쪽 원, y는 오른쪽 원이며, 음영 처리된 영역은 각 연산자가 선택하는 부분을 보여줍니다.\n\n\n\n\n& 및 | 외에도 R에는 && 및 ||도 있습니다. dplyr 함수에서 사용하지 마세요! 이를 단락(short-circuiting) 연산자라고 하며 단일 TRUE 또는 FALSE만 반환합니다. 이것들은 데이터 과학이 아니라 프로그래밍에 중요합니다.\n\n12.3.1 결측값\n부울 대수의 결측값 규칙은 언뜻 보기에 일관성이 없어 보이기 때문에 설명하기가 조금 까다롭습니다:\n\ndf &lt;- tibble(x = c(TRUE, FALSE, NA))\n\ndf |&gt; \n  mutate(\n    and = x & NA,\n    or = x | NA\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   x     and   or   \n#&gt;   &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 TRUE  NA    TRUE \n#&gt; 2 FALSE FALSE NA   \n#&gt; 3 NA    NA    NA\n\n무슨 일이 일어나고 있는지 이해하려면 NA | TRUE(NA 또는 TRUE)에 대해 생각해 보세요. 논리형 벡터의 결측값은 값이 TRUE 또는 FALSE일 수 있음을 의미합니다. TRUE | TRUE와 FALSE | TRUE는 둘 중 하나가 적어도 TRUE이므로 둘 다 TRUE입니다. NA | TRUE 또한 NA가 TRUE 또는 FALSE일 수 있으므로 TRUE여야 합니다. 그러나 NA | FALSE는 NA가 TRUE인지 FALSE인지 모르기 때문에 NA입니다. 두 조건이 모두 충족되어야 한다는 점을 고려하면 &에도 유사한 추론이 적용됩니다. 따라서 NA & TRUE는 NA가 TRUE 또는 FALSE일 수 있으므로 NA이고, NA & FALSE는 조건 중 하나가 적어도 FALSE이므로 FALSE입니다.\n\n12.3.2 연산 순서\n연산 순서가 영어처럼 작동하지 않는다는 점에 유의하세요. 11월 또는 12월에 출발한 모든 항공편을 찾는 다음 코드를 살펴보세요:\n\nflights |&gt; \n   filter(month == 11 | month == 12)\n\n영어에서 말하는 것처럼 쓰고 싶을 수도 있습니다: “11월 또는 12월에 출발한 모든 항공편 찾기.”\n\nflights |&gt; \n   filter(month == 11 | 12)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n이 코드는 오류가 발생하지 않지만 작동하지도 않는 것 같습니다. 무슨 일일까요? 여기서 R은 먼저 month == 11을 평가하여 nov라고 하는 논리형 벡터를 생성합니다. nov | 12를 계산합니다. 논리 연산자와 함께 숫자를 사용하면 0을 제외한 모든 것을 TRUE로 변환하므로 이는 nov | TRUE와 동일하며, 이는 항상 TRUE이므로 모든 행이 선택됩니다:\n\nflights |&gt; \n  mutate(\n    nov = month == 11,\n    final = nov | 12,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;   month nov   final\n#&gt;   &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1     1 FALSE TRUE \n#&gt; 2     1 FALSE TRUE \n#&gt; 3     1 FALSE TRUE \n#&gt; 4     1 FALSE TRUE \n#&gt; 5     1 FALSE TRUE \n#&gt; 6     1 FALSE TRUE \n#&gt; # ℹ 336,770 more rows\n\n\n12.3.3 %in%\n\n==와 |를 올바른 순서로 가져오는 문제를 피하는 쉬운 방법은 %in%를 사용하는 것입니다. x %in% y는 x와 길이가 같은 논리형 벡터를 반환하며 x의 값이 y의 어디에든 있을 때마다 TRUE입니다.\n\n1:12 %in% c(1, 5, 11)\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\nletters[1:10] %in% c(\"a\", \"e\", \"i\", \"o\", \"u\")\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n\n따라서 11월과 12월의 모든 항공편을 찾으려면 다음과 같이 쓸 수 있습니다:\n\nflights |&gt; \n  filter(month %in% c(11, 12))\n\n%in%은 NA에 대해 ==와 다른 규칙을 따릅니다. NA %in% NA는 TRUE이기 때문입니다.\n\nc(1, 2, NA) == NA\n#&gt; [1] NA NA NA\nc(1, 2, NA) %in% NA\n#&gt; [1] FALSE FALSE  TRUE\n\n이것은 유용한 단축키가 될 수 있습니다:\n\nflights |&gt; \n  filter(dep_time %in% c(NA, 0800))\n#&gt; # A tibble: 8,803 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      800            800         0     1022           1014\n#&gt; 2  2013     1     1      800            810       -10      949            955\n#&gt; 3  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 4  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 5  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 6  2013     1     1       NA            600        NA       NA            901\n#&gt; # ℹ 8,797 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n\n12.3.4 연습문제\n\n\narr_delay는 누락되었지만 dep_delay는 누락되지 않은 모든 항공편을 찾으세요. arr_time이나 sched_arr_time은 누락되지 않았지만 arr_delay는 누락된 모든 항공편을 찾으세요.\n\ndep_time이 누락된 항공편은 몇 개입니까? 이 행들에서 다른 어떤 변수들이 누락되었습니까? 이 행들은 무엇을 나타낼 수 있습니까?\n\ndep_time 누락이 항공편 취소를 의미한다고 가정하고 일별 취소된 항공편 수를 살펴보세요. 패턴이 있습니까? 취소된 항공편 비율과 취소되지 않은 항공편의 평균 지연 사이에 연관성이 있습니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "logicals.html#sec-logical-summaries",
    "href": "logicals.html#sec-logical-summaries",
    "title": "12  논리형 벡터",
    "section": "\n12.4 요약(Summaries)",
    "text": "12.4 요약(Summaries)\n다음 섹션에서는 논리형 벡터를 요약하는 데 유용한 몇 가지 기술을 설명합니다. 논리형 벡터와 구체적으로 작동하는 함수뿐만 아니라 숫자 벡터와 작동하는 함수도 사용할 수 있습니다.\n\n12.4.1 논리형 요약\n두 가지 주요 논리형 요약이 있습니다: any()와 all(). any(x)는 |와 동일합니다. x에 TRUE가 하나라도 있으면 TRUE를 반환합니다. all(x)는 &와 동일합니다. x의 모든 값이 TRUE인 경우에만 TRUE를 반환합니다. 대부분의 요약 함수와 마찬가지로 na.rm = TRUE로 결측값을 없앨 수 있습니다.\n예를 들어 all()과 any()를 사용하여 모든 항공편이 출발 시 최대 1시간 지연되었는지 또는 도착 시 5시간 이상 지연된 항공편이 있는지 알아볼 수 있습니다. 그리고 group_by()를 사용하면 일별로 수행할 수 있습니다:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    all_delayed = all(dep_delay &lt;= 60, na.rm = TRUE),\n    any_long_delay = any(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day all_delayed any_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;       &lt;lgl&gt;         \n#&gt; 1  2013     1     1 FALSE       TRUE          \n#&gt; 2  2013     1     2 FALSE       TRUE          \n#&gt; 3  2013     1     3 FALSE       FALSE         \n#&gt; 4  2013     1     4 FALSE       FALSE         \n#&gt; 5  2013     1     5 FALSE       TRUE          \n#&gt; 6  2013     1     6 FALSE       FALSE         \n#&gt; # ℹ 359 more rows\n\n그러나 대부분의 경우 any()와 all()은 다소 조잡하며, 얼마나 많은 값이 TRUE 또는 FALSE인지에 대한 세부 정보를 얻을 수 있다면 좋을 것입니다. 그것은 우리를 숫자 요약으로 이끕니다.\n\n12.4.2 논리형 벡터의 숫자 요약\n숫자 맥락에서 논리형 벡터를 사용할 때 TRUE는 1이 되고 FALSE는 0이 됩니다. 이것은 sum()과 mean()을 논리형 벡터와 함께 사용할 때 매우 유용하게 만듭니다. sum(x)는 TRUE의 개수를 제공하고 mean(x)는 TRUE의 비율을 제공합니다(mean()은 단지 sum()을 length()로 나눈 것이기 때문입니다).\n예를 들어 이를 통해 출발 시 최대 1시간 지연된 항공편의 비율과 도착 시 5시간 이상 지연된 항공편의 수를 볼 수 있습니다:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    proportion_delayed = mean(dep_delay &lt;= 60, na.rm = TRUE),\n    count_long_delay = sum(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day proportion_delayed count_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;dbl&gt;            &lt;int&gt;\n#&gt; 1  2013     1     1              0.939                3\n#&gt; 2  2013     1     2              0.914                3\n#&gt; 3  2013     1     3              0.941                0\n#&gt; 4  2013     1     4              0.953                0\n#&gt; 5  2013     1     5              0.964                1\n#&gt; 6  2013     1     6              0.959                0\n#&gt; # ℹ 359 more rows\n\n\n12.4.3 논리형 부분집합\n요약에서 논리형 벡터를 사용하는 마지막 용도가 하나 있습니다. 논리형 벡터를 사용하여 단일 변수를 관심 있는 하위 집합으로 필터링할 수 있습니다. 이것은 기본(base) [ (부분집합이라고 발음) 연산자를 사용하며, 이에 대해서는 Section 27.2 에서 더 자세히 배울 것입니다.\n실제로 지연된 항공편에 대한 평균 지연만 보고 싶다고 상상해 보세요. 그렇게 하는 한 가지 방법은 먼저 항공편을 필터링한 다음 평균 지연을 계산하는 것입니다:\n\nflights |&gt; \n  filter(arr_delay &gt; 0) |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day behind     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5   461\n#&gt; 2  2013     1     2   32.0   535\n#&gt; 3  2013     1     3   27.7   460\n#&gt; 4  2013     1     4   28.3   297\n#&gt; 5  2013     1     5   22.6   238\n#&gt; 6  2013     1     6   24.4   381\n#&gt; # ℹ 359 more rows\n\n이것은 작동하지만 일찍 도착한 항공편에 대한 평균 지연도 계산하고 싶다면 어떻게 해야 할까요? 별도의 필터 단계를 수행한 다음 두 데이터 프레임을 결합하는 방법을 파악해야 합니다3. 대신 [를 사용하여 인라인 필터링을 수행할 수 있습니다: arr_delay[arr_delay &gt; 0]은 양의 도착 지연만 산출합니다.\n결과는 다음과 같습니다:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay[arr_delay &gt; 0], na.rm = TRUE),\n    ahead = mean(arr_delay[arr_delay &lt; 0], na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 6\n#&gt;    year month   day behind ahead     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5 -12.5   842\n#&gt; 2  2013     1     2   32.0 -14.3   943\n#&gt; 3  2013     1     3   27.7 -18.2   914\n#&gt; 4  2013     1     4   28.3 -17.0   915\n#&gt; 5  2013     1     5   22.6 -14.0   720\n#&gt; 6  2013     1     6   24.4 -13.6   832\n#&gt; # ℹ 359 more rows\n\n또한 그룹 크기의 차이에 유의하세요. 첫 번째 청크에서 n()은 일별 지연된 항공편 수를 제공합니다. 두 번째에서는 n()이 전체 항공편 수를 제공합니다.\n\n12.4.4 연습문제\n\n\nsum(is.na(x))는 무엇을 말해줍니까? mean(is.na(x))는 어떻습니까?\n논리형 벡터에 적용될 때 prod()는 무엇을 반환합니까? 어떤 논리형 요약 함수와 동일합니까? 논리형 벡터에 적용될 때 min()은 무엇을 반환합니까? 어떤 논리형 요약 함수와 동일합니까? 문서를 읽고 몇 가지 실험을 수행하세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "logicals.html#조건부-변환",
    "href": "logicals.html#조건부-변환",
    "title": "12  논리형 벡터",
    "section": "\n12.5 조건부 변환",
    "text": "12.5 조건부 변환\n논리형 벡터의 가장 강력한 기능 중 하나는 조건부 변환, 즉 조건 x에 대해 한 가지 작업을 수행하고 조건 y에 대해 다른 작업을 수행하는 데 사용하는 것입니다. 이를 위한 두 가지 중요한 도구는 if_else()와 case_when()입니다.\n\n12.5.1 if_else()\n\n조건이 TRUE일 때 한 값을 사용하고 FALSE일 때 다른 값을 사용하려면 dplyr::if_else()4를 사용할 수 있습니다. 항상 if_else()의 처음 세 인수를 사용합니다. 첫 번째 인수 condition은 논리형 벡터이고, 두 번째 true는 조건이 참일 때 출력을 제공하고, 세 번째 false는 조건이 거짓일 때 출력을 제공합니다.\n숫자 벡터에 “+ve”(양수) 또는 “-ve”(음수)로 레이블을 지정하는 간단한 예제로 시작하겠습니다:\n\nx &lt;- c(-3:3, NA)\nif_else(x &gt; 0, \"+ve\", \"-ve\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" NA\n\n입력이 NA인 경우 사용될 선택적 네 번째 인수 missing이 있습니다:\n\nif_else(x &gt; 0, \"+ve\", \"-ve\", \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\ntrue 및 false 인수에 벡터를 사용할 수도 있습니다. 예를 들어 이를 통해 abs()의 최소 구현을 만들 수 있습니다:\n\nif_else(x &lt; 0, -x, x)\n#&gt; [1]  3  2  1  0  1  2  3 NA\n\n지금까지 모든 인수는 동일한 벡터를 사용했지만 물론 섞어서 사용할 수 있습니다. 예를 들어 다음과 같이 coalesce()의 간단한 버전을 구현할 수 있습니다:\n\nx1 &lt;- c(NA, 1, 2, NA)\ny1 &lt;- c(3, NA, 4, 6)\nif_else(is.na(x1), y1, x1)\n#&gt; [1] 3 1 2 6\n\n위의 레이블링 예제에서 작은 부적절함을 눈치챘을 수 있습니다. 0은 양수도 음수도 아닙니다. if_else()를 추가하여 이를 해결할 수 있습니다:\n\nif_else(x == 0, \"0\", if_else(x &lt; 0, \"-ve\", \"+ve\"), \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\n이것은 이미 읽기가 조금 어렵고 조건이 더 많으면 더 어려워질 것이라고 상상할 수 있습니다. 대신 dplyr::case_when()으로 전환할 수 있습니다.\n\n12.5.2 case_when()\n\ndplyr의 case_when()은 SQL의 CASE 문에서 영감을 받았으며 다양한 조건에 대해 다른 계산을 수행하는 유연한 방법을 제공합니다. 불행히도 tidyverse에서 사용할 다른 어떤 것과도 비슷해 보이지 않는 특별한 구문을 가지고 있습니다. condition ~ output과 같은 쌍을 취합니다. condition은 논리형 벡터여야 합니다. TRUE이면 output이 사용됩니다.\n즉, 이전의 중첩된 if_else()를 다음과 같이 다시 만들 수 있습니다:\n\nx &lt;- c(-3:3, NA)\ncase_when(\n  x == 0   ~ \"0\",\n  x &lt; 0    ~ \"-ve\", \n  x &gt; 0    ~ \"+ve\",\n  is.na(x) ~ \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\n이것은 더 많은 코드이지만 더 명시적입니다.\ncase_when()이 어떻게 작동하는지 설명하기 위해 몇 가지 더 간단한 경우를 살펴보겠습니다. 일치하는 사례가 없으면 출력은 NA를 얻습니다:\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" NA    \"+ve\" \"+ve\" \"+ve\" NA\n\n“기본값”/포괄적(catch all) 값을 만들려면 .default를 사용하세요:\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\",\n  .default = \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"???\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\n그리고 여러 조건이 일치하면 첫 번째 조건만 사용됩니다:\n\ncase_when(\n  x &gt; 0 ~ \"+ve\",\n  x &gt; 2 ~ \"big\"\n)\n#&gt; [1] NA    NA    NA    NA    \"+ve\" \"+ve\" \"+ve\" NA\n\nif_else()와 마찬가지로 ~의 양쪽에서 변수를 사용할 수 있으며 문제에 필요한 대로 변수를 섞어서 사용할 수 있습니다. 예를 들어 case_when()을 사용하여 도착 지연에 대해 사람이 읽을 수 있는 레이블을 제공할 수 있습니다:\n\nflights |&gt; \n  mutate(\n    status = case_when(\n      is.na(arr_delay)      ~ \"cancelled\",\n      arr_delay &lt; -30       ~ \"very early\",\n      arr_delay &lt; -15       ~ \"early\",\n      abs(arr_delay) &lt;= 15  ~ \"on time\",\n      arr_delay &lt; 60        ~ \"late\",\n      arr_delay &lt; Inf       ~ \"very late\",\n    ),\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 2\n#&gt;   arr_delay status \n#&gt;       &lt;dbl&gt; &lt;chr&gt;  \n#&gt; 1        11 on time\n#&gt; 2        20 late   \n#&gt; 3        33 late   \n#&gt; 4       -18 early  \n#&gt; 5       -25 early  \n#&gt; 6        12 on time\n#&gt; # ℹ 336,770 more rows\n\n이런 종류의 복잡한 case_when() 문을 작성할 때는 주의하세요. 저의 처음 두 번의 시도는 &lt;와 &gt;를 섞어 사용했고 계속해서 겹치는 조건을 실수로 만들었습니다.\n\n12.5.3 호환 가능한 유형\nif_else()와 case_when() 모두 출력에 호환 가능한(compatible) 유형이 필요합니다. 호환되지 않으면 다음과 같은 오류가 표시됩니다:\n\nif_else(TRUE, \"a\", 1)\n#&gt; Error in `if_else()`:\n#&gt; ! Can't combine `true` &lt;character&gt; and `false` &lt;double&gt;.\n\ncase_when(\n  x &lt; -1 ~ TRUE,  \n  x &gt; 0  ~ now()\n)\n#&gt; Error in `case_when()`:\n#&gt; ! Can't combine `..1 (right)` &lt;logical&gt; and `..2 (right)` &lt;datetime&lt;local&gt;&gt;.\n\n전반적으로 한 유형의 벡터를 다른 유형으로 자동 변환하는 것은 오류의 일반적인 원인이기 때문에 호환되는 유형은 상대적으로 적습니다. 다음은 호환되는 가장 중요한 사례입니다:\n\n\nSection 12.4.2 에서 논의했듯이 숫자형 벡터와 논리형 벡터는 호환됩니다.\n문자열과 팩터(Chapter 16)는 호환됩니다. 팩터를 제한된 값 집합을 가진 문자열로 생각할 수 있기 때문입니다.\n\nChapter 17 에서 논의할 날짜와 날짜-시간은 호환됩니다. 날짜를 날짜-시간의 특수한 경우로 생각할 수 있기 때문입니다.\n기술적으로 논리형 벡터인 NA는 모든 것과 호환됩니다. 모든 벡터에는 결측값을 나타내는 방법이 있기 때문입니다.\n\n이러한 규칙을 암기할 필요는 없지만 tidyverse 전체에 일관되게 적용되므로 시간이 지남에 따라 제2의 천성이 될 것입니다.\n\n12.5.4 연습문제\n\n숫자는 2로 나누어 떨어지면 짝수이며, R에서는 x %% 2 == 0으로 알 수 있습니다. 이 사실과 if_else()를 사용하여 0에서 20 사이의 각 숫자가 짝수인지 홀수인지 확인하세요.\nx &lt;- c(\"Monday\", \"Saturday\", \"Wednesday\")와 같은 요일 벡터가 주어지면 if_else() 문을 사용하여 주말이나 평일로 레이블을 지정하세요.\nif_else()를 사용하여 x라는 숫자 벡터의 절대값을 계산하세요.\nflights의 month 및 day 열을 사용하여 중요한 미국 공휴일(예: 새해 첫날, 7월 4일, 추수감사절, 크리스마스)에 레이블을 지정하는 case_when() 문을 작성하세요. 먼저 TRUE 또는 FALSE인 논리형 열을 만든 다음 공휴일 이름을 제공하거나 NA인 문자 열을 만드세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "logicals.html#요약",
    "href": "logicals.html#요약",
    "title": "12  논리형 벡터",
    "section": "\n12.6 요약",
    "text": "12.6 요약\n논리형 벡터의 정의는 각 값이 TRUE, FALSE 또는 NA여야 하므로 간단합니다. 그러나 논리형 벡터는 엄청난 힘을 제공합니다. 이 장에서는 &gt;, &lt;, &lt;=, &gt;=, ==, !=, is.na()로 논리형 벡터를 만드는 방법, !, &, |로 결합하는 방법, any(), all(), sum(), mean()으로 요약하는 방법을 배웠습니다. 또한 논리형 벡터의 값에 따라 값을 반환할 수 있는 강력한 if_else() 및 case_when() 함수를 배웠습니다.\n다음 장들에서 논리형 벡터를 계속해서 보게 될 것입니다. 예를 들어 Chapter 14 에서는 pattern과 일치하는 x 요소에 대해 TRUE인 논리형 벡터를 반환하는 str_detect(x, pattern)에 대해 배우고, Chapter 17 에서는 날짜와 시간의 비교에서 논리형 벡터를 생성할 것입니다. 하지만 지금은 다음으로 가장 중요한 유형의 벡터인 수치형 벡터로 넘어가겠습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "logicals.html#footnotes",
    "href": "logicals.html#footnotes",
    "title": "12  논리형 벡터",
    "section": "",
    "text": "R은 일반적으로 사용자를 위해 print를 호출하지만(x는 print(x)의 단축키임), 다른 인수를 제공하려는 경우 명시적으로 호출하는 것이 유용합니다.↩︎\n즉, xor(x, y)는 x가 참이거나 y가 참이지만 둘 다 참은 아닌 경우 참입니다. 이것이 우리가 일반적으로 영어에서 “or”를 사용하는 방식입니다. “아이스크림이나 케이크 드실래요?”라는 질문에 “둘 다”는 일반적으로 허용되는 대답이 아닙니다.↩︎\nChapter 19 에서 다룰 것입니다.↩︎\ndplyr의 if_else()는 기본 R의 ifelse()와 매우 유사합니다. ifelse()보다 if_else()의 두 가지 주요 장점이 있습니다: 결측값에 대해 어떤 일이 발생해야 하는지 선택할 수 있고, 변수 유형이 호환되지 않는 경우 if_else()가 의미 있는 오류를 제공할 가능성이 훨씬 더 높습니다.↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>논리형 벡터</span>"
    ]
  },
  {
    "objectID": "numbers.html",
    "href": "numbers.html",
    "title": "13  숫자",
    "section": "",
    "text": "13.1 소개\n수치형 벡터는 데이터 과학의 중추이며, 책의 앞부분에서 이미 여러 번 사용했습니다. 이제 R에서 수치형 벡터로 수행할 수 있는 작업을 체계적으로 조사하여 수치형 벡터와 관련된 향후 문제를 해결할 수 있는 준비를 확실히 할 때입니다.\n문자열이 있는 경우 숫자를 만드는 몇 가지 도구를 제공하고 count()에 대해 조금 더 자세히 설명하는 것으로 시작하겠습니다. 그런 다음 mutate()와 잘 어울리는 다양한 수치 변환을 살펴볼 것입니다. 여기에는 다른 유형의 벡터에도 적용할 수 있지만 수치형 벡터에 자주 사용되는 보다 일반적인 변환이 포함됩니다. 마지막으로 summarize()와 잘 어울리는 요약 함수를 다루고 mutate()와 함께 사용하는 방법도 보여줄 것입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#소개",
    "href": "numbers.html#소개",
    "title": "13  숫자",
    "section": "",
    "text": "13.1.1 선수 지식\n이 장에서는 대부분 기본(base) R의 함수를 사용하는데, 이는 패키지를 로드하지 않고도 사용할 수 있습니다. 하지만 mutate() 및 filter()와 같은 tidyverse 함수 내에서 이러한 기본 R 함수를 사용할 것이므로 여전히 tidyverse가 필요합니다. 지난 장과 마찬가지로 nycflights13의 실제 예제와 c() 및 tribble()로 만든 장난감 예제를 사용할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(nycflights13)",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#숫자-만들기",
    "href": "numbers.html#숫자-만들기",
    "title": "13  숫자",
    "section": "\n13.2 숫자 만들기",
    "text": "13.2 숫자 만들기\n대부분의 경우 R의 수치 유형인 정수(integer) 또는 배정밀도 실수(double) 중 하나로 이미 기록된 숫자를 얻게 됩니다. 그러나 어떤 경우에는 열 헤더에서 피벗하여 생성했거나 데이터 가져오기 프로세스에서 문제가 발생했기 때문에 문자열로 된 숫자를 만날 수도 있습니다.\nreadr은 문자열을 숫자로 파싱하기 위한 두 가지 유용한 함수인 parse_double()과 parse_number()를 제공합니다. 숫자가 문자열로 작성되었을 때 parse_double()을 사용하세요:\n\nx &lt;- c(\"1.2\", \"5.6\", \"1e3\")\nparse_double(x)\n#&gt; [1]    1.2    5.6 1000.0\n\n문자열에 무시하고 싶은 숫자가 아닌 텍스트가 포함되어 있는 경우 parse_number()를 사용하세요. 이것은 통화 데이터와 백분율에 특히 유용합니다:\n\nx &lt;- c(\"$1,234\", \"USD 3,513\", \"59%\")\nparse_number(x)\n#&gt; [1] 1234 3513   59",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#sec-counts",
    "href": "numbers.html#sec-counts",
    "title": "13  숫자",
    "section": "\n13.3 개수(Counts)",
    "text": "13.3 개수(Counts)\n개수와 약간의 기본 산술만으로 얼마나 많은 데이터 과학을 수행할 수 있는지 놀랍기 때문에 dplyr은 count()를 사용하여 가능한 한 쉽게 개수를 셀 수 있도록 노력합니다. 이 함수는 분석 중 빠른 탐색 및 확인에 좋습니다:\n\nflights |&gt; count(dest)\n#&gt; # A tibble: 105 × 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ABQ     254\n#&gt; 2 ACK     265\n#&gt; 3 ALB     439\n#&gt; 4 ANC       8\n#&gt; 5 ATL   17215\n#&gt; 6 AUS    2439\n#&gt; # ℹ 99 more rows\n\n(Chapter 4 의 조언에도 불구하고 계산이 예상대로 작동하는지 빠르게 확인하기 위해 콘솔에서 주로 사용되므로 count()는 보통 한 줄에 씁니다.)\n가장 흔한 값을 보려면 sort = TRUE를 추가하세요:\n\nflights |&gt; count(dest, sort = TRUE)\n#&gt; # A tibble: 105 × 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ORD   17283\n#&gt; 2 ATL   17215\n#&gt; 3 LAX   16174\n#&gt; 4 BOS   15508\n#&gt; 5 MCO   14082\n#&gt; 6 CLT   14064\n#&gt; # ℹ 99 more rows\n\n그리고 모든 값을 보려면 |&gt; View() 또는 |&gt; print(n = Inf)를 사용할 수 있다는 것을 기억하세요.\ngroup_by(), summarize(), n()을 사용하여 “수동으로” 동일한 계산을 수행할 수 있습니다. 이것은 동시에 다른 요약을 계산할 수 있기 때문에 유용합니다:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 105 × 3\n#&gt;   dest      n delay\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n#&gt; 1 ABQ     254  4.38\n#&gt; 2 ACK     265  4.85\n#&gt; 3 ALB     439 14.4 \n#&gt; 4 ANC       8 -2.5 \n#&gt; 5 ATL   17215 11.3 \n#&gt; 6 AUS    2439  6.02\n#&gt; # ℹ 99 more rows\n\nn()은 인수를 받지 않고 대신 “현재” 그룹에 대한 정보에 액세스하는 특수 요약 함수입니다. 즉, dplyr 동사 내부에서만 작동합니다:\n\nn()\n#&gt; Error in `n()`:\n#&gt; ! Must only be used inside data-masking verbs like `mutate()`,\n#&gt;   `filter()`, and `group_by()`.\n\n유용하게 사용할 수 있는 n()과 count()의 몇 가지 변형이 있습니다:\n\n\nn_distinct(x)는 하나 이상의 변수의 고유한(unique) 값의 수를 셉니다. 예를 들어 어떤 목적지가 가장 많은 항공사에 의해 운항되는지 파악할 수 있습니다:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(carriers = n_distinct(carrier)) |&gt; \n  arrange(desc(carriers))\n#&gt; # A tibble: 105 × 2\n#&gt;   dest  carriers\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 ATL          7\n#&gt; 2 BOS          7\n#&gt; 3 CLT          7\n#&gt; 4 ORD          7\n#&gt; 5 TPA          7\n#&gt; 6 AUS          6\n#&gt; # ℹ 99 more rows\n\n\n\n가중 개수는 합계입니다. 예를 들어 각 비행기가 비행한 마일 수를 “셀” 수 있습니다:\n\nflights |&gt; \n  group_by(tailnum) |&gt; \n  summarize(miles = sum(distance))\n#&gt; # A tibble: 4,044 × 2\n#&gt;   tailnum  miles\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 D942DN    3418\n#&gt; 2 N0EGMQ  250866\n#&gt; 3 N10156  115966\n#&gt; 4 N102UW   25722\n#&gt; 5 N103US   24619\n#&gt; 6 N104UW   25157\n#&gt; # ℹ 4,038 more rows\n\n가중 개수는 흔한 문제이므로 count()에는 동일한 작업을 수행하는 wt 인수가 있습니다:\n\nflights |&gt; count(tailnum, wt = distance)\n\n\n\nsum()과 is.na()를 결합하여 결측값을 셀 수 있습니다. flights 데이터셋에서 이것은 취소된 항공편을 나타냅니다:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(n_cancelled = sum(is.na(dep_time))) \n#&gt; # A tibble: 105 × 2\n#&gt;   dest  n_cancelled\n#&gt;   &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 ABQ             0\n#&gt; 2 ACK             0\n#&gt; 3 ALB            20\n#&gt; 4 ANC             0\n#&gt; 5 ATL           317\n#&gt; 6 AUS            21\n#&gt; # ℹ 99 more rows\n\n\n\n\n13.3.1 연습문제\n\n\ncount()를 사용하여 주어진 변수에 대해 결측값이 있는 행의 수를 어떻게 셀 수 있습니까?\n\ncount()에 대한 다음 호출을 확장하여 대신 group_by(), summarize(), arrange()를 사용하세요:\n\nflights |&gt; count(dest, sort = TRUE)\nflights |&gt; count(tailnum, wt = distance)",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#수치-변환",
    "href": "numbers.html#수치-변환",
    "title": "13  숫자",
    "section": "\n13.4 수치 변환",
    "text": "13.4 수치 변환\n변환 함수는 출력이 입력과 길이가 같기 때문에 mutate()와 잘 작동합니다. 대부분의 변환 함수는 이미 기본 R에 내장되어 있습니다. 모두 나열하는 것은 비현실적이므로 이 섹션에서는 가장 유용한 것들을 보여줄 것입니다. 예를 들어 R은 꿈꿔왔던 모든 삼각 함수를 제공하지만 데이터 과학에는 거의 필요하지 않으므로 여기에는 나열하지 않습니다.\n\n13.4.1 산술 및 재활용 규칙\nChapter 2 에서 산술(+, -, *, /, ^)의 기초를 소개했고 그 이후로 많이 사용했습니다. 이 함수들은 초등학교에서 배운 것을 수행하기 때문에 엄청난 설명이 필요하지 않습니다. 하지만 왼쪽과 오른쪽의 길이가 다를 때 어떤 일이 일어나는지 결정하는 재활용 규칙(recycling rules) 에 대해 잠시 이야기해야 합니다. 이것은 flights |&gt; mutate(air_time = air_time / 60)과 같은 작업에 중요합니다. / 왼쪽에는 336,776개의 숫자가 있지만 오른쪽에는 하나만 있기 때문입니다.\nR은 짧은 벡터를 재활용(recycling), 즉 반복하여 길이가 일치하지 않는 것을 처리합니다. 데이터 프레임 외부에서 몇 가지 벡터를 생성하면 이 작동 방식을 더 쉽게 볼 수 있습니다:\n\nx &lt;- c(1, 2, 10, 20)\nx / 5\n#&gt; [1] 0.2 0.4 2.0 4.0\n# 다음의 단축 표현입니다\nx / c(5, 5, 5, 5)\n#&gt; [1] 0.2 0.4 2.0 4.0\n\n일반적으로 단일 숫자(즉, 길이 1의 벡터)만 재활용하고 싶지만 R은 더 짧은 길이의 벡터를 재활용합니다. 보통(항상은 아니지만) 긴 벡터가 짧은 벡터의 배수가 아닌 경우 경고를 제공합니다:\n\nx * c(1, 2)\n#&gt; [1]  1  4 10 40\nx * c(1, 2, 3)\n#&gt; Warning in x * c(1, 2, 3): longer object length is not a multiple of shorter\n#&gt; object length\n#&gt; [1]  1  4 30 20\n\n이러한 재활용 규칙은 논리 비교(==, &lt;, &lt;=, &gt;, &gt;=, !=)에도 적용되며, 실수로 %in% 대신 ==를 사용하고 데이터 프레임의 행 수가 불행한 경우 놀라운 결과로 이어질 수 있습니다. 예를 들어 1월과 2월의 모든 항공편을 찾으려는 이 코드를 살펴보세요:\n\nflights |&gt; \n  filter(month == c(1, 2))\n#&gt; # A tibble: 25,977 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      542            540         2      923            850\n#&gt; 3  2013     1     1      554            600        -6      812            837\n#&gt; 4  2013     1     1      555            600        -5      913            854\n#&gt; 5  2013     1     1      557            600        -3      838            846\n#&gt; 6  2013     1     1      558            600        -2      849            851\n#&gt; # ℹ 25,971 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n코드는 오류 없이 실행되지만 원하는 것을 반환하지 않습니다. 재활용 규칙 때문에 홀수 행에서 1월에 출발한 항공편과 짝수 행에서 2월에 출발한 항공편을 찾습니다. 그리고 불행히도 flights의 행 수가 짝수이므로 경고가 없습니다.\n이러한 유형의 침묵의 실패로부터 보호하기 위해 대부분의 tidyverse 함수는 단일 값만 재활용하는 더 엄격한 형태의 재활용을 사용합니다. 불행히도 핵심 계산이 filter()가 아니라 기본 R 함수 ==에 의해 수행되므로 여기에서는 도움이 되지 않습니다.\n\n13.4.2 최소 및 최대\n산술 함수는 한 쌍의 변수와 함께 작동합니다. 밀접하게 관련된 두 함수는 pmin()과 pmax()이며, 두 개 이상의 변수가 주어지면 각 행에서 가장 작은 값이나 가장 큰 값을 반환합니다:\n\ndf &lt;- tribble(\n  ~x, ~y,\n  1,  3,\n  5,  2,\n  7, NA,\n)\n\ndf |&gt; \n  mutate(\n    min = pmin(x, y, na.rm = TRUE),\n    max = pmax(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     3\n#&gt; 2     5     2     2     5\n#&gt; 3     7    NA     7     7\n\n이것들은 여러 관측값을 받아 단일 값을 반환하는 요약 함수 min() 및 max()와는 다릅니다. 모든 최소값과 모든 최대값이 동일한 값을 가질 때 잘못된 형식을 사용했음을 알 수 있습니다:\n\ndf |&gt; \n  mutate(\n    min = min(x, y, na.rm = TRUE),\n    max = max(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     7\n#&gt; 2     5     2     1     7\n#&gt; 3     7    NA     1     7\n\n\n13.4.3 모듈러 연산\n모듈러 연산은 소수점에 대해 배우기 전에 수행했던 수학 유형, 즉 정수와 나머지를 산출하는 나눗셈의 기술 이름입니다. R에서 %/%는 정수 나눗셈을 수행하고 %%는 나머지를 계산합니다:\n\n1:10 %/% 3\n#&gt;  [1] 0 0 1 1 1 2 2 2 3 3\n1:10 %% 3\n#&gt;  [1] 1 2 0 1 2 0 1 2 0 1\n\n모듈러 연산은 flights 데이터셋에 편리합니다. sched_dep_time 변수를 hour와 minute로 푸는 데 사용할 수 있기 때문입니다:\n\nflights |&gt; \n  mutate(\n    hour = sched_dep_time %/% 100,\n    minute = sched_dep_time %% 100,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;   sched_dep_time  hour minute\n#&gt;            &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1            515     5     15\n#&gt; 2            529     5     29\n#&gt; 3            540     5     40\n#&gt; 4            545     5     45\n#&gt; 5            600     6      0\n#&gt; 6            558     5     58\n#&gt; # ℹ 336,770 more rows\n\n이것을 Section 12.4 의 mean(is.na(x)) 트릭과 결합하여 취소된 항공편의 비율이 하루 동안 어떻게 변하는지 확인할 수 있습니다. 결과는 Figure 13.1 에 나와 있습니다.\n\nflights |&gt; \n  group_by(hour = sched_dep_time %/% 100) |&gt; \n  summarize(prop_cancelled = mean(is.na(dep_time)), n = n()) |&gt; \n  filter(hour &gt; 1) |&gt; \n  ggplot(aes(x = hour, y = prop_cancelled)) +\n  geom_line(color = \"grey50\") + \n  geom_point(aes(size = n))\n\n\n\n\n\n\nFigure 13.1: x축에 예정된 출발 시간, y축에 취소된 항공편의 비율이 있는 선 플롯. 취소는 오후 8시까지 하루 종일 누적되는 것 같으며, 매우 늦은 항공편은 취소될 가능성이 훨씬 적습니다.\n\n\n\n\n\n13.4.4 로그\n로그는 여러 자릿수(orders of magnitude)에 걸친 데이터를 처리하고 지수 성장을 선형 성장으로 변환하는 데 매우 유용한 변환입니다. R에서는 세 가지 로그를 선택할 수 있습니다: log()(자연 로그, 밑 e), log2()(밑 2), log10()(밑 10). log2() 또는 log10()을 사용하는 것이 좋습니다. log2()는 로그 척도에서 1의 차이가 원래 척도에서 두 배에 해당하고 -1의 차이가 절반에 해당하기 때문에 해석하기 쉽습니다. 반면 log10()은 역변환하기 쉽습니다(예: 3은 10^3 = 1000). log()의 역함수는 exp()입니다. log2() 또는 log10()의 역함수를 계산하려면 2^ 또는 10^를 사용해야 합니다.\n\n13.4.5 반올림\n숫자를 가장 가까운 정수로 반올림하려면 round(x)를 사용하세요:\n\nround(123.456)\n#&gt; [1] 123\n\n두 번째 인수 digits로 반올림의 정밀도를 제어할 수 있습니다. round(x, digits)는 가장 가까운 10^-n으로 반올림하므로 digits = 2는 가장 가까운 0.01로 반올림합니다. 이 정의는 round(x, -3)이 가장 가까운 천 단위로 반올림한다는 것을 의미하므로 유용합니다:\n\nround(123.456, 2)  # 두 자리\n#&gt; [1] 123.46\nround(123.456, 1)  # 한 자리\n#&gt; [1] 123.5\nround(123.456, -1) # 가장 가까운 십 단위로 반올림\n#&gt; [1] 120\nround(123.456, -2) # 가장 가까운 백 단위로 반올림\n#&gt; [1] 100\n\nround()에는 언뜻 보기에 놀라운 이상한 점이 하나 있습니다:\n\nround(c(1.5, 2.5))\n#&gt; [1] 2 2\n\nround()는 “반을 짝수로 반올림(round half to even)” 또는 은행가 반올림(Banker’s rounding)이라고 알려진 방법을 사용합니다: 숫자가 두 정수 사이의 중간에 있으면 짝수 정수로 반올림됩니다. 이것은 반올림을 편향되지 않게 유지하기 때문에 좋은 전략입니다. 0.5의 절반은 올림되고 절반은 내림됩니다.\nround()는 항상 내림하는 floor()와 항상 올림하는 ceiling()과 짝을 이룹니다:\n\nx &lt;- 123.456\n\nfloor(x)\n#&gt; [1] 123\nceiling(x)\n#&gt; [1] 124\n\n이 함수들에는 digits 인수가 없으므로 대신 축소하고 반올림한 다음 다시 확대할 수 있습니다:\n\n# 가장 가까운 두 자리로 내림\nfloor(x / 0.01) * 0.01\n#&gt; [1] 123.45\n# 가장 가까운 두 자리로 올림\nceiling(x / 0.01) * 0.01\n#&gt; [1] 123.46\n\nround()를 다른 숫자의 배수로 반올림하려는 경우 동일한 기술을 사용할 수 있습니다:\n\n# 가장 가까운 4의 배수로 반올림\nround(x / 4) * 4\n#&gt; [1] 124\n\n# 가장 가까운 0.25로 반올림\nround(x / 0.25) * 0.25\n#&gt; [1] 123.5\n\n\n13.4.6 숫자를 범위로 자르기\n수치형 벡터를 이산 버킷으로 나누려면(일명 비닝) cut()1을 사용하세요:\n\nx &lt;- c(1, 2, 5, 10, 15, 20)\ncut(x, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] (0,5]   (0,5]   (0,5]   (5,10]  (10,15] (15,20]\n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\n나누기(breaks)는 균등하게 간격을 둘 필요가 없습니다:\n\ncut(x, breaks = c(0, 5, 10, 100))\n#&gt; [1] (0,5]    (0,5]    (0,5]    (5,10]   (10,100] (10,100]\n#&gt; Levels: (0,5] (5,10] (10,100]\n\n선택적으로 자신만의 labels를 제공할 수 있습니다. labels는 breaks보다 하나 적어야 한다는 점에 유의하세요.\n\ncut(x, \n  breaks = c(0, 5, 10, 15, 20), \n  labels = c(\"sm\", \"md\", \"lg\", \"xl\")\n)\n#&gt; [1] sm sm sm md lg xl\n#&gt; Levels: sm md lg xl\n\n나누기 범위 밖의 값은 NA가 됩니다:\n\ny &lt;- c(NA, -10, 5, 10, 30)\ncut(y, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] &lt;NA&gt;   &lt;NA&gt;   (0,5]  (5,10] &lt;NA&gt;  \n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\n구간이 [a, b)인지 (a, b]인지, 가장 낮은 구간이 [a, b]여야 하는지 제어하는 right 및 include.lowest와 같은 다른 유용한 인수에 대해서는 설명서를 참조하세요.\n\n13.4.7 누적 및 롤링 집계\n기본 R은 누적 합, 곱, 최소 및 최대를 위해 cumsum(), cumprod(), cummin(), cummax()를 제공합니다. dplyr은 누적 평균을 위한 cummean()을 제공합니다. 누적 합이 실제로 가장 많이 나오는 경향이 있습니다:\n\nx &lt;- 1:10\ncumsum(x)\n#&gt;  [1]  1  3  6 10 15 21 28 36 45 55\n\n더 복잡한 롤링 또는 슬라이딩 집계가 필요한 경우 slider 패키지를 사용해 보세요.\n\n13.4.8 연습문제\n\nFigure 13.1 를 생성하는 데 사용된 코드의 각 줄이 무엇을 하는지 말로 설명하세요.\nR은 어떤 삼각 함수를 제공합니까? 이름을 추측하고 설명서를 찾아보세요. 도(degrees)를 사용합니까, 아니면 라디안(radians)을 사용합니까?\n\n현재 dep_time과 sched_dep_time은 보기에 편리하지만 실제로는 연속적인 숫자가 아니기 때문에 계산하기 어렵습니다. 아래 코드를 실행하여 기본적인 문제를 볼 수 있습니다. 각 시간 사이에 간격이 있습니다.\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  ggplot(aes(x = sched_dep_time, y = dep_delay)) +\n  geom_point()\n\n더 진실한 시간 표현(소수 시간 또는 자정 이후 분)으로 변환하세요.\n\ndep_time과 arr_time을 가장 가까운 5분 단위로 반올림하세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#일반적인-변환",
    "href": "numbers.html#일반적인-변환",
    "title": "13  숫자",
    "section": "\n13.5 일반적인 변환",
    "text": "13.5 일반적인 변환\n다음 섹션에서는 수치형 벡터에 자주 사용되지만 다른 모든 열 유형에도 적용할 수 있는 몇 가지 일반적인 변환을 설명합니다.\n\n13.5.1 순위(Ranks)\ndplyr은 SQL에서 영감을 얻은 여러 순위 함수를 제공하지만 항상 dplyr::min_rank()로 시작해야 합니다. 동점을 처리하는 일반적인 방법(예: 1등, 2등, 2등, 4등)을 사용합니다.\n\nx &lt;- c(1, 5, 5, 17, 22, NA)\nmin_rank(x)\n#&gt; [1]  1  2  2  4  5 NA\n\n가장 작은 값이 가장 낮은 순위를 얻습니다. 가장 큰 값에 가장 작은 순위를 부여하려면 desc(x)를 사용하세요:\n\nmin_rank(desc(x))\n#&gt; [1]  5  3  3  2  1 NA\n\nmin_rank()가 필요한 작업을 수행하지 않으면 변형인 dplyr::row_number(), dplyr::dense_rank(), dplyr::percent_rank(), dplyr::cume_dist()를 살펴보세요. 자세한 내용은 설명서를 참조하세요.\n\ndf &lt;- tibble(x = x)\ndf |&gt; \n  mutate(\n    row_number = row_number(x),\n    dense_rank = dense_rank(x),\n    percent_rank = percent_rank(x),\n    cume_dist = cume_dist(x)\n  )\n#&gt; # A tibble: 6 × 5\n#&gt;       x row_number dense_rank percent_rank cume_dist\n#&gt;   &lt;dbl&gt;      &lt;int&gt;      &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1          1          1         0          0.2\n#&gt; 2     5          2          2         0.25       0.6\n#&gt; 3     5          3          2         0.25       0.6\n#&gt; 4    17          4          3         0.75       0.8\n#&gt; 5    22          5          4         1          1  \n#&gt; 6    NA         NA         NA        NA         NA\n\n기본 R의 rank()에 적절한 ties.method 인수를 선택하여 동일한 결과를 많이 얻을 수 있습니다. 아마도 NA를 NA로 유지하려면 na.last = \"keep\"을 설정하고 싶을 것입니다.\nrow_number()는 dplyr 동사 내부에서 인수 없이 사용할 수도 있습니다. 이 경우 “현재” 행의 번호를 제공합니다. %% 또는 %/%와 결합하면 데이터를 비슷한 크기의 그룹으로 나누는 유용한 도구가 될 수 있습니다:\n\ndf &lt;- tibble(id = 1:10)\n\ndf |&gt; \n  mutate(\n    row0 = row_number() - 1,\n    three_groups = row0 %% 3,\n    three_in_each_group = row0 %/% 3\n  )\n#&gt; # A tibble: 10 × 4\n#&gt;      id  row0 three_groups three_in_each_group\n#&gt;   &lt;int&gt; &lt;dbl&gt;        &lt;dbl&gt;               &lt;dbl&gt;\n#&gt; 1     1     0            0                   0\n#&gt; 2     2     1            1                   0\n#&gt; 3     3     2            2                   0\n#&gt; 4     4     3            0                   1\n#&gt; 5     5     4            1                   1\n#&gt; 6     6     5            2                   1\n#&gt; # ℹ 4 more rows\n\n\n13.5.2 오프셋(Offsets)\ndplyr::lead()와 dplyr::lag()를 사용하면 “현재” 값 바로 앞이나 뒤의 값을 참조할 수 있습니다. 입력과 길이가 같은 벡터를 반환하며 시작이나 끝에 NA가 채워집니다:\n\nx &lt;- c(2, 5, 11, 11, 19, 35)\nlag(x)\n#&gt; [1] NA  2  5 11 11 19\nlead(x)\n#&gt; [1]  5 11 11 19 35 NA\n\n\n\nx - lag(x)는 현재 값과 이전 값의 차이를 제공합니다.\n\nx - lag(x)\n#&gt; [1] NA  3  6  0  8 16\n\n\n\nx == lag(x)는 현재 값이 언제 변경되는지 알려줍니다.\n\nx == lag(x)\n#&gt; [1]    NA FALSE FALSE  TRUE FALSE FALSE\n\n\n\n두 번째 인수 n을 사용하여 한 위치 이상 리드하거나 래그할 수 있습니다.\n\n13.5.3 연속 식별자\n때로는 이벤트가 발생할 때마다 새 그룹을 시작하고 싶을 때가 있습니다. 예를 들어 웹사이트 데이터를 볼 때 이벤트를 세션으로 나누고 싶은데, 마지막 활동 이후 x분 이상의 간격이 있은 후 새 세션을 시작하는 것이 일반적입니다. 예를 들어 누군가가 웹사이트를 방문한 시간이 있다고 상상해 보세요:\n\nevents &lt;- tibble(\n  time = c(0, 1, 2, 3, 5, 10, 12, 15, 17, 19, 20, 27, 28, 30)\n)\n\n그리고 각 이벤트 사이의 시간을 계산하고 자격을 갖출 만큼 충분히 큰 간격이 있는지 파악했습니다:\n\nevents &lt;- events |&gt; \n  mutate(\n    diff = time - lag(time, default = first(time)),\n    has_gap = diff &gt;= 5\n  )\nevents\n#&gt; # A tibble: 14 × 3\n#&gt;    time  diff has_gap\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  \n#&gt; 1     0     0 FALSE  \n#&gt; 2     1     1 FALSE  \n#&gt; 3     2     1 FALSE  \n#&gt; 4     3     1 FALSE  \n#&gt; 5     5     2 FALSE  \n#&gt; 6    10     5 TRUE   \n#&gt; # ℹ 8 more rows\n\n하지만 그 논리형 벡터에서 어떻게 group_by()할 수 있는 것으로 갈 수 있을까요? Section 13.4.7 의 cumsum()이 구해주러 옵니다. 갭, 즉 has_gap이 TRUE이면 group이 1씩 증가하기 때문입니다(Section 12.4.2):\n\nevents |&gt; mutate(\n  group = cumsum(has_gap)\n)\n#&gt; # A tibble: 14 × 4\n#&gt;    time  diff has_gap group\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;   &lt;int&gt;\n#&gt; 1     0     0 FALSE       0\n#&gt; 2     1     1 FALSE       0\n#&gt; 3     2     1 FALSE       0\n#&gt; 4     3     1 FALSE       0\n#&gt; 5     5     2 FALSE       0\n#&gt; 6    10     5 TRUE        1\n#&gt; # ℹ 8 more rows\n\n그룹화 변수를 만드는 또 다른 접근 방식은 consecutive_id()로, 인수 중 하나가 변경될 때마다 새 그룹을 시작합니다. 예를 들어 이 stackoverflow 질문에서 영감을 받아 반복되는 값이 많은 데이터 프레임이 있다고 상상해 보세요:\n\ndf &lt;- tibble(\n  x = c(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"d\", \"e\", \"a\", \"a\", \"b\", \"b\"),\n  y = c(1, 2, 3, 2, 4, 1, 3, 9, 4, 8, 10, 199)\n)\n\n반복되는 각 x의 첫 번째 행을 유지하려면 group_by(), consecutive_id(), slice_head()를 사용할 수 있습니다:\n\ndf |&gt; \n  group_by(id = consecutive_id(x)) |&gt; \n  slice_head(n = 1)\n#&gt; # A tibble: 7 × 3\n#&gt; # Groups:   id [7]\n#&gt;   x         y    id\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 a         1     1\n#&gt; 2 b         2     2\n#&gt; 3 c         4     3\n#&gt; 4 d         3     4\n#&gt; 5 e         9     5\n#&gt; 6 a         4     6\n#&gt; # ℹ 1 more row\n\n\n13.5.4 연습문제\n\n순위 함수를 사용하여 가장 많이 지연된 10개의 항공편을 찾으세요. 동점은 어떻게 처리하고 싶습니까? min_rank()에 대한 설명을 주의 깊게 읽으세요.\n어떤 비행기(tailnum)가 정시 기록이 가장 나쁩니까?\n지연을 최대한 피하고 싶다면 하루 중 언제 비행해야 합니까?\nflights |&gt; group_by(dest) |&gt; filter(row_number() &lt; 4)는 무엇을 합니까? flights |&gt; group_by(dest) |&gt; filter(row_number(dep_delay) &lt; 4)는 무엇을 합니까?\n각 목적지에 대해 총 지연 분을 계산하세요. 각 항공편에 대해 목적지에 대한 총 지연의 비율을 계산하세요.\n\n지연은 일반적으로 시간적으로 상관관계가 있습니다: 초기 지연을 유발한 문제가 해결된 후에도 이전 항공편이 떠날 수 있도록 나중 항공편이 지연됩니다. lag()를 사용하여 한 시간 동안의 평균 항공편 지연이 이전 시간의 평균 지연과 어떻게 관련되어 있는지 탐색하세요.\n\nflights |&gt; \n  mutate(hour = dep_time %/% 100) |&gt; \n  group_by(year, month, day, hour) |&gt; \n  summarize(\n    dep_delay = mean(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(n &gt; 5)\n\n\n각 목적지를 살펴보세요. 의심스럽게 빠른 항공편(즉, 잠재적인 데이터 입력 오류를 나타내는 항공편)을 찾을 수 있습니까? 해당 목적지로 가는 가장 짧은 항공편에 대한 항공편의 비행 시간을 계산하세요. 공중에서 가장 많이 지연된 항공편은 무엇입니까?\n적어도 두 항공사가 운항하는 모든 목적지를 찾으세요. 그 목적지들을 사용하여 동일한 목적지에 대한 성과를 기반으로 항공사의 상대적 순위를 매기세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#숫자-요약",
    "href": "numbers.html#숫자-요약",
    "title": "13  숫자",
    "section": "\n13.6 숫자 요약",
    "text": "13.6 숫자 요약\n이미 소개한 개수, 평균, 합계만 사용해도 많은 것을 얻을 수 있지만 R은 다른 많은 유용한 요약 함수를 제공합니다. 유용할 만한 선택 항목은 다음과 같습니다.\n\n13.6.1 중심\n지금까지 우리는 주로 값 벡터의 중심을 요약하기 위해 mean()을 사용했습니다. Section 3.6 에서 보았듯이 평균은 합계를 개수로 나눈 것이기 때문에 소수의 비정상적으로 높거나 낮은 값에도 민감합니다. 대안은 median()을 사용하는 것입니다. 이는 벡터의 “중간”에 있는 값, 즉 값의 50%는 그 위에 있고 50%는 그 아래에 있는 값을 찾습니다. 관심 있는 변수의 분포 모양에 따라 평균 또는 중앙값이 중심의 더 나은 척도가 될 수 있습니다. 예를 들어 대칭 분포의 경우 일반적으로 평균을 보고하는 반면 치우친 분포의 경우 일반적으로 중앙값을 보고합니다.\nFigure 13.2 은 각 목적지에 대한 평균 대 중앙값 출발 지연(분)을 비교합니다. 중앙값 지연은 항상 평균 지연보다 작습니다. 항공편은 때때로 몇 시간 늦게 출발하지만 몇 시간 일찍 출발하는 경우는 없기 때문입니다.\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    mean = mean(dep_delay, na.rm = TRUE),\n    median = median(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  ggplot(aes(x = mean, y = median)) + \n  geom_abline(slope = 1, intercept = 0, color = \"white\", linewidth = 2) +\n  geom_point()\n\n\n\n\n\n\nFigure 13.2: 일일 출발 지연을 평균 대신 중앙값으로 요약할 때의 차이를 보여주는 산점도.\n\n\n\n\n최빈값(mode), 즉 가장 흔한 값에 대해서도 궁금할 수 있습니다. 이것은 매우 간단한 경우에만 잘 작동하는 요약(그래서 고등학교에서 배웠을 수도 있음)이지만 많은 실제 데이터셋에서는 잘 작동하지 않습니다. 데이터가 이산형인 경우 가장 흔한 값이 여러 개 있을 수 있고, 데이터가 연속형인 경우 모든 값이 아주 조금씩 다르기 때문에 가장 흔한 값이 없을 수 있습니다. 이러한 이유로 통계학자들은 최빈값을 잘 사용하지 않는 경향이 있으며 기본 R에는 포함된 최빈값 함수가 없습니다2.\n\n13.6.2 최소, 최대 및 분위수\n중심 이외의 위치에 관심이 있다면 어떻게 해야 할까요? min()과 max()는 가장 큰 값과 가장 작은 값을 제공합니다. 또 다른 강력한 도구는 중앙값의 일반화인 quantile()입니다. quantile(x, 0.25)는 값의 25%보다 큰 x 값을 찾고, quantile(x, 0.5)는 중앙값과 동일하며, quantile(x, 0.95)는 값의 95%보다 큰 값을 찾습니다.\nflights 데이터의 경우 가장 많이 지연된 항공편의 5%는 매우 극단적일 수 있으므로 최대값보다는 지연의 95% 분위수를 보고 싶을 수 있습니다.\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    max = max(dep_delay, na.rm = TRUE),\n    q95 = quantile(dep_delay, 0.95, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day   max   q95\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2013     1     1   853  70.1\n#&gt; 2  2013     1     2   379  85  \n#&gt; 3  2013     1     3   291  68  \n#&gt; 4  2013     1     4   288  60  \n#&gt; 5  2013     1     5   327  41  \n#&gt; 6  2013     1     6   202  51  \n#&gt; # ℹ 359 more rows\n\n\n13.6.3 산포(Spread)\n때로는 데이터의 대부분이 어디에 있는지보다는 어떻게 퍼져 있는지에 관심이 있을 수 있습니다. 일반적으로 사용되는 두 가지 요약은 표준 편차 sd(x)와 사분위수 범위 IQR()입니다. sd()는 아마 이미 익숙할 것이므로 여기서 설명하지 않겠지만 IQR()은 생소할 수 있습니다. 이것은 quantile(x, 0.75) - quantile(x, 0.25)이며 데이터의 중간 50%를 포함하는 범위를 제공합니다.\n이것을 사용하여 flights 데이터의 작은 이상함을 드러낼 수 있습니다. 공항은 항상 같은 장소에 있기 때문에 출발지와 목적지 사이의 거리 산포가 0일 것이라고 예상할 수 있습니다. 그러나 아래 코드는 EGE 공항에 대한 데이터 이상함을 보여줍니다:\n\nflights |&gt; \n  group_by(origin, dest) |&gt; \n  summarize(\n    distance_iqr = IQR(distance), \n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(distance_iqr &gt; 0)\n#&gt; # A tibble: 2 × 4\n#&gt;   origin dest  distance_iqr     n\n#&gt;   &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 EWR    EGE              1   110\n#&gt; 2 JFK    EGE              1   103\n\n\n13.6.4 분포\n위에서 설명한 모든 요약 통계는 분포를 단일 숫자로 줄이는 방법이라는 점을 기억할 가치가 있습니다. 이는 근본적으로 축소적이며 잘못된 요약을 선택하면 그룹 간의 중요한 차이를 쉽게 놓칠 수 있음을 의미합니다. 그렇기 때문에 요약 통계를 확정하기 전에 항상 분포를 시각화하는 것이 좋습니다.\nFigure 13.3 는 출발 지연의 전체 분포를 보여줍니다. 분포가 너무 치우쳐 있어서 데이터의 대부분을 보려면 확대해야 합니다. 이는 평균이 좋은 요약이 아닐 수 있으며 대신 중앙값을 선호할 수 있음을 시사합니다.\n\n\n\n\n\n\n\nFigure 13.3: (왼쪽) 전체 데이터의 히스토그램은 매우 치우쳐 있어 세부 정보를 얻기 어렵습니다. (오른쪽) 2시간 미만의 지연으로 확대하면 대부분의 관측값에서 무슨 일이 일어나고 있는지 볼 수 있습니다.\n\n\n\n\n하위 그룹의 분포가 전체와 유사한지 확인하는 것도 좋습니다. 다음 플롯에서는 dep_delay의 365개 빈도 다각형(매일 하나씩)이 겹쳐져 있습니다. 분포는 일반적인 패턴을 따르는 것으로 보이며 매일 동일한 요약을 사용해도 괜찮음을 시사합니다.\n\nflights |&gt;\n  filter(dep_delay &lt; 120) |&gt; \n  ggplot(aes(x = dep_delay, group = interaction(day, month))) + \n  geom_freqpoly(binwidth = 5, alpha = 1/5)\n\n\n\n\n\n\n\n작업 중인 데이터에 특별히 맞춤화된 사용자 정의 요약을 탐색하는 것을 두려워하지 마세요. 이 경우 일찍 출발한 항공편과 늦게 출발한 항공편을 별도로 요약하거나 값이 너무 심하게 치우쳐 있으므로 로그 변환을 시도해 볼 수 있습니다. 마지막으로 Section 3.6 에서 배운 내용을 잊지 마세요: 수치 요약을 생성할 때마다 각 그룹의 관측값 수를 포함하는 것이 좋습니다.\n\n13.6.5 위치\n수치형 벡터에 유용하지만 다른 모든 유형의 값과도 작동하는 요약 유형이 하나 더 있습니다. 특정 위치의 값을 추출하는 것입니다: first(x), last(x), nth(x, n).\n예를 들어 매일 첫 번째, 다섯 번째, 마지막 출발을 찾을 수 있습니다:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    first_dep = first(dep_time, na_rm = TRUE), \n    fifth_dep = nth(dep_time, 5, na_rm = TRUE),\n    last_dep = last(dep_time, na_rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n#&gt; # A tibble: 365 × 6\n#&gt; # Groups:   year, month [12]\n#&gt;    year month   day first_dep fifth_dep last_dep\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt;     &lt;int&gt;    &lt;int&gt;\n#&gt; 1  2013     1     1       517       554     2356\n#&gt; 2  2013     1     2        42       535     2354\n#&gt; 3  2013     1     3        32       520     2349\n#&gt; 4  2013     1     4        25       531     2358\n#&gt; 5  2013     1     5        14       534     2357\n#&gt; 6  2013     1     6        16       555     2355\n#&gt; # ℹ 359 more rows\n\n(참고: dplyr 함수는 _를 사용하여 함수 및 인수 이름의 구성 요소를 구분하므로 이러한 함수는 na.rm 대신 na_rm을 사용합니다.)\nSection 27.2 에서 다시 다룰 [에 익숙하다면 이러한 함수가 필요한지 궁금할 수 있습니다. 세 가지 이유가 있습니다: default 인수를 사용하면 지정된 위치가 존재하지 않는 경우 기본값을 제공할 수 있고, order_by 인수를 사용하면 행의 순서를 로컬에서 재정의할 수 있으며, na_rm 인수를 사용하면 결측값을 삭제할 수 있습니다.\n위치에서 값을 추출하는 것은 순위에 대한 필터링을 보완합니다. 필터링은 각 관측값이 별도의 행에 있는 모든 변수를 제공합니다:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  mutate(r = min_rank(sched_dep_time)) |&gt; \n  filter(r %in% c(1, max(r)))\n#&gt; # A tibble: 1,195 × 20\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1     2353           2359        -6      425            445\n#&gt; 3  2013     1     1     2353           2359        -6      418            442\n#&gt; 4  2013     1     1     2356           2359        -3      425            437\n#&gt; 5  2013     1     2       42           2359        43      518            442\n#&gt; 6  2013     1     2      458            500        -2      703            650\n#&gt; # ℹ 1,189 more rows\n#&gt; # ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n\n13.6.6 mutate()와 함께\n이름에서 알 수 있듯이 요약 함수는 일반적으로 summarize()와 짝을 이룹니다. 그러나 Section 13.4.1 에서 논의한 재활용 규칙 때문에 mutate()와 유용하게 짝을 이룰 수도 있으며, 특히 어떤 종류의 그룹 표준화를 수행하려는 경우에 그렇습니다. 예를 들어:\n\n\nx / sum(x)는 전체에 대한 비율을 계산합니다.\n\n(x - mean(x)) / sd(x)는 Z-점수(평균 0 및 표준 편차 1로 표준화)를 계산합니다.\n\n(x - min(x)) / (max(x) - min(x))는 범위 [0, 1]로 표준화합니다.\n\nx / first(x)는 첫 번째 관측값을 기반으로 지수를 계산합니다.\n\n13.6.7 연습문제\n\n항공편 그룹의 전형적인 지연 특성을 평가하는 적어도 5가지 다른 방법을 브레인스토밍하세요. mean()은 언제 유용합니까? median()은 언제 유용합니까? 다른 것을 사용하고 싶을 때는 언제입니까? 도착 지연을 사용해야 할까요, 출발 지연을 사용해야 할까요? planes의 데이터를 사용하고 싶은 이유는 무엇일까요?\n어떤 목적지가 공중 속도에서 가장 큰 변동을 보입니까?\nEGE의 모험을 더 탐구하기 위해 플롯을 만드세요. 공항이 위치를 옮겼다는 증거를 찾을 수 있습니까? 차이를 설명할 수 있는 다른 변수를 찾을 수 있습니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#요약",
    "href": "numbers.html#요약",
    "title": "13  숫자",
    "section": "\n13.7 요약",
    "text": "13.7 요약\n여러분은 이미 숫자를 다루는 많은 도구에 익숙하며 이 장을 읽고 나면 R에서 그것들을 사용하는 방법을 알게 되었습니다. 또한 순위 및 오프셋과 같이 일반적으로 수치형 벡터에 적용되지만 배타적이지는 않은 유용한 일반 변환 몇 가지를 배웠습니다. 마지막으로 여러 수치 요약을 살펴보고 고려해야 할 몇 가지 통계적 과제에 대해 논의했습니다.\n다음 두 장에 걸쳐 stringr 패키지로 문자열을 다루는 방법에 대해 자세히 알아볼 것입니다. 문자열은 큰 주제이므로 문자열의 기초에 대한 장과 정규 표현식에 대한 장 두 개를 얻습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "numbers.html#footnotes",
    "href": "numbers.html#footnotes",
    "title": "13  숫자",
    "section": "",
    "text": "ggplot2는 cut_interval(), cut_number(), cut_width()에서 일반적인 경우에 대한 몇 가지 도우미를 제공합니다. ggplot2는 인정하건대 이러한 함수가 살기에는 이상한 곳이지만 히스토그램 계산의 일부로 유용하며 tidyverse의 다른 부분이 존재하기 전에 작성되었습니다.↩︎\nmode() 함수는 완전히 다른 일을 합니다!↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>숫자</span>"
    ]
  },
  {
    "objectID": "strings.html",
    "href": "strings.html",
    "title": "14  문자열",
    "section": "",
    "text": "14.1 소개\n지금까지 자세한 내용은 많이 배우지 않고 많은 문자열을 사용했습니다. 이제 문자열을 자세히 살펴보고, 문자열이 어떻게 작동하는지 배우고, 자유롭게 사용할 수 있는 강력한 문자열 조작 도구를 마스터할 때입니다.\n문자열과 문자형 벡터를 만드는 세부 사항부터 시작하겠습니다. 그런 다음 데이터에서 문자열을 만드는 방법과 반대로 데이터에서 문자열을 추출하는 방법을 알아볼 것입니다. 그 다음 개별 문자로 작업하는 도구에 대해 논의할 것입니다. 이 장은 개별 문자로 작업하는 함수와 다른 언어로 작업할 때 영어에 대한 기대가 잘못될 수 있는 부분에 대한 간단한 논의로 마무리됩니다.\n다음 장에서도 문자열 작업을 계속할 것이며, 거기서는 정규 표현식의 힘에 대해 더 배우게 될 것입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#소개",
    "href": "strings.html#소개",
    "title": "14  문자열",
    "section": "",
    "text": "14.1.1 선수 지식\n이 장에서는 핵심 tidyverse의 일부인 stringr 패키지의 함수를 사용할 것입니다. 또한 조작할 재미있는 문자열을 제공하는 babynames 데이터도 사용할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(babynames)\n\n모든 stringr 함수는 str_로 시작하기 때문에 stringr 함수를 사용하고 있는지 금방 알 수 있습니다. 이것은 RStudio를 사용하는 경우 특히 유용한데, str_을 입력하면 자동 완성이 트리거되어 사용 가능한 함수에 대한 기억을 되살릴 수 있기 때문입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#문자열-만들기",
    "href": "strings.html#문자열-만들기",
    "title": "14  문자열",
    "section": "\n14.2 문자열 만들기",
    "text": "14.2 문자열 만들기\n책의 앞부분에서 문자열을 스치듯 만들었지만 세부 사항은 논의하지 않았습니다. 먼저 작은따옴표(') 또는 큰따옴표(\")를 사용하여 문자열을 만들 수 있습니다. 두 가지의 동작에는 차이가 없으므로 일관성을 위해 tidyverse 스타일 가이드에서는 문자열에 여러 개의 \"가 포함되어 있지 않는 한 \"를 사용할 것을 권장합니다.\n\nstring1 &lt;- \"This is a string\"\nstring2 &lt;- 'If I want to include a \"quote\" inside a string, I use single quotes'\n\n따옴표를 닫는 것을 잊어버리면 연속 프롬프트인 +가 표시됩니다:\n&gt; \"This is a string without a closing quote\n+ \n+ \n+ HELP I'M STUCK IN A STRING\n이런 일이 발생하고 어떤 따옴표를 닫아야 할지 모르겠다면 Escape 키를 눌러 취소하고 다시 시도하세요.\n\n14.2.1 이스케이프(Escapes)\n문자열에 리터럴 작은따옴표나 큰따옴표를 포함하려면 \\를 사용하여 “이스케이프”할 수 있습니다:\n\ndouble_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\"\n\n따라서 문자열에 리터럴 백슬래시를 포함하려면 이스케이프해야 합니다: \"\\\\\":\n\nbackslash &lt;- \"\\\\\"\n\n문자열의 인쇄된 표현은 이스케이프를 보여주기 때문에 문자열 자체와 동일하지 않다는 점에 유의하세요(즉, 문자열을 인쇄할 때 출력을 복사하여 붙여넣으면 해당 문자열을 다시 만들 수 있습니다). 문자열의 원시 내용을 보려면 str_view()1를 사용하세요:\n\nx &lt;- c(single_quote, double_quote, backslash)\nx\n#&gt; [1] \"'\"  \"\\\"\" \"\\\\\"\nstr_view(x)\n#&gt; [1] │ '\n#&gt; [2] │ \"\n#&gt; [3] │ \\\n\n\n14.2.2 원시 문자열(Raw strings)\n여러 따옴표나 백슬래시로 문자열을 만드는 것은 금방 헷갈립니다. 문제를 설명하기 위해 double_quote 및 single_quote 변수를 정의한 코드 블록의 내용을 포함하는 문자열을 만들어 보겠습니다:\n\ntricky &lt;- \"double_quote &lt;- \\\"\\\\\\\"\\\" # or '\\\"'\nsingle_quote &lt;- '\\\\'' # or \\\"'\\\"\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     │ single_quote &lt;- '\\'' # or \"'\"\n\n백슬래시가 정말 많네요! (이것을 때때로 기우는 이쑤시개 증후군이라고 합니다.) 이스케이프를 제거하려면 대신 원시 문자열2을 사용할 수 있습니다:\n\ntricky &lt;- r\"(double_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\")\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     │ single_quote &lt;- '\\'' # or \"'\"\n\n원시 문자열은 일반적으로 r\"(\"로 시작하고 )\"로 끝납니다. 그러나 문자열에 )\"가 포함되어 있는 경우 대신 r\"[]\" 또는 r\"{}\"를 사용할 수 있으며, 그래도 충분하지 않은 경우 대시를 원하는 만큼 삽입하여 열고 닫는 쌍을 고유하게 만들 수 있습니다. 예: r\"--()--\", r\"---()---\" 등. 원시 문자열은 모든 텍스트를 처리할 수 있을 만큼 유연합니다.\n\n14.2.3 기타 특수 문자\n\", ', \\ 외에도 유용하게 사용할 수 있는 몇 가지 다른 특수 문자가 있습니다. 가장 일반적인 것은 \\n(새 줄)과 \\t(탭)입니다. 또한 \\u 또는 \\U로 시작하는 유니코드 이스케이프가 포함된 문자열을 볼 수도 있습니다. 이것은 모든 시스템에서 작동하는 영어가 아닌 문자를 쓰는 방법입니다. ?Quotes에서 다른 특수 문자의 전체 목록을 볼 수 있습니다.\n\nx &lt;- c(\"one\\ntwo\", \"one\\ttwo\", \"\\u00b5\", \"\\U0001f604\")\nx\n#&gt; [1] \"one\\ntwo\" \"one\\ttwo\" \"µ\"        \"😄\"\nstr_view(x)\n#&gt; [1] │ one\n#&gt;     │ two\n#&gt; [2] │ one{\\t}two\n#&gt; [3] │ µ\n#&gt; [4] │ 😄\n\nstr_view()는 탭을 쉽게 찾을 수 있도록 중괄호를 사용합니다3. 텍스트 작업의 어려움 중 하나는 텍스트에 공백이 포함될 수 있는 방법이 다양하다는 것인데, 이러한 배경 지식은 뭔가 이상한 일이 일어나고 있음을 인식하는 데 도움이 됩니다.\n\n14.2.4 연습문제\n\n\n다음 값을 포함하는 문자열을 만드세요:\n\nHe said \"That's amazing!\"\n\\a\\b\\c\\d\n\\\\\\\\\\\n\n\n\nR 세션에서 문자열을 만들고 인쇄하세요. 특수 문자 “0a0”은 어떻게 됩니까? str_view()는 어떻게 표시합니까? 이 특수 문자가 무엇인지 구글링해 볼 수 있습니까?\n\nx &lt;- \"This\\u00a0is\\u00a0tricky\"",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#데이터에서-많은-문자열-만들기",
    "href": "strings.html#데이터에서-많은-문자열-만들기",
    "title": "14  문자열",
    "section": "\n14.3 데이터에서 많은 문자열 만들기",
    "text": "14.3 데이터에서 많은 문자열 만들기\n이제 “손으로” 문자열 한두 개를 만드는 기본 사항을 배웠으므로 다른 문자열에서 문자열을 만드는 세부 사항으로 들어갑니다. 이것은 작성한 텍스트를 데이터 프레임의 문자열과 결합하려는 일반적인 문제를 해결하는 데 도움이 됩니다. 예를 들어 “Hello”와 name 변수를 결합하여 인사를 만들 수 있습니다. str_c() 및 str_glue()를 사용하여 이를 수행하는 방법과 mutate()와 함께 사용하는 방법을 보여줄 것입니다. 그러면 자연스럽게 summarize()와 함께 어떤 stringr 함수를 사용할 수 있는지에 대한 질문이 제기되므로 문자열 요약 함수인 str_flatten()에 대한 논의로 이 섹션을 마무리하겠습니다.\n\n14.3.1 str_c()\n\nstr_c()는 임의의 수의 벡터를 인수로 받아 문자 벡터를 반환합니다:\n\nstr_c(\"x\", \"y\")\n#&gt; [1] \"xy\"\nstr_c(\"x\", \"y\", \"z\")\n#&gt; [1] \"xyz\"\nstr_c(\"Hello \", c(\"John\", \"Susan\"))\n#&gt; [1] \"Hello John\"  \"Hello Susan\"\n\nstr_c()는 기본 paste0()과 매우 유사하지만 재활용 및 결측값 전파에 대한 일반적인 tidyverse 규칙을 준수하여 mutate()와 함께 사용되도록 설계되었습니다:\n\ndf &lt;- tibble(name = c(\"Flora\", \"David\", \"Terra\", NA))\ndf |&gt; mutate(greeting = str_c(\"Hi \", name, \"!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  &lt;NA&gt;\n\n결측값을 다른 방식으로 표시하려면 coalesce()를 사용하여 대체하세요. 원하는 것에 따라 str_c() 내부 또는 외부에서 사용할 수 있습니다:\n\ndf |&gt; \n  mutate(\n    greeting1 = str_c(\"Hi \", coalesce(name, \"you\"), \"!\"),\n    greeting2 = coalesce(str_c(\"Hi \", name, \"!\"), \"Hi!\")\n  )\n#&gt; # A tibble: 4 × 3\n#&gt;   name  greeting1 greeting2\n#&gt;   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora! Hi Flora!\n#&gt; 2 David Hi David! Hi David!\n#&gt; 3 Terra Hi Terra! Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi you!   Hi!\n\n\n14.3.2 str_glue()\n\nstr_c()로 많은 고정 문자열과 가변 문자열을 섞는다면 \"를 많이 입력하게 되어 코드의 전체 목표를 보기가 어렵습니다. glue 패키지에서 str_glue()4를 통해 대안적인 접근 방식을 제공합니다. 특별한 기능이 있는 단일 문자열을 제공합니다: {} 내부의 모든 것은 따옴표 밖에 있는 것처럼 평가됩니다:\n\ndf |&gt; mutate(greeting = str_glue(\"Hi {name}!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;glue&gt;   \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi NA!\n\n보시다시피 str_glue()는 현재 결측값을 문자열 \"NA\"로 변환하므로 불행히도 str_c()와 일관성이 없습니다.\n문자열에 일반 { 또는 }를 포함해야 하는 경우 어떻게 되는지 궁금할 수도 있습니다. 어떻게든 이스케이프해야 한다고 추측했다면 올바른 방향입니다. 비결은 glue가 약간 다른 이스케이프 기술을 사용한다는 것입니다: \\와 같은 특수 문자를 접두사로 붙이는 대신 특수 문자를 두 배로 늘립니다:\n\ndf |&gt; mutate(greeting = str_glue(\"{{Hi {name}!}}\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting   \n#&gt;   &lt;chr&gt; &lt;glue&gt;     \n#&gt; 1 Flora {Hi Flora!}\n#&gt; 2 David {Hi David!}\n#&gt; 3 Terra {Hi Terra!}\n#&gt; 4 &lt;NA&gt;  {Hi NA!}\n\n\n14.3.3 str_flatten()\n\nstr_c()와 str_glue()는 출력이 입력과 길이가 같기 때문에 mutate()와 잘 작동합니다. summarize()와 잘 작동하는 함수, 즉 항상 단일 문자열을 반환하는 함수를 원한다면 어떻게 해야 할까요? 그것이 str_flatten()5의 역할입니다: 문자 벡터를 받아 벡터의 각 요소를 단일 문자열로 결합합니다:\n\nstr_flatten(c(\"x\", \"y\", \"z\"))\n#&gt; [1] \"xyz\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \")\n#&gt; [1] \"x, y, z\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \", last = \", and \")\n#&gt; [1] \"x, y, and z\"\n\n이것은 summarize()와 잘 작동하게 만듭니다:\n\ndf &lt;- tribble(\n  ~ name, ~ fruit,\n  \"Carmen\", \"banana\",\n  \"Carmen\", \"apple\",\n  \"Marvin\", \"nectarine\",\n  \"Terence\", \"cantaloupe\",\n  \"Terence\", \"papaya\",\n  \"Terence\", \"mandarin\"\n)\ndf |&gt;\n  group_by(name) |&gt; \n  summarize(fruits = str_flatten(fruit, \", \"))\n#&gt; # A tibble: 3 × 2\n#&gt;   name    fruits                      \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                       \n#&gt; 1 Carmen  banana, apple               \n#&gt; 2 Marvin  nectarine                   \n#&gt; 3 Terence cantaloupe, papaya, mandarin\n\n\n14.3.4 연습문제\n\n\n다음 입력에 대해 paste0()과 str_c()의 결과를 비교하고 대조하세요:\n\nstr_c(\"hi \", NA)\nstr_c(letters[1:2], letters[1:3])\n\n\npaste()와 paste0()의 차이점은 무엇입니까? str_c()로 paste()와 동등한 것을 어떻게 재현할 수 있습니까?\n\n다음 표현식을 str_c()에서 str_glue()로 또는 그 반대로 변환하세요:\n\nstr_c(\"The price of \", food, \" is \", price)\nstr_glue(\"I'm {age} years old and live in {country}\")\nstr_c(\"\\\\section{\", title, \"}\")",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#문자열에서-데이터-추출",
    "href": "strings.html#문자열에서-데이터-추출",
    "title": "14  문자열",
    "section": "\n14.4 문자열에서 데이터 추출",
    "text": "14.4 문자열에서 데이터 추출\n여러 변수가 하나의 문자열에 함께 섞여 있는 것은 매우 일반적입니다. 이 섹션에서는 이를 추출하기 위해 네 가지 tidyr 함수를 사용하는 방법을 배웁니다:\n\ndf |&gt; separate_longer_delim(col, delim)\ndf |&gt; separate_longer_position(col, width)\ndf |&gt; separate_wider_delim(col, delim, names)\ndf |&gt; separate_wider_position(col, widths)\n\n자세히 보면 여기에 공통 패턴이 있음을 알 수 있습니다: separate_, 그 다음 longer 또는 wider, 그 다음 _, 그 다음 delim 또는 position으로. 이는 이 네 가지 함수가 두 가지 더 단순한 기본 요소로 구성되어 있기 때문입니다:\n\n\npivot_longer() 및 pivot_wider()와 마찬가지로 _longer 함수는 새 행을 생성하여 입력 데이터 프레임을 길게 만들고 _wider 함수는 새 열을 생성하여 입력 데이터 프레임을 넓게 만듭니다.\n\ndelim은 \", \" 또는 \" \"와 같은 구분 기호로 문자열을 분할합니다. position은 c(3, 5, 2)와 같이 지정된 너비로 분할합니다.\n\nChapter 15 에서 이 제품군의 마지막 멤버인 separate_wider_regex()로 돌아올 것입니다. 이것은 wider 함수 중 가장 유연하지만 사용하기 전에 정규 표현식에 대해 알고 있어야 합니다.\n다음 두 섹션에서는 이러한 분리 함수 뒤에 있는 기본 아이디어를 제공할 것입니다. 먼저 행으로 분리(조금 더 간단함)하고 그 다음 열로 분리합니다. wider 함수가 문제를 진단하기 위해 제공하는 도구에 대해 논의하며 마무리하겠습니다.\n\n14.4.1 행으로 분리\n문자열을 행으로 분리하는 것은 구성 요소의 수가 행마다 다를 때 가장 유용한 경향이 있습니다. 가장 일반적인 경우는 구분 기호를 기반으로 분할하기 위해 separate_longer_delim()이 필요한 경우입니다:\n\ndf1 &lt;- tibble(x = c(\"a,b,c\", \"d,e\", \"f\"))\ndf1 |&gt; \n  separate_longer_delim(x, delim = \",\")\n#&gt; # A tibble: 6 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a    \n#&gt; 2 b    \n#&gt; 3 c    \n#&gt; 4 d    \n#&gt; 5 e    \n#&gt; 6 f\n\n야생에서 separate_longer_position()을 보는 것은 더 드물지만, 일부 오래된 데이터셋은 각 문자가 값을 기록하는 데 사용되는 매우 간결한 형식을 사용합니다:\n\ndf2 &lt;- tibble(x = c(\"1211\", \"131\", \"21\"))\ndf2 |&gt; \n  separate_longer_position(x, width = 1)\n#&gt; # A tibble: 9 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1    \n#&gt; 2 2    \n#&gt; 3 1    \n#&gt; 4 1    \n#&gt; 5 1    \n#&gt; 6 3    \n#&gt; # ℹ 3 more rows\n\n\n14.4.2 열로 분리\n문자열을 열로 분리하는 것은 각 문자열에 고정된 수의 구성 요소가 있고 이를 열로 펼치고 싶을 때 가장 유용한 경향이 있습니다. 열 이름을 지정해야 하기 때문에 longer 등가물보다 약간 더 복잡합니다. 예를 들어 다음 데이터셋에서 x는 .로 구분된 코드, 에디션 번호, 연도로 구성됩니다. separate_wider_delim()을 사용하려면 두 인수에서 구분 기호와 이름을 제공합니다:\n\ndf3 &lt;- tibble(x = c(\"a10.1.2022\", \"b10.2.2011\", \"e15.1.2015\"))\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", \"edition\", \"year\")\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   code  edition year \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 a10   1       2022 \n#&gt; 2 b10   2       2011 \n#&gt; 3 e15   1       2015\n\n특정 조각이 유용하지 않은 경우 NA 이름을 사용하여 결과에서 생략할 수 있습니다:\n\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", NA, \"year\")\n  )\n#&gt; # A tibble: 3 × 2\n#&gt;   code  year \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 a10   2022 \n#&gt; 2 b10   2011 \n#&gt; 3 e15   2015\n\nseparate_wider_position()은 일반적으로 각 열의 너비를 지정하기 때문에 약간 다르게 작동합니다. 따라서 이름은 새 열의 이름을 제공하고 값은 차지하는 문자 수인 명명된 정수 벡터를 제공합니다. 이름을 지정하지 않아 출력에서 값을 생략할 수 있습니다:\n\ndf4 &lt;- tibble(x = c(\"202215TX\", \"202122LA\", \"202325CA\")) \ndf4 |&gt; \n  separate_wider_position(\n    x,\n    widths = c(year = 4, age = 2, state = 2)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   year  age   state\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 2022  15    TX   \n#&gt; 2 2021  22    LA   \n#&gt; 3 2023  25    CA\n\n\n14.4.3 넓히기 문제 진단\nseparate_wider_delim()6은 고정되고 알려진 열 집합을 필요로 합니다. 일부 행에 예상된 수의 조각이 없으면 어떻게 될까요? 조각이 너무 적거나 너무 많은 두 가지 가능한 문제가 있으므로 separate_wider_delim()은 도움이 되는 두 가지 인수 too_few와 too_many를 제공합니다. 다음 샘플 데이터셋으로 too_few 케이스를 먼저 살펴보겠습니다:\n\ndf &lt;- tibble(a = c(\"1-1-1\", \"1-1-2\", \"1-3\", \"1-3-2\", \"1\"))\n\ndf |&gt; \n  separate_wider_delim(\n    a,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `a`.\n#&gt; ! 2 values were too short.\n#&gt; ℹ Use `too_few = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_few = \"align_start\"/\"align_end\"` to silence this message.\n\n오류가 발생하지만 오류는 진행 방법에 대한 몇 가지 제안을 제공합니다. 문제를 디버깅하는 것부터 시작하겠습니다:\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    a,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `a_ok`, `a_pieces`, and\n#&gt; `a_remainder`.\ndebug\n#&gt; # A tibble: 5 × 7\n#&gt;   x     y     z     a     a_ok  a_pieces a_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1     1     1     1-1-1 TRUE         3 \"\"         \n#&gt; 2 1     1     2     1-1-2 TRUE         3 \"\"         \n#&gt; 3 1     3     &lt;NA&gt;  1-3   FALSE        2 \"\"         \n#&gt; 4 1     3     2     1-3-2 TRUE         3 \"\"         \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;  1     FALSE        1 \"\"\n\n디버그 모드를 사용하면 출력에 a_ok, a_pieces, a_remainder라는 세 개의 추가 열이 추가됩니다(다른 이름의 변수를 분리하면 다른 접두사가 붙습니다). 여기서 a_ok를 사용하면 실패한 입력을 빠르게 찾을 수 있습니다:\n\ndebug |&gt; filter(!a_ok)\n#&gt; # A tibble: 2 × 7\n#&gt;   x     y     z     a     a_ok  a_pieces a_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1     3     &lt;NA&gt;  1-3   FALSE        2 \"\"         \n#&gt; 2 1     &lt;NA&gt;  &lt;NA&gt;  1     FALSE        1 \"\"\n\na_pieces는 예상되는 3(names의 길이)과 비교하여 몇 개의 조각이 발견되었는지 알려줍니다. a_remainder는 조각이 너무 적을 때는 유용하지 않지만 잠시 후에 다시 보게 될 것입니다.\n이 디버깅 정보를 보면 구분 기호 전략에 문제가 있거나 분리하기 전에 전처리를 더 해야 한다는 것을 알 수 있습니다. 이 경우 업스트림에서 문제를 수정하고 too_few = \"debug\"를 제거하여 새로운 문제가 오류가 되도록 하세요.\n다른 경우에는 누락된 조각을 NA로 채우고 계속 진행하고 싶을 수 있습니다. too_few = \"align_start\"와 too_few = \"align_end\"는 NA가 어디로 가야 하는지 제어할 수 있게 해줍니다:\n\ndf |&gt; \n  separate_wider_delim(\n    a,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"align_start\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     &lt;NA&gt; \n#&gt; 4 1     3     2    \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;\n\n조각이 너무 많은 경우에도 동일한 원칙이 적용됩니다:\n\ndf &lt;- tibble(a = c(\"1-1-1\", \"1-1-2\", \"1-3-5-6\", \"1-3-2\", \"1-3-5-7-9\"))\n\ndf |&gt; \n  separate_wider_delim(\n    a,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `a`.\n#&gt; ! 2 values were too long.\n#&gt; ℹ Use `too_many = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_many = \"drop\"/\"merge\"` to silence this message.\n\n하지만 이제 결과를 디버깅할 때 a_remainder의 목적을 볼 수 있습니다:\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    a,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `a_ok`, `a_pieces`, and\n#&gt; `a_remainder`.\ndebug |&gt; filter(!a_ok)\n#&gt; # A tibble: 2 × 7\n#&gt;   x     y     z     a         a_ok  a_pieces a_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1     3     5     1-3-5-6   FALSE        4 -6         \n#&gt; 2 1     3     5     1-3-5-7-9 FALSE        5 -7-9\n\n너무 많은 조각을 처리하기 위한 약간 다른 옵션 세트가 있습니다: 추가 조각을 조용히 “삭제(drop)”하거나 모두 최종 열로 “병합(merge)”할 수 있습니다:\n\ndf |&gt; \n  separate_wider_delim(\n    a,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"drop\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5    \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5\n\n\ndf |&gt; \n  separate_wider_delim(\n    a,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"merge\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5-6  \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5-7-9",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#문자letters",
    "href": "strings.html#문자letters",
    "title": "14  문자열",
    "section": "\n14.5 문자(Letters)",
    "text": "14.5 문자(Letters)\n이 섹션에서는 문자열 내의 개별 문자로 작업할 수 있는 함수를 소개합니다. 문자열의 길이를 찾고, 하위 문자열을 추출하고, 플롯과 테이블에서 긴 문자열을 처리하는 방법을 배웁니다.\n\n14.5.1 길이\nstr_length()는 문자열의 문자 수를 알려줍니다:\n\nstr_length(c(\"a\", \"R for data science\", NA))\n#&gt; [1]  1 18 NA\n\n이것을 count()와 함께 사용하여 미국 아기 이름 길이의 분포를 찾은 다음 filter()와 함께 사용하여 가장 긴 이름(우연히 15자임)을 볼 수 있습니다7:\n\nbabynames |&gt;\n  count(length = str_length(name), wt = n)\n#&gt; # A tibble: 14 × 2\n#&gt;   length        n\n#&gt;    &lt;int&gt;    &lt;int&gt;\n#&gt; 1      2   338150\n#&gt; 2      3  8589596\n#&gt; 3      4 48506739\n#&gt; 4      5 87011607\n#&gt; 5      6 90749404\n#&gt; 6      7 72120767\n#&gt; # ℹ 8 more rows\n\nbabynames |&gt; \n  filter(str_length(name) == 15) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 34 × 2\n#&gt;   name                n\n#&gt;   &lt;chr&gt;           &lt;int&gt;\n#&gt; 1 Franciscojavier   123\n#&gt; 2 Christopherjohn   118\n#&gt; 3 Johnchristopher   118\n#&gt; 4 Christopherjame   108\n#&gt; 5 Christophermich    52\n#&gt; 6 Ryanchristopher    45\n#&gt; # ℹ 28 more rows\n\n\n14.5.2 부분집합\nstr_sub(string, start, end)를 사용하여 문자열의 일부를 추출할 수 있습니다. 여기서 start와 end는 부분 문자열이 시작하고 끝나야 하는 위치입니다. start 및 end 인수는 포함적이므로 반환된 문자열의 길이는 end - start + 1이 됩니다:\n\nx &lt;- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n#&gt; [1] \"App\" \"Ban\" \"Pea\"\n\n음수 값을 사용하여 문자열 끝에서부터 거꾸로 셀 수 있습니다: -1은 마지막 문자, -2는 끝에서 두 번째 문자 등입니다.\n\nstr_sub(x, -3, -1)\n#&gt; [1] \"ple\" \"ana\" \"ear\"\n\n문자열이 너무 짧아도 str_sub()는 실패하지 않습니다: 가능한 한 많이 반환합니다:\n\nstr_sub(\"a\", 1, 5)\n#&gt; [1] \"a\"\n\nstr_sub()를 mutate()와 함께 사용하여 각 이름의 첫 글자와 마지막 글자를 찾을 수 있습니다:\n\nbabynames |&gt; \n  mutate(\n    first = str_sub(name, 1, 1),\n    last = str_sub(name, -1, -1)\n  )\n#&gt; # A tibble: 1,924,665 × 7\n#&gt;    year sex   name          n   prop first last \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1  1880 F     Mary       7065 0.0724 M     y    \n#&gt; 2  1880 F     Anna       2604 0.0267 A     a    \n#&gt; 3  1880 F     Emma       2003 0.0205 E     a    \n#&gt; 4  1880 F     Elizabeth  1939 0.0199 E     h    \n#&gt; 5  1880 F     Minnie     1746 0.0179 M     e    \n#&gt; 6  1880 F     Margaret   1578 0.0162 M     t    \n#&gt; # ℹ 1,924,659 more rows\n\n\n14.5.3 연습문제\n\n아기 이름 길이의 분포를 계산할 때 wt = n을 사용한 이유는 무엇입니까?\n\nstr_length()와 str_sub()를 사용하여 각 아기 이름에서 중간 글자를 추출하세요. 문자열의 문자 수가 짝수이면 어떻게 하시겠습니까?\n시간이 지남에 따라 아기 이름 길이에 주요 추세가 있습니까? 첫 글자와 마지막 글자의 인기는 어떻습니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#sec-other-languages",
    "href": "strings.html#sec-other-languages",
    "title": "14  문자열",
    "section": "\n14.6 영어가 아닌 텍스트",
    "text": "14.6 영어가 아닌 텍스트\n지금까지 우리는 영어 텍스트에 초점을 맞췄는데, 두 가지 이유로 작업하기가 특히 쉽습니다. 첫째, 영어 알파벳은 비교적 간단합니다. 26개의 글자만 있습니다. 둘째(그리고 아마도 더 중요한 것은), 우리가 오늘날 사용하는 컴퓨팅 인프라는 주로 영어 사용자에 의해 설계되었습니다. 불행히도 영어가 아닌 언어를 완전히 다룰 지면이 없습니다. 그럼에도 불구하고 인코딩, 문자 변형, 로케일 의존 함수 등 여러분이 직면할 수 있는 가장 큰 과제 중 일부에 대해 주의를 환기시키고 싶었습니다.\n\n14.6.1 인코딩(Encoding)\n영어가 아닌 텍스트로 작업할 때 첫 번째 과제는 종종 인코딩입니다. 무슨 일이 일어나고 있는지 이해하려면 컴퓨터가 문자열을 표현하는 방법을 알아야 합니다. R에서는 charToRaw()를 사용하여 문자열의 기본 표현을 얻을 수 있습니다:\n\ncharToRaw(\"Hadley\")\n#&gt; [1] 48 61 64 6c 65 79\n\n이 6개의 16진수 각각은 하나의 글자를 나타냅니다. 48은 H, 61은 a 등입니다. 16진수에서 문자로의 매핑을 인코딩이라고 하며, 이 경우 인코딩은 ASCII라고 합니다. ASCII는 미국 정보 교환 표준 코드(American Standard Code for Information Interchange)이기 때문에 영어 문자를 표현하는 데 훌륭합니다.\n영어 이외의 언어에서는 상황이 그렇게 쉽지 않습니다. 컴퓨팅 초기에는 영어가 아닌 문자를 인코딩하기 위한 많은 경쟁 표준이 있었습니다. 예를 들어 유럽에는 두 가지 다른 인코딩이 있었습니다. 라틴1(일명 ISO-8859-1)은 서유럽 언어에 사용되었고 라틴2(일명 ISO-8859-2)는 중부 유럽 언어에 사용되었습니다. 라틴1에서 바이트 b1은 “±”이지만 라틴2에서는 “ą”입니다! 다행히 오늘날에는 거의 모든 곳에서 지원되는 하나의 표준이 있습니다: UTF-8. UTF-8은 오늘날 인간이 사용하는 거의 모든 문자와 이모티콘과 같은 많은 추가 기호를 인코딩할 수 있습니다.\nreadr은 모든 곳에서 UTF-8을 사용합니다. 이것은 좋은 기본값이지만 UTF-8을 사용하지 않는 오래된 시스템에서 생성된 데이터에 대해서는 실패할 것입니다. 이런 일이 발생하면 문자열을 인쇄할 때 이상하게 보일 것입니다. 때로는 한두 개의 문자가 엉망이 될 수 있고, 때로는 완전한 횡설수설을 얻을 수 있습니다. 예를 들어 비정상적인 인코딩을 가진 두 개의 인라인 CSV가 있습니다8:\n\nx1 &lt;- \"text\\nEl Ni\\xf1o was particularly bad this year\"\nread_csv(x1)$text\n#&gt; [1] \"El Ni\\xf1o was particularly bad this year\"\n\nx2 &lt;- \"text\\n\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd\"\nread_csv(x2)$text\n#&gt; [1] \"\\x82\\xb1\\x82\\xf1\\x82ɂ\\xbf\\x82\\xcd\"\n\n이를 올바르게 읽으려면 locale 인수를 통해 인코딩을 지정합니다:\n\nread_csv(x1, locale = locale(encoding = \"Latin1\"))$text\n#&gt; [1] \"El Niño was particularly bad this year\"\n\nread_csv(x2, locale = locale(encoding = \"Shift-JIS\"))$text\n#&gt; [1] \"こんにちは\"\n\n올바른 인코딩을 어떻게 찾습니까? 운이 좋다면 데이터 문서 어딘가에 포함되어 있을 것입니다. 불행히도 그런 경우는 드물기 때문에 readr은 파악하는 데 도움이 되는 guess_encoding()을 제공합니다. 완벽하지는 않고 텍스트가 많을 때(여기처럼 텍스트가 적을 때와 달리) 더 잘 작동하지만 시작하기에 합리적인 곳입니다. 올바른 것을 찾기 전에 몇 가지 다른 인코딩을 시도할 것을 예상하세요.\n인코딩은 풍부하고 복잡한 주제입니다. 여기서는 겉만 핥았습니다. 더 배우고 싶다면 http://kunststube.net/encoding/의 자세한 설명을 읽어보는 것을 추천합니다.\n\n14.6.2 문자 변형\n악센트가 있는 언어로 작업하는 것은 악센트가 있는 문자가 단일 개별 문자(예: ü)로 인코딩되거나 악센트가 없는 문자(예: u)와 분음 부호(예: ¨)를 결합하여 두 문자로 인코딩될 수 있으므로 문자의 위치를 결정할 때(예: str_length() 및 str_sub() 사용) 상당한 어려움을 줍니다. 예를 들어 이 코드는 똑같이 보이는 ü를 표현하는 두 가지 방법을 보여줍니다:\n\nu &lt;- c(\"\\u00fc\", \"u\\u0308\")\nstr_view(u)\n#&gt; [1] │ ü\n#&gt; [2] │ ü\n\n그러나 두 문자열은 길이가 다르고 첫 번째 문자가 다릅니다:\n\nstr_length(u)\n#&gt; [1] 1 2\nstr_sub(u, 1, 1)\n#&gt; [1] \"ü\" \"u\"\n\n마지막으로 ==로 이 문자열들을 비교하면 다르다고 해석되는 반면 stringr의 편리한 str_equal() 함수는 둘 다 모양이 같다는 것을 인식합니다:\n\nu[[1]] == u[[2]]\n#&gt; [1] FALSE\n\nstr_equal(u[[1]], u[[2]])\n#&gt; [1] TRUE\n\n\n14.6.3 로케일 의존 함수\n마지막으로 동작이 로케일(locale) 에 따라 달라지는 소수의 stringr 함수가 있습니다. 로케일은 언어와 유사하지만 언어 내의 지역적 변형을 처리하기 위한 선택적 지역 지정자를 포함합니다. 로케일은 소문자 언어 약어로 지정되며 선택적으로 _와 대문자 지역 식별자가 뒤따릅니다. 예를 들어 “en”은 영어, “en_GB”는 영국 영어, “en_US”는 미국 영어입니다. 언어 코드를 아직 모른다면 위키백과에 좋은 목록이 있으며 stringi::stri_locale_list()를 보면 stringr에서 지원되는 코드를 볼 수 있습니다.\n기본 R 문자열 함수는 운영 체제에서 설정한 로케일을 자동으로 사용합니다. 즉, 기본 R 문자열 함수는 해당 언어에 대해 예상하는 작업을 수행하지만 다른 국가에 사는 사람과 코드를 공유하면 코드가 다르게 작동할 수 있습니다. 이 문제를 피하기 위해 stringr은 “en” 로케일을 사용하여 영어 규칙을 기본값으로 사용하며 이를 재정의하려면 locale 인수를 지정해야 합니다. 다행히 로케일이 정말 중요한 함수 세트는 대소문자 변경과 정렬 두 가지뿐입니다.\n대소문자 변경 규칙은 언어마다 다릅니다. 예를 들어 터키어에는 점이 있는 i와 점이 없는 i 두 가지가 있습니다. 두 개의 별도 문자이므로 대문자로 다르게 표기됩니다:\n\nstr_to_upper(c(\"i\", \"ı\"))\n#&gt; [1] \"I\" \"I\"\nstr_to_upper(c(\"i\", \"ı\"), locale = \"tr\")\n#&gt; [1] \"İ\" \"I\"\n\n문자열 정렬은 알파벳 순서에 따라 달라지며 알파벳 순서는 모든 언어에서 동일하지 않습니다9! 예를 들어 체코어에서 “ch”는 알파벳에서 h 뒤에 오는 복합 문자입니다.\n\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"))\n#&gt; [1] \"a\"  \"c\"  \"ch\" \"h\"  \"z\"\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"), locale = \"cs\")\n#&gt; [1] \"a\"  \"c\"  \"h\"  \"ch\" \"z\"\n\n이것은 dplyr::arrange()로 문자열을 정렬할 때도 나타나며, 이것이 locale 인수가 있는 이유입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#요약",
    "href": "strings.html#요약",
    "title": "14  문자열",
    "section": "\n14.7 요약",
    "text": "14.7 요약\n이 장에서는 문자열 생성, 결합, 추출 방법과 영어가 아닌 문자열에서 직면할 수 있는 몇 가지 문제에 대해 stringr 패키지의 강력한 기능 중 일부를 배웠습니다. 이제 문자열 작업을 위한 가장 중요하고 강력한 도구 중 하나인 정규 표현식을 배울 때입니다. 정규 표현식은 문자열 내의 패턴을 설명하기 위한 매우 간결하지만 매우 표현력이 풍부한 언어이며 다음 장의 주제입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "strings.html#footnotes",
    "href": "strings.html#footnotes",
    "title": "14  문자열",
    "section": "",
    "text": "또는 기본 R 함수 writeLines()를 사용하세요.↩︎\nR 4.0.0 이상에서 사용 가능합니다.↩︎\nstr_view()는 또한 색상을 사용하여 탭, 공백, 일치 항목 등을 강조합니다. 색상은 현재 책에 표시되지 않지만 대화식으로 코드를 실행할 때 알 수 있습니다.↩︎\nstringr을 사용하지 않는 경우 glue::glue()를 사용하여 직접 액세스할 수도 있습니다.↩︎\n기본 R의 등가물은 collapse 인수와 함께 사용되는 paste()입니다.↩︎\n동일한 원칙이 separate_wider_position() 및 separate_wider_regex()에도 적용됩니다.↩︎\n이 항목들을 보면 babynames 데이터가 공백이나 하이픈을 삭제하고 15자 이후를 자른다고 추측할 수 있습니다.↩︎\n여기서는 특수 \\x를 사용하여 이진 데이터를 문자열로 직접 인코딩하고 있습니다.↩︎\n중국어와 같이 알파벳이 없는 언어의 정렬은 훨씬 더 복잡합니다.↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "regexps.html",
    "href": "regexps.html",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "",
    "text": "15.1 소개 (Introduction)\nChapter 14 장에서 문자열 작업을 위한 유용한 함수들을 많이 배웠습니다. 이번 장에서는 문자열 내의 패턴을 설명하는 간결하고 강력한 언어인 정규 표현식(regular expressions)을 사용하는 함수들에 초점을 맞출 것입니다. “정규 표현식”이라는 용어는 발음하기 좀 길기 때문에 대부분의 사람들은 “regex”1 또는 “regexp”로 줄여서 부릅니다.\n이 장은 정규 표현식의 기초와 데이터 분석에 가장 유용한 stringr 함수들로 시작합니다. 그런 다음 패턴에 대한 지식을 확장하여 7가지 중요한 새 주제(이스케이프, 앵커, 문자 클래스, 단축 클래스, 수량자, 우선순위, 그룹화)를 다룰 것입니다. 다음으로 stringr 함수가 작업할 수 있는 다른 유형의 패턴들과 정규 표현식의 동작을 조정할 수 있는 다양한 “플래그(flags)”에 대해 이야기할 것입니다. 마지막으로 tidyverse와 기본 R(base R)의 다른 곳에서 정규 표현식을 사용할 수 있는 경우들을 살펴보며 마무리하겠습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#소개-introduction",
    "href": "regexps.html#소개-introduction",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "",
    "text": "15.1.1 선수 과목 (Prerequisites)\n이 장에서는 tidyverse의 핵심 멤버인 stringr과 tidyr의 정규 표현식 함수들과 babynames 패키지의 데이터를 사용할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(babynames)\n\n이 장 전반에 걸쳐 기본 아이디어를 얻을 수 있는 매우 간단한 인라인 예제, 아기 이름 데이터, 그리고 stringr의 세 가지 문자 벡터를 혼합하여 사용할 것입니다:\n\n\nfruit: 80가지 과일 이름이 들어 있습니다.\n\nwords: 980개의 일반적인 영어 단어가 들어 있습니다.\n\nsentences: 720개의 짧은 문장이 들어 있습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-reg-basics",
    "href": "regexps.html#sec-reg-basics",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "\n15.2 패턴 기초 (Pattern basics)",
    "text": "15.2 패턴 기초 (Pattern basics)\nstr_view()를 사용하여 정규 표현식 패턴이 어떻게 작동하는지 알아볼 것입니다. 지난 장에서는 문자열과 출력된 표현을 더 잘 이해하기 위해 str_view()를 사용했지만, 이제는 두 번째 인수로 정규 표현식을 사용하여 활용할 것입니다. 정규 표현식이 제공되면 str_view()는 일치하는 문자열 벡터의 요소만 보여주며, 각 일치 항목을 &lt;&gt;로 감싸고 가능한 경우 파란색으로 강조 표시합니다.\n가장 간단한 패턴은 문자와 숫자로 구성되며, 이는 해당 문자와 정확히 일치합니다:\n\nstr_view(fruit, \"berry\")\n#&gt;  [6] │ bil&lt;berry&gt;\n#&gt;  [7] │ black&lt;berry&gt;\n#&gt; [10] │ blue&lt;berry&gt;\n#&gt; [11] │ boysen&lt;berry&gt;\n#&gt; [19] │ cloud&lt;berry&gt;\n#&gt; [21] │ cran&lt;berry&gt;\n#&gt; ... and 8 more\n\n문자와 숫자는 정확히 일치하며 이를 리터럴 문자(literal characters)라고 합니다. ., +, *, [, ], ?와 같은 대부분의 구두점 문자는 특별한 의미2를 가지며 메타문자(metacharacters)라고 합니다. 예를 들어, .은 어떤 문자3와도 일치하므로 \"a.\"는 “a” 뒤에 다른 문자가 오는 모든 문자열과 일치합니다:\n\nstr_view(c(\"a\", \"ab\", \"ae\", \"bd\", \"ea\", \"eab\"), \"a.\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ae&gt;\n#&gt; [6] │ e&lt;ab&gt;\n\n또는 “a” 뒤에 세 글자가 오고 그 뒤에 “e”가 오는 모든 과일을 찾을 수도 있습니다:\n\nstr_view(fruit, \"a...e\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt;  [7] │ bl&lt;ackbe&gt;rry\n#&gt; [48] │ mand&lt;arine&gt;\n#&gt; [51] │ nect&lt;arine&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [64] │ pomegr&lt;anate&gt;\n#&gt; ... and 2 more\n\n수량자(Quantifiers)는 패턴이 일치할 수 있는 횟수를 제어합니다:\n\n\n?: 패턴을 선택적으로 만듭니다 (즉, 0회 또는 1회 일치).\n\n+: 패턴을 반복하게 합니다 (즈, 적어도 1회 이상 일치).\n\n*: 패턴을 선택적이거나 반복하게 합니다 (즈, 0회를 포함하여 횟수에 상관없이 일치).\n\n\n# ab?는 \"a\" 뒤에 선택적으로 \"b\"가 오는 것과 일치합니다.\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ab&gt;b\n\n# ab+는 \"a\" 뒤에 적어도 하나 이상의 \"b\"가 오는 것과 일치합니다.\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\n# ab*는 \"a\" 뒤에 \"b\"가 횟수에 상관없이(0회 포함) 오는 것과 일치합니다.\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\n문자 클래스(Character classes)는 []로 정의되며 문자 집합과 일치시킬 수 있습니다. 예를 들어 [abcd]는 “a”, “b”, “c” 또는 “d”와 일치합니다. ^로 시작하여 일치를 반전시킬 수도 있습니다: [^abcd]는 “a”, “b”, “c”, “d”를 제외한 모든 것과 일치합니다. 이 아이디어를 사용하여 모음으로 둘러싸인 “x”나 자음으로 둘러싸인 “y”가 포함된 단어를 찾을 수 있습니다:\n\nstr_view(words, \"[aeiou]x[aeiou]\")\n#&gt; [284] │ &lt;exa&gt;ct\n#&gt; [285] │ &lt;exa&gt;mple\n#&gt; [288] │ &lt;exe&gt;rcise\n#&gt; [289] │ &lt;exi&gt;st\nstr_view(words, \"[^aeiou]y[^aeiou]\")\n#&gt; [836] │ &lt;sys&gt;tem\n#&gt; [901] │ &lt;typ&gt;e\n\n대안(alternation)인 |를 사용하여 하나 이상의 대체 패턴 중에서 선택할 수 있습니다. 예를 들어, 다음 패턴은 “apple”, “melon”, “nut” 또는 반복되는 모음이 포함된 과일을 찾습니다.\n\nstr_view(fruit, \"apple|melon|nut\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [13] │ canary &lt;melon&gt;\n#&gt; [20] │ coco&lt;nut&gt;\n#&gt; [52] │ &lt;nut&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [72] │ rock &lt;melon&gt;\n#&gt; ... and 1 more\nstr_view(fruit, \"aa|ee|ii|oo|uu\")\n#&gt;  [9] │ bl&lt;oo&gt;d orange\n#&gt; [33] │ g&lt;oo&gt;seberry\n#&gt; [47] │ lych&lt;ee&gt;\n#&gt; [66] │ purple mangost&lt;ee&gt;n\n\n정규 표현식은 매우 간결하고 많은 구두점 문자를 사용하기 때문에 처음에는 압도적이고 읽기 어려워 보일 수 있습니다. 걱정하지 마세요. 연습하면 나아질 것이고, 간단한 패턴은 곧 자연스러워질 것입니다. 유용한 stringr 함수들로 연습하며 그 과정을 시작해 봅시다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-stringr-regex-funs",
    "href": "regexps.html#sec-stringr-regex-funs",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "\n15.3 주요 함수 (Key functions)",
    "text": "15.3 주요 함수 (Key functions)\n이제 정규 표현식의 기초를 익혔으니, stringr 및 tidyr 함수들과 함께 사용해 봅시다. 다음 섹션에서는 일치 항목의 존재 여부 감지, 일치 횟수 계산, 일치 항목을 고정 텍스트로 교체, 패턴을 사용한 텍스트 추출 방법을 배울 것입니다.\n\n15.3.1 일치 감지 (Detect matches)\nstr_detect()는 패턴이 문자 벡터의 요소와 일치하면 TRUE, 그렇지 않으면 FALSE인 논리형 벡터를 반환합니다:\n\nstr_detect(c(\"a\", \"b\", \"c\"), \"[aeiou]\")\n#&gt; [1]  TRUE FALSE FALSE\n\nstr_detect()는 초기 벡터와 길이가 같은 논리형 벡터를 반환하므로 filter()와 잘 어울립니다. 예를 들어, 이 코드는 소문자 “x”가 포함된 가장 인기 있는 이름들을 찾습니다:\n\nbabynames |&gt; \n  filter(str_detect(name, \"x\")) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 974 × 2\n#&gt;   name           n\n#&gt;   &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 Alexander 665492\n#&gt; 2 Alexis    399551\n#&gt; 3 Alex      278705\n#&gt; 4 Alexandra 232223\n#&gt; 5 Max       148787\n#&gt; 6 Alexa     123032\n#&gt; # ℹ 968 more rows\n\n또한 str_detect()를 sum() 또는 mean()과 짝을 지어 summarize()와 함께 사용할 수도 있습니다: sum(str_detect(x, pattern))은 일치하는 관측값의 수를 알려주고, mean(str_detect(x, pattern))은 일치하는 비율을 알려줍니다. 예를 들어, 다음 스니펫은 “x”가 포함된 아기 이름4의 비율을 연도별로 계산하고 시각화합니다. 최근 들어 인기가 급격히 증가한 것 같네요!\n\nbabynames |&gt; \n  group_by(year) |&gt; \n  summarize(prop_x = mean(str_detect(name, \"x\"))) |&gt; \n  ggplot(aes(x = year, y = prop_x)) + \n  geom_line()\n\n\n\n\n\n\n\nstr_detect()와 밀접하게 관련된 두 가지 함수가 있습니다: str_subset()과 str_which()입니다. str_subset()은 일치하는 문자열만 포함하는 문자 벡터를 반환합니다. str_which()는 일치하는 문자열의 위치를 나타내는 정수 벡터를 반환합니다.\n\n15.3.2 일치 횟수 계산 (Count matches)\nstr_detect()보다 한 단계 더 복잡한 것은 str_count()입니다: 참 또는 거짓 대신 각 문자열에 일치하는 항목이 몇 개인지 알려줍니다.\n\nx &lt;- c(\"apple\", \"banana\", \"pear\")\nstr_count(x, \"p\")\n#&gt; [1] 2 0 1\n\n각 일치는 이전 일치가 끝난 곳에서 시작한다는 점에 유의하세요. 즉, 정규 표현식 일치는 절대 겹치지 않습니다. 예를 들어, \"abababa\"에서 \"aba\" 패턴은 몇 번 일치할까요? 정규 표현식은 세 번이 아니라 두 번이라고 말합니다:\n\nstr_count(\"abababa\", \"aba\")\n#&gt; [1] 2\nstr_view(\"abababa\", \"aba\")\n#&gt; [1] │ &lt;aba&gt;b&lt;aba&gt;\n\nstr_count()를 mutate()와 함께 사용하는 것은 자연스럽습니다. 다음 예제는 str_count()와 문자 클래스를 사용하여 각 이름의 모음과 자음 수를 계산합니다.\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 Aaban        10      2          3\n#&gt; 2 Aabha         5      2          3\n#&gt; 3 Aabid         2      2          3\n#&gt; 4 Aabir         1      2          3\n#&gt; 5 Aabriella     5      4          5\n#&gt; 6 Aada          1      2          2\n#&gt; # ℹ 97,304 more rows\n\n자세히 보면 계산에 뭔가 이상한 점이 있음을 알 수 있습니다: “Aaban”에는 “a”가 세 개 있지만 요약에는 모음이 두 개뿐이라고 보고합니다. 이는 정규 표현식이 대소문자를 구분하기 때문입니다. 이 문제를 해결할 수 있는 세 가지 방법이 있습니다:\n\n문자 클래스에 대문자 모음을 추가합니다: str_count(name, \"[aeiouAEIOU]\").\n정규 표현식에 대소문자를 무시하도록 지시합니다: str_count(name, regex(\"[aeiou]\", ignore_case = TRUE)). 이에 대해서는 Section 15.5.1 에서 더 자세히 다룰 것입니다.\n\nstr_to_lower()를 사용하여 이름을 소문자로 변환합니다: str_count(str_to_lower(name), \"[aeiou]\").\n\n이러한 다양한 접근 방식은 문자열 작업을 할 때 꽤 일반적입니다. 패턴을 더 복잡하게 만들거나 문자열에 전처리를 수행하는 등 목표에 도달하는 방법은 종종 여러 가지가 있습니다. 한 가지 접근 방식으로 막히면 기어를 바꿔 다른 관점에서 문제를 해결하는 것이 종종 유용할 수 있습니다.\n이 경우 이름에 두 가지 함수를 적용하고 있으므로 먼저 변환하는 것이 더 쉽다고 생각합니다:\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    name = str_to_lower(name),\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 aaban        10      3          2\n#&gt; 2 aabha         5      3          2\n#&gt; 3 aabid         2      3          2\n#&gt; 4 aabir         1      3          2\n#&gt; 5 aabriella     5      5          4\n#&gt; 6 aada          1      3          1\n#&gt; # ℹ 97,304 more rows\n\n\n15.3.3 값 교체 (Replace values)\n일치 항목을 감지하고 계산하는 것 외에도 str_replace()와 str_replace_all()을 사용하여 수정할 수도 있습니다. str_replace()는 첫 번째 일치 항목을 교체하고, 이름에서 알 수 있듯이 str_replace_all()은 모든 일치 항목을 교체합니다.\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_replace_all(x, \"[aeiou]\", \"-\")\n#&gt; [1] \"-ppl-\"  \"p--r\"   \"b-n-n-\"\n\nstr_remove()와 str_remove_all()은 str_replace(x, pattern, \"\")의 편리한 단축형입니다:\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_remove_all(x, \"[aeiou]\")\n#&gt; [1] \"ppl\" \"pr\"  \"bnn\"\n\n이 함수들은 데이터 정리를 할 때 mutate()와 자연스럽게 짝을 이루며, 일관성 없는 서식의 층을 벗겨내기 위해 반복적으로 적용하는 경우가 많습니다.\n\n15.3.4 변수 추출 (Extract variables)\n마지막으로 논의할 함수는 정규 표현식을 사용하여 한 열의 데이터를 하나 이상의 새 열로 추출하는 separate_wider_regex()입니다. 이것은 Section 14.4.2 에서 배운 separate_wider_position() 및 separate_wider_delim() 함수의 동료입니다. 이 함수들은 개별 벡터가 아닌 데이터 프레임의 (열)에서 작동하기 때문에 tidyr에 있습니다.\n작동 방식을 보여주기 위해 간단한 데이터셋을 만들어 보겠습니다. 여기 babynames에서 파생된 데이터가 있는데, 이름, 성별, 나이가 다소 이상한 형식5으로 되어 있습니다:\n\ndf &lt;- tribble(\n  ~str,\n  \"&lt;Sheryl&gt;-F_34\",\n  \"&lt;Kisha&gt;-F_45\", \n  \"&lt;Brandon&gt;-N_33\",\n  \"&lt;Sharon&gt;-F_38\", \n  \"&lt;Penny&gt;-F_58\",\n  \"&lt;Justin&gt;-M_41\", \n  \"&lt;Patricia&gt;-F_84\", \n)\n\nseparate_wider_regex()를 사용하여 이 데이터를 추출하려면 각 조각과 일치하는 정규 표현식 시퀀스를 구성하기만 하면 됩니다. 해당 조각의 내용이 출력에 나타나게 하려면 이름을 지정합니다:\n\ndf |&gt; \n  separate_wider_regex(\n    str,\n    patterns = c(\n      \"&lt;\", \n      name = \"[A-Za-z]+\", \n      \"&gt;-\", \n      gender = \".\",\n      \"_\",\n      age = \"[0-9]+\"\n    )\n  )\n#&gt; # A tibble: 7 × 3\n#&gt;   name    gender age  \n#&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 Sheryl  F      34   \n#&gt; 2 Kisha   F      45   \n#&gt; 3 Brandon N      33   \n#&gt; 4 Sharon  F      38   \n#&gt; 5 Penny   F      58   \n#&gt; 6 Justin  M      41   \n#&gt; # ℹ 1 more row\n\n일치에 실패하면 separate_wider_delim() 및 separate_wider_position()과 마찬가지로 too_few = \"debug\"를 사용하여 무엇이 잘못되었는지 파악할 수 있습니다.\n\n15.3.5 연습문제 (Exercises)\n\n모음이 가장 많은 아기 이름은 무엇인가요? 모음의 비율이 가장 높은 이름은 무엇인가요? (힌트: 분모는 무엇인가요?)\n\"a/b/c/d/e\"의 모든 슬래시(forward slashes)를 백슬래시(backslashes)로 바꾸세요. 모든 백슬래시를 슬래시로 바꾸어 변환을 취소하려고 하면 어떻게 되나요? (이 문제는 곧 논의할 것입니다.)\nstr_replace_all()을 사용하여 간단한 버전의 str_to_lower()를 구현하세요.\n여러분의 국가에서 일반적으로 쓰이는 전화번호와 일치하는 정규 표현식을 만드세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#패턴-상세-pattern-details",
    "href": "regexps.html#패턴-상세-pattern-details",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "\n15.4 패턴 상세 (Pattern details)",
    "text": "15.4 패턴 상세 (Pattern details)\n이제 패턴 언어의 기초와 이를 stringr 및 tidyr 함수와 함께 사용하는 방법을 이해했으므로, 더 자세한 내용을 파헤쳐 볼 시간입니다. 먼저, 특별하게 취급될 메타문자를 일치시킬 수 있게 해주는 이스케이프(escaping)로 시작할 것입니다. 다음으로 문자열의 시작이나 끝을 일치시킬 수 있게 해주는 앵커(anchors)에 대해 배울 것입니다. 그 다음, 집합의 모든 문자와 일치시킬 수 있게 해주는 문자 클래스(character classes)와 그 단축형에 대해 더 자세히 알아볼 것입니다. 다음으로 패턴이 일치할 수 있는 횟수를 제어하는 수량자(quantifiers)의 마지막 세부 사항을 배울 것입니다. 그리고 중요하지만 복잡한 주제인 연산자 우선순위(operator precedence)와 괄호를 다뤄야 합니다. 마지막으로 패턴의 구성 요소를 그룹화(grouping)하는 세부 사항으로 마무리하겠습니다.\n여기서 사용하는 용어는 각 구성 요소의 기술적인 이름입니다. 항상 그 목적을 가장 잘 연상시키는 것은 아니지만, 나중에 더 자세한 내용을 구글링하려면 정확한 용어를 아는 것이 매우 도움이 됩니다.\n\n15.4.1 이스케이프 (Escaping)\n리터럴 .과 일치시키려면 정규 표현식에 메타문자6를 문자 그대로 일치시키도록 지시하는 이스케이프(escape)가 필요합니다. 문자열과 마찬가지로 정규 표현식은 이스케이프에 백슬래시를 사용합니다. 따라서 .과 일치시키려면 정규 표현식 \\.이 필요합니다. 불행히도 이것은 문제를 일으킵니다. 우리는 정규 표현식을 나타내기 위해 문자열을 사용하며, \\는 문자열에서도 이스케이프 기호로 사용됩니다. 따라서 정규 표현식 \\.을 만들려면 다음 예제와 같이 문자열 \"\\\\.\"이 필요합니다.\n\n# 정규 표현식 \\.를 만들려면 \\\\.를 사용해야 합니다.\ndot &lt;- \"\\\\.\"\n\n# 하지만 표현식 자체에는 \\가 하나만 포함됩니다.\nstr_view(dot)\n#&gt; [1] │ \\.\n\n# 그리고 이것은 R에게 명시적인 .을 찾으라고 지시합니다.\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n#&gt; [2] │ &lt;a.c&gt;\n\n이 책에서는 보통 \\.와 같이 따옴표 없이 정규 표현식을 작성할 것입니다. 실제로 입력해야 할 내용을 강조해야 하는 경우 \"\\\\.\"와 같이 따옴표로 묶고 추가 이스케이프를 추가할 것입니다.\n\\가 정규 표현식에서 이스케이프 문자로 사용된다면, 리터럴 \\는 어떻게 일치시킬까요? 음, 그것을 이스케이프하여 정규 표현식 \\\\를 만들어야 합니다. 그 정규 표현식을 만들려면 문자열을 사용해야 하는데, 문자열도 \\를 이스케이프해야 합니다. 즉, 리터럴 \\ 하나와 일치시키려면 \"\\\\\\\\\"를 작성해야 합니다. 하나를 일치시키기 위해 백슬래시 네 개가 필요합니다!\n\nx &lt;- \"a\\\\b\"\nstr_view(x)\n#&gt; [1] │ a\\b\nstr_view(x, \"\\\\\\\\\")\n#&gt; [1] │ a&lt;\\&gt;b\n\n대안으로, Section 14.2.2 에서 배운 원시 문자열(raw strings)을 사용하는 것이 더 쉬울 수 있습니다. 이렇게 하면 이스케이프 계층 하나를 피할 수 있습니다:\n\nstr_view(x, r\"{\\\\}\")\n#&gt; [1] │ a&lt;\\&gt;b\n\n리터럴 ., $, |, *, +, ?, {, }, (, )와 일치시키려는 경우 백슬래시 이스케이프를 사용하는 대신 문자 클래스를 사용할 수 있습니다: [.], [$], [|], … 모두 리터럴 값과 일치합니다.\n\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[.]c\")\n#&gt; [2] │ &lt;a.c&gt;\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \".[*]c\")\n#&gt; [3] │ &lt;a*c&gt;\n\n\n15.4.2 앵커 (Anchors)\n기본적으로 정규 표현식은 문자열의 어느 부분과도 일치합니다. 시작이나 끝에서 일치시키려면 ^를 사용하여 시작을 일치시키거나 $를 사용하여 끝을 일치시키도록 정규 표현식을 앵커(anchor)해야 합니다:\n\nstr_view(fruit, \"^a\")\n#&gt; [1] │ &lt;a&gt;pple\n#&gt; [2] │ &lt;a&gt;pricot\n#&gt; [3] │ &lt;a&gt;vocado\nstr_view(fruit, \"a$\")\n#&gt;  [4] │ banan&lt;a&gt;\n#&gt; [15] │ cherimoy&lt;a&gt;\n#&gt; [30] │ feijo&lt;a&gt;\n#&gt; [36] │ guav&lt;a&gt;\n#&gt; [56] │ papay&lt;a&gt;\n#&gt; [74] │ satsum&lt;a&gt;\n\n$가 문자열의 시작과 일치해야 한다고 생각하기 쉬운데, 달러 금액을 그렇게 쓰기 때문입니다. 하지만 정규 표현식이 원하는 것은 그게 아닙니다.\n정규 표현식이 전체 문자열과만 일치하도록 강제하려면 ^와 $로 모두 앵커를 걸어야 합니다:\n\nstr_view(fruit, \"apple\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [62] │ pine&lt;apple&gt;\nstr_view(fruit, \"^apple$\")\n#&gt; [1] │ &lt;apple&gt;\n\n또한 \\b를 사용하여 단어 사이의 경계(즉, 단어의 시작 또는 끝)를 일치시킬 수 있습니다. 이는 RStudio의 찾기 및 바꾸기 도구를 사용할 때 특히 유용할 수 있습니다. 예를 들어, sum()의 모든 사용을 찾으려면 \\bsum\\b를 검색하여 summarize, summary, rowsum 등과 일치하는 것을 피할 수 있습니다:\n\nx &lt;- c(\"summary(x)\", \"summarize(df)\", \"rowsum(x)\", \"sum(x)\")\nstr_view(x, \"sum\")\n#&gt; [1] │ &lt;sum&gt;mary(x)\n#&gt; [2] │ &lt;sum&gt;marize(df)\n#&gt; [3] │ row&lt;sum&gt;(x)\n#&gt; [4] │ &lt;sum&gt;(x)\nstr_view(x, \"\\\\bsum\\\\b\")\n#&gt; [4] │ &lt;sum&gt;(x)\n\n단독으로 사용될 때 앵커는 너비가 0인 일치(zero-width match)를 생성합니다:\n\nstr_view(\"abc\", c(\"$\", \"^\", \"\\\\b\"))\n#&gt; [1] │ abc&lt;&gt;\n#&gt; [2] │ &lt;&gt;abc\n#&gt; [3] │ &lt;&gt;abc&lt;&gt;\n\n이것은 독립형 앵커를 교체할 때 어떤 일이 발생하는지 이해하는 데 도움이 됩니다:\n\nstr_replace_all(\"abc\", c(\"$\", \"^\", \"\\\\b\"), \"--\")\n#&gt; [1] \"abc--\"   \"--abc\"   \"--abc--\"\n\n\n15.4.3 문자 클래스 (Character classes)\n문자 클래스 또는 문자 집합을 사용하면 집합 내의 모든 문자와 일치시킬 수 있습니다. 위에서 논의했듯이 []를 사용하여 자신만의 집합을 구성할 수 있습니다. 여기서 [abc]는 “a”, “b” 또는 “c”와 일치하고 [^abc]는 “a”, “b”, “c”를 제외한 모든 문자와 일치합니다. ^ 외에도 [] 내부에서 특별한 의미를 갖는 두 가지 다른 문자가 있습니다:\n\n\n-는 범위를 정의합니다. 예를 들어 [a-z]는 모든 소문자와 일치하고 [0-9]는 모든 숫자와 일치합니다.\n\n\\는 특수 문자를 이스케이프하므로 [\\^\\-\\]]는 ^, - 또는 ]와 일치합니다.\n\n몇 가지 예는 다음과 같습니다:\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"[abc]+\")\n#&gt; [1] │ &lt;abc&gt;d ABCD 12345 -!@#%.\nstr_view(x, \"[a-z]+\")\n#&gt; [1] │ &lt;abcd&gt; ABCD 12345 -!@#%.\nstr_view(x, \"[^a-z0-9]+\")\n#&gt; [1] │ abcd&lt; ABCD &gt;12345&lt; -!@#%.&gt;\n\n# [] 내부에서 특별한 문자를 일치시키려면 이스케이프가 필요합니다.\nstr_view(\"a-b-c\", \"[a-c]\")\n#&gt; [1] │ &lt;a&gt;-&lt;b&gt;-&lt;c&gt;\nstr_view(\"a-b-c\", \"[a\\\\-c]\")\n#&gt; [1] │ &lt;a&gt;&lt;-&gt;b&lt;-&gt;&lt;c&gt;\n\n일부 문자 클래스는 너무 자주 사용되어 자체 단축형을 가지고 있습니다. 이미 .을 보았는데, 이는 개행 문자를 제외한 모든 문자와 일치합니다. 특히 유용한 다른 세 쌍이 있습니다7:\n\n\n\\d는 모든 숫자와 일치합니다;\\D는 숫자가 아닌 모든 것과 일치합니다.\n\n\\s는 모든 공백(예: 스페이스, 탭, 개행)과 일치합니다;\\S는 공백이 아닌 모든 것과 일치합니다.\n\n\\w는 모든 “단어” 문자, 즉 문자와 숫자와 일치합니다;\\W는 모든 “비단어” 문자와 일치합니다.\n\n다음 코드는 문자, 숫자 및 구두점 문자의 선택으로 6가지 단축형을 보여줍니다.\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"\\\\d+\")\n#&gt; [1] │ abcd ABCD &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\D+\")\n#&gt; [1] │ &lt;abcd ABCD &gt;12345&lt; -!@#%.&gt;\nstr_view(x, \"\\\\s+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; &gt;-!@#%.\nstr_view(x, \"\\\\S+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; &lt;-!@#%.&gt;\nstr_view(x, \"\\\\w+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\W+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; -!@#%.&gt;\n\n\n15.4.4 수량자 (Quantifiers)\n수량자는 패턴이 일치하는 횟수를 제어합니다. Section 15.2 에서 ? (0회 또는 1회 일치), + (1회 이상 일치), * (0회 이상 일치)에 대해 배웠습니다. 예를 들어 colou?r는 미국식 또는 영국식 철자와 일치하고, \\d+는 하나 이상의 숫자와 일치하며, \\s?는 단일 공백 항목과 선택적으로 일치합니다. {}를 사용하여 일치 횟수를 정확하게 지정할 수도 있습니다:\n\n\n{n}: 정확히 n번 일치합니다.\n\n{n,}: 적어도 n번 일치합니다.\n\n{n,m}: n번에서 m번 사이로 일치합니다.\n\n15.4.5 연산자 우선순위와 괄호 (Operator precedence and parentheses)\nab+는 무엇과 일치할까요? “a” 뒤에 하나 이상의 “b”가 오는 것과 일치할까요, 아니면 “ab”가 횟수에 상관없이 반복되는 것과 일치할까요? ^a|b$는 무엇과 일치할까요? 완전한 문자열 a 또는 완전한 문자열 b와 일치할까요, 아니면 a로 시작하는 문자열 또는 b로 끝나는 문자열과 일치할까요?\n이 질문들에 대한 답은 학교에서 배웠을 PEMDAS 또는 BEDMAS 규칙과 유사한 연산자 우선순위에 의해 결정됩니다. a + b * c는 (a + b) * c가 아니라 a + (b * c)와 동일하다는 것을 알고 있습니다. 왜냐하면 *가 더 높은 우선순위를 가지고 +가 더 낮은 우선순위를 가지기 때문입니다: +보다 *를 먼저 계산합니다.\n마찬가지로 정규 표현식에도 고유한 우선순위 규칙이 있습니다: 수량자는 높은 우선순위를 가지고 대안(alternation)은 낮은 우선순위를 가집니다. 즉, ab+는 a(b+)와 동일하고 ^a|b$는 (^a)|(b$)와 동일합니다. 대수학에서와 마찬가지로 괄호를 사용하여 일반적인 순서를 재정의할 수 있습니다. 하지만 대수학과는 달리 정규 표현식의 우선순위 규칙을 기억하기 어려울 수 있으므로 괄호를 자유롭게 사용하세요.\n\n15.4.6 그룹화와 캡처 (Grouping and capturing)\n연산자 우선순위를 재정의하는 것 외에도 괄호는 또 다른 중요한 효과를 가집니다: 일치의 하위 구성 요소를 사용할 수 있게 해주는 캡처 그룹(capturing groups)을 생성합니다.\n캡처 그룹을 사용하는 첫 번째 방법은 역참조(back reference)를 사용하여 일치 내에서 다시 참조하는 것입니다: \\1은 첫 번째 괄호에 포함된 일치를 참조하고, \\2는 두 번째 괄호, 이런 식입니다. 예를 들어, 다음 패턴은 반복되는 문자 쌍이 있는 모든 과일을 찾습니다:\n\nstr_view(fruit, \"(..)\\\\1\")\n#&gt;  [4] │ b&lt;anan&gt;a\n#&gt; [20] │ &lt;coco&gt;nut\n#&gt; [22] │ &lt;cucu&gt;mber\n#&gt; [41] │ &lt;juju&gt;be\n#&gt; [56] │ &lt;papa&gt;ya\n#&gt; [73] │ s&lt;alal&gt; berry\n\n그리고 이것은 동일한 문자 쌍으로 시작하고 끝나는 모든 단어를 찾습니다:\n\nstr_view(words, \"^(..).*\\\\1$\")\n#&gt; [152] │ &lt;church&gt;\n#&gt; [217] │ &lt;decide&gt;\n#&gt; [617] │ &lt;photograph&gt;\n#&gt; [699] │ &lt;require&gt;\n#&gt; [739] │ &lt;sense&gt;\n\nstr_replace()에서도 역참조를 사용할 수 있습니다. 예를 들어, 이 코드는 sentences에서 두 번째와 세 번째 단어의 순서를 바꿉니다:\n\nsentences |&gt; \n  str_replace(\"(\\\\w+) (\\\\w+) (\\\\w+)\", \"\\\\1 \\\\3 \\\\2\") |&gt; \n  str_view()\n#&gt; [1] │ The canoe birch slid on the smooth planks.\n#&gt; [2] │ Glue sheet the to the dark blue background.\n#&gt; [3] │ It's to easy tell the depth of a well.\n#&gt; [4] │ These a days chicken leg is a rare dish.\n#&gt; [5] │ Rice often is served in round bowls.\n#&gt; [6] │ The of juice lemons makes fine punch.\n#&gt; ... and 714 more\n\n각 그룹에 대한 일치 항목을 추출하려면 str_match()를 사용할 수 있습니다. 하지만 str_match()는 행렬을 반환하므로 작업하기가 특별히 쉽지는 않습니다8:\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  head()\n#&gt;      [,1]                [,2]     [,3]    \n#&gt; [1,] \"the smooth planks\" \"smooth\" \"planks\"\n#&gt; [2,] \"the sheet to\"      \"sheet\"  \"to\"    \n#&gt; [3,] \"the depth of\"      \"depth\"  \"of\"    \n#&gt; [4,] NA                  NA       NA      \n#&gt; [5,] NA                  NA       NA      \n#&gt; [6,] NA                  NA       NA\n\n티블(tibble)로 변환하고 열 이름을 지정할 수 있습니다:\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  as_tibble(.name_repair = \"minimal\") |&gt; \n  set_names(\"match\", \"word1\", \"word2\")\n#&gt; # A tibble: 720 × 3\n#&gt;   match             word1  word2 \n#&gt;   &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 the smooth planks smooth planks\n#&gt; 2 the sheet to      sheet  to    \n#&gt; 3 the depth of      depth  of    \n#&gt; 4 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 5 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 6 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; # ℹ 714 more rows\n\n하지만 그러면 기본적으로 separate_wider_regex()의 자체 버전을 다시 만든 셈이 됩니다. 실제로 separate_wider_regex()는 내부적으로 패턴 벡터를 그룹화를 사용하여 명명된 구성 요소를 캡처하는 단일 정규 표현식으로 변환합니다.\n가끔은 일치 그룹을 생성하지 않고 괄호를 사용하고 싶을 때가 있습니다. (?:)를 사용하여 비캡처 그룹(non-capturing group)을 만들 수 있습니다.\n\nx &lt;- c(\"a gray cat\", \"a grey dog\")\nstr_match(x, \"gr(e|a)y\")\n#&gt;      [,1]   [,2]\n#&gt; [1,] \"gray\" \"a\" \n#&gt; [2,] \"grey\" \"e\"\nstr_match(x, \"gr(?:e|a)y\")\n#&gt;      [,1]  \n#&gt; [1,] \"gray\"\n#&gt; [2,] \"grey\"\n\n\n15.4.7 연습문제 (Exercises)\n\n리터럴 문자열 \"'\\와 어떻게 일치시키겠습니까? \"$^$\"는 어떻습니까?\n이 패턴들이 왜 \\와 일치하지 않는지 설명하세요: \"\\\", \"\\\\\", \"\\\\\\\".\n\nstringr::words의 일반적인 단어 코퍼스가 주어졌을 때, 다음 단어를 모두 찾는 정규 표현식을 만드세요:\n\n“y”로 시작하는 단어.\n“y”로 시작하지 않는 단어.\n“x”로 끝나는 단어.\n정확히 세 글자인 단어. (str_length()를 사용하여 속이지 마세요!)\n일곱 글자 이상인 단어.\n모음-자음 쌍이 포함된 단어.\n적어도 두 개의 모음-자음 쌍이 연속으로 포함된 단어.\n반복되는 모음-자음 쌍으로만 구성된 단어.\n\n\n다음 각 단어의 영국식 또는 미국식 철자와 일치하는 11개의 정규 표현식을 만드세요: airplane/aeroplane, aluminum/aluminium, analog/analogue, ass/arse, center/centre, defense/defence, donut/doughnut, gray/grey, modeling/modelling, skeptic/sceptic, summarize/summarise. 가능한 가장 짧은 정규 표현식을 만들어 보세요!\nwords에서 첫 글자와 마지막 글자를 바꾸세요. 그 문자열 중 여전히 words인 것은 무엇입니까?\n\n이 정규 표현식들이 무엇과 일치하는지 말로 설명하세요: (각 항목이 정규 표현식인지 아니면 정규 표현식을 정의하는 문자열인지 주의 깊게 읽으세요.)\n\n^.*$\n\"\\\\{.+\\\\}\"\n\\d{4}-\\d{2}-\\d{2}\n\"\\\\\\\\{4}\"\n\\..\\..\\..\n(.)\\1\\1\n\"(..)\\\\1\"\n\n\nhttps://regexcrossword.com/challenges/beginner 에서 초보자용 정규 표현식 십자말풀이를 풀어보세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#패턴-제어-pattern-control",
    "href": "regexps.html#패턴-제어-pattern-control",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "\n15.5 패턴 제어 (Pattern control)",
    "text": "15.5 패턴 제어 (Pattern control)\n단순한 문자열 대신 패턴 객체를 사용하여 일치의 세부 사항에 대해 추가적인 제어를 행사할 수 있습니다. 이를 통해 아래 설명된 대로 소위 정규 표현식 플래그를 제어하고 다양한 유형의 고정 문자열을 일치시킬 수 있습니다.\n\n15.5.1 정규 표현식 플래그 (Regex flags)\n정규 표현식의 세부 사항을 제어하는 데 사용할 수 있는 여러 설정이 있습니다. 이러한 설정은 다른 프로그래밍 언어에서 종종 플래그(flags)라고 불립니다. stringr에서는 regex() 호출로 패턴을 감싸서 이를 사용할 수 있습니다. 가장 유용한 플래그는 아마도 ignore_case = TRUE일 것입니다. 이를 통해 문자가 대문자 또는 소문자 형태 모두와 일치할 수 있기 때문입니다:\n\nbananas &lt;- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n#&gt; [1] │ &lt;banana&gt;\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n#&gt; [1] │ &lt;banana&gt;\n#&gt; [2] │ &lt;Banana&gt;\n#&gt; [3] │ &lt;BANANA&gt;\n\n여러 줄 문자열(즉, \\n이 포함된 문자열)로 많은 작업을 하는 경우 dotall과 multiline도 유용할 수 있습니다:\n\n\ndotall = TRUE는 .이 \\n을 포함한 모든 것과 일치하게 합니다:\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \".Line\")\n#&gt; ✖ Empty `string` provided.\nstr_view(x, regex(\".Line\", dotall = TRUE))\n#&gt; [1] │ Line 1&lt;\n#&gt;     │ Line&gt; 2&lt;\n#&gt;     │ Line&gt; 3\n\n\n\nmultiline = TRUE는 ^와 $가 전체 문자열의 시작과 끝이 아니라 각 줄의 시작과 끝과 일치하게 합니다:\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \"^Line\")\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ Line 2\n#&gt;     │ Line 3\nstr_view(x, regex(\"^Line\", multiline = TRUE))\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ &lt;Line&gt; 2\n#&gt;     │ &lt;Line&gt; 3\n\n\n\n마지막으로, 복잡한 정규 표현식을 작성하고 있고 나중에 이해하지 못할까 봐 걱정된다면 comments = TRUE를 시도해 볼 수 있습니다. 이것은 패턴 언어를 조정하여 공백과 새 줄, 그리고 # 뒤의 모든 것을 무시하게 합니다. 이를 통해 다음 예제와 같이 주석과 공백을 사용하여 복잡한 정규 표현식을 더 이해하기 쉽게 만들 수 있습니다9:\n\nphone &lt;- regex(\n  r\"(\n    \\(?     # 선택적 여는 괄호\n    (\\d{3}) # 지역 번호\n    [)\\-]?  # 선택적 닫는 괄호 또는 대시\n    \\ ?     # 선택적 공백\n    (\\d{3}) # 또 다른 세 숫자\n    [\\ -]?  # 선택적 공백 또는 대시\n    (\\d{4}) # 네 개의 추가 숫자\n  )\", \n  comments = TRUE\n)\n\nstr_extract(c(\"514-791-8141\", \"(123) 456 7890\", \"123456\"), phone)\n#&gt; [1] \"514-791-8141\"   \"(123) 456 7890\" NA\n\n주석을 사용하면서 공백, 개행 또는 #과 일치시키려면 \\로 이스케이프해야 합니다.\n\n15.5.2 고정 일치 (Fixed matches)\nfixed()를 사용하여 정규 표현식 규칙에서 제외(opt-out)할 수 있습니다:\n\nstr_view(c(\"\", \"a\", \".\"), fixed(\".\"))\n#&gt; [3] │ &lt;.&gt;\n\nfixed()는 대소문자를 무시하는 기능도 제공합니다:\n\nstr_view(\"x X\", \"X\")\n#&gt; [1] │ x &lt;X&gt;\nstr_view(\"x X\", fixed(\"X\", ignore_case = TRUE))\n#&gt; [1] │ &lt;x&gt; &lt;X&gt;\n\n영어가 아닌 텍스트로 작업하는 경우 fixed() 대신 coll()을 원할 것입니다. coll()은 지정한 locale에서 사용하는 대문자화에 대한 전체 규칙을 구현하기 때문입니다. 로케일에 대한 자세한 내용은 Section 14.6 를 참조하세요.\n\nstr_view(\"i İ ı I\", fixed(\"İ\", ignore_case = TRUE))\n#&gt; [1] │ i &lt;İ&gt; ı I\nstr_view(\"i İ ı I\", coll(\"İ\", ignore_case = TRUE, locale = \"tr\"))\n#&gt; [1] │ &lt;i&gt; &lt;İ&gt; ı I",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#실습-practice",
    "href": "regexps.html#실습-practice",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "\n15.6 실습 (Practice)",
    "text": "15.6 실습 (Practice)\n이러한 아이디어를 실습하기 위해 다음으로 몇 가지 반(semi)-실제적인 문제를 해결해 보겠습니다. 세 가지 일반적인 기술에 대해 논의할 것입니다:\n\n간단한 긍정 및 부정 대조군(controls)을 생성하여 작업 확인하기\n정규 표현식과 불리언 대수(Boolean algebra) 결합하기\n문자열 조작을 사용하여 복잡한 패턴 생성하기\n\n\n15.6.1 작업 확인 (Check your work)\n먼저, “The”로 시작하는 모든 문장을 찾아봅시다. ^ 앵커만 사용하는 것으로는 충분하지 않습니다:\n\nstr_view(sentences, \"^The\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [4] │ &lt;The&gt;se days a chicken leg is a rare dish.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; ... and 271 more\n\n왜냐하면 그 패턴은 They나 These와 같은 단어로 시작하는 문장과도 일치하기 때문입니다. “e”가 단어의 마지막 글자인지 확인해야 하는데, 이는 단어 경계를 추가하여 수행할 수 있습니다:\n\nstr_view(sentences, \"^The\\\\b\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; [13] │ &lt;The&gt; source of the huge river is the clear spring.\n#&gt; ... and 250 more\n\n대명사로 시작하는 모든 문장을 찾는 것은 어떨까요?\n\nstr_view(sentences, \"^She|He|It|They\\\\b\")\n#&gt;  [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt; [15] │ &lt;He&gt;lp the woman get back to her feet.\n#&gt; [27] │ &lt;He&gt;r purse was full of useless trash.\n#&gt; [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt; [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt; [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; ... and 57 more\n\n결과를 빠르게 검사해 보면 가짜 일치(spurious matches)가 발생하고 있음을 알 수 있습니다. 이는 괄호를 사용하는 것을 잊었기 때문입니다:\n\nstr_view(sentences, \"^(She|He|It|They)\\\\b\")\n#&gt;   [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt;  [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt;  [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt;  [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; [116] │ &lt;He&gt; ordered peach pie with ice cream.\n#&gt; [127] │ &lt;It&gt; caught its hind paw in a rusty trap.\n#&gt; ... and 51 more\n\n처음 몇 개의 일치 항목에서 발생하지 않았다면 그러한 실수를 어떻게 발견할 수 있을지 궁금할 것입니다. 좋은 기술은 몇 가지 긍정 및 부정 일치를 생성하고 이를 사용하여 패턴이 예상대로 작동하는지 테스트하는 것입니다:\n\npos &lt;- c(\"He is a boy\", \"She had a good time\")\nneg &lt;- c(\"Shells come from the sea\", \"Hadley said 'It's a great day'\")\n\npattern &lt;- \"^(She|He|It|They)\\\\b\"\nstr_detect(pos, pattern)\n#&gt; [1] TRUE TRUE\nstr_detect(neg, pattern)\n#&gt; [1] FALSE FALSE\n\n일반적으로 부정적인 예보다 좋은 긍정적인 예를 생각해 내는 것이 훨씬 쉽습니다. 정규 표현식에 충분히 익숙해져서 자신의 약점이 어디인지 예측할 수 있게 되기까지는 시간이 걸리기 때문입니다. 그럼에도 불구하고 그것들은 여전히 유용합니다: 문제를 작업하면서 천천히 실수의 컬렉션을 축적하여 같은 실수를 두 번 다시 하지 않도록 할 수 있습니다.\n\n15.6.2 불리언 연산 (Boolean operations)\n자음만 포함된 단어를 찾고 싶다고 상상해 보세요. 한 가지 기술은 모음을 제외한 모든 문자를 포함하는 문자 클래스([^aeiou])를 만든 다음, 그것이 임의의 수의 문자와 일치하도록 허용하고([^aeiou]+), 시작과 끝에 앵커를 걸어 전체 문자열과 일치하도록 강제하는 것입니다(^[^aeiou]+$):\n\nstr_view(words, \"^[^aeiou]+$\")\n#&gt; [123] │ &lt;by&gt;\n#&gt; [249] │ &lt;dry&gt;\n#&gt; [328] │ &lt;fly&gt;\n#&gt; [538] │ &lt;mrs&gt;\n#&gt; [895] │ &lt;try&gt;\n#&gt; [952] │ &lt;why&gt;\n\n하지만 문제를 뒤집어서 이 문제를 좀 더 쉽게 만들 수 있습니다. 자음만 포함된 단어를 찾는 대신, 모음이 하나도 포함되지 않은 단어를 찾을 수 있습니다:\n\nstr_view(words[!str_detect(words, \"[aeiou]\")])\n#&gt; [1] │ by\n#&gt; [2] │ dry\n#&gt; [3] │ fly\n#&gt; [4] │ mrs\n#&gt; [5] │ try\n#&gt; [6] │ why\n\n이것은 논리적 조합, 특히 “and” 또는 “not”과 관련된 조합을 다룰 때마다 유용한 기술입니다. 예를 들어, “a”와 “b”가 포함된 모든 단어를 찾고 싶다고 상상해 보세요. 정규 표현식에는 “and” 연산자가 내장되어 있지 않으므로, “a” 뒤에 “b”가 오거나 “b” 뒤에 “a”가 오는 모든 단어를 찾는 방식으로 해결해야 합니다:\n\nstr_view(words, \"a.*b|b.*a\")\n#&gt;  [2] │ &lt;ab&gt;le\n#&gt;  [3] │ &lt;ab&gt;out\n#&gt;  [4] │ &lt;ab&gt;solute\n#&gt; [62] │ &lt;availab&gt;le\n#&gt; [66] │ &lt;ba&gt;by\n#&gt; [67] │ &lt;ba&gt;ck\n#&gt; ... and 24 more\n\n두 번의 str_detect() 호출 결과를 결합하는 것이 더 간단합니다:\n\nwords[str_detect(words, \"a\") & str_detect(words, \"b\")]\n#&gt;  [1] \"able\"      \"about\"     \"absolute\"  \"available\" \"baby\"      \"back\"     \n#&gt;  [7] \"bad\"       \"bag\"       \"balance\"   \"ball\"      \"bank\"      \"bar\"      \n#&gt; [13] \"base\"      \"basis\"     \"bear\"      \"beat\"      \"beauty\"    \"because\"  \n#&gt; [19] \"black\"     \"board\"     \"boat\"      \"break\"     \"brilliant\" \"britain\"  \n#&gt; [25] \"debate\"    \"husband\"   \"labour\"    \"maybe\"     \"probable\"  \"table\"\n\n모든 모음이 포함된 단어가 있는지 확인하고 싶다면 어떨까요? 패턴으로 한다면 5! (120)개의 서로 다른 패턴을 생성해야 합니다:\n\nwords[str_detect(words, \"a.*e.*i.*o.*u\")]\n# ...\nwords[str_detect(words, \"u.*o.*i.*e.*a\")]\n\n다섯 번의 str_detect() 호출을 결합하는 것이 훨씬 간단합니다:\n\nwords[\n  str_detect(words, \"a\") &\n  str_detect(words, \"e\") &\n  str_detect(words, \"i\") &\n  str_detect(words, \"o\") &\n  str_detect(words, \"u\")\n]\n#&gt; character(0)\n\n일반적으로 문제를 해결하는 단일 정규 표현식을 만들다가 막히면, 한 걸음 물러서서 문제를 더 작은 조각으로 나누어 다음 단계로 넘어가기 전에 각 과제를 해결할 수 있는지 생각해 보세요.\n\n15.6.3 코드로 패턴 생성하기 (Creating a pattern with code)\n색상을 언급하는 모든 sentences를 찾고 싶다면 어떨까요? 기본 아이디어는 간단합니다: 대안(alternation)을 단어 경계와 결합하기만 하면 됩니다.\n\nstr_view(sentences, \"\\\\b(red|green|blue)\\\\b\")\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [148] │ The spot on the blotter was made by &lt;green&gt; ink.\n#&gt; [160] │ The sofa cushion is &lt;red&gt; and of light weight.\n#&gt; [174] │ The sky that morning was clear and bright &lt;blue&gt;.\n#&gt; ... and 20 more\n\n하지만 색상의 수가 늘어나면 이 패턴을 손으로 구성하는 것은 금방 지루해질 것입니다. 색상을 벡터에 저장할 수 있다면 좋지 않을까요?\n\nrgb &lt;- c(\"red\", \"green\", \"blue\")\n\n음, 할 수 있습니다! str_c()와 str_flatten()을 사용하여 벡터에서 패턴을 생성하기만 하면 됩니다:\n\nstr_c(\"\\\\b(\", str_flatten(rgb, \"|\"), \")\\\\b\")\n#&gt; [1] \"\\\\b(red|green|blue)\\\\b\"\n\n좋은 색상 목록이 있다면 이 패턴을 더 포괄적으로 만들 수 있습니다. 시작할 수 있는 한 곳은 R이 플롯에 사용할 수 있는 내장 색상 목록입니다:\n\nstr_view(colors())\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ antiquewhite1\n#&gt; [5] │ antiquewhite2\n#&gt; [6] │ antiquewhite3\n#&gt; ... and 651 more\n\n하지만 먼저 번호가 매겨진 변형을 제거해 봅시다:\n\ncols &lt;- colors()\ncols &lt;- cols[!str_detect(cols, \"\\\\d\")]\nstr_view(cols)\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ aquamarine\n#&gt; [5] │ azure\n#&gt; [6] │ beige\n#&gt; ... and 137 more\n\n그런 다음 이것을 하나의 거대한 패턴으로 바꿀 수 있습니다. 패턴이 너무 커서 여기서는 보여주지 않겠지만, 작동하는 것을 볼 수 있습니다:\n\npattern &lt;- str_c(\"\\\\b(\", str_flatten(cols, \"|\"), \")\\\\b\")\nstr_view(sentences, pattern)\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [12] │ A rod is used to catch &lt;pink&gt; &lt;salmon&gt;.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [66] │ Cars and busses stalled in &lt;snow&gt; drifts.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [112] │ Leaves turn &lt;brown&gt; and &lt;yellow&gt; in the fall.\n#&gt; ... and 57 more\n\n이 예제에서 cols에는 문자와 숫자만 포함되어 있으므로 메타문자에 대해 걱정할 필요가 없습니다. 하지만 일반적으로 기존 문자열에서 패턴을 생성할 때는 str_escape()를 통해 실행하여 문자 그대로 일치하도록 하는 것이 현명합니다.\n\n15.6.4 연습문제 (Exercises)\n\n\n다음 각 과제에 대해 단일 정규 표현식과 여러 str_detect() 호출의 조합을 모두 사용하여 해결해 보세요.\n\n\nx로 시작하거나 끝나는 모든 words를 찾으세요.\n모음으로 시작하고 자음으로 끝나는 모든 words를 찾으세요.\n각기 다른 모음이 적어도 하나씩 포함된 words가 있나요?\n\n\n“c 뒤가 아니면 e 앞에 i (i before e except after c)” 규칙에 대한 증거와 반대 증거를 찾는 패턴을 구성하세요.\ncolors()에는 “lightgray” 및 “darkblue”와 같은 여러 수식어가 포함되어 있습니다. 이러한 수식어를 어떻게 자동으로 식별할 수 있을까요? (수식된 색상을 감지한 다음 제거하는 방법을 생각해 보세요).\n기본 R(base R) 데이터셋을 찾는 정규 표현식을 만드세요. data() 함수의 특별한 사용을 통해 이러한 데이터셋 목록을 얻을 수 있습니다: data(package = \"datasets\")$results[, \"Item\"]. 많은 오래된 데이터셋은 개별 벡터입니다; 이들은 괄호 안에 그룹화 “데이터 프레임”의 이름을 포함하고 있으므로 이를 제거해야 합니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#다른-곳에서의-정규-표현식-regular-expressions-in-other-places",
    "href": "regexps.html#다른-곳에서의-정규-표현식-regular-expressions-in-other-places",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "\n15.7 다른 곳에서의 정규 표현식 (Regular expressions in other places)",
    "text": "15.7 다른 곳에서의 정규 표현식 (Regular expressions in other places)\nstringr 및 tidyr 함수에서와 마찬가지로 R에는 정규 표현식을 사용할 수 있는 다른 많은 곳이 있습니다. 다음 섹션에서는 더 넓은 tidyverse와 기본 R(base R)의 다른 유용한 함수들을 설명합니다.\n\n15.7.1 tidyverse\n정규 표현식을 사용하고 싶을 만한 다른 세 가지 특히 유용한 곳이 있습니다.\n\nmatches(pattern)은 이름이 제공된 패턴과 일치하는 모든 변수를 선택합니다. 이것은 변수를 선택하는 모든 tidyverse 함수(예: select(), rename_with(), across())에서 사용할 수 있는 “tidyselect” 함수입니다.\npivot_longer()의 names_pattern 인수는 separate_wider_regex()와 마찬가지로 정규 표현식 벡터를 받습니다. 복잡한 구조를 가진 변수 이름에서 데이터를 추출할 때 유용합니다.\nseparate_longer_delim() 및 separate_wider_delim()의 delim 인수는 일반적으로 고정 문자열과 일치하지만, regex()를 사용하여 패턴과 일치하도록 만들 수 있습니다. 예를 들어, 선택적으로 공백이 뒤따르는 쉼표, 즉 regex(\", ?\")와 일치시키려는 경우 유용합니다.\n\n15.7.2 기본 R (Base R)\napropos(pattern)은 전역 환경에서 사용할 수 있는 객체 중 주어진 패턴과 일치하는 모든 객체를 검색합니다. 함수 이름이 잘 기억나지 않을 때 유용합니다:\n\napropos(\"replace\")\n#&gt; [1] \"%+replace%\"       \"replace\"          \"replace_na\"      \n#&gt; [4] \"replace_theme\"    \"setReplaceMethod\" \"str_replace\"     \n#&gt; [7] \"str_replace_all\"  \"str_replace_na\"   \"theme_replace\"\n\nlist.files(path, pattern)은 path에 있는 파일 중 정규 표현식 pattern과 일치하는 모든 파일을 나열합니다. 예를 들어, 다음을 사용하여 현재 디렉터리의 모든 R Markdown 파일을 찾을 수 있습니다:\n\nhead(list.files(pattern = \"\\\\.Rmd$\"))\n#&gt; character(0)\n\n기본 R에서 사용하는 패턴 언어는 stringr에서 사용하는 것과 아주 약간 다르다는 점에 유의할 가치가 있습니다. 이는 stringr이 stringi 패키지 위에 구축되었고, stringi는 다시 ICU 엔진 위에 구축된 반면, 기본 R 함수는 perl = TRUE 설정 여부에 따라 TRE 엔진 또는 PCRE 엔진을 사용하기 때문입니다. 다행히 정규 표현식의 기초는 매우 잘 확립되어 있어 이 책에서 배울 패턴으로 작업할 때 변형을 거의 겪지 않을 것입니다. 복잡한 유니코드 문자 범위와 같은 고급 기능이나 (?…) 구문을 사용하는 특수 기능에 의존하기 시작할 때만 차이점을 인지하면 됩니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#요약-summary",
    "href": "regexps.html#요약-summary",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "\n15.8 요약 (Summary)",
    "text": "15.8 요약 (Summary)\n모든 구두점 문자가 잠재적으로 의미로 과부하되어 있는 정규 표현식은 가장 간결한 언어 중 하나입니다. 처음에는 확실히 혼란스럽지만, 눈으로 읽고 뇌로 이해하도록 훈련하면 R과 다른 많은 곳에서 사용할 수 있는 강력한 기술을 잠금 해제하게 됩니다.\n이 장에서는 가장 유용한 stringr 함수와 정규 표현식 언어의 가장 중요한 구성 요소를 학습하여 정규 표현식 마스터가 되기 위한 여정을 시작했습니다. 그리고 더 배울 수 있는 자료가 많이 있습니다.\n시작하기 좋은 곳은 vignette(\"regular-expressions\", package = \"stringr\")입니다: stringr이 지원하는 전체 구문 집합을 문서화하고 있습니다. 또 다른 유용한 참고 자료는 https://www.regular-expressions.info/입니다. R에 특화된 것은 아니지만, 정규 표현식의 가장 고급 기능과 내부 작동 방식에 대해 배우는 데 사용할 수 있습니다.\nstringr이 Marek Gagolewski의 stringi 패키지 위에 구현되었다는 것을 아는 것도 좋습니다. stringr에서 필요한 기능을 수행하는 함수를 찾는 데 어려움을 겪고 있다면 stringi를 찾아보는 것을 두려워하지 마세요. stringi는 stringr과 동일한 규칙을 많이 따르기 때문에 매우 쉽게 익힐 수 있습니다.\n다음 장에서는 문자열과 밀접하게 관련된 데이터 구조인 팩터(factors)에 대해 이야기하겠습니다. 팩터는 R에서 범주형 데이터, 즉 문자열 벡터로 식별되는 고정되고 알려진 가능한 값 집합을 가진 데이터를 나타내는 데 사용됩니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "regexps.html#footnotes",
    "href": "regexps.html#footnotes",
    "title": "15  정규 표현식 (Regular expressions)",
    "section": "",
    "text": "‘레젝스’(hard-g) 또는 ‘레직스’(soft-g)로 발음할 수 있습니다.↩︎\nSection 15.4.1 에서 이러한 특수 의미를 이스케이프(escape)하는 방법을 배울 것입니다.↩︎\n음, \\n을 제외한 모든 문자입니다.↩︎\n이것은 “x”가 포함된 이름의 비율을 제공합니다. x가 포함된 이름을 가진 아기의 비율을 원한다면 가중 평균을 수행해야 합니다.↩︎\n실제 생활에서는 이렇게 이상한 것을 절대 볼 수 없을 거라고 안심시켜 드리고 싶지만, 불행히도 경력을 쌓다 보면 훨씬 더 이상한 것들을 보게 될 것입니다!↩︎\n메타문자의 전체 집합은 .^$\\|*+?{}[]() 입니다.↩︎\n\\d 또는 \\s가 포함된 정규 표현식을 만들려면 문자열에 대해 \\를 이스케이프해야 하므로 \"\\\\d\" 또는 \"\\\\s\"를 입력해야 함을 기억하세요.↩︎\n주로 이 책에서 행렬에 대해 논의하지 않기 때문입니다!↩︎\ncomments = TRUE는 여기서 사용하는 것처럼 원시 문자열과 결합할 때 특히 효과적입니다.↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>정규 표현식 (Regular expressions)</span>"
    ]
  },
  {
    "objectID": "factors.html",
    "href": "factors.html",
    "title": "16  팩터(Factors)",
    "section": "",
    "text": "16.1 소개\n팩터(Factors)는 범주형 변수, 즉 고정되고 알려진 가능한 값 집합을 가진 변수에 사용됩니다. 또한 문자 벡터를 알파벳 순서가 아닌 순서로 표시하려는 경우에도 유용합니다.\n데이터 분석을 위해 팩터가 필요한 이유1와 factor()로 팩터를 생성하는 방법부터 시작하겠습니다. 그런 다음 실험할 수 있는 많은 범주형 변수가 포함된 gss_cat 데이터셋을 소개합니다. 그 후 해당 데이터셋을 사용하여 팩터의 순서와 값을 수정하는 연습을 한 다음, 순서형 팩터에 대한 논의로 마무리하겠습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#소개",
    "href": "factors.html#소개",
    "title": "16  팩터(Factors)",
    "section": "",
    "text": "16.1.1 선수 지식\n기본(base) R은 팩터를 생성하고 조작하기 위한 몇 가지 기본 도구를 제공합니다. 핵심 tidyverse의 일부인 forcats 패키지로 이를 보완할 것입니다. 이 패키지는 팩터 작업을 위한 광범위한 도우미를 사용하여 범주형(categorical) 변수(그리고 factors의 애너그램입니다!)를 다루는 도구를 제공합니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#팩터-기초",
    "href": "factors.html#팩터-기초",
    "title": "16  팩터(Factors)",
    "section": "\n16.2 팩터 기초",
    "text": "16.2 팩터 기초\n월을 기록하는 변수가 있다고 상상해 보세요:\n\nx1 &lt;- c(\"Dec\", \"Apr\", \"Jan\", \"Mar\")\n\n문자열을 사용하여 이 변수를 기록하면 두 가지 문제가 있습니다:\n\n\n가능한 달은 12개뿐이며 오타로부터 당신을 구해줄 것이 없습니다:\n\nx2 &lt;- c(\"Dec\", \"Apr\", \"Jam\", \"Mar\")\n\n\n\n유용한 방식으로 정렬되지 않습니다:\n\nsort(x1)\n#&gt; [1] \"Apr\" \"Dec\" \"Jan\" \"Mar\"\n\n\n\n팩터를 사용하여 이 두 가지 문제를 모두 해결할 수 있습니다. 팩터를 생성하려면 유효한 수준(levels) 의 리스트를 생성하는 것으로 시작해야 합니다:\n\nmonth_levels &lt;- c(\n  \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n  \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n)\n\n이제 팩터를 만들 수 있습니다:\n\ny1 &lt;- factor(x1, levels = month_levels)\ny1\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nsort(y1)\n#&gt; [1] Jan Mar Apr Dec\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n그리고 수준에 없는 값은 조용히 NA로 변환됩니다:\n\ny2 &lt;- factor(x2, levels = month_levels)\ny2\n#&gt; [1] Dec  Apr  &lt;NA&gt; Mar \n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n이것은 위험해 보이므로 대신 forcats::fct()를 사용하고 싶을 수 있습니다:\n\ny2 &lt;- fct(x2, levels = month_levels)\n#&gt; Error in `fct()`:\n#&gt; ! All values of `x` must appear in `levels` or `na`\n#&gt; ℹ Missing level: \"Jam\"\n\n수준을 생략하면 데이터에서 알파벳 순서로 가져옵니다:\n\nfactor(x1)\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Apr Dec Jan Mar\n\n알파벳 순서로 정렬하는 것은 모든 컴퓨터가 문자열을 같은 방식으로 정렬하지 않기 때문에 약간 위험합니다. 따라서 forcats::fct()는 첫 번째 등장 순서로 정렬합니다:\n\nfct(x1)\n#&gt; [1] Dec Apr Jan Mar\n#&gt; Levels: Dec Apr Jan Mar\n\n유효한 수준 집합에 직접 액세스해야 하는 경우 levels()를 사용하여 수행할 수 있습니다:\n\nlevels(y2)\n#&gt;  [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\ncol_factor()를 사용하여 readr로 데이터를 읽을 때 팩터를 생성할 수도 있습니다:\n\ncsv &lt;- \"\nmonth,value\nJan,12\nFeb,56\nMar,12\"\n\ndf &lt;- read_csv(csv, col_types = cols(month = col_factor(month_levels)))\ndf$month\n#&gt; [1] Jan Feb Mar\n#&gt; Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#종합-사회-조사general-social-survey",
    "href": "factors.html#종합-사회-조사general-social-survey",
    "title": "16  팩터(Factors)",
    "section": "\n16.3 종합 사회 조사(General Social Survey)",
    "text": "16.3 종합 사회 조사(General Social Survey)\n이 장의 나머지 부분에서는 forcats::gss_cat을 사용할 것입니다. 이것은 시카고 대학의 독립 연구 기관인 NORC가 수행하는 장기 미국 설문 조사인 종합 사회 조사(General Social Survey)의 데이터 샘플입니다. 설문 조사에는 수천 개의 질문이 있으므로 gss_cat에서 해들리(Hadley)는 팩터로 작업할 때 직면하게 될 몇 가지 일반적인 문제를 설명할 수 있는 몇 가지를 선택했습니다.\n\ngss_cat\n#&gt; # A tibble: 21,483 × 9\n#&gt;    year marital         age race  rincome        partyid           \n#&gt;   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;             \n#&gt; 1  2000 Never married    26 White $8000 to 9999  Ind,near rep      \n#&gt; 2  2000 Divorced         48 White $8000 to 9999  Not str republican\n#&gt; 3  2000 Widowed          67 White Not applicable Independent       \n#&gt; 4  2000 Never married    39 White Not applicable Ind,near rep      \n#&gt; 5  2000 Divorced         25 White Not applicable Not str democrat  \n#&gt; 6  2000 Married          25 White $20000 - 24999 Strong democrat   \n#&gt; # ℹ 21,477 more rows\n#&gt; # ℹ 3 more variables: relig &lt;fct&gt;, denom &lt;fct&gt;, tvhours &lt;int&gt;\n\n(이 데이터셋은 패키지에서 제공하므로 ?gss_cat으로 변수에 대한 자세한 정보를 얻을 수 있음을 기억하세요.)\n팩터가 티블에 저장되어 있으면 수준을 그렇게 쉽게 볼 수 없습니다. 보는 한 가지 방법은 count()를 사용하는 것입니다:\n\ngss_cat |&gt;\n  count(race)\n#&gt; # A tibble: 3 × 2\n#&gt;   race      n\n#&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1 Other  1959\n#&gt; 2 Black  3129\n#&gt; 3 White 16395\n\n팩터로 작업할 때 가장 일반적인 두 가지 작업은 수준의 순서를 변경하는 것과 수준의 값을 변경하는 것입니다. 이러한 작업은 아래 섹션에 설명되어 있습니다.\n\n16.3.1 연습문제\n\nrincome(보고된 소득)의 분포를 탐색하세요. 기본 막대 차트를 이해하기 어렵게 만드는 것은 무엇입니까? 플롯을 어떻게 개선할 수 있습니까?\n이 설문 조사에서 가장 흔한 relig는 무엇입니까? 가장 흔한 partyid는 무엇입니까?\ndenom(교파)은 어떤 relig에 적용됩니까? 테이블로 어떻게 알아낼 수 있습니까? 시각화로 어떻게 알아낼 수 있습니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-modifying-factor-order",
    "href": "factors.html#sec-modifying-factor-order",
    "title": "16  팩터(Factors)",
    "section": "\n16.4 팩터 순서 수정",
    "text": "16.4 팩터 순서 수정\n시각화에서 팩터 수준의 순서를 변경하는 것이 유용한 경우가 많습니다. 예를 들어 종교 전반에 걸쳐 하루 평균 TV 시청 시간을 탐색하고 싶다고 상상해 보세요:\n\nrelig_summary &lt;- gss_cat |&gt;\n  group_by(relig) |&gt;\n  summarize(\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(relig_summary, aes(x = tvhours, y = relig)) +\n  geom_point()\n\n\n\n\n\n\n\n전체적인 패턴이 없기 때문에 이 플롯을 읽기 어렵습니다. fct_reorder()를 사용하여 relig의 수준을 재정렬하여 개선할 수 있습니다. fct_reorder()는 세 가지 인수를 취합니다:\n\n\n.f, 수준을 수정하려는 팩터.\n\n.x, 수준을 재정렬하는 데 사용하려는 수치형 벡터.\n선택적으로 .fun, .f의 각 값에 대해 .x의 값이 여러 개 있는 경우 사용되는 함수. 기본값은 median입니다.\n\n\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n  geom_point()\n\n\n\n\n\n\n\n종교를 재정렬하면 “Don’t know” 범주의 사람들이 TV를 훨씬 더 많이 보고 힌두교 및 기타 동양 종교는 훨씬 덜 본다는 것을 훨씬 쉽게 알 수 있습니다.\n더 복잡한 변환을 만들기 시작하면 aes() 밖으로 이동하여 별도의 mutate() 단계로 옮기는 것이 좋습니다. 예를 들어 위의 플롯을 다음과 같이 다시 쓸 수 있습니다:\n\nrelig_summary |&gt;\n  mutate(\n    relig = fct_reorder(relig, tvhours)\n  ) |&gt;\n  ggplot(aes(x = tvhours, y = relig)) +\n  geom_point()\n\n보고된 소득 수준에 따라 평균 연령이 어떻게 변하는지 살펴보는 유사한 플롯을 만들면 어떨까요?\n\nrincome_summary &lt;- gss_cat |&gt;\n  group_by(rincome) |&gt;\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(rincome_summary, aes(x = age, y = fct_reorder(rincome, age))) +\n  geom_point()\n\n\n\n\n\n\n\n여기서 수준을 임의로 재정렬하는 것은 좋은 생각이 아닙니다! rincome은 이미 우리가 건드려서는 안 되는 원칙적인 순서를 가지고 있기 때문입니다. fct_reorder()는 수준이 임의로 정렬된 팩터에만 사용하세요.\n그러나 “Not applicable”을 다른 특수 수준과 함께 맨 앞으로 끌어오는 것은 의미가 있습니다. fct_relevel()을 사용할 수 있습니다. 이것은 팩터 .f와 줄의 맨 앞으로 이동하려는 임의의 수의 수준을 취합니다.\n\nggplot(rincome_summary, aes(x = age, y = fct_relevel(rincome, \"Not applicable\"))) +\n  geom_point()\n\n\n\n\n\n\n\n“Not applicable”의 평균 연령이 그렇게 높은 이유는 무엇이라고 생각합니까?\n플롯의 선에 색상을 입힐 때 유용한 또 다른 유형의 재정렬이 있습니다. fct_reorder2(.f, .x, .y)는 가장 큰 .x 값과 연관된 .y 값으로 팩터 .f를 재정렬합니다. 이렇게 하면 플롯의 맨 오른쪽에 있는 선의 색상이 범례와 정렬되기 때문에 플롯을 읽기 쉬워집니다.\nby_age &lt;- gss_cat |&gt;\n  filter(!is.na(age)) |&gt;\n  count(age, marital) |&gt;\n  group_by(age) |&gt;\n  mutate(\n    prop = n / sum(n)\n  )\n\nggplot(by_age, aes(x = age, y = prop, color = marital)) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\")\n\nggplot(by_age, aes(x = age, y = prop, color = fct_reorder2(marital, age, prop))) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(color = \"marital\")\n\n\n\n\n\n\n\n\n\n\n마지막으로 막대 플롯의 경우 fct_infreq()를 사용하여 빈도 내림차순으로 수준을 정렬할 수 있습니다. 추가 변수가 필요하지 않기 때문에 가장 간단한 재정렬 유형입니다. 막대 플롯에서 가장 큰 값이 왼쪽이 아닌 오른쪽에 오도록 빈도 오름차순으로 하려면 fct_rev()와 결합하세요.\n\ngss_cat |&gt;\n  mutate(marital = marital |&gt; fct_infreq() |&gt; fct_rev()) |&gt;\n  ggplot(aes(x = marital)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n16.4.1 연습문제\n\ntvhours에 의심스럽게 높은 숫자가 몇 개 있습니다. 평균이 좋은 요약입니까?\ngss_cat의 각 팩터에 대해 수준의 순서가 임의적인지 원칙적인지 식별하세요.\n“Not applicable”을 수준의 맨 앞으로 이동시켰는데 왜 플롯의 맨 아래로 이동했습니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#팩터-수준-수정",
    "href": "factors.html#팩터-수준-수정",
    "title": "16  팩터(Factors)",
    "section": "\n16.5 팩터 수준 수정",
    "text": "16.5 팩터 수준 수정\n수준의 순서를 변경하는 것보다 더 강력한 것은 값을 변경하는 것입니다. 이를 통해 출판을 위해 레이블을 명확히 하고 상위 수준 디스플레이를 위해 수준을 축소할 수 있습니다. 가장 일반적이고 강력한 도구는 fct_recode()입니다. 각 수준의 값을 다시 코딩하거나 변경할 수 있습니다. 예를 들어 gss_cat 데이터 프레임의 partyid 변수를 가져와 보겠습니다:\n\ngss_cat |&gt; count(partyid)\n#&gt; # A tibble: 10 × 2\n#&gt;   partyid                n\n#&gt;   &lt;fct&gt;              &lt;int&gt;\n#&gt; 1 No answer            154\n#&gt; 2 Don't know             1\n#&gt; 3 Other party          393\n#&gt; 4 Strong republican   2314\n#&gt; 5 Not str republican  3032\n#&gt; 6 Ind,near rep        1791\n#&gt; # ℹ 4 more rows\n\n수준이 간결하고 일관성이 없습니다. 더 길게 수정하고 병렬 구조를 사용해 보겠습니다. tidyverse의 대부분의 이름 바꾸기 및 다시 코딩 함수와 마찬가지로 새 값은 왼쪽에 가고 이전 값은 오른쪽에 갑니다:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\"\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 10 × 2\n#&gt;   partyid                   n\n#&gt;   &lt;fct&gt;                 &lt;int&gt;\n#&gt; 1 No answer               154\n#&gt; 2 Don't know                1\n#&gt; 3 Other party             393\n#&gt; 4 Republican, strong     2314\n#&gt; 5 Republican, weak       3032\n#&gt; 6 Independent, near rep  1791\n#&gt; # ℹ 4 more rows\n\nfct_recode()는 명시적으로 언급되지 않은 수준은 그대로 두고 존재하지 않는 수준을 실수로 참조하면 경고합니다.\n그룹을 결합하기 위해 여러 이전 수준을 동일한 새 수준에 할당할 수 있습니다:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\",\n      \"Other\"                 = \"No answer\",\n      \"Other\"                 = \"Don't know\",\n      \"Other\"                 = \"Other party\"\n    )\n  )\n\n이 기술을 주의해서 사용하세요. 진정으로 다른 범주를 함께 그룹화하면 오해의 소지가 있는 결과를 초래할 수 있습니다.\n많은 수준을 축소하려는 경우 fct_collapse()가 fct_recode()의 유용한 변형입니다. 각 새 변수에 대해 이전 수준의 벡터를 제공할 수 있습니다:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_collapse(partyid,\n      \"other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n      \"rep\" = c(\"Strong republican\", \"Not str republican\"),\n      \"ind\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n      \"dem\" = c(\"Not str democrat\", \"Strong democrat\")\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 4 × 2\n#&gt;   partyid     n\n#&gt;   &lt;fct&gt;   &lt;int&gt;\n#&gt; 1 other     548\n#&gt; 2 rep      5346\n#&gt; 3 ind      8409\n#&gt; 4 dem      7180\n\n때로는 플롯이나 테이블을 더 간단하게 만들기 위해 작은 그룹을 덩어리로 묶고 싶을 때가 있습니다. 그것이 fct_lump_*() 함수 패밀리의 역할입니다. fct_lump_lowfreq()는 가장 작은 그룹 범주를 “Other”로 점진적으로 묶는 간단한 시작점이며, 항상 “Other”를 가장 작은 범주로 유지합니다.\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_lowfreq(relig)) |&gt;\n  count(relig)\n#&gt; # A tibble: 2 × 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Other      10637\n\n이 경우 별로 도움이 되지 않습니다. 이 설문 조사의 대다수 미국인이 개신교인 것은 사실이지만 아마도 더 자세한 내용을 보고 싶을 것입니다! 대신 fct_lump_n()을 사용하여 정확히 10개의 그룹을 원한다고 지정할 수 있습니다:\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_n(relig, n = 10)) |&gt;\n  count(relig, sort = TRUE)\n#&gt; # A tibble: 10 × 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Catholic    5124\n#&gt; 3 None        3523\n#&gt; 4 Christian    689\n#&gt; 5 Other        458\n#&gt; 6 Jewish       388\n#&gt; # ℹ 4 more rows\n\n다른 경우에 유용한 fct_lump_min() 및 fct_lump_prop()에 대해 알아보려면 문서를 읽어보세요.\n\n16.5.1 연습문제\n\n민주당, 공화당, 무소속으로 식별되는 사람들의 비율은 시간이 지남에 따라 어떻게 변했습니까?\nrincome을 어떻게 작은 범주 집합으로 축소할 수 있습니까?\n위의 fct_lump 예제에 9개의 그룹(other 제외)이 있음을 주목하세요. 왜 10개가 아닙니까? (힌트: ?fct_lump를 입력하고 other_level 인수의 기본값이 “Other”인지 확인하세요.)",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-ordered-factors",
    "href": "factors.html#sec-ordered-factors",
    "title": "16  팩터(Factors)",
    "section": "\n16.6 순서형 팩터(Ordered factors)",
    "text": "16.6 순서형 팩터(Ordered factors)\n계속하기 전에 특수 유형의 팩터인 순서형 팩터에 대해 간단히 언급하는 것이 중요합니다. ordered() 함수로 생성된 순서형 팩터는 수준 간의 엄격한 순서를 의미하지만 수준 간의 차이의 크기에 대해서는 아무것도 지정하지 않습니다. 수준에 순위가 있지만 정확한 수치적 순위가 없음을 알 때 순서형 팩터를 사용합니다.\n인쇄될 때 팩터 수준 사이에 &lt; 기호를 사용하므로 순서형 팩터를 식별할 수 있습니다:\n\nordered(c(\"a\", \"b\", \"c\"))\n#&gt; [1] a b c\n#&gt; Levels: a &lt; b &lt; c\n\n기본 R과 tidyverse 모두에서 순서형 팩터는 일반 팩터와 매우 유사하게 작동합니다. 동작의 차이를 알아차릴 수 있는 곳은 두 곳뿐입니다:\n\n순서형 팩터를 ggplot2의 color 또는 fill에 매핑하면 순위를 암시하는 색상 척도인 scale_color_viridis()/scale_fill_viridis()가 기본값이 됩니다.\n선형 모델에서 순서형 예측 변수를 사용하면 “다항식 대비(polynomial contrasts)”를 사용합니다. 이것들은 약간 유용하지만 통계학 박사 학위가 있지 않는 한 들어본 적이 없을 것이며, 그렇다 하더라도 아마 일상적으로 해석하지는 않을 것입니다. 더 알고 싶다면 Lisa DeBruine의 vignette(\"contrasts\", package = \"faux\")를 추천합니다.\n\n이 책의 목적을 위해 일반 팩터와 순서형 팩터를 올바르게 구별하는 것은 특별히 중요하지 않습니다. 그러나 더 넓게 보면 특정 분야(특히 사회 과학)에서는 순서형 팩터를 광범위하게 사용합니다. 이러한 맥락에서는 다른 분석 패키지가 적절한 동작을 제공할 수 있도록 올바르게 식별하는 것이 중요합니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#요약",
    "href": "factors.html#요약",
    "title": "16  팩터(Factors)",
    "section": "\n16.7 요약",
    "text": "16.7 요약\n이 장에서는 팩터 작업을 위한 편리한 forcats 패키지를 소개하고 가장 일반적으로 사용되는 함수를 소개했습니다. forcats에는 여기서 논의할 공간이 없었던 다른 다양한 도우미가 포함되어 있으므로 이전에 경험해보지 못한 요인 분석 문제에 직면할 때마다 참조 색인을 훑어보고 문제를 해결하는 데 도움이 될 수 있는 미리 준비된 함수가 있는지 확인하는 것을 강력히 추천합니다.\n이 장을 읽은 후 팩터에 대해 더 알고 싶다면 Amelia McNamara와 Nicholas Horton의 논문 Wrangling categorical data in R을 읽어보는 것을 추천합니다. 이 논문은 stringsAsFactors: An unauthorized biography 및 stringsAsFactors = &lt;sigh&gt;에서 논의된 역사의 일부를 설명하고 이 책에 설명된 범주형 데이터에 대한 깔끔한 접근 방식과 기본 R 방법을 비교합니다. 논문의 초기 버전은 forcats 패키지에 동기를 부여하고 범위를 지정하는 데 도움이 되었습니다. Amelia와 Nick에게 감사합니다!\n다음 장에서는 기어를 바꿔 R에서 날짜와 시간에 대해 배우기 시작할 것입니다. 날짜와 시간은 겉보기에는 단순해 보이지만 곧 알게 되겠지만 더 많이 알수록 더 복잡해지는 것 같습니다!",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "factors.html#footnotes",
    "href": "factors.html#footnotes",
    "title": "16  팩터(Factors)",
    "section": "",
    "text": "모델링에도 정말 중요합니다.↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>팩터(Factors)</span>"
    ]
  },
  {
    "objectID": "datetimes.html",
    "href": "datetimes.html",
    "title": "17  날짜와 시간",
    "section": "",
    "text": "17.1 소개\n이 장에서는 R에서 날짜와 시간으로 작업하는 방법을 보여줄 것입니다. 언뜻 보기에 날짜와 시간은 간단해 보입니다. 일상 생활에서 항상 사용하며 큰 혼란을 일으키지 않는 것 같습니다. 하지만 날짜와 시간에 대해 더 많이 알수록 더 복잡해지는 것 같습니다!\n워밍업으로 1년에 며칠이 있는지, 하루에 몇 시간이 있는지 생각해 보세요. 대부분의 연도에는 365일이 있지만 윤년에는 366일이 있다는 것을 기억할 것입니다. 연도가 윤년인지 확인하는 전체 규칙을 알고 있습니까1? 하루의 시간 수는 조금 덜 분명합니다. 대부분의 날은 24시간이지만 일광 절약 시간제(DST)를 사용하는 곳에서는 매년 하루는 23시간이고 다른 하루는 25시간입니다.\n날짜와 시간은 두 가지 물리적 현상(지구의 자전과 태양 공전)과 달, 시간대, DST를 포함한 수많은 지정학적 현상을 조화시켜야 하기 때문에 어렵습니다. 이 장에서는 날짜와 시간의 모든 세부 사항을 가르치지는 않지만 일반적인 데이터 분석 과제에 도움이 될 실용적인 기술의 탄탄한 기초를 제공할 것입니다.\n다양한 입력에서 날짜-시간을 생성하는 방법을 보여주는 것으로 시작하여 날짜-시간이 생기면 연도, 월, 일과 같은 구성 요소를 추출하는 방법을 보여줄 것입니다. 그런 다음 수행하려는 작업에 따라 다양한 종류가 있는 시간 스팬(time spans)으로 작업하는 까다로운 주제에 대해 자세히 알아볼 것입니다. 시간대로 인해 발생하는 추가 문제에 대한 간략한 논의로 마무리하겠습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "datetimes.html#소개",
    "href": "datetimes.html#소개",
    "title": "17  날짜와 시간",
    "section": "",
    "text": "17.1.1 선수 지식\n이 장에서는 R에서 날짜와 시간을 더 쉽게 다룰 수 있게 해주는 lubridate 패키지에 초점을 맞출 것입니다. 최신 tidyverse 릴리스부터 lubridate는 핵심 tidyverse의 일부입니다. 연습 데이터로 nycflights13도 필요합니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(nycflights13)",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "datetimes.html#sec-creating-datetimes",
    "href": "datetimes.html#sec-creating-datetimes",
    "title": "17  날짜와 시간",
    "section": "\n17.2 날짜/시간 생성",
    "text": "17.2 날짜/시간 생성\n시간의 한 순간을 나타내는 세 가지 유형의 날짜/시간 데이터가 있습니다:\n\n날짜(Date). 티블은 이것을 &lt;date&gt;로 인쇄합니다.\n하루 중 시간(Time). 티블은 이것을 &lt;time&gt;으로 인쇄합니다.\n날짜-시간(Date-time) 은 날짜에 시간을 더한 것입니다. 시간의 한 순간을 고유하게 식별합니다(일반적으로 가장 가까운 초까지). 티블은 이것을 &lt;dttm&gt;으로 인쇄합니다. 기본 R은 이것을 POSIXct라고 부르지만 발음하기 쉽지는 않습니다.\n\n이 장에서는 R에 시간을 저장하기 위한 기본 클래스가 없으므로 날짜와 날짜-시간에 집중할 것입니다. 필요한 경우 hms 패키지를 사용할 수 있습니다.\n항상 필요에 맞는 가장 간단한 데이터 유형을 사용해야 합니다. 즉, 날짜-시간 대신 날짜를 사용할 수 있다면 그렇게 해야 합니다. 날짜-시간은 시간대를 처리해야 하므로 상당히 더 복잡합니다. 이 장의 마지막 부분에서 다시 다룰 것입니다.\n현재 날짜나 날짜-시간을 얻으려면 today() 또는 now()를 사용할 수 있습니다:\n\ntoday()\n#&gt; [1] \"2025-12-25\"\nnow()\n#&gt; [1] \"2025-12-25 01:33:20 KST\"\n\n그렇지 않은 경우 다음 섹션에서는 날짜/시간을 생성할 가능성이 있는 네 가지 방법을 설명합니다:\n\nreadr로 파일을 읽는 동안.\n문자열에서.\n개별 날짜-시간 구성 요소에서.\n기존 날짜/시간 객체에서.\n\n\n17.2.1 가져오는 동안\nCSV에 ISO8601 날짜 또는 날짜-시간이 포함되어 있으면 아무것도 할 필요가 없습니다. readr이 자동으로 인식합니다:\n\ncsv &lt;- \"\n  date,datetime\n  2022-01-02,2022-01-02 05:12\n\"\nread_csv(csv)\n#&gt; # A tibble: 1 × 2\n#&gt;   date       datetime           \n#&gt;   &lt;date&gt;     &lt;dttm&gt;             \n#&gt; 1 2022-01-02 2022-01-02 05:12:00\n\nISO8601을 들어본 적이 없다면 날짜의 구성 요소가 가장 큰 것부터 가장 작은 것 순으로 -로 구분되어 구성되는 날짜 쓰기 국제 표준2입니다. 예를 들어 ISO8601에서 2022년 5월 3일은 2022-05-03입니다. ISO8601 날짜에는 시, 분, 초가 :로 구분되고 날짜와 시간 구성 요소가 T 또는 공백으로 구분되는 시간도 포함될 수 있습니다. 예를 들어 2022년 5월 3일 오후 4시 26분을 2022-05-03 16:26 또는 2022-05-03T16:26으로 쓸 수 있습니다.\n다른 날짜-시간 형식의 경우 날짜-시간 형식과 함께 col_types와 col_date() 또는 col_datetime()을 사용해야 합니다. readr에서 사용하는 날짜-시간 형식은 많은 프로그래밍 언어에서 사용되는 표준이며 % 뒤에 단일 문자로 날짜 구성 요소를 설명합니다. 예를 들어 %Y-%m-%d는 연도, -, 월(숫자), -, 일인 날짜를 지정합니다. 표 Table 17.1 은 모든 옵션을 나열합니다.\n\n\nTable 17.1: readr이 이해하는 모든 날짜 형식\n\n\n\n유형\n코드\n의미\n예\n\n\n\n연도\n%Y\n4자리 연도\n2021\n\n\n\n%y\n2자리 연도\n21\n\n\n월\n%m\n숫자\n2\n\n\n\n%b\n약어 이름\nFeb\n\n\n\n%B\n전체 이름\nFebruary\n\n\n일\n%d\n한 자리 또는 두 자리\n2\n\n\n\n%e\n두 자리\n02\n\n\n시간\n%H\n24시간제 시\n13\n\n\n\n%I\n12시간제 시\n1\n\n\n\n%p\nAM/PM\npm\n\n\n\n%M\n분\n35\n\n\n\n%S\n초\n45\n\n\n\n%OS\n소수 부분이 있는 초\n45.35\n\n\n\n%Z\n시간대 이름\nAmerica/Chicago\n\n\n\n%z\nUTC로부터의 오프셋\n+0800\n\n\n기타\n%.\n숫자가 아닌 문자 하나 건너뛰기\n:\n\n\n\n%*\n숫자가 아닌 문자 여러 개 건너뛰기\n\n\n\n\n\n\n\n그리고 이 코드는 매우 모호한 날짜에 적용된 몇 가지 옵션을 보여줍니다:\n\ncsv &lt;- \"\n  date\n  01/02/15\n\"\n\nread_csv(csv, col_types = cols(date = col_date(\"%m/%d/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-01-02\n\nread_csv(csv, col_types = cols(date = col_date(\"%d/%m/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-02-01\n\nread_csv(csv, col_types = cols(date = col_date(\"%y/%m/%d\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2001-02-15\n\n날짜 형식을 어떻게 지정하든 R로 가져오면 항상 같은 방식으로 표시된다는 점에 유의하세요.\n%b 또는 %B를 사용하고 영어가 아닌 날짜로 작업하는 경우 locale()도 제공해야 합니다. date_names_langs()의 기본 제공 언어 목록을 보거나 date_names()로 직접 만드세요.\n\n17.2.2 문자열에서\n날짜-시간 사양 언어는 강력하지만 날짜 형식에 대한 신중한 분석이 필요합니다. 대안적인 접근 방식은 구성 요소의 순서를 지정하면 형식을 자동으로 결정하려고 시도하는 lubridate의 도우미를 사용하는 것입니다. 사용하려면 날짜에 연도, 월, 일이 나타나는 순서를 확인한 다음 “y”, “m”, “d”를 같은 순서로 배열하세요. 그러면 날짜를 파싱할 lubridate 함수의 이름이 됩니다. 예를 들어:\n\nymd(\"2017-01-31\")\n#&gt; [1] \"2017-01-31\"\nmdy(\"January 31st, 2017\")\n#&gt; [1] \"2017-01-31\"\ndmy(\"31-Jan-2017\")\n#&gt; [1] \"2017-01-31\"\n\nymd()와 친구들은 날짜를 생성합니다. 날짜-시간을 생성하려면 파싱 함수 이름에 밑줄과 “h”, “m”, “s” 중 하나 이상을 추가하세요:\n\nymd_hms(\"2017-01-31 20:11:59\")\n#&gt; [1] \"2017-01-31 20:11:59 UTC\"\nmdy_hm(\"01/31/2017 08:01\")\n#&gt; [1] \"2017-01-31 08:01:00 UTC\"\n\n시간대를 제공하여 날짜에서 날짜-시간 생성을 강제할 수도 있습니다:\n\nymd(\"2017-01-31\", tz = \"UTC\")\n#&gt; [1] \"2017-01-31 UTC\"\n\n여기서는 UTC3 시간대를 사용했는데, GMT 또는 그리니치 표준시, 경도 0도에서의 시간4으로 알고 있을 수도 있습니다. 일광 절약 시간제를 사용하지 않아 계산하기가 조금 더 쉽습니다.\n\n17.2.3 개별 구성 요소에서\n단일 문자열 대신 날짜-시간의 개별 구성 요소가 여러 열에 분산되어 있을 때가 있습니다. 이것이 flights 데이터에 있는 것입니다:\n\nflights |&gt; \n  select(year, month, day, hour, minute)\n#&gt; # A tibble: 336,776 × 5\n#&gt;    year month   day  hour minute\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  2013     1     1     5     15\n#&gt; 2  2013     1     1     5     29\n#&gt; 3  2013     1     1     5     40\n#&gt; 4  2013     1     1     5     45\n#&gt; 5  2013     1     1     6      0\n#&gt; 6  2013     1     1     5     58\n#&gt; # ℹ 336,770 more rows\n\n이런 종류의 입력에서 날짜/시간을 생성하려면 날짜의 경우 make_date(), 날짜-시간의 경우 make_datetime()을 사용하세요:\n\nflights |&gt; \n  select(year, month, day, hour, minute) |&gt; \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year month   day  hour minute departure          \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n#&gt; 1  2013     1     1     5     15 2013-01-01 05:15:00\n#&gt; 2  2013     1     1     5     29 2013-01-01 05:29:00\n#&gt; 3  2013     1     1     5     40 2013-01-01 05:40:00\n#&gt; 4  2013     1     1     5     45 2013-01-01 05:45:00\n#&gt; 5  2013     1     1     6      0 2013-01-01 06:00:00\n#&gt; 6  2013     1     1     5     58 2013-01-01 05:58:00\n#&gt; # ℹ 336,770 more rows\n\nflights의 4개 시간 열 각각에 대해 동일한 작업을 수행해 보겠습니다. 시간이 약간 이상한 형식으로 표현되어 있으므로 모듈러 연산을 사용하여 시와 분 구성 요소를 뽑아냅니다. 날짜-시간 변수를 생성한 후 이 장의 나머지 부분에서 탐색할 변수에 집중합니다.\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\nflights_dt &lt;- flights |&gt; \n  filter(!is.na(dep_time), !is.na(arr_time)) |&gt; \n  mutate(\n    dep_time = make_datetime_100(year, month, day, dep_time),\n    arr_time = make_datetime_100(year, month, day, arr_time),\n    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)\n  ) |&gt; \n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\nflights_dt\n#&gt; # A tibble: 328,063 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n#&gt; 2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n#&gt; 3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n#&gt; 4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n#&gt; 5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n#&gt; 6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n#&gt; # ℹ 328,057 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\n이 데이터를 사용하여 일년 내내 출발 시간 분포를 시각화할 수 있습니다:\n\nflights_dt |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 86400) # 86400초 = 1일\n\n\n\n\n\n\n\n또는 하루 안에:\n\nflights_dt |&gt; \n  filter(dep_time &lt; ymd(20130102)) |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 600) # 600초 = 10분\n\n\n\n\n\n\n\n숫자 맥락(예: 히스토그램)에서 날짜-시간을 사용할 때 1은 1초를 의미하므로 86400의 binwidth는 하루를 의미합니다. 날짜의 경우 1은 1일을 의미합니다.\n\n17.2.4 다른 유형에서\n날짜-시간과 날짜 사이를 전환하고 싶을 수 있습니다. 그것이 as_datetime()과 as_date()의 역할입니다:\n\nas_datetime(today())\n#&gt; [1] \"2025-12-25 UTC\"\nas_date(now())\n#&gt; [1] \"2025-12-25\"\n\n때때로 “Unix Epoch”인 1970-01-01로부터의 숫자 오프셋으로 날짜/시간을 얻을 수 있습니다. 오프셋이 초 단위이면 as_datetime()을 사용하고, 일 단위이면 as_date()를 사용하세요.\n\nas_datetime(60 * 60 * 10)\n#&gt; [1] \"1970-01-01 10:00:00 UTC\"\nas_date(365 * 10 + 2)\n#&gt; [1] \"1980-01-01\"\n\n\n17.2.5 연습문제\n\n\n유효하지 않은 날짜가 포함된 문자열을 파싱하면 어떻게 됩니까?\n\nymd(c(\"2010-10-10\", \"bananas\"))\n\n\ntoday()의 tzone 인수는 무엇을 합니까? 왜 중요합니까?\n\n다음 각 날짜-시간에 대해 readr 열 사양과 lubridate 함수를 사용하여 파싱하는 방법을 보여주세요.\n\nd1 &lt;- \"January 1, 2010\"\nd2 &lt;- \"2015-Mar-07\"\nd3 &lt;- \"06-Jun-2017\"\nd4 &lt;- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 &lt;- \"12/30/14\" # 2014년 12월 30일\nt1 &lt;- \"1705\"\nt2 &lt;- \"11:15:10.12 PM\"",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "datetimes.html#날짜-시간-구성-요소",
    "href": "datetimes.html#날짜-시간-구성-요소",
    "title": "17  날짜와 시간",
    "section": "\n17.3 날짜-시간 구성 요소",
    "text": "17.3 날짜-시간 구성 요소\n이제 R의 날짜-시간 데이터 구조로 날짜-시간 데이터를 가져오는 방법을 알았으니, 무엇을 할 수 있는지 살펴보겠습니다. 이 섹션에서는 개별 구성 요소를 가져오고 설정할 수 있는 접근자(accessor) 함수에 초점을 맞출 것입니다. 다음 섹션에서는 산술이 날짜-시간과 어떻게 작동하는지 살펴보겠습니다.\n\n17.3.1 구성 요소 가져오기\n접근자 함수 year(), month(), mday()(월의 일), yday()(연도의 일), wday()(요일), hour(), minute(), second()로 날짜의 개별 부분을 뽑아낼 수 있습니다. 이것들은 사실상 make_datetime()의 반대입니다.\n\ndatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n#&gt; [1] 2026\nmonth(datetime)\n#&gt; [1] 7\nmday(datetime)\n#&gt; [1] 8\n\nyday(datetime)\n#&gt; [1] 189\nwday(datetime)\n#&gt; [1] 4\n\nmonth()와 wday()의 경우 label = TRUE를 설정하여 월이나 요일의 약어 이름을 반환할 수 있습니다. 전체 이름을 반환하려면 abbr = FALSE를 설정하세요.\n\nmonth(datetime, label = TRUE)\n#&gt; [1] Jul\n#&gt; 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\nwday(datetime, label = TRUE, abbr = FALSE)\n#&gt; [1] Wednesday\n#&gt; 7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday\n\nwday()를 사용하여 주말보다 주중에 더 많은 항공편이 출발한다는 것을 확인할 수 있습니다:\n\nflights_dt |&gt; \n  mutate(wday = wday(dep_time, label = TRUE)) |&gt; \n  ggplot(aes(x = wday)) +\n  geom_bar()\n\n\n\n\n\n\n\n시간 내 분별 평균 출발 지연도 볼 수 있습니다. 흥미로운 패턴이 있습니다: 20-30분 및 50-60분에 출발하는 항공편은 나머지 시간대보다 지연이 훨씬 적습니다!\n\nflights_dt |&gt; \n  mutate(minute = minute(dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE),\n    n = n()\n  ) |&gt; \n  ggplot(aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\n흥미롭게도 예정된 출발 시간을 보면 그렇게 강력한 패턴이 보이지 않습니다:\n\nsched_dep &lt;- flights_dt |&gt; \n  mutate(minute = minute(sched_dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(sched_dep, aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\n그렇다면 실제 출발 시간에서 왜 그런 패턴이 보일까요? 음, 사람이 수집한 많은 데이터와 마찬가지로 Figure 17.1 에서 볼 수 있듯이 “좋은” 출발 시간에 항공편이 출발하는 쪽으로 강한 편향이 있습니다. 사람의 판단이 포함된 데이터로 작업할 때는 항상 이런 종류의 패턴에 주의하세요!\n\n\n\n\n\n\n\nFigure 17.1: 매 시간 출발하도록 예정된 항공편 수를 보여주는 빈도 다각형. 0과 30과 같은 둥근 숫자에 대한 선호도가 강하고 일반적으로 5의 배수인 숫자에 대한 선호도가 강함을 알 수 있습니다.\n\n\n\n\n\n17.3.2 반올림\n개별 구성 요소를 플롯하는 대안적인 접근 방식은 floor_date(), round_date(), ceiling_date()를 사용하여 날짜를 가까운 시간 단위로 반올림하는 것입니다. 각 함수는 조정할 날짜 벡터와 내림(floor), 올림(ceiling) 또는 반올림(round)할 단위 이름을 취합니다. 예를 들어 이를 통해 주당 항공편 수를 플롯할 수 있습니다:\n\nflights_dt |&gt; \n  count(week = floor_date(dep_time, \"week\")) |&gt; \n  ggplot(aes(x = week, y = n)) +\n  geom_line() + \n  geom_point()\n\n\n\n\n\n\n\n반올림을 사용하여 dep_time과 해당 날짜의 가장 이른 순간 간의 차이를 계산하여 하루 동안의 항공편 분포를 보여줄 수 있습니다:\n\nflights_dt |&gt; \n  mutate(dep_hour = dep_time - floor_date(dep_time, \"day\")) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n#&gt; Don't know how to automatically pick scale for object of type &lt;difftime&gt;.\n#&gt; Defaulting to continuous.\n\n\n\n\n\n\n\n한 쌍의 날짜-시간 간의 차이를 계산하면 difftime이 생성됩니다(Section 17.4.3 에서 자세히 설명). 더 유용한 x축을 얻기 위해 이를 hms 객체로 변환할 수 있습니다:\n\nflights_dt |&gt; \n  mutate(dep_hour = hms::as_hms(dep_time - floor_date(dep_time, \"day\"))) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n\n\n\n\n\n\n\n\n17.3.3 구성 요소 수정\n각 접근자 함수를 사용하여 날짜/시간의 구성 요소를 수정할 수도 있습니다. 데이터 분석에서는 많이 나오지 않지만, 명백히 잘못된 날짜가 있는 데이터를 정리할 때 유용할 수 있습니다.\n\n(datetime &lt;- ymd_hms(\"2026-07-08 12:34:56\"))\n#&gt; [1] \"2026-07-08 12:34:56 UTC\"\n\nyear(datetime) &lt;- 2030\ndatetime\n#&gt; [1] \"2030-07-08 12:34:56 UTC\"\nmonth(datetime) &lt;- 01\ndatetime\n#&gt; [1] \"2030-01-08 12:34:56 UTC\"\nhour(datetime) &lt;- hour(datetime) + 1\ndatetime\n#&gt; [1] \"2030-01-08 13:34:56 UTC\"\n\n또는 기존 변수를 수정하는 대신 update()로 새 날짜-시간을 만들 수 있습니다. 이것은 한 단계로 여러 값을 설정할 수도 있습니다:\n\nupdate(datetime, year = 2030, month = 2, mday = 2, hour = 2)\n#&gt; [1] \"2030-02-02 02:34:56 UTC\"\n\n값이 너무 크면 롤오버됩니다:\n\nupdate(ymd(\"2023-02-01\"), mday = 30)\n#&gt; [1] \"2023-03-02\"\nupdate(ymd(\"2023-02-01\"), hour = 400)\n#&gt; [1] \"2023-02-17 16:00:00 UTC\"\n\n\n17.3.4 연습문제\n\n하루 중 비행 시간 분포는 일년 내내 어떻게 변합니까?\ndep_time, sched_dep_time, dep_delay를 비교하세요. 일관성이 있습니까? 발견한 내용을 설명하세요.\nair_time을 출발과 도착 사이의 기간과 비교하세요. 발견한 내용을 설명하세요. (힌트: 공항의 위치를 고려하세요.)\n평균 지연 시간은 하루 동안 어떻게 변합니까? dep_time을 사용해야 할까요, sched_dep_time을 사용해야 할까요? 이유는 무엇입니까?\n지연 가능성을 최소화하려면 요일 중 언제 출발해야 합니까?\ndiamonds$carat과 flights$sched_dep_time의 분포를 유사하게 만드는 것은 무엇입니까?\n20-30분 및 50-60분의 항공편 조기 출발이 일찍 출발하는 예정된 항공편으로 인해 발생한다는 가설을 확인하세요. 힌트: 항공편이 지연되었는지 여부를 알려주는 이진 변수를 만드세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "datetimes.html#시간-스팬time-spans",
    "href": "datetimes.html#시간-스팬time-spans",
    "title": "17  날짜와 시간",
    "section": "\n17.4 시간 스팬(Time spans)",
    "text": "17.4 시간 스팬(Time spans)\n다음으로 뺄셈, 덧셈, 나눗셈을 포함하여 날짜 산술이 어떻게 작동하는지 배울 것입니다. 그 과정에서 시간 스팬을 나타내는 세 가지 중요한 클래스에 대해 배우게 됩니다:\n\n\n지속 시간(Durations), 정확한 초 수를 나타냅니다.\n\n기간(Periods), 주 및 월과 같은 인간 단위를 나타냅니다.\n\n구간(Intervals), 시작점과 끝점을 나타냅니다.\n\n지속 시간, 기간, 구간 중에서 어떻게 선택합니까? 항상 그렇듯이 문제를 해결하는 가장 간단한 데이터 구조를 선택하세요. 물리적 시간만 중요하다면 지속 시간을 사용하세요. 인간 시간을 추가해야 한다면 기간을 사용하세요. 스팬이 인간 단위로 얼마나 긴지 파악해야 한다면 구간을 사용하세요.\n\n17.4.1 지속 시간(Durations)\nR에서 두 날짜를 빼면 difftime 객체를 얻습니다:\n\n# 해들리는 몇 살입니까?\nh_age &lt;- today() - ymd(\"1979-10-14\")\nh_age\n#&gt; Time difference of 16874 days\n\ndifftime 클래스 객체는 초, 분, 시, 일 또는 주 단위의 시간 스팬을 기록합니다. 이 모호함은 difftime 작업을 약간 고통스럽게 만들 수 있으므로 lubridate는 항상 초를 사용하는 대안인 지속 시간(duration) 을 제공합니다.\n\nas.duration(h_age)\n#&gt; [1] \"1457913600s (~46.2 years)\"\n\n지속 시간은 편리한 생성자 무더기와 함께 제공됩니다:\n\ndseconds(15)\n#&gt; [1] \"15s\"\ndminutes(10)\n#&gt; [1] \"600s (~10 minutes)\"\ndhours(c(12, 24))\n#&gt; [1] \"43200s (~12 hours)\" \"86400s (~1 days)\"\nddays(0:5)\n#&gt; [1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n#&gt; [4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\ndweeks(3)\n#&gt; [1] \"1814400s (~3 weeks)\"\ndyears(1)\n#&gt; [1] \"31557600s (~1 years)\"\n\n지속 시간은 항상 시간 스팬을 초 단위로 기록합니다. 더 큰 단위는 분, 시, 일, 주, 연을 초로 변환하여 생성됩니다. 1분은 60초, 1시간은 60분, 하루는 24시간, 1주는 7일입니다. 더 큰 시간 단위는 더 문제가 됩니다. 1년은 “평균” 일 수, 즉 365.25일을 사용합니다. 변동이 너무 크기 때문에 1월을 지속 시간으로 변환할 방법이 없습니다.\n지속 시간을 더하고 곱할 수 있습니다:\n\n2 * dyears(1)\n#&gt; [1] \"63115200s (~2 years)\"\ndyears(1) + dweeks(12) + dhours(15)\n#&gt; [1] \"38869200s (~1.23 years)\"\n\n날짜에 지속 시간을 더하고 뺄 수 있습니다:\n\ntomorrow &lt;- today() + ddays(1)\nlast_year &lt;- today() - dyears(1)\n\n그러나 지속 시간은 정확한 초 수를 나타내므로 때로는 예상치 못한 결과를 얻을 수 있습니다:\n\none_am &lt;- ymd_hms(\"2026-03-08 01:00:00\", tz = \"America/New_York\")\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\n\n왜 3월 8일 오전 1시의 하루 뒤가 3월 9일 오전 2시일까요? 날짜를 주의 깊게 보면 시간대가 변경되었음을 알 수 있습니다. 3월 8일은 DST가 시작되는 날이기 때문에 23시간밖에 없습니다. 따라서 하루 전체 분량의 초를 더하면 다른 시간이 됩니다.\n\n17.4.2 기간(Periods)\n이 문제를 해결하기 위해 lubridate는 기간(periods) 을 제공합니다. 기간은 시간 스팬이지만 초 단위의 고정된 길이가 없으며 대신 일 및 월과 같은 “인간” 시간으로 작동합니다. 이를 통해 더 직관적인 방식으로 작동할 수 있습니다:\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\n지속 시간과 마찬가지로 기간은 여러 친근한 생성자 함수로 만들 수 있습니다.\n\nhours(c(12, 24))\n#&gt; [1] \"12H 0M 0S\" \"24H 0M 0S\"\ndays(7)\n#&gt; [1] \"7d 0H 0M 0S\"\nmonths(1:6)\n#&gt; [1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n#&gt; [5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\n\n기간을 더하고 곱할 수 있습니다:\n\n10 * (months(6) + days(1))\n#&gt; [1] \"60m 10d 0H 0M 0S\"\ndays(50) + hours(25) + minutes(2)\n#&gt; [1] \"50d 25H 2M 0S\"\n\n그리고 물론 날짜에 더할 수 있습니다. 지속 시간과 비교할 때 기간은 예상한 대로 수행될 가능성이 더 큽니다:\n\n# 윤년\nymd(\"2024-01-01\") + dyears(1)\n#&gt; [1] \"2024-12-31 06:00:00 UTC\"\nymd(\"2024-01-01\") + years(1)\n#&gt; [1] \"2025-01-01\"\n\n# 일광 절약 시간\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\n기간을 사용하여 비행 날짜와 관련된 이상한 점을 수정해 보겠습니다. 일부 비행기는 뉴욕시에서 출발하기 전에 목적지에 도착한 것으로 보입니다.\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 10,633 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    BQN           9        -4 2013-01-01 19:29:00 2013-01-01 19:20:00\n#&gt; 2 JFK    DFW          59        NA 2013-01-01 19:39:00 2013-01-01 18:40:00\n#&gt; 3 EWR    TPA          -2         9 2013-01-01 20:58:00 2013-01-01 21:00:00\n#&gt; 4 EWR    SJU          -6       -12 2013-01-01 21:02:00 2013-01-01 21:08:00\n#&gt; 5 EWR    SFO          11       -14 2013-01-01 21:08:00 2013-01-01 20:57:00\n#&gt; 6 LGA    FLL         -10        -2 2013-01-01 21:20:00 2013-01-01 21:30:00\n#&gt; # ℹ 10,627 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\n이들은 야간 비행편입니다. 출발 및 도착 시간 모두에 동일한 날짜 정보를 사용했지만 이 항공편들은 다음 날 도착했습니다. 각 야간 비행편의 도착 시간에 days(1)을 더하여 이를 수정할 수 있습니다.\n\nflights_dt &lt;- flights_dt |&gt; \n  mutate(\n    overnight = arr_time &lt; dep_time,\n    arr_time = arr_time + days(overnight),\n    sched_arr_time = sched_arr_time + days(overnight)\n  )\n\n이제 모든 항공편이 물리 법칙을 따릅니다.\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 0 × 10\n#&gt; # ℹ 10 variables: origin &lt;chr&gt;, dest &lt;chr&gt;, dep_delay &lt;dbl&gt;,\n#&gt; #   arr_delay &lt;dbl&gt;, dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, …\n\n\n17.4.3 구간(Intervals)\ndyears(1) / ddays(365)는 무엇을 반환합니까? dyears()는 평균 연도당 초 수(365.25일)로 정의되므로 1이 아닙니다.\nyears(1) / days(1)은 무엇을 반환합니까? 음, 연도가 2015년이었다면 365를 반환해야 하지만 2016년이었다면 366을 반환해야 합니다! lubridate가 명확한 단일 답변을 제공하기에는 정보가 충분하지 않습니다. 대신 추정치를 제공합니다:\n\nyears(1) / days(1)\n#&gt; [1] 365.25\n\n더 정확한 측정을 원한다면 구간(interval) 을 사용해야 합니다. 구간은 시작 및 종료 날짜 시간의 쌍이거나 시작점이 있는 지속 시간으로 생각할 수 있습니다.\nstart %--% end를 작성하여 구간을 만들 수 있습니다:\n\ny2023 &lt;- ymd(\"2023-01-01\") %--% ymd(\"2024-01-01\")\ny2024 &lt;- ymd(\"2024-01-01\") %--% ymd(\"2025-01-01\")\n\ny2023\n#&gt; [1] 2023-01-01 UTC--2024-01-01 UTC\ny2024\n#&gt; [1] 2024-01-01 UTC--2025-01-01 UTC\n\n그런 다음 days()로 나누어 그 해에 며칠이 들어가는지 알아낼 수 있습니다:\n\ny2023 / days(1)\n#&gt; [1] 365\ny2024 / days(1)\n#&gt; [1] 366\n\n\n17.4.4 연습문제\n\nR을 막 배우기 시작한 사람에게 days(!overnight)와 days(overnight)를 설명하세요. 알아야 할 핵심 사실은 무엇입니까?\n2015년 매월 1일인 날짜 벡터를 만드세요. 현재 연도의 매월 1일인 날짜 벡터를 만드세요.\n생일(날짜)이 주어지면 나이를 년 단위로 반환하는 함수를 작성하세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "datetimes.html#시간대",
    "href": "datetimes.html#시간대",
    "title": "17  날짜와 시간",
    "section": "\n17.5 시간대",
    "text": "17.5 시간대\n시간대는 지정학적 실체와의 상호 작용으로 인해 엄청나게 복잡한 주제입니다. 다행히 데이터 분석에 모두 중요한 것은 아니므로 모든 세부 사항을 파헤칠 필요는 없지만 정면으로 다뤄야 할 몇 가지 과제가 있습니다.\n\n첫 번째 과제는 시간대의 일상적인 이름이 모호한 경향이 있다는 것입니다. 예를 들어 미국인이라면 EST 또는 동부 표준시에 익숙할 것입니다. 그러나 호주와 캐나다에도 EST가 있습니다! 혼란을 피하기 위해 R은 국제 표준 IANA 시간대를 사용합니다. 이들은 일관된 명명 체계 {area}/{location}을 사용하며 일반적으로 {continent}/{city} 또는 {ocean}/{city} 형식입니다. 예로는 “America/New_York”, “Europe/Paris”, “Pacific/Auckland”가 있습니다.\n일반적으로 시간대를 국가 또는 국가 내 지역과 관련된 것으로 생각하는데 왜 도시를 사용하는지 궁금할 수 있습니다. 이는 IANA 데이터베이스가 수십 년 분량의 시간대 규칙을 기록해야 하기 때문입니다. 수십 년 동안 국가는 이름을 꽤 자주 바꾸거나(또는 분리되거나), 도시 이름은 그대로 유지되는 경향이 있습니다. 또 다른 문제는 이름이 현재 행동뿐만 아니라 전체 역사도 반영해야 한다는 것입니다. 예를 들어 “America/New_York”과 “America/Detroit” 모두에 대한 시간대가 있습니다. 이 두 도시는 현재 동부 표준시를 사용하지만 1969-1972년에 미시간(디트로이트가 위치한 주)은 DST를 따르지 않았으므로 다른 이름이 필요합니다. 이 이야기 중 일부를 읽으려면 원시 시간대 데이터베이스(https://www.iana.org/time-zones에서 사용 가능)를 읽을 가치가 있습니다!\nSys.timezone()으로 R이 생각하는 현재 시간대를 알 수 있습니다:\n\nSys.timezone()\n#&gt; [1] \"Asia/Seoul\"\n\n(R이 모르면 NA를 얻습니다.)\n그리고 OlsonNames()로 모든 시간대 이름의 전체 목록을 볼 수 있습니다:\n\nlength(OlsonNames())\n#&gt; [1] 598\nhead(OlsonNames())\n#&gt; [1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n#&gt; [4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"\n\nR에서 시간대는 인쇄만 제어하는 날짜-시간의 속성입니다. 예를 들어 다음 세 객체는 동일한 순간을 나타냅니다:\n\nx1 &lt;- ymd_hms(\"2024-06-01 12:00:00\", tz = \"America/New_York\")\nx1\n#&gt; [1] \"2024-06-01 12:00:00 EDT\"\n\nx2 &lt;- ymd_hms(\"2024-06-01 18:00:00\", tz = \"Europe/Copenhagen\")\nx2\n#&gt; [1] \"2024-06-01 18:00:00 CEST\"\n\nx3 &lt;- ymd_hms(\"2024-06-02 04:00:00\", tz = \"Pacific/Auckland\")\nx3\n#&gt; [1] \"2024-06-02 04:00:00 NZST\"\n\n뺄셈을 사용하여 동일한 시간인지 확인할 수 있습니다:\n\nx1 - x2\n#&gt; Time difference of 0 secs\nx1 - x3\n#&gt; Time difference of 0 secs\n\n달리 명시되지 않는 한 lubridate는 항상 UTC를 사용합니다. UTC(협정 세계시)는 과학계에서 사용하는 표준 시간대이며 GMT(그리니치 표준시)와 대략 동일합니다. DST가 없어 계산을 위한 편리한 표현을 만듭니다. c()와 같이 날짜-시간을 결합하는 작업은 종종 시간대를 삭제합니다. 이 경우 날짜-시간은 첫 번째 요소의 시간대로 표시됩니다:\n\nx4 &lt;- c(x1, x2, x3)\nx4\n#&gt; [1] \"2024-06-01 12:00:00 EDT\" \"2024-06-01 12:00:00 EDT\"\n#&gt; [3] \"2024-06-01 12:00:00 EDT\"\n\n두 가지 방법으로 시간대를 변경할 수 있습니다:\n\n\n시간의 순간은 그대로 두고 표시되는 방식을 변경합니다. 순간은 맞지만 더 자연스러운 표시를 원할 때 사용하세요.\n\nx4a &lt;- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n#&gt; [1] \"2024-06-02 02:30:00 +1030\" \"2024-06-02 02:30:00 +1030\"\n#&gt; [3] \"2024-06-02 02:30:00 +1030\"\nx4a - x4\n#&gt; Time differences in secs\n#&gt; [1] 0 0 0\n\n(이것은 또한 시간대의 또 다른 과제를 보여줍니다: 모두 정수 시간 오프셋은 아닙니다!)\n\n\n기본 시간의 순간을 변경합니다. 잘못된 시간대로 표시된 인스턴트가 있고 이를 수정해야 할 때 사용하세요.\n\nx4b &lt;- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n#&gt; [1] \"2024-06-01 12:00:00 +1030\" \"2024-06-01 12:00:00 +1030\"\n#&gt; [3] \"2024-06-01 12:00:00 +1030\"\nx4b - x4\n#&gt; Time differences in hours\n#&gt; [1] -14.5 -14.5 -14.5",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "datetimes.html#요약",
    "href": "datetimes.html#요약",
    "title": "17  날짜와 시간",
    "section": "\n17.6 요약",
    "text": "17.6 요약\n이 장에서는 lubridate가 날짜-시간 데이터 작업을 돕기 위해 제공하는 도구를 소개했습니다. 날짜와 시간으로 작업하는 것은 필요 이상으로 어렵게 보일 수 있지만, 이 장이 그 이유를 아는 데 도움이 되었기를 바랍니다 — 날짜-시간은 언뜻 보기에 생각했던 것보다 더 복잡하며 모든 가능한 상황을 처리하면 복잡성이 추가됩니다. 데이터가 일광 절약 경계를 넘지 않거나 윤년이 포함되지 않더라도 함수는 이를 처리할 수 있어야 합니다.\n다음 장에서는 결측값을 종합적으로 다룹니다. 몇 군데에서 보았고 의심할 여지 없이 자신의 분석에서 마주쳤을 것이며, 이제 이를 다루기 위한 유용한 기술 꾸러미를 제공할 때입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "datetimes.html#footnotes",
    "href": "datetimes.html#footnotes",
    "title": "17  날짜와 시간",
    "section": "",
    "text": "4로 나누어 떨어지면 윤년이지만, 100으로도 나누어 떨어지면 윤년이 아니고, 400으로도 나누어 떨어지면 윤년입니다. 즉, 400년마다 97번의 윤년이 있습니다.↩︎\nhttps://xkcd.com/1179/↩︎\nUTC가 무엇의 약자인지 궁금할 수 있습니다. 영어 “Coordinated Universal Time”과 프랑스어 “Temps Universel Coordonné” 사이의 타협입니다.↩︎\n경도 시스템을 만든 나라가 어디인지 맞추는 데 상은 없습니다.↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>날짜와 시간</span>"
    ]
  },
  {
    "objectID": "missing-values.html",
    "href": "missing-values.html",
    "title": "18  결측값(Missing values)",
    "section": "",
    "text": "18.1 소개\n이 책의 앞부분에서 결측값의 기본 사항을 이미 배웠습니다. Chapter 1 에서 플롯을 만들 때 경고를 유발하는 것으로 처음 보았고, Section 3.5.2 에서 요약 통계 계산을 방해하는 것으로 보았으며, Section 12.2.2 에서 전염성이 있는 특성과 존재 여부를 확인하는 방법에 대해 배웠습니다. 이제 세부 사항을 더 알아보기 위해 결측값에 대해 더 깊이 다룰 것입니다.\nNA로 기록된 결측값으로 작업하기 위한 몇 가지 일반적인 도구에 대해 논의하는 것으로 시작하겠습니다. 그런 다음 데이터에 단순히 없는 값인 암시적(implicitly) 결측값의 아이디어를 탐구하고 이를 명시적(explicit)으로 만드는 데 사용할 수 있는 몇 가지 도구를 보여줄 것입니다. 데이터에 나타나지 않는 팩터 수준으로 인해 발생하는 빈 그룹에 대한 관련 논의로 마무리하겠습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>결측값(Missing values)</span>"
    ]
  },
  {
    "objectID": "missing-values.html#소개",
    "href": "missing-values.html#소개",
    "title": "18  결측값(Missing values)",
    "section": "",
    "text": "18.1.1 선수 지식\n결측 데이터 작업을 위한 함수는 대부분 tidyverse의 핵심 멤버인 dplyr 및 tidyr에서 제공됩니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>결측값(Missing values)</span>"
    ]
  },
  {
    "objectID": "missing-values.html#명시적-결측값",
    "href": "missing-values.html#명시적-결측값",
    "title": "18  결측값(Missing values)",
    "section": "\n18.2 명시적 결측값",
    "text": "18.2 명시적 결측값\n먼저 NA가 보이는 셀인 명시적 결측값을 생성하거나 제거하는 몇 가지 편리한 도구를 살펴보겠습니다.\n\n18.2.1 마지막 관측값 이월(Last observation carried forward)\n결측값의 일반적인 용도 중 하나는 데이터 입력 편의입니다. 데이터를 손으로 입력할 때 결측값은 때때로 이전 행의 값이 반복됨(또는 이월됨)을 나타냅니다:\n\ntreatment &lt;- tribble(\n  ~person,           ~treatment, ~response,\n  \"Derrick Whitmore\", 1,         7,\n  NA,                 2,         10,\n  NA,                 3,         NA,\n  \"Katherine Burke\",  1,         4\n)\n\ntidyr::fill()을 사용하여 이러한 결측값을 채울 수 있습니다. 이것은 select()처럼 작동하며 일련의 열을 취합니다:\n\ntreatment |&gt;\n  fill(everything())\n#&gt; # A tibble: 4 × 3\n#&gt;   person           treatment response\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 Derrick Whitmore         1        7\n#&gt; 2 Derrick Whitmore         2       10\n#&gt; 3 Derrick Whitmore         3       10\n#&gt; 4 Katherine Burke          1        4\n\n이 처리를 때때로 “마지막 관측값 이월(last observation carried forward)” 또는 줄여서 locf라고 합니다. .direction 인수를 사용하여 더 이국적인 방식으로 생성된 결측값을 채울 수 있습니다.\n\n18.2.2 고정 값\n때때로 결측값은 0과 같이 알려진 고정 값을 나타냅니다. dplyr::coalesce()를 사용하여 대체할 수 있습니다:\n\nx &lt;- c(1, 4, 5, 7, NA)\ncoalesce(x, 0)\n#&gt; [1] 1 4 5 7 0\n\n때로는 구체적인 값이 실제로 결측값을 나타내는 정반대의 문제에 부딪힐 수 있습니다. 이는 일반적으로 결측값을 나타내는 적절한 방법이 없는 오래된 소프트웨어에서 생성된 데이터에서 발생하므로 99 또는 -999와 같은 특수한 값을 대신 사용해야 합니다.\n가능하면 데이터를 읽을 때, 예를 들어 readr::read_csv()의 na 인수를 사용하여(예: read_csv(path, na = \"99\")) 이 문제를 처리하세요. 나중에 문제를 발견하거나 데이터 소스가 읽을 때 처리할 방법을 제공하지 않는 경우 dplyr::na_if()를 사용할 수 있습니다:\n\nx &lt;- c(1, 4, 5, 7, -99)\nna_if(x, -99)\n#&gt; [1]  1  4  5  7 NA\n\n\n18.2.3 NaN\n계속하기 전에 때때로 마주칠 수 있는 특별한 유형의 결측값이 하나 있습니다. NaN(“난”이라고 발음) 또는 숫자가 아님(not a number)입니다. 일반적으로 NA와 똑같이 작동하기 때문에 아는 것이 그리 중요하지는 않습니다:\n\nx &lt;- c(NA, NaN)\nx * 10\n#&gt; [1]  NA NaN\nx == 1\n#&gt; [1] NA NA\nis.na(x)\n#&gt; [1] TRUE TRUE\n\nNA와 NaN을 구별해야 하는 드문 경우에는 is.nan(x)를 사용할 수 있습니다.\n일반적으로 결과가 불확정적인 수학적 연산을 수행할 때 NaN을 만나게 됩니다:\n\n0 / 0 \n#&gt; [1] NaN\n0 * Inf\n#&gt; [1] NaN\nInf - Inf\n#&gt; [1] NaN\nsqrt(-1)\n#&gt; Warning in sqrt(-1): NaNs produced\n#&gt; [1] NaN",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>결측값(Missing values)</span>"
    ]
  },
  {
    "objectID": "missing-values.html#sec-missing-implicit",
    "href": "missing-values.html#sec-missing-implicit",
    "title": "18  결측값(Missing values)",
    "section": "\n18.3 암시적 결측값",
    "text": "18.3 암시적 결측값\n지금까지 우리는 명시적으로(explicitly) 누락된, 즉 데이터에서 NA를 볼 수 있는 결측값에 대해 이야기했습니다. 하지만 전체 데이터 행이 데이터에 단순히 없는 경우 결측값이 암시적으로(implicitly) 누락될 수도 있습니다. 분기별 주식 가격을 기록하는 간단한 데이터셋으로 차이점을 설명해 보겠습니다:\n\nstocks &lt;- tibble(\n  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),\n  qtr   = c(   1,    2,    3,    4,    2,    3,    4),\n  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)\n)\n\n이 데이터셋에는 두 개의 결측 관측값이 있습니다:\n\n2020년 4분기의 price는 값이 NA이기 때문에 명시적으로 누락되었습니다.\n2021년 1분기의 price는 데이터셋에 단순히 나타나지 않기 때문에 암시적으로 누락되었습니다.\n\n차이점에 대해 생각하는 한 가지 방법은 다음과 같은 선(Zen)적인 화두입니다:\n\n명시적 결측값은 부재의 존재(presence of an absence)입니다.\n암시적 결측값은 존재의 부재(absence of a presence)입니다.\n\n때로는 물리적으로 작업할 무언가를 갖기 위해 암시적 결측을 명시적으로 만들고 싶을 때가 있습니다. 다른 경우에는 명시적 결측이 데이터 구조에 의해 강제되고 그것들을 제거하고 싶을 때가 있습니다. 다음 섹션에서는 암시적 결측과 명시적 결측 사이를 이동하는 몇 가지 도구에 대해 설명합니다.\n\n18.3.1 피벗(Pivoting)\n암시적 결측을 명시적으로 만들고 그 반대로 만들 수 있는 도구 하나를 이미 보았습니다: 피벗입니다. 데이터를 더 넓게 만들면 행과 새 열의 모든 조합에 값이 있어야 하기 때문에 암시적 결측값이 명시적으로 될 수 있습니다. 예를 들어 stocks를 피벗하여 quarter를 열에 넣으면 두 결측값이 모두 명시적으로 됩니다:\n\nstocks |&gt;\n  pivot_wider(\n    names_from = qtr, \n    values_from = price\n  )\n#&gt; # A tibble: 2 × 5\n#&gt;    year   `1`   `2`   `3`   `4`\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020  1.88  0.59  0.35 NA   \n#&gt; 2  2021 NA     0.92  0.17  2.66\n\n기본적으로 데이터를 길게 만들면 명시적 결측값이 보존되지만, 데이터가 깔끔하지 않기 때문에 존재하는 구조적 결측값인 경우 values_drop_na = TRUE를 설정하여 삭제(암시적으로 만듦)할 수 있습니다. 자세한 내용은 Section 5.2 의 예제를 참조하세요.\n\n18.3.2 완료(Complete)\ntidyr::complete()를 사용하면 존재해야 하는 행의 조합을 정의하는 변수 집합을 제공하여 명시적 결측값을 생성할 수 있습니다. 예를 들어 stocks 데이터에 year와 qtr의 모든 조합이 존재해야 한다는 것을 알고 있습니다:\n\nstocks |&gt;\n  complete(year, qtr)\n#&gt; # A tibble: 8 × 3\n#&gt;    year   qtr price\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020     1  1.88\n#&gt; 2  2020     2  0.59\n#&gt; 3  2020     3  0.35\n#&gt; 4  2020     4 NA   \n#&gt; 5  2021     1 NA   \n#&gt; 6  2021     2  0.92\n#&gt; # ℹ 2 more rows\n\n일반적으로 기존 변수의 이름으로 complete()를 호출하여 누락된 조합을 채웁니다. 그러나 때로는 개별 변수 자체가 불완전하므로 대신 자신의 데이터를 제공할 수 있습니다. 예를 들어 stocks 데이터셋이 2019년부터 2021년까지 실행되어야 한다는 것을 알 수 있으므로 year에 대해 해당 값을 명시적으로 제공할 수 있습니다:\n\nstocks |&gt;\n  complete(year = 2019:2021, qtr)\n#&gt; # A tibble: 12 × 3\n#&gt;    year   qtr price\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2019     1 NA   \n#&gt; 2  2019     2 NA   \n#&gt; 3  2019     3 NA   \n#&gt; 4  2019     4 NA   \n#&gt; 5  2020     1  1.88\n#&gt; 6  2020     2  0.59\n#&gt; # ℹ 6 more rows\n\n변수의 범위는 정확하지만 모든 값이 있는 것은 아닌 경우 full_seq(x, 1)을 사용하여 min(x)에서 max(x)까지 1씩 간격을 둔 모든 값을 생성할 수 있습니다.\n경우에 따라 관측값의 전체 집합이 변수의 단순한 조합으로 생성될 수 없습니다. 이 경우 complete()가 수행하는 작업을 수동으로 수행할 수 있습니다. 존재해야 하는 모든 행을 포함하는 데이터 프레임을 만든 다음(필요한 기술 조합을 사용하여) dplyr::full_join()을 사용하여 원본 데이터셋과 결합합니다.\n\n18.3.3 조인(Joins)\n이것은 암시적으로 누락된 관측값을 드러내는 또 다른 중요한 방법인 조인으로 우리를 이끕니다. Chapter 19 에서 조인에 대해 자세히 배우게 되겠지만, 한 데이터셋의 값이 누락되었다는 것을 다른 데이터셋과 비교할 때만 알 수 있는 경우가 많기 때문에 여기서 간단히 언급하고 싶었습니다.\ndplyr::anti_join(x, y)는 y에 일치하는 항목이 없는 x의 행만 선택하므로 여기에서 특히 유용한 도구입니다. 예를 들어 두 개의 anti_join()을 사용하여 flights에 언급된 4개의 공항과 722대의 비행기에 대한 정보가 누락되었음을 드러낼 수 있습니다:\n\nlibrary(nycflights13)\n\nflights |&gt; \n  distinct(faa = dest) |&gt; \n  anti_join(airports)\n#&gt; Joining with `by = join_by(faa)`\n#&gt; # A tibble: 4 × 1\n#&gt;   faa  \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\nflights |&gt; \n  distinct(tailnum) |&gt; \n  anti_join(planes)\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 722 × 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # ℹ 716 more rows\n\n\n18.3.4 연습문제\n\n항공사와 planes에서 누락된 것으로 보이는 행 사이에 어떤 관계를 찾을 수 있습니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>결측값(Missing values)</span>"
    ]
  },
  {
    "objectID": "missing-values.html#팩터와-빈-그룹",
    "href": "missing-values.html#팩터와-빈-그룹",
    "title": "18  결측값(Missing values)",
    "section": "\n18.4 팩터와 빈 그룹",
    "text": "18.4 팩터와 빈 그룹\n마지막 유형의 결측은 팩터로 작업할 때 발생할 수 있는 관측값이 포함되지 않은 그룹인 빈 그룹입니다. 예를 들어 사람들에 대한 건강 정보가 포함된 데이터셋이 있다고 상상해 보세요:\n\nhealth &lt;- tibble(\n  name   = c(\"Ikaia\", \"Oletta\", \"Leriah\", \"Dashay\", \"Tresaun\"),\n  smoker = factor(c(\"no\", \"no\", \"no\", \"no\", \"no\"), levels = c(\"yes\", \"no\")),\n  age    = c(34, 88, 75, 47, 56),\n)\n\n그리고 dplyr::count()로 흡연자 수를 세고 싶습니다:\n\nhealth |&gt; count(smoker)\n#&gt; # A tibble: 1 × 2\n#&gt;   smoker     n\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 no         5\n\n이 데이터셋에는 비흡연자만 포함되어 있지만 흡연자가 존재한다는 것은 알고 있습니다. 흡연자 그룹은 비어 있습니다. .drop = FALSE를 사용하여 데이터에 보이지 않는 그룹을 포함하여 모든 그룹을 유지하도록 count()에 요청할 수 있습니다:\n\nhealth |&gt; count(smoker, .drop = FALSE)\n#&gt; # A tibble: 2 × 2\n#&gt;   smoker     n\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 yes        0\n#&gt; 2 no         5\n\n동일한 원칙이 ggplot2의 이산 축에도 적용되며, 이산 축도 값이 없는 수준을 삭제합니다. 적절한 이산 축에 drop = FALSE를 제공하여 강제로 표시할 수 있습니다:\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete()\n\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete(drop = FALSE)\n\n\n\n\n\n\n\n\n\n\n동일한 문제가 dplyr::group_by()에서 더 일반적으로 발생합니다. 그리고 다시 .drop = FALSE를 사용하여 모든 팩터 수준을 보존할 수 있습니다:\n\nhealth |&gt; \n  group_by(smoker, .drop = FALSE) |&gt; \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  )\n#&gt; # A tibble: 2 × 6\n#&gt;   smoker     n mean_age min_age max_age sd_age\n#&gt;   &lt;fct&gt;  &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 yes        0      NaN     Inf    -Inf   NA  \n#&gt; 2 no         5       60      34      88   21.6\n\n여기서 흥미로운 결과를 얻을 수 있는데, 빈 그룹을 요약할 때 요약 함수가 길이가 0인 벡터에 적용되기 때문입니다. 길이 0인 빈 벡터와 각각 길이 1인 결측값 사이에는 중요한 차이가 있습니다.\n\n# 두 개의 결측값을 포함하는 벡터\nx1 &lt;- c(NA, NA)\nlength(x1)\n#&gt; [1] 2\n\n# 아무것도 포함하지 않는 벡터\nx2 &lt;- numeric()\nlength(x2)\n#&gt; [1] 0\n\n모든 요약 함수는 길이가 0인 벡터와 함께 작동하지만 언뜻 보기에 놀라운 결과를 반환할 수 있습니다. 여기서 mean(age)가 NaN을 반환하는 것을 볼 수 있습니다. mean(age) = sum(age)/length(age)인데 여기서는 0/0이기 때문입니다. max()와 min()은 빈 벡터에 대해 -Inf와 Inf를 반환하므로 결과를 새로운 데이터의 비어 있지 않은 벡터와 결합하고 다시 계산하면 새로운 데이터의 최소값 또는 최대값을 얻게 됩니다1.\n때로는 더 간단한 접근 방식은 요약을 수행한 다음 complete()를 사용하여 암시적 결측을 명시적으로 만드는 것입니다.\n\nhealth |&gt; \n  group_by(smoker) |&gt; \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  ) |&gt; \n  complete(smoker)\n#&gt; # A tibble: 2 × 6\n#&gt;   smoker     n mean_age min_age max_age sd_age\n#&gt;   &lt;fct&gt;  &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 yes       NA       NA      NA      NA   NA  \n#&gt; 2 no         5       60      34      88   21.6\n\n이 접근 방식의 주요 단점은 개수가 0이어야 한다는 것을 알고 있음에도 불구하고 개수에 대해 NA를 얻는다는 것입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>결측값(Missing values)</span>"
    ]
  },
  {
    "objectID": "missing-values.html#요약",
    "href": "missing-values.html#요약",
    "title": "18  결측값(Missing values)",
    "section": "\n18.5 요약",
    "text": "18.5 요약\n결측값은 이상합니다! 때로는 명시적인 NA로 기록되지만 다른 때에는 부재를 통해서만 알 수 있습니다. 이 장에서는 명시적 결측값으로 작업하는 도구, 암시적 결측값을 밝혀내는 도구를 제공하고 암시적이 명시적이 되거나 그 반대가 될 수 있는 몇 가지 방법에 대해 논의했습니다.\n다음 장에서는 이 파트의 마지막 장인 조인을 다룹니다. 데이터 프레임 안에 넣는 것이 아니라 데이터 프레임 전체와 작동하는 도구에 대해 논의할 것이기 때문에 지금까지의 장과는 약간 다릅니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>결측값(Missing values)</span>"
    ]
  },
  {
    "objectID": "missing-values.html#footnotes",
    "href": "missing-values.html#footnotes",
    "title": "18  결측값(Missing values)",
    "section": "",
    "text": "즉, min(c(x, y))는 항상 min(min(x), min(y))와 같습니다.↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>결측값(Missing values)</span>"
    ]
  },
  {
    "objectID": "joins.html",
    "href": "joins.html",
    "title": "19  조인(Joins)",
    "section": "",
    "text": "19.1 소개\n데이터 분석에 단일 데이터 프레임만 포함되는 경우는 드뭅니다. 일반적으로 많은 데이터 프레임이 있으며 관심 있는 질문에 답하려면 이들을 조인(join), 즉 결합해야 합니다. 이 장에서는 두 가지 중요한 조인 유형을 소개합니다:\n조인에서 두 데이터 프레임을 연결하는 데 사용되는 변수인 키(keys)에 대해 논의하는 것으로 시작하겠습니다. nycflights13 패키지의 데이터셋에 있는 키를 검사하여 이론을 공고히 한 다음, 그 지식을 사용하여 데이터 프레임을 조인하기 시작할 것입니다. 다음으로 행에 대한 조치에 초점을 맞춰 조인이 작동하는 방식에 대해 설명합니다. 기본 동등 관계보다 키를 일치시키는 더 유연한 방법을 제공하는 조인 제품군인 비동등 조인(non-equi joins)에 대한 논의로 마무리하겠습니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "joins.html#소개",
    "href": "joins.html#소개",
    "title": "19  조인(Joins)",
    "section": "",
    "text": "변형 조인(Mutating joins): 다른 데이터 프레임의 일치하는 관측값에서 한 데이터 프레임에 새 변수를 추가합니다.\n필터링 조인(Filtering joins): 다른 데이터 프레임의 관측값과 일치하는지 여부에 따라 한 데이터 프레임에서 관측값을 필터링합니다.\n\n\n\n19.1.1 선수 지식\n이 장에서는 dplyr의 조인 함수를 사용하여 nycflights13의 5가지 관련 데이터셋을 탐색합니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(nycflights13)",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "joins.html#키keys",
    "href": "joins.html#키keys",
    "title": "19  조인(Joins)",
    "section": "\n19.2 키(Keys)",
    "text": "19.2 키(Keys)\n조인을 이해하려면 먼저 두 테이블이 각 테이블 내의 키 쌍을 통해 어떻게 연결될 수 있는지 이해해야 합니다. 이 섹션에서는 두 가지 유형의 키에 대해 배우고 nycflights13 패키지의 데이터셋에서 두 가지 예를 모두 볼 것입니다. 또한 키가 유효한지 확인하는 방법과 테이블에 키가 없는 경우 수행할 작업을 배웁니다.\n\n19.2.1 기본 키와 외래 키\n모든 조인에는 기본 키와 외래 키라는 한 쌍의 키가 포함됩니다. 기본 키(Primary key) 는 각 관측값을 고유하게 식별하는 변수 또는 변수 집합입니다. 둘 이상의 변수가 필요한 경우 키를 복합 키(compound key) 라고 합니다. 예를 들어 nycflights13에서:\n\n\nairlines는 각 항공사에 대한 두 가지 데이터인 항공사 코드와 전체 이름을 기록합니다. 두 글자 항공사 코드로 항공사를 식별할 수 있으므로 carrier가 기본 키가 됩니다.\n\nairlines\n#&gt; # A tibble: 16 × 2\n#&gt;   carrier name                    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                   \n#&gt; 1 9E      Endeavor Air Inc.       \n#&gt; 2 AA      American Airlines Inc.  \n#&gt; 3 AS      Alaska Airlines Inc.    \n#&gt; 4 B6      JetBlue Airways         \n#&gt; 5 DL      Delta Air Lines Inc.    \n#&gt; 6 EV      ExpressJet Airlines Inc.\n#&gt; # ℹ 10 more rows\n\n\n\nairports는 각 공항에 대한 데이터를 기록합니다. 세 글자 공항 코드로 각 공항을 식별할 수 있으므로 faa가 기본 키가 됩니다.\n\nairports\n#&gt; # A tibble: 1,458 × 8\n#&gt;   faa   name                            lat   lon   alt    tz dst  \n#&gt;   &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A    \n#&gt; 2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A    \n#&gt; 3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A    \n#&gt; 4 06N   Randall Airport                41.4 -74.4   523    -5 A    \n#&gt; 5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A    \n#&gt; 6 0A9   Elizabethton Municipal Airpo…  36.4 -82.2  1593    -5 A    \n#&gt; # ℹ 1,452 more rows\n#&gt; # ℹ 1 more variable: tzone &lt;chr&gt;\n\n\n\nplanes는 각 비행기에 대한 데이터를 기록합니다. 꼬리 번호로 비행기를 식별할 수 있으므로 tailnum이 기본 키가 됩니다.\n\nplanes\n#&gt; # A tibble: 3,322 × 9\n#&gt;   tailnum  year type              manufacturer    model     engines\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 N10156   2004 Fixed wing multi… EMBRAER         EMB-145XR       2\n#&gt; 2 N102UW   1998 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 3 N103US   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 4 N104UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 5 N10575   2002 Fixed wing multi… EMBRAER         EMB-145LR       2\n#&gt; 6 N105UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; # ℹ 3,316 more rows\n#&gt; # ℹ 3 more variables: seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\n\n\nweather는 출발 공항의 날씨에 대한 데이터를 기록합니다. 위치와 시간의 조합으로 각 관측값을 식별할 수 있으므로 origin과 time_hour가 복합 기본 키가 됩니다.\n\nweather\n#&gt; # A tibble: 26,115 × 15\n#&gt;   origin  year month   day  hour  temp  dewp humid wind_dir\n#&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 EWR     2013     1     1     1  39.0  26.1  59.4      270\n#&gt; 2 EWR     2013     1     1     2  39.0  27.0  61.6      250\n#&gt; 3 EWR     2013     1     1     3  39.0  28.0  64.4      240\n#&gt; 4 EWR     2013     1     1     4  39.9  28.0  62.2      250\n#&gt; 5 EWR     2013     1     1     5  39.0  28.0  64.4      260\n#&gt; 6 EWR     2013     1     1     6  37.9  28.0  67.2      240\n#&gt; # ℹ 26,109 more rows\n#&gt; # ℹ 6 more variables: wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, …\n\n\n\n외래 키(Foreign key) 는 다른 테이블의 기본 키에 해당하는 변수(또는 변수 집합)입니다. 예를 들어:\n\n\nflights$tailnum은 기본 키 planes$tailnum에 해당하는 외래 키입니다.\n\nflights$carrier는 기본 키 airlines$carrier에 해당하는 외래 키입니다.\n\nflights$origin은 기본 키 airports$faa에 해당하는 외래 키입니다.\n\nflights$dest는 기본 키 airports$faa에 해당하는 외래 키입니다.\n\nflights$origin-flights$time_hour는 복합 기본 키 weather$origin-weather$time_hour에 해당하는 복합 외래 키입니다.\n\n이러한 관계는 Figure 19.1 에 시각적으로 요약되어 있습니다.\n\n\n\n\n\n\n\nFigure 19.1: nycflights13 패키지의 5개 데이터 프레임 간의 연결. 기본 키를 구성하는 변수는 회색으로 표시되며 화살표로 해당 외래 키에 연결됩니다.\n\n\n\n\n이 키들의 설계에서 좋은 특징을 발견할 수 있습니다. 기본 키와 외래 키는 거의 항상 동일한 이름을 가지고 있으며, 이는 곧 보게 되겠지만 조인 작업을 훨씬 쉽게 만들어 줄 것입니다. 반대 관계도 주목할 가치가 있습니다. 여러 테이블에서 사용되는 거의 모든 변수 이름은 각 장소에서 동일한 의미를 갖습니다. 예외는 단 하나뿐입니다. year는 flights에서는 출발 연도를 의미하고 planes에서는 제조 연도를 의미합니다. 이것은 실제로 테이블을 조인하기 시작할 때 중요해질 것입니다.\n\n19.2.2 기본 키 확인\n이제 각 테이블의 기본 키를 식별했으므로 실제로 각 관측값을 고유하게 식별하는지 확인하는 것이 좋습니다. 그렇게 하는 한 가지 방법은 기본 키를 count()하고 n이 1보다 큰 항목을 찾는 것입니다. planes와 weather는 모두 좋아 보입니다:\n\nplanes |&gt; \n  count(tailnum) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 2\n#&gt; # ℹ 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt;\n\nweather |&gt; \n  count(time_hour, origin) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 3\n#&gt; # ℹ 3 variables: time_hour &lt;dttm&gt;, origin &lt;chr&gt;, n &lt;int&gt;\n\n또한 기본 키에 결측값이 있는지 확인해야 합니다. 값이 누락되면 관측값을 식별할 수 없습니다!\n\nplanes |&gt; \n  filter(is.na(tailnum))\n#&gt; # A tibble: 0 × 9\n#&gt; # ℹ 9 variables: tailnum &lt;chr&gt;, year &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;,\n#&gt; #   model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\nweather |&gt; \n  filter(is.na(time_hour) | is.na(origin))\n#&gt; # A tibble: 0 × 15\n#&gt; # ℹ 15 variables: origin &lt;chr&gt;, year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;,\n#&gt; #   hour &lt;int&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;, humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;, …\n\n\n19.2.3 대리 키(Surrogate keys)\n지금까지 우리는 flights의 기본 키에 대해 이야기하지 않았습니다. 외래 키로 사용하는 데이터 프레임이 없기 때문에 여기서는 별로 중요하지 않지만, 다른 사람들에게 설명할 방법이 있다면 관측값으로 작업하기가 더 쉽기 때문에 고려해 볼 만합니다.\n약간의 생각과 실험 끝에 우리는 함께 각 항공편을 고유하게 식별하는 세 가지 변수가 있다고 결정했습니다:\n\nflights |&gt; \n  count(time_hour, carrier, flight) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: time_hour &lt;dttm&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, n &lt;int&gt;\n\n중복이 없으면 time_hour-carrier-flight가 자동으로 기본 키가 될까요? 확실히 좋은 시작이지만 보장하지는 않습니다. 예를 들어 고도와 위도는 airports에 대한 좋은 기본 키입니까?\n\nairports |&gt;\n  count(alt, lat) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 × 3\n#&gt;     alt   lat     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    13  40.6     2\n\n고도와 위도로 공항을 식별하는 것은 분명히 나쁜 생각이며 일반적으로 변수 조합이 좋은 기본 키를 만드는지 여부를 데이터만으로는 알 수 없습니다. 그러나 항공편의 경우 time_hour, carrier, flight의 조합은 합리적으로 보입니다. 동일한 비행 편명을 가진 여러 항공편이 동시에 공중에 있다면 항공사와 고객에게 정말 혼란스러울 것이기 때문입니다.\n그렇긴 해도 행 번호를 사용하는 간단한 숫자 대리 키를 도입하는 것이 더 나을 수 있습니다:\n\nflights2 &lt;- flights |&gt; \n  mutate(id = row_number(), .before = 1)\nflights2\n#&gt; # A tibble: 336,776 × 20\n#&gt;      id  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1     1  2013     1     1      517            515         2      830\n#&gt; 2     2  2013     1     1      533            529         4      850\n#&gt; 3     3  2013     1     1      542            540         2      923\n#&gt; 4     4  2013     1     1      544            545        -1     1004\n#&gt; 5     5  2013     1     1      554            600        -6      812\n#&gt; 6     6  2013     1     1      554            558        -4      740\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\n대리 키는 다른 사람들과 소통할 때 특히 유용할 수 있습니다. 2013-01-03 오전 9시에 출발한 UA430을 보라고 말하는 것보다 2001번 항공편을 보라고 말하는 것이 훨씬 쉽습니다.\n\n19.2.4 연습문제\n\nFigure 19.1 에서 weather와 airports 사이의 관계를 그리는 것을 잊었습니다. 관계는 무엇이며 다이어그램에 어떻게 나타나야 합니까?\nweather에는 NYC의 3개 출발 공항에 대한 정보만 포함되어 있습니다. 미국 전역의 공항에 대한 날씨 기록이 포함되어 있다면 flights와 어떤 추가 연결이 생길까요?\nweather의 year, month, day, hour, origin 변수는 거의 복합 키를 형성하지만 중복 관측값이 있는 시간이 하나 있습니다. 그 시간의 특별한 점을 파악할 수 있습니까?\n우리는 일년 중 며칠은 특별하고 평소보다 비행하는 사람이 적다는 것을 알고 있습니다(예: 크리스마스 이브와 크리스마스 당일). 해당 데이터를 데이터 프레임으로 어떻게 나타낼 수 있습니까? 기본 키는 무엇입니까? 기존 데이터 프레임과 어떻게 연결됩니까?\nLahman 패키지의 Batting, People, Salaries 데이터 프레임 간의 연결을 설명하는 다이어그램을 그리세요. People, Managers, AwardsManagers 간의 관계를 보여주는 다른 다이어그램을 그리세요. Batting, Pitching, Fielding 데이터 프레임 간의 관계를 어떻게 특성화하시겠습니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-mutating-joins",
    "href": "joins.html#sec-mutating-joins",
    "title": "19  조인(Joins)",
    "section": "\n19.3 기본 조인",
    "text": "19.3 기본 조인\n이제 키를 통해 데이터 프레임이 어떻게 연결되는지 이해했으므로 조인을 사용하여 flights 데이터셋을 더 잘 이해할 수 있습니다. dplyr은 6가지 조인 함수를 제공합니다: left_join(), inner_join(), right_join(), full_join(), semi_join(), anti_join(). 모두 동일한 인터페이스를 가지고 있습니다: 한 쌍의 데이터 프레임(x와 y)을 취하고 데이터 프레임을 반환합니다. 출력의 행과 열 순서는 주로 x에 의해 결정됩니다.\n이 섹션에서는 하나의 변형 조인 left_join()과 두 개의 필터링 조인 semi_join() 및 anti_join()을 사용하는 방법을 배웁니다. 다음 섹션에서는 이러한 함수가 어떻게 작동하는지, 그리고 나머지 inner_join(), right_join(), full_join()에 대해 정확히 배울 것입니다.\n\n19.3.1 변형 조인(Mutating joins)\n변형 조인을 사용하면 두 데이터 프레임의 변수를 결합할 수 있습니다. 먼저 키로 관측값을 일치시킨 다음 한 데이터 프레임에서 다른 데이터 프레임으로 변수를 복사합니다. mutate()와 마찬가지로 조인 함수는 오른쪽에 변수를 추가하므로 데이터셋에 변수가 많으면 새 변수가 보이지 않을 수 있습니다. 이 예제에서는 변수가 6개뿐인 좁은 데이터셋을 만들어 무슨 일이 일어나고 있는지 더 쉽게 볼 수 있도록 하겠습니다1:\n\nflights2 &lt;- flights |&gt; \n  select(year, time_hour, origin, dest, tailnum, carrier)\nflights2\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year time_hour           origin dest  tailnum carrier\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA     \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA     \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA     \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL     \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA     \n#&gt; # ℹ 336,770 more rows\n\n네 가지 유형의 변형 조인이 있지만 거의 항상 사용하는 하나가 있습니다: left_join(). 출력이 항상 조인하는 데이터 프레임인 x와 동일한 행을 갖기 때문에 특별합니다2. left_join()의 주된 용도는 추가 메타데이터를 추가하는 것입니다. 예를 들어 left_join()을 사용하여 flights2 데이터에 전체 항공사 이름을 추가할 수 있습니다:\n\nflights2 |&gt;\n  left_join(airlines)\n#&gt; Joining with `by = join_by(carrier)`\n#&gt; # A tibble: 336,776 × 7\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines In…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines In…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines I…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines In…\n#&gt; # ℹ 336,770 more rows\n\n또는 각 비행기가 출발할 때의 온도와 풍속을 알아낼 수 있습니다:\n\nflights2 |&gt; \n  left_join(weather |&gt; select(origin, time_hour, temp, wind_speed))\n#&gt; Joining with `by = join_by(time_hour, origin)`\n#&gt; # A tibble: 336,776 × 8\n#&gt;    year time_hour           origin dest  tailnum carrier  temp wind_speed\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA       39.0       12.7\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA       39.9       15.0\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA       39.0       15.0\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6       39.0       15.0\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL       39.9       16.1\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA       39.0       12.7\n#&gt; # ℹ 336,770 more rows\n\n또는 어떤 크기의 비행기가 비행했는지:\n\nflights2 |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 336,776 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Fixed wing multi en…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      Fixed wing multi en…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Fixed wing multi en…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      Fixed wing multi en…\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Fixed wing multi en…\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Fixed wing multi en…\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 2 more variables: engines &lt;int&gt;, seats &lt;int&gt;\n\nleft_join()이 x의 행에 대한 일치 항목을 찾지 못하면 새 변수를 결측값으로 채웁니다. 예를 들어 꼬리 번호가 N3ALAA인 비행기에 대한 정보가 없으므로 type, engines, seats는 누락됩니다:\n\nflights2 |&gt; \n  filter(tailnum == \"N3ALAA\") |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 63 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type  engines seats\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 2  2013 2013-01-02 18:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 3  2013 2013-01-03 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 4  2013 2013-01-07 19:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 5  2013 2013-01-08 17:00:00 JFK    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 6  2013 2013-01-16 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; # ℹ 57 more rows\n\n이 장의 나머지 부분에서 이 문제로 몇 번 돌아올 것입니다.\n\n19.3.2 조인 키 지정\n기본적으로 left_join()은 두 데이터 프레임에 모두 나타나는 모든 변수를 조인 키로 사용합니다. 이를 소위 자연(natural) 조인이라고 합니다. 유용한 경험적 방법이지만 항상 작동하는 것은 아닙니다. 예를 들어 flights2를 전체 planes 데이터셋과 조인하려고 하면 어떻게 될까요?\n\nflights2 |&gt; \n  left_join(planes)\n#&gt; Joining with `by = join_by(year, tailnum)`\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier type  manufacturer\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 5 more variables: model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, …\n\n조인이 tailnum과 year를 복합 키로 사용하려고 하기 때문에 누락된 일치 항목이 많이 발생합니다. flights와 planes 모두 year 열이 있지만 의미가 다릅니다. flights$year는 비행이 발생한 연도이고 planes$year는 비행기가 제조된 연도입니다. 우리는 tailnum으로만 조인하고 싶으므로 join_by()를 사용하여 명시적 사양을 제공해야 합니다:\n\nflights2 |&gt; \n  left_join(planes, join_by(tailnum))\n#&gt; # A tibble: 336,776 × 14\n#&gt;   year.x time_hour           origin dest  tailnum carrier year.y\n#&gt;    &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999\n#&gt; 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998\n#&gt; 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990\n#&gt; 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012\n#&gt; 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991\n#&gt; 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 7 more variables: type &lt;chr&gt;, manufacturer &lt;chr&gt;, model &lt;chr&gt;, …\n\nyear 변수는 출력에서 접미사(year.x 및 year.y)로 구분되어 변수가 x 또는 y 인수에서 왔는지 알려줍니다. suffix 인수로 기본 접미사를 재정의할 수 있습니다.\njoin_by(tailnum)은 join_by(tailnum == tailnum)의 줄임말입니다. 두 가지 이유로 이 더 긴 형식에 대해 아는 것이 중요합니다. 첫째, 두 테이블 간의 관계를 설명합니다. 키는 동일해야 합니다. 이것이 이러한 유형의 조인을 종종 동등 조인(equi join) 이라고 부르는 이유입니다. Section 19.5 에서 비동등 조인에 대해 배울 것입니다.\n둘째, 각 테이블에서 서로 다른 조인 키를 지정하는 방법입니다. 예를 들어 flight2와 airports 테이블을 조인하는 방법에는 dest 또는 origin의 두 가지가 있습니다:\n\nflights2 |&gt; \n  left_join(airports, join_by(dest == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      George Bush Interco…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      George Bush Interco…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Miami Intl          \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;                \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Hartsfield Jackson …\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Chicago Ohare Intl  \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\nflights2 |&gt; \n  left_join(airports, join_by(origin == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name               \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;              \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Newark Liberty Intl\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      La Guardia         \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      John F Kennedy Intl\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      John F Kennedy Intl\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      La Guardia         \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Newark Liberty Intl\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\n이전 코드에서는 문자 벡터를 사용하여 조인 키를 지정하는 다른 방법을 볼 수 있습니다:\n\n\nby = \"x\"는 join_by(x)에 해당합니다.\n\nby = c(\"a\" = \"x\")는 join_by(a == x)에 해당합니다.\n\n이제 join_by()가 존재하므로 더 명확하고 유연한 사양을 제공하기 때문에 선호합니다.\ninner_join(), right_join(), full_join()은 left_join()과 동일한 인터페이스를 가집니다. 차이점은 유지하는 행입니다. 왼쪽 조인은 x의 모든 행을 유지하고, 오른쪽 조인은 y의 모든 행을 유지하고, 전체 조인은 x 또는 y의 모든 행을 유지하고, 내부 조인은 x와 y 모두에서 발생하는 행만 유지합니다. 나중에 이에 대해 더 자세히 다시 다룰 것입니다.\n\n19.3.3 필터링 조인(Filtering joins)\n짐작할 수 있듯이 필터링 조인의 주요 조치는 행을 필터링하는 것입니다. 세미 조인과 안티 조인의 두 가지 유형이 있습니다. 세미 조인(Semi-joins) 은 y에 일치하는 항목이 있는 x의 모든 행을 유지합니다. 예를 들어 세미 조인을 사용하여 airports 데이터셋을 필터링하여 출발 공항만 표시할 수 있습니다:\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == origin))\n#&gt; # A tibble: 3 × 8\n#&gt;   faa   name                  lat   lon   alt    tz dst   tzone           \n#&gt;   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n#&gt; 1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York\n#&gt; 2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n#&gt; 3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York\n\n또는 목적지만:\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == dest))\n#&gt; # A tibble: 101 × 8\n#&gt;   faa   name                     lat    lon   alt    tz dst   tzone          \n#&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          \n#&gt; 1 ABQ   Albuquerque Internati…  35.0 -107.   5355    -7 A     America/Denver \n#&gt; 2 ACK   Nantucket Mem           41.3  -70.1    48    -5 A     America/New_Yo…\n#&gt; 3 ALB   Albany Intl             42.7  -73.8   285    -5 A     America/New_Yo…\n#&gt; 4 ANC   Ted Stevens Anchorage…  61.2 -150.    152    -9 A     America/Anchor…\n#&gt; 5 ATL   Hartsfield Jackson At…  33.6  -84.4  1026    -5 A     America/New_Yo…\n#&gt; 6 AUS   Austin Bergstrom Intl   30.2  -97.7   542    -6 A     America/Chicago\n#&gt; # ℹ 95 more rows\n\n안티 조인(Anti-joins) 은 그 반대입니다. y에 일치하는 항목이 없는 x의 모든 행을 반환합니다. Section 18.3 의 주제인 데이터에 암시된 결측값을 찾는 데 유용합니다. 암시적으로 누락된 값은 NA로 표시되지 않고 부재로만 존재합니다. 예를 들어 일치하는 목적지 공항이 없는 항공편을 찾아 airports에서 누락된 행을 찾을 수 있습니다:\n\nflights2 |&gt; \n  anti_join(airports, join_by(dest == faa)) |&gt; \n  distinct(dest)\n#&gt; # A tibble: 4 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\n또는 planes에서 누락된 tailnum을 찾을 수 있습니다:\n\nflights2 |&gt;\n  anti_join(planes, join_by(tailnum)) |&gt; \n  distinct(tailnum)\n#&gt; # A tibble: 722 × 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # ℹ 716 more rows\n\n\n19.3.4 연습문제\n\n(일년 전체 과정에서) 최악의 지연이 있는 48시간을 찾으세요. weather 데이터와 상호 참조하세요. 패턴을 볼 수 있습니까?\n\n이 코드를 사용하여 가장 인기 있는 10개 목적지를 찾았다고 상상해 보세요:\n\ntop_dest &lt;- flights2 |&gt;\n  count(dest, sort = TRUE) |&gt;\n  head(10)\n\n그 목적지로 가는 모든 항공편을 어떻게 찾을 수 있습니까?\n\n모든 출발 항공편에 해당 시간의 날씨 데이터가 있습니까?\nplanes에 일치하는 기록이 없는 꼬리 번호의 공통점은 무엇입니까? (힌트: 하나의 변수가 문제의 약 90%를 설명합니다.)\n해당 비행기를 운항한 모든 carrier를 나열하는 열을 planes에 추가하세요. 각 비행기는 단일 항공사에 의해 운항되기 때문에 비행기와 항공사 사이에 암시적인 관계가 있을 것이라고 기대할 수 있습니다. 이전 장에서 배운 도구를 사용하여 이 가설을 확인하거나 기각하세요.\nflights에 출발 및 도착 공항의 위도와 경도를 추가하세요. 조인 전이나 후에 열 이름을 바꾸는 것이 더 쉽습니까?\n\n목적지별 평균 지연을 계산한 다음 airports 데이터 프레임에 조인하여 지연의 공간적 분포를 보여줄 수 있도록 하세요. 미국 지도를 그리는 쉬운 방법은 다음과 같습니다:\n\nairports |&gt;\n  semi_join(flights, join_by(faa == dest)) |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n    borders(\"state\") +\n    geom_point() +\n    coord_quickmap()\n\n점의 size 또는 color를 사용하여 각 공항의 평균 지연을 표시하고 싶을 수 있습니다.\n\n2013년 6월 13일에 무슨 일이 일어났습니까? 지연 지도를 그린 다음 Google을 사용하여 날씨와 상호 참조하세요.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "joins.html#조인은-어떻게-작동합니까",
    "href": "joins.html#조인은-어떻게-작동합니까",
    "title": "19  조인(Joins)",
    "section": "\n19.4 조인은 어떻게 작동합니까?",
    "text": "19.4 조인은 어떻게 작동합니까?\n이제 조인을 몇 번 사용했으므로 x의 각 행이 y의 행과 어떻게 일치하는지에 초점을 맞춰 조인이 작동하는 방식에 대해 자세히 알아볼 때입니다. Figure 19.2 에 표시된 아래 정의된 간단한 티블을 사용하여 조인의 시각적 표현을 소개하는 것으로 시작하겠습니다. 이 예제에서는 key라는 단일 키와 단일 값 열(val_x 및 val_y)을 사용하지만 아이디어는 모두 여러 키와 여러 값으로 일반화됩니다.\n\nx &lt;- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     3, \"x3\"\n)\ny &lt;- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     4, \"y3\"\n)\n\n\n\n\n\n\n\n\nFigure 19.2: 두 개의 간단한 테이블의 그래픽 표현. 색상이 지정된 key 열은 배경색을 키 값에 매핑합니다. 회색 열은 따라오는 “값” 열을 나타냅니다.\n\n\n\n\nFigure 19.3 는 시각적 표현의 기초를 소개합니다. x의 각 행과 y의 각 행에서 그려진 선 사이의 교차점으로 x와 y 사이의 모든 잠재적 일치를 보여줍니다. 출력의 행과 열은 주로 x에 의해 결정되므로 x 테이블은 수평이며 출력과 일치합니다.\n\n\n\n\n\n\n\nFigure 19.3: 조인이 작동하는 방식을 이해하려면 가능한 모든 일치를 생각하는 것이 유용합니다. 여기서는 연결선 그리드로 보여줍니다.\n\n\n\n\n특정 유형의 조인을 설명하기 위해 일치 항목을 점으로 나타냅니다. 일치 항목은 키, x 값, y 값을 포함하는 새 데이터 프레임인 출력의 행을 결정합니다. 예를 들어 Figure 19.4 는 키가 동일한 경우에만 행이 유지되는 내부 조인을 보여줍니다.\n\n\n\n\n\n\n\nFigure 19.4: 내부 조인은 x의 각 행을 key 값이 같은 y의 행과 일치시킵니다. 각 일치 항목은 출력에서 하나의 행이 됩니다.\n\n\n\n\n동일한 원칙을 적용하여 데이터 프레임 중 하나 이상에 나타나는 관측값을 유지하는 외부 조인(outer joins) 을 설명할 수 있습니다. 이러한 조인은 각 데이터 프레임에 추가 “가상” 관측값을 추가하여 작동합니다. 이 관측값에는 다른 키가 일치하지 않는 경우 일치하는 키와 NA로 채워진 값이 있습니다. 세 가지 유형의 외부 조인이 있습니다:\n\n\n왼쪽 조인은 x의 모든 관측값을 유지합니다(Figure 19.5). x의 모든 행은 y의 NA 행과 일치하도록 폴백할 수 있으므로 출력에 보존됩니다.\n\n\n\n\n\n\n\nFigure 19.5: x의 모든 행이 출력에 나타나는 왼쪽 조인의 시각적 표현.\n\n\n\n\n\n\n오른쪽 조인은 y의 모든 관측값을 유지합니다(Figure 19.6). y의 모든 행은 x의 NA 행과 일치하도록 폴백할 수 있으므로 출력에 보존됩니다. 출력은 여전히 가능한 한 x와 일치합니다. y의 모든 추가 행은 끝에 추가됩니다.\n\n\n\n\n\n\n\nFigure 19.6: y의 모든 행이 출력에 나타나는 오른쪽 조인의 시각적 표현.\n\n\n\n\n\n\n전체 조인은 x 또는 y에 나타나는 모든 관측값을 유지합니다(Figure 19.7). x와 y 모두 NA 폴백 행이 있으므로 x와 y의 모든 행이 출력에 포함됩니다. 다시 출력은 x의 모든 행으로 시작하고 일치하지 않는 나머지 y 행이 뒤따릅니다.\n\n\n\n\n\n\n\nFigure 19.7: x와 y의 모든 행이 출력에 나타나는 전체 조인의 시각적 표현.\n\n\n\n\n\n\n외부 조인 유형이 어떻게 다른지 보여주는 또 다른 방법은 Figure 19.8 과 같은 벤 다이어그램을 사용하는 것입니다. 그러나 이것은 어떤 행이 보존되는지 기억을 되살릴 수는 있지만 열에서 무슨 일이 일어나는지 설명하지 못하기 때문에 훌륭한 표현은 아닙니다.\n\n\n\n\n\n\n\nFigure 19.8: 내부, 왼쪽, 오른쪽, 전체 조인의 차이를 보여주는 벤 다이어그램.\n\n\n\n\n여기에 표시된 조인은 키가 같으면 행이 일치하는 소위 동등(equi) 조인입니다. 동등 조인은 가장 일반적인 유형의 조인이므로 일반적으로 동등 접두사를 생략하고 “동등 내부 조인”이 아닌 그냥 “내부 조인”이라고 말합니다. Section 19.5 에서 비동등 조인으로 다시 돌아올 것입니다.\n\n19.4.1 행 일치\n지금까지 x의 행이 y의 0개 또는 1개 행과 일치하면 어떻게 되는지 살펴보았습니다. 둘 이상의 행과 일치하면 어떻게 됩니까? 무슨 일이 일어나고 있는지 이해하기 위해 먼저 inner_join()에 초점을 맞추고 그림을 그려보겠습니다(Figure 19.9).\n\n\n\n\n\n\n\nFigure 19.9: x의 행이 일치할 수 있는 세 가지 방법. x1은 y의 한 행과 일치하고, x2는 y의 두 행과 일치하며, x3은 y의 0개 행과 일치합니다. x에 3개 행이 있고 출력에 3개 행이 있지만 행 간에 직접적인 대응 관계는 없다는 점에 유의하세요.\n\n\n\n\nx의 행에 대해 세 가지 가능한 결과가 있습니다:\n\n아무것도 일치하지 않으면 삭제됩니다.\n\ny의 1개 행과 일치하면 보존됩니다.\n\ny의 1개 이상의 행과 일치하면 각 일치 항목에 대해 한 번씩 복제됩니다.\n\n원칙적으로 이는 출력의 행과 x의 행 사이에 보장된 대응 관계가 없음을 의미하지만 실제로는 거의 문제를 일으키지 않습니다. 그러나 행의 조합적 폭발을 일으킬 수 있는 특히 위험한 경우가 하나 있습니다. 다음 두 테이블을 조인한다고 상상해 보세요:\n\ndf1 &lt;- tibble(key = c(1, 2, 2), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 &lt;- tibble(key = c(1, 2, 2), val_y = c(\"y1\", \"y2\", \"y3\"))\n\ndf1의 첫 번째 행은 df2의 한 행과만 일치하지만 두 번째와 세 번째 행은 모두 두 행과 일치합니다. 이것을 때때로 다대다(many-to-many) 조인이라고 하며 dplyr이 경고를 보내도록 합니다:\n\ndf1 |&gt; \n  inner_join(df2, join_by(key))\n#&gt; Warning in inner_join(df1, df2, join_by(key)): Detected an unexpected many-to-many relationship between `x` and `y`.\n#&gt; ℹ Row 2 of `x` matches multiple rows in `y`.\n#&gt; ℹ Row 2 of `y` matches multiple rows in `x`.\n#&gt; ℹ If a many-to-many relationship is expected, set `relationship =\n#&gt;   \"many-to-many\"` to silence this warning.\n#&gt; # A tibble: 5 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     2 x2    y3   \n#&gt; 4     2 x3    y2   \n#&gt; 5     2 x3    y3\n\n의도적으로 이 작업을 수행하는 경우 경고가 제안하는 대로 relationship = \"many-to-many\"를 설정할 수 있습니다.\n\n19.4.2 필터링 조인\n일치하는 항목 수는 필터링 조인의 동작도 결정합니다. 세미 조인은 Figure 19.10 와 같이 y에 하나 이상의 일치 항목이 있는 x의 행을 유지합니다. 안티 조인은 Figure 19.11 와 같이 y에 0개의 행이 일치하는 x의 행을 유지합니다. 두 경우 모두 일치 항목의 존재 여부만 중요합니다. 몇 번 일치하는지는 중요하지 않습니다. 즉, 필터링 조인은 변형 조인처럼 행을 중복시키지 않습니다.\n\n\n\n\n\n\n\nFigure 19.10: 세미 조인에서는 일치 항목이 있다는 것만 중요합니다. 그렇지 않으면 y의 값은 출력에 영향을 주지 않습니다.\n\n\n\n\n\n\n\n\n\n\n\nFigure 19.11: 안티 조인은 세미 조인의 반대이며 y에 일치하는 항목이 있는 x의 행을 삭제합니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-non-equi-joins",
    "href": "joins.html#sec-non-equi-joins",
    "title": "19  조인(Joins)",
    "section": "\n19.5 비동등 조인(Non-equi joins)",
    "text": "19.5 비동등 조인(Non-equi joins)\n지금까지 x 키가 y 키와 같으면 행이 일치하는 동등 조인만 보았습니다. 이제 그 제한을 완화하고 한 쌍의 행이 일치하는지 확인하는 다른 방법에 대해 논의하겠습니다.\n하지만 그렇게 하기 전에 위에서 만든 단순화를 다시 살펴봐야 합니다. 동등 조인에서 x 키와 y는 항상 동일하므로 출력에 하나만 표시하면 됩니다. keep = TRUE를 사용하여 dplyr에 두 키를 모두 유지하도록 요청할 수 있으며, 이는 아래 코드와 Figure 19.12 의 다시 그려진 inner_join()으로 이어집니다.\n\nx |&gt; inner_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 2 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2\n\n\n\n\n\n\n\n\nFigure 19.12: 출력에 x와 y 키를 모두 보여주는 내부 조인.\n\n\n\n\n동등 조인에서 벗어나면 키 값이 종종 다르기 때문에 항상 키를 표시합니다. 예를 들어 x$key와 y$key가 같을 때만 일치시키는 대신 x$key가 y$key보다 크거나 같을 때마다 일치시켜 Figure 19.13 로 이어질 수 있습니다. dplyr의 조인 함수는 이 차이점 동등 조인과 비동등 조인을 이해하므로 비동등 조인을 수행할 때 항상 두 키를 모두 표시합니다.\n\n\n\n\n\n\n\nFigure 19.13: x 키가 y 키보다 크거나 같아야 하는 비동등 조인. 많은 행이 여러 일치 항목을 생성합니다.\n\n\n\n\n비동등 조인은 조인이 아닌 것이 무엇인지만 알려주고 무엇인지 알려주지 않기 때문에 특별히 유용한 용어는 아닙니다. dplyr은 4가지 특히 유용한 비동등 조인 유형을 식별하여 도움을 줍니다:\n\n\n교차 조인(Cross joins) 은 모든 행 쌍을 일치시킵니다.\n\n부등 조인(Inequality joins) 은 == 대신 &lt;, &lt;=, &gt;, &gt;=를 사용합니다.\n\n롤링 조인(Rolling joins) 은 부등 조인과 유사하지만 가장 가까운 일치 항목만 찾습니다.\n\n중첩 조인(Overlap joins) 은 범위와 함께 작동하도록 설계된 특수한 유형의 부등 조인입니다.\n\n이들 각각은 다음 섹션에서 자세히 설명합니다.\n\n19.5.1 교차 조인(Cross joins)\n교차 조인은 Figure 19.14 와 같이 모든 것을 일치시켜 행의 데카르트 곱(Cartesian product)을 생성합니다. 이는 출력이 nrow(x) * nrow(y)개의 행을 가짐을 의미합니다.\n\n\n\n\n\n\n\nFigure 19.14: 교차 조인은 x의 각 행을 y의 모든 행과 일치시킵니다.\n\n\n\n\n교차 조인은 순열을 생성할 때 유용합니다. 예를 들어 아래 코드는 가능한 모든 이름 쌍을 생성합니다. df를 자신에게 조인하므로 이를 때때로 자체 조인(self-join) 이라고 합니다. 교차 조인은 모든 행을 일치시킬 때 내부/왼쪽/오른쪽/전체 구분 없기 때문에 다른 조인 함수를 사용합니다.\n\ndf &lt;- tibble(name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\ndf |&gt; cross_join(df)\n#&gt; # A tibble: 16 × 2\n#&gt;   name.x name.y\n#&gt;   &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 John   John  \n#&gt; 2 John   Simon \n#&gt; 3 John   Tracy \n#&gt; 4 John   Max   \n#&gt; 5 Simon  John  \n#&gt; 6 Simon  Simon \n#&gt; # ℹ 10 more rows\n\n\n19.5.2 부등 조인(Inequality joins)\n부등 조인은 &lt;, &lt;=, &gt;=, &gt;를 사용하여 가능한 일치 항목 집합을 제한합니다(Figure 19.13 및 Figure 19.15).\n\n\n\n\n\n\n\nFigure 19.15: x의 키가 y의 키보다 작은 행에서 x가 y에 조인되는 부등 조인. 이것은 왼쪽 상단 모서리에 삼각형 모양을 만듭니다.\n\n\n\n\n부등 조인은 매우 일반적이어서 의미 있는 특정 사용 사례를 생각해내기 어렵습니다. 작고 유용한 기술 중 하나는 모든 순열을 생성하는 대신 모든 조합을 생성하도록 교차 조인을 제한하는 데 사용하는 것입니다:\n\ndf &lt;- tibble(id = 1:4, name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\n\ndf |&gt; inner_join(df, join_by(id &lt; id))\n#&gt; # A tibble: 6 × 4\n#&gt;    id.x name.x  id.y name.y\n#&gt;   &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; \n#&gt; 1     1 John       2 Simon \n#&gt; 2     1 John       3 Tracy \n#&gt; 3     1 John       4 Max   \n#&gt; 4     2 Simon      3 Tracy \n#&gt; 5     2 Simon      4 Max   \n#&gt; 6     3 Tracy      4 Max\n\n\n19.5.3 롤링 조인(Rolling joins)\n롤링 조인은 부등식을 만족하는 모든 행을 얻는 대신 가장 가까운 행만 얻는 특수한 유형의 부등 조인입니다(Figure 19.16). closest()를 추가하여 모든 부등 조인을 롤링 조인으로 바꿀 수 있습니다. 예를 들어 join_by(closest(x &lt;= y))는 x보다 크거나 같은 가장 작은 y와 일치하고 join_by(closest(x &gt; y))는 x보다 작은 가장 큰 y와 일치합니다.\n\n\n\n\n\n\n\nFigure 19.16: 롤링 조인은 크거나 같음 부등 조인과 유사하지만 첫 번째 값만 일치시킵니다.\n\n\n\n\n롤링 조인은 완벽하게 정렬되지 않는 두 개의 날짜 테이블이 있고 테이블 1의 날짜보다 이전(또는 이후)에 오는 테이블 2의 (예를 들어) 가장 가까운 날짜를 찾으려는 경우에 특히 유용합니다.\n예를 들어 사무실의 파티 계획 위원회 책임자라고 상상해 보세요. 회사가 꽤 인색해서 개별 파티를 하는 대신 분기에 한 번만 파티를 엽니다. 파티가 언제 열릴지 결정하는 규칙은 조금 복잡합니다. 파티는 항상 월요일에 열리고, 많은 사람들이 휴가 중이므로 1월 첫째 주는 건너뛰고, 2022년 3분기의 첫 번째 월요일은 7월 4일이므로 일주일 미뤄야 합니다. 그 결과 다음과 같은 파티 날짜가 나옵니다:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\"))\n)\n\n이제 직원 생일 테이블이 있다고 상상해 보세요:\n\nset.seed(123)\nemployees &lt;- tibble(\n  name = sample(babynames::babynames$name, 100),\n  birthday = ymd(\"2022-01-01\") + (sample(365, 100, replace = TRUE) - 1)\n)\nemployees\n#&gt; # A tibble: 100 × 2\n#&gt;   name     birthday  \n#&gt;   &lt;chr&gt;    &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22\n#&gt; 2 Orean    2022-06-26\n#&gt; 3 Kirstyn  2022-02-11\n#&gt; 4 Amparo   2022-11-11\n#&gt; 5 Belen    2022-03-25\n#&gt; 6 Rayshaun 2022-01-11\n#&gt; # ℹ 94 more rows\n\n그리고 각 직원에 대해 생일 이전(또는 당일)에 오는 마지막 파티 날짜를 찾고 싶습니다. 롤링 조인으로 표현할 수 있습니다:\n\nemployees |&gt; \n  left_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 100 × 4\n#&gt;   name     birthday       q party     \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10\n#&gt; 2 Orean    2022-06-26     2 2022-04-04\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03\n#&gt; 5 Belen    2022-03-25     1 2022-01-10\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10\n#&gt; # ℹ 94 more rows\n\n하지만 이 접근 방식에는 한 가지 문제가 있습니다. 생일이 1월 10일 이전인 사람들은 파티를 얻지 못합니다:\n\nemployees |&gt; \n  anti_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 2 × 2\n#&gt;   name   birthday  \n#&gt;   &lt;chr&gt;  &lt;date&gt;    \n#&gt; 1 Maks   2022-01-07\n#&gt; 2 Nalani 2022-01-04\n\n이 문제를 해결하려면 중첩 조인이라는 다른 방식으로 문제에 접근해야 합니다.\n\n19.5.4 중첩 조인(Overlap joins)\n중첩 조인은 부등 조인을 사용하여 간격 작업을 더 쉽게 만드는 세 가지 도우미를 제공합니다:\n\n\nbetween(x, y_lower, y_upper)는 x &gt;= y_lower, x &lt;= y_upper의 줄임말입니다.\n\nwithin(x_lower, x_upper, y_lower, y_upper)는 x_lower &gt;= y_lower, x_upper &lt;= y_upper의 줄임말입니다.\n\noverlaps(x_lower, x_upper, y_lower, y_upper)는 x_lower &lt;= y_upper, x_upper &gt;= y_lower의 줄임말입니다.\n\n그것들을 어떻게 사용할 수 있는지 알아보기 위해 생일 예제를 계속해 보겠습니다. 위에서 사용한 전략에는 한 가지 문제가 있습니다. 1월 1-9일 생일 이전에 파티가 없습니다. 따라서 각 파티가 걸쳐 있는 날짜 범위를 명시하고 초반 생일에 대해 특별한 경우를 만드는 것이 더 나을 수 있습니다:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-11\", \"2022-10-02\", \"2022-12-31\"))\n)\nparties\n#&gt; # A tibble: 4 × 4\n#&gt;       q party      start      end       \n#&gt;   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2     2 2022-04-04 2022-04-04 2022-07-11\n#&gt; 3     3 2022-07-11 2022-07-11 2022-10-02\n#&gt; 4     4 2022-10-03 2022-10-03 2022-12-31\n\n해들리(Hadley)는 데이터 입력에 끔찍하게 서툴러서 파티 기간이 겹치지 않는지 확인하고 싶었습니다. 이를 수행하는 한 가지 방법은 자체 조인을 사용하여 시작-종료 간격이 다른 것과 겹치는지 확인하는 것입니다:\n\nparties |&gt; \n  inner_join(parties, join_by(overlaps(start, end, start, end), q &lt; q)) |&gt; \n  select(start.x, end.x, start.y, end.y)\n#&gt; # A tibble: 1 × 4\n#&gt;   start.x    end.x      start.y    end.y     \n#&gt;   &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 2022-04-04 2022-07-11 2022-07-11 2022-10-02\n\n이런, 겹치는 부분이 있으니 문제를 해결하고 계속해 보겠습니다:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-10\", \"2022-10-02\", \"2022-12-31\"))\n)\n\n이제 각 직원을 파티에 연결할 수 있습니다. 파티를 배정받지 못한 직원이 있는지 빨리 알아보고 싶기 때문에 unmatched = \"error\"를 사용하기에 좋은 곳입니다.\n\nemployees |&gt; \n  inner_join(parties, join_by(between(birthday, start, end)), unmatched = \"error\")\n#&gt; # A tibble: 100 × 6\n#&gt;   name     birthday       q party      start      end       \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2 Orean    2022-06-26     2 2022-04-04 2022-04-04 2022-07-10\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03 2022-10-03 2022-12-31\n#&gt; 5 Belen    2022-03-25     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; # ℹ 94 more rows\n\n\n19.5.5 연습문제\n\n\n이 동등 조인에서 키에 무슨 일이 일어나고 있는지 설명할 수 있습니까? 왜 다릅니까?\n\nx |&gt; full_join(y, join_by(key == key))\n#&gt; # A tibble: 4 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt; \n#&gt; 4     4 &lt;NA&gt;  y3\n\nx |&gt; full_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 4 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2   \n#&gt; 3     3 x3       NA &lt;NA&gt; \n#&gt; 4    NA &lt;NA&gt;      4 y3\n\n\n파티 기간이 다른 파티 기간과 겹치는지 찾을 때 join_by()에서 q &lt; q를 사용했습니다. 이유는 무엇입니까? 이 부등식을 제거하면 어떻게 됩니까?",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "joins.html#요약",
    "href": "joins.html#요약",
    "title": "19  조인(Joins)",
    "section": "\n19.6 요약",
    "text": "19.6 요약\n이 장에서는 변형 및 필터링 조인을 사용하여 한 쌍의 데이터 프레임에서 데이터를 결합하는 방법을 배웠습니다. 그 과정에서 키를 식별하는 방법과 기본 키와 외래 키의 차이점을 배웠습니다. 또한 조인이 작동하는 방식과 출력에 몇 개의 행이 있는지 파악하는 방법도 이해했습니다. 마지막으로 비동등 조인의 힘을 살짝 엿보고 몇 가지 흥미로운 사용 사례를 보았습니다.\n이 장으로 개별 열과 티블에서 사용할 수 있는 도구에 중점을 둔 책의 “변형(Transform)” 파트가 마무리됩니다. 논리형 벡터, 숫자, 전체 테이블 작업을 위한 dplyr 및 기본 함수, 문자열 작업을 위한 stringr 함수, 날짜-시간 작업을 위한 lubridate 함수, 팩터 작업을 위한 forcats 함수에 대해 배웠습니다.\n책의 다음 파트에서는 다양한 유형의 데이터를 깔끔한 형태로 R로 가져오는 방법에 대해 더 자세히 배울 것입니다.",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "joins.html#footnotes",
    "href": "joins.html#footnotes",
    "title": "19  조인(Joins)",
    "section": "",
    "text": "RStudio에서는 View()를 사용하여 이 문제를 피할 수도 있음을 기억하세요.↩︎\n100% 사실은 아니지만 그렇지 않을 때마다 경고를 받게 됩니다.↩︎",
    "crumbs": [
      "변형 (Transform)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>조인(Joins)</span>"
    ]
  },
  {
    "objectID": "import.html",
    "href": "import.html",
    "title": "가져오기 (Import)",
    "section": "",
    "text": "책의 이 파트에서는 더 넓은 범위의 데이터를 R로 가져오는 방법과 이를 분석에 유용한 형태로 만드는 방법을 배웁니다. 때로는 적절한 데이터 가져오기 패키지의 함수를 호출하는 것만으로 충분할 수도 있습니다. 하지만 더 복잡한 경우에는 선호하는 깔끔한 직사각형(tidy rectangle) 형태를 만들기 위해 정리(tidying)와 변형(transformation)이 모두 필요할 수 있습니다.\n\n\n\n\n\n\n\nFigure 1: 데이터 가져오기는 데이터 과학 프로세스의 시작입니다. 데이터가 없으면 데이터 과학을 할 수 없습니다!\n\n\n\n\n책의 이 파트에서는 다음과 같은 방식으로 저장된 데이터에 접근하는 방법을 배웁니다:\n\n20  스프레드시트 에서는 Excel 스프레드시트와 Google 스프레드시트에서 데이터를 가져오는 방법을 배웁니다.\n21  데이터베이스 에서는 데이터베이스에서 데이터를 R로 가져오는 방법(그리고 R에서 데이터를 데이터베이스로 내보내는 방법도 조금) 배웁니다.\n22  Arrow 에서는 특히 데이터가 파켓(parquet) 형식으로 저장된 경우, 메모리 부족(out-of-memory) 데이터를 작업하기 위한 강력한 도구인 Arrow에 대해 배웁니다.\n23  계층적 데이터 에서는 JSON 형식으로 저장된 데이터에 의해 생성된 깊게 중첩된 리스트를 포함하여 계층적 데이터를 작업하는 방법을 배웁니다.\n24  웹 스크래핑 에서는 웹페이지에서 데이터를 추출하는 기술과 과학인 웹 “스크래핑(scraping)”을 배웁니다.\n\n여기서 다루지 않는 두 가지 중요한 tidyverse 패키지가 있습니다: haven과 xml2. SPSS, Stata, SAS 파일의 데이터를 작업한다면 haven 패키지(https://haven.tidyverse.org)를 확인하세요. XML 데이터를 작업한다면 xml2 패키지(https://xml2.r-lib.org)를 확인하세요. 그렇지 않은 경우 어떤 패키지를 사용해야 할지 알아내기 위해 조사가 필요할 것입니다. 구글(google)은 여러분의 친구입니다 😃.",
    "crumbs": [
      "가져오기 (Import)"
    ]
  },
  {
    "objectID": "spreadsheets.html",
    "href": "spreadsheets.html",
    "title": "20  스프레드시트",
    "section": "",
    "text": "20.1 소개\nChapter 7 에서 .csv 및 .tsv와 같은 일반 텍스트 파일에서 데이터를 가져오는 방법에 대해 배웠습니다. 이제 Excel 스프레드시트나 Google 스프레드시트에서 데이터를 가져오는 방법을 배울 때입니다. 이는 Chapter 7 에서 배운 내용을 기반으로 하지만 스프레드시트의 데이터로 작업할 때의 추가 고려 사항과 복잡성에 대해서도 논의할 것입니다.\n본인이나 공동 작업자가 데이터 정리를 위해 스프레드시트를 사용하고 있다면 Karl Broman과 Kara Woo의 논문 “Data Organization in Spreadsheets”(https://doi.org/10.1080/00031305.2017.1375989)를 읽어보는 것을 강력히 추천합니다. 이 논문에 제시된 모범 사례는 스프레드시트에서 R로 데이터를 가져와 분석하고 시각화할 때 많은 골칫거리를 덜어줄 것입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>스프레드시트</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#엑셀excel",
    "href": "spreadsheets.html#엑셀excel",
    "title": "20  스프레드시트",
    "section": "\n20.2 엑셀(Excel)",
    "text": "20.2 엑셀(Excel)\nMicrosoft Excel은 데이터가 스프레드시트 파일 내의 워크시트에 구성되는 널리 사용되는 스프레드시트 소프트웨어 프로그램입니다.\n\n20.2.1 선수 지식\n이 섹션에서는 readxl 패키지를 사용하여 R에서 Excel 스프레드시트의 데이터를 로드하는 방법을 배웁니다. 이 패키지는 핵심 tidyverse는 아니므로 명시적으로 로드해야 하지만 tidyverse 패키지를 설치할 때 자동으로 설치됩니다. 나중에 Excel 스프레드시트를 생성할 수 있게 해주는 writexl 패키지도 사용할 것입니다.\n\nlibrary(readxl)\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(writexl)\n\n\n20.2.2 시작하기\nreadxl 함수의 대부분은 Excel 스프레드시트를 R로 로드할 수 있게 해줍니다:\n\n\nread_xls()는 xls 형식의 Excel 파일을 읽습니다.\n\nread_xlsx()는 xlsx 형식의 Excel 파일을 읽습니다.\n\nread_excel()은 xls 및 xlsx 형식의 파일을 모두 읽을 수 있습니다. 입력에 따라 파일 유형을 추측합니다.\n\n이러한 함수들은 이전에 다른 유형의 파일(예: read_csv(), read_table() 등)을 읽기 위해 소개한 다른 함수들과 마찬가지로 유사한 구문을 가지고 있습니다. 이 장의 나머지 부분에서는 read_excel() 사용에 초점을 맞출 것입니다.\n\n20.2.3 엑셀 스프레드시트 읽기\nFigure 20.1 은 우리가 R로 읽어들일 스프레드시트가 Excel에서 어떻게 보이는지 보여줍니다. 이 스프레드시트는 https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w/에서 Excel 파일로 다운로드할 수 있습니다.\n\n\n\n\n\n\n\nFigure 20.1: Excel의 students.xlsx라는 스프레드시트.\n\n\n\n\nread_excel()의 첫 번째 인수는 읽을 파일의 경로입니다.\n\nstudents &lt;- read_excel(\"data/students.xlsx\")\n\nread_excel()은 파일을 티블로 읽어들입니다.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\n데이터에는 6명의 학생이 있고 각 학생에 대해 5개의 변수가 있습니다. 그러나 이 데이터셋에서 해결하고 싶은 몇 가지 사항이 있습니다:\n\n\n열 이름이 제각각입니다. col_names 인수를 사용하여 snake_case와 같이 일관된 형식을 따르는 열 이름을 제공할 수 있습니다.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\")\n)\n#&gt; # A tibble: 7 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1 Student ID Full Name        favourite.food     mealPlan            AGE  \n#&gt; 2 1          Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 3 2          Barclay Lynn     French fries       Lunch only          5    \n#&gt; 4 3          Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 5 4          Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 6 5          Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 7 6          Güvenç Attila    Ice cream          Lunch only          6\n\n불행히도 이것은 완벽하게 작동하지 않았습니다. 이제 우리가 원하는 변수 이름을 얻었지만 이전에 헤더 행이었던 것이 이제 데이터의 첫 번째 관측값으로 나타납니다. skip 인수를 사용하여 해당 행을 명시적으로 건너뛸 수 있습니다.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\nfavourite_food 열에서 관측값 중 하나가 N/A인데, 이는 “사용할 수 없음(not available)”을 의미하지만 현재 NA로 인식되지 않습니다(이 N/A와 목록의 네 번째 학생 나이 사이의 대조를 확인하세요). na 인수를 사용하여 NA로 인식되어야 하는 문자열을 지정할 수 있습니다. 기본적으로 \"\"(빈 문자열, 또는 스프레드시트에서 읽는 경우 빈 셀이나 =NA() 수식이 있는 셀)만 NA로 인식됩니다.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\")\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\n남아있는 또 다른 문제는 age가 문자 변수로 읽혔지만 실제로는 숫자여야 한다는 것입니다. 플랫 파일에서 데이터를 읽기 위한 read_csv() 및 친구들과 마찬가지로 read_excel()에 col_types 인수를 제공하고 읽어들이는 변수의 열 유형을 지정할 수 있습니다. 하지만 구문은 약간 다릅니다. 옵션은 \"skip\", \"guess\", \"logical\", \"numeric\", \"date\", \"text\" 또는 \"list\"입니다.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"numeric\")\n)\n#&gt; Warning: Expecting numeric in E6 / R6C5: got 'five'\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch    NA\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n그러나 이것도 원하는 결과를 정확하게 생성하지는 못했습니다. age가 숫자여야 한다고 지정함으로써 숫자가 아닌 항목(값 five를 가짐)이 있는 하나의 셀을 NA로 만들었습니다. 이 경우 나이를 \"text\"로 읽은 다음 데이터가 R에 로드되면 변경해야 합니다.\n\nstudents &lt;- read_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"text\")\n)\n\nstudents &lt;- students |&gt; \n  mutate(\n    age = if_else(age == \"five\", \"5\", age),\n    age = parse_number(age)\n  )\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\n우리가 원하는 형식으로 데이터를 로드하는 데 여러 단계와 시행착오가 필요했으며 이는 예상치 못한 일이 아닙니다. 데이터 과학은 반복적인 프로세스이며, 인간이 스프레드시트에 데이터를 입력하고 데이터 저장뿐만 아니라 공유 및 통신에도 사용하는 경향이 있기 때문에 스프레드시트에서 데이터를 읽어오는 반복 프로세스는 다른 일반 텍스트, 사각형 데이터 파일에 비해 훨씬 더 지루할 수 있습니다.\n데이터를 로드하고 살펴볼 때까지 데이터가 어떻게 생겼는지 정확히 알 수 있는 방법은 없습니다. 음, 사실 한 가지 방법이 있습니다. Excel에서 파일을 열어 엿볼 수 있습니다. 그렇게 하려면 원본 데이터 파일은 그대로 두고 R로 읽어오는 동안 대화식으로 열어보고 탐색할 Excel 파일의 사본을 만드는 것이 좋습니다. 이렇게 하면 검사하는 동안 실수로 스프레드시트의 내용을 덮어쓰지 않도록 할 수 있습니다. 또한 우리가 여기서 한 것처럼 데이터를 로드하고, 엿보고, 코드를 조정하고, 다시 로드하고, 결과에 만족할 때까지 반복하는 것을 두려워해서는 안 됩니다.\n\n20.2.4 워크시트 읽기\n스프레드시트와 플랫 파일을 구별하는 중요한 기능은 워크시트라고 하는 여러 시트의 개념입니다. Figure 20.2 는 여러 워크시트가 있는 Excel 스프레드시트를 보여줍니다. 데이터는 palmerpenguins 패키지에서 가져왔으며 https://docs.google.com/spreadsheets/d/1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY/에서 이 스프레드시트를 Excel 파일로 다운로드할 수 있습니다. 각 워크시트에는 데이터가 수집된 서로 다른 섬의 펭귄 정보가 포함되어 있습니다.\n\n\n\n\n\n\n\nFigure 20.2: 세 개의 워크시트가 포함된 Excel의 penguins.xlsx라는 스프레드시트.\n\n\n\n\nread_excel()의 sheet 인수를 사용하여 스프레드시트에서 단일 워크시트를 읽을 수 있습니다. 지금까지 의존해 온 기본값은 첫 번째 시트입니다.\n\nread_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\")\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm     bill_depth_mm      flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;            \n#&gt; 1 Adelie  Torgersen 39.1               18.7               181              \n#&gt; 2 Adelie  Torgersen 39.5               17.399999999999999 186              \n#&gt; 3 Adelie  Torgersen 40.299999999999997 18                 195              \n#&gt; 4 Adelie  Torgersen NA                 NA                 NA               \n#&gt; 5 Adelie  Torgersen 36.700000000000003 19.3               193              \n#&gt; 6 Adelie  Torgersen 39.299999999999997 20.6               190              \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;chr&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\n숫자 데이터가 포함된 것으로 보이는 일부 변수는 문자열 \"NA\"가 실제 NA로 인식되지 않아 문자로 읽힙니다.\n\npenguins_torgersen &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\", na = \"NA\")\n\npenguins_torgersen\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\n또는 excel_sheets()를 사용하여 Excel 스프레드시트의 모든 워크시트에 대한 정보를 얻은 다음 관심 있는 워크시트를 읽을 수 있습니다.\n\nexcel_sheets(\"data/penguins.xlsx\")\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\n워크시트의 이름을 알게 되면 read_excel()로 개별적으로 읽을 수 있습니다.\n\npenguins_biscoe &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Biscoe Island\", na = \"NA\")\npenguins_dream  &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Dream Island\", na = \"NA\")\n\n이 경우 전체 펭귄 데이터셋은 스프레드시트의 세 워크시트에 분산되어 있습니다. 각 워크시트에는 동일한 수의 열이 있지만 행 수는 다릅니다.\n\ndim(penguins_torgersen)\n#&gt; [1] 52  8\ndim(penguins_biscoe)\n#&gt; [1] 168   8\ndim(penguins_dream)\n#&gt; [1] 124   8\n\nbind_rows()로 합칠 수 있습니다.\n\npenguins &lt;- bind_rows(penguins_torgersen, penguins_biscoe, penguins_dream)\npenguins\n#&gt; # A tibble: 344 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 338 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nChapter 26 에서는 반복적인 코드 없이 이러한 종류의 작업을 수행하는 방법에 대해 이야기할 것입니다.\n\n20.2.5 시트의 일부 읽기\n많은 사람들이 데이터 저장뿐만 아니라 프레젠테이션용으로도 Excel 스프레드시트를 사용하기 때문에 스프레드시트에서 R로 읽으려는 데이터의 일부가 아닌 셀 항목을 찾는 것은 매우 일반적입니다. Figure 20.3 은 그러한 스프레드시트를 보여줍니다. 시트 중간에 데이터 프레임처럼 보이는 것이 있지만 데이터 위와 아래의 셀에 관련 없는 텍스트가 있습니다.\n\n\n\n\n\n\n\nFigure 20.3: Excel의 deaths.xlsx라는 스프레드시트.\n\n\n\n\n이 스프레드시트는 readxl 패키지에서 제공하는 예제 스프레드시트 중 하나입니다. readxl_example() 함수를 사용하여 패키지가 설치된 디렉터리에서 시스템의 스프레드시트를 찾을 수 있습니다. 이 함수는 평소와 같이 read_excel()에서 사용할 수 있는 스프레드시트의 경로를 반환합니다.\n\ndeaths_path &lt;- readxl_example(\"deaths.xlsx\")\ndeaths &lt;- read_excel(deaths_path)\n#&gt; New names:\n#&gt; • `` -&gt; `...2`\n#&gt; • `` -&gt; `...3`\n#&gt; • `` -&gt; `...4`\n#&gt; • `` -&gt; `...5`\n#&gt; • `` -&gt; `...6`\ndeaths\n#&gt; # A tibble: 18 × 6\n#&gt;   `Lots of people`    ...2       ...3  ...4     ...5          ...6           \n#&gt;   &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;          \n#&gt; 1 simply cannot resi… &lt;NA&gt;       &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          some notes     \n#&gt; 2 at                  the        top   &lt;NA&gt;     of            their spreadsh…\n#&gt; 3 or                  merging    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          cells          \n#&gt; 4 Name                Profession Age   Has kids Date of birth Date of death  \n#&gt; 5 David Bowie         musician   69    TRUE     17175         42379          \n#&gt; 6 Carrie Fisher       actor      60    TRUE     20749         42731          \n#&gt; # ℹ 12 more rows\n\n상위 3개 행과 하위 4개 행은 데이터 프레임의 일부가 아닙니다. skip 및 n_max 인수를 사용하여 이러한 관련 없는 행을 제거할 수 있지만 셀 범위(cell ranges)를 사용하는 것이 좋습니다. Excel에서 왼쪽 상단 셀은 A1입니다. 열을 따라 오른쪽으로 이동하면 셀 레이블이 알파벳 순으로 이동합니다. 즉, B1, C1 등입니다. 그리고 열을 따라 아래로 이동하면 셀 레이블의 숫자가 증가합니다. 즉, A2, A3 등입니다.\n여기서 우리가 읽으려는 데이터는 셀 A5에서 시작하여 셀 F15에서 끝납니다. 스프레드시트 표기법으로 이것은 A5:F15이며 range 인수에 제공합니다:\n\nread_excel(deaths_path, range = \"A5:F15\")\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.2.6 데이터 유형\nCSV 파일에서 모든 값은 문자열입니다. 이것이 데이터에 대해 특별히 진실은 아니지만 단순합니다. 모든 것이 문자열입니다.\nExcel 스프레드시트의 기본 데이터는 더 복잡합니다. 셀은 다음 네 가지 중 하나일 수 있습니다:\n\nTRUE, FALSE 또는 NA와 같은 부울(boolean).\n“10” 또는 “10.5”와 같은 숫자.\n날짜시간(datetime), “11/1/21” 또는 “11/1/21 3:00 PM”과 같이 시간을 포함할 수도 있습니다.\n“ten”과 같은 텍스트 문자열.\n\n스프레드시트 데이터로 작업할 때 기본 데이터가 셀에 표시되는 것과 매우 다를 수 있음을 명심하는 것이 중요합니다. 예를 들어 Excel에는 정수 개념이 없습니다. 모든 숫자는 부동 소수점으로 저장되지만 사용자 정의 가능한 소수점 자릿수로 데이터를 표시하도록 선택할 수 있습니다. 마찬가지로 날짜는 실제로 숫자로 저장되며, 구체적으로는 1900년 1월 1일 이후의 초 수입니다. Excel에서 서식을 적용하여 날짜 표시 방식을 사용자 정의할 수 있습니다. 혼란스럽게도 숫자처럼 보이지만 실제로는 문자열인 것을 가질 수도 있습니다(예: Excel 셀에 '10 입력).\n기본 데이터가 저장되는 방식과 표시되는 방식 간의 이러한 차이점은 데이터가 R로 로드될 때 놀라움을 유발할 수 있습니다. 기본적으로 readxl은 주어진 열의 데이터 유형을 추측합니다. 권장되는 워크플로우는 readxl이 열 유형을 추측하게 하고, 추측된 열 유형에 만족하는지 확인한 다음, 그렇지 않은 경우 돌아가서 Section 20.2.3 에 표시된 대로 col_types를 지정하여 다시 가져오는 것입니다.\n또 다른 과제는 Excel 스프레드시트의 열에 이러한 유형이 혼합되어 있는 경우입니다(예: 일부 셀은 숫자, 다른 셀은 텍스트, 다른 셀은 날짜). R로 데이터를 가져올 때 readxl은 몇 가지 결정을 내려야 합니다. 이 경우 이 열의 유형을 \"list\"로 설정할 수 있으며, 그러면 벡터의 각 요소 유형이 추측되는 길이 1 벡터의 리스트로 열을 로드합니다.\n\n\n\n\n\n\n때로는 데이터가 셀 배경색이나 텍스트가 굵게 표시되었는지 여부와 같이 더 이국적인 방식으로 저장되기도 합니다. 이런 경우 tidyxl 패키지가 유용할 수 있습니다. Excel의 표가 아닌 데이터로 작업하는 전략에 대한 자세한 내용은 https://nacnudus.github.io/spreadsheet-munging-strategies/를 참조하세요.\n\n\n\n\n20.2.7 엑셀로 쓰기\n그런 다음 쓸 수 있는 작은 데이터 프레임을 만들어 보겠습니다. item은 팩터이고 quantity는 정수라는 점에 유의하세요.\n\nbake_sale &lt;- tibble(\n  item     = factor(c(\"brownie\", \"cupcake\", \"cookie\")),\n  quantity = c(10, 5, 8)\n)\n\nbake_sale\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;fct&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\nwritexl 패키지의 write_xlsx() 함수를 사용하여 데이터를 Excel 파일로 디스크에 다시 쓸 수 있습니다:\n\nwrite_xlsx(bake_sale, path = \"data/bake-sale.xlsx\")\n\nFigure 20.4 은 Excel에서 데이터가 어떻게 보이는지 보여줍니다. 열 이름이 포함되어 있고 굵게 표시되어 있음을 주목하세요. col_names 및 format_headers 인수를 FALSE로 설정하여 끌 수 있습니다.\n\n\n\n\n\n\n\nFigure 20.4: Excel의 bake-sale.xlsx라는 스프레드시트.\n\n\n\n\nCSV에서 읽는 것과 마찬가지로 데이터를 다시 읽을 때 데이터 유형에 대한 정보가 손실됩니다. 이로 인해 Excel 파일은 중간 결과를 캐싱하는 데에도 신뢰할 수 없습니다. 대안은 Section 7.5 을 참조하세요.\n\nread_excel(\"data/bake-sale.xlsx\")\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\n\n20.2.8 서식이 지정된 출력\nwritexl 패키지는 간단한 Excel 스프레드시트를 작성하기 위한 가벼운 솔루션이지만 스프레드시트 내의 시트에 쓰기 및 스타일링과 같은 추가 기능에 관심이 있다면 openxlsx 패키지를 사용하고 싶을 것입니다. 여기서는 이 패키지를 사용하는 세부 사항에 대해 설명하지 않겠지만 openxlsx를 사용하여 R에서 Excel로 작성된 데이터에 대한 추가 서식 기능에 대한 광범위한 논의를 위해 https://ycphs.github.io/openxlsx/articles/Formatting.html을 읽는 것을 추천합니다.\n이 패키지는 tidyverse의 일부가 아니므로 함수와 워크플로우가 낯설게 느껴질 수 있습니다. 예를 들어 함수 이름은 camelCase이고 여러 함수를 파이프라인으로 구성할 수 없으며 인수는 tidyverse에서 흔히 볼 수 있는 것과는 다른 순서입니다. 하지만 괜찮습니다. 이 책 밖으로 R 학습 및 사용이 확장됨에 따라 R에서 특정 목표를 달성하기 위해 사용할 수 있는 다양한 R 패키지에서 사용되는 다양한 스타일을 접하게 될 것입니다. 새 패키지에서 사용되는 코딩 스타일에 익숙해지는 좋은 방법은 함수 설명서에 제공된 예제를 실행하여 구문과 출력 형식에 대한 감을 잡고 패키지와 함께 제공될 수 있는 비네트를 읽는 것입니다.\n\n20.2.9 연습문제\n\n\nExcel 파일에서 다음 데이터셋을 만들고 survey.xlsx로 저장하세요. 또는 여기에서 Excel 파일로 다운로드할 수 있습니다.\n\n\n\n\n\n\n\n\n그런 다음 survey_id는 문자 변수로, n_pets는 수치형 변수로 R로 읽어들입니다.\n\n#&gt; # A tibble: 6 × 2\n#&gt;   survey_id n_pets\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 1              0\n#&gt; 2 2              1\n#&gt; 3 3             NA\n#&gt; 4 4              2\n#&gt; 5 5              2\n#&gt; 6 6             NA\n\n\n\n다른 Excel 파일에서 다음 데이터셋을 만들고 roster.xlsx로 저장하세요. 또는 여기에서 Excel 파일로 다운로드할 수 있습니다.\n\n\n\n\n\n\n\n\n그런 다음 R로 읽어들입니다. 결과 데이터 프레임의 이름은 roster여야 하며 다음과 같아야 합니다.\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12\n\n\n\n새 Excel 파일에서 다음 데이터셋을 만들고 sales.xlsx로 저장하세요. 또는 여기에서 Excel 파일로 다운로드할 수 있습니다.\n\n\n\n\n\n\n\n\na. sales.xlsx를 읽어서 sales로 저장합니다. 데이터 프레임은 id와 n이 열 이름이고 9개의 행이 있는 다음과 같아야 합니다.\n\n#&gt; # A tibble: 9 × 2\n#&gt;   id      n    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 Brand 1 n    \n#&gt; 2 1234    8    \n#&gt; 3 8721    2    \n#&gt; 4 1822    3    \n#&gt; 5 Brand 2 n    \n#&gt; 6 3333    1    \n#&gt; 7 2156    3    \n#&gt; 8 3987    6    \n#&gt; 9 3216    5\n\nb. sales를 추가로 수정하여 3개의 열(brand, id, n)과 7개의 데이터 행이 있는 다음과 같은 깔끔한 형식으로 만드세요. id와 n은 숫자이고 brand는 문자 변수라는 점에 유의하세요.\n\n#&gt; # A tibble: 7 × 3\n#&gt;   brand      id     n\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Brand 1  1234     8\n#&gt; 2 Brand 1  8721     2\n#&gt; 3 Brand 1  1822     3\n#&gt; 4 Brand 2  3333     1\n#&gt; 5 Brand 2  2156     3\n#&gt; 6 Brand 2  3987     6\n#&gt; 7 Brand 2  3216     5\n\n\nbake_sale 데이터 프레임을 다시 만들고 openxlsx 패키지의 write.xlsx() 함수를 사용하여 Excel 파일로 작성하세요.\nChapter 7 에서 열 이름을 스네이크 케이스로 바꾸는 janitor::clean_names() 함수에 대해 배웠습니다. 이 섹션의 앞부분에서 소개한 students.xlsx 파일을 읽고 이 함수를 사용하여 열 이름을 “청소”하세요.\nread_xls()로 .xlsx 확장자를 가진 파일을 읽으려고 하면 어떻게 됩니까?",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>스프레드시트</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#구글-스프레드시트google-sheets",
    "href": "spreadsheets.html#구글-스프레드시트google-sheets",
    "title": "20  스프레드시트",
    "section": "\n20.3 구글 스프레드시트(Google Sheets)",
    "text": "20.3 구글 스프레드시트(Google Sheets)\nGoogle 스프레드시트는 또 다른 널리 사용되는 스프레드시트 프로그램입니다. 무료이며 웹 기반입니다. Excel과 마찬가지로 Google 스프레드시트에서도 데이터는 스프레드시트 파일 내의 워크시트(시트라고도 함)에 구성됩니다.\n\n20.3.1 선수 지식\n이 섹션도 스프레드시트에 초점을 맞추지만 이번에는 googlesheets4 패키지로 Google 스프레드시트에서 데이터를 로드합니다. 이 패키지도 핵심 tidyverse가 아니므로 명시적으로 로드해야 합니다.\n\nlibrary(googlesheets4)\nlibrary(tidyverse)\n\n패키지 이름에 대한 간단한 참고: googlesheets4는 Sheets API v4의 v4를 사용하여 Google 스프레드시트에 대한 R 인터페이스를 제공하므로 이름이 그렇습니다.\n\n20.3.2 시작하기\ngooglesheets4 패키지의 주요 함수는 read_sheet()이며, URL이나 파일 ID에서 Google 스프레드시트를 읽습니다. 이 함수는 range_read()라는 이름으로도 사용됩니다.\n또한 gs4_create()로 새 시트를 만들거나 sheet_write() 및 친구들로 기존 시트에 쓸 수도 있습니다.\n이 섹션에서는 Excel 섹션과 동일한 데이터셋으로 작업하여 Excel과 Google 스프레드시트에서 데이터를 읽는 워크플로우의 유사점과 차이점을 강조합니다. readxl 및 googlesheets4 패키지는 모두 Chapter 7 에서 본 read_csv() 함수를 제공하는 readr 패키지의 기능을 모방하도록 설계되었습니다. 따라서 read_excel()을 read_sheet()로 교체하는 것만으로 많은 작업을 수행할 수 있습니다. 그러나 Excel과 Google 스프레드시트가 정확히 같은 방식으로 작동하지 않으므로 다른 작업에는 함수 호출에 대한 추가 업데이트가 필요할 수 있습니다.\n\n20.3.3 구글 스프레드시트 읽기\nFigure 20.5 는 우리가 R로 읽어들일 스프레드시트가 Google 스프레드시트에서 어떻게 보이는지 보여줍니다. 이것은 Figure 20.1 과 동일한 데이터셋이지만 Excel 대신 Google 스프레드시트에 저장되어 있습니다.\n\n\n\n\n\n\n\nFigure 20.5: 브라우저 창의 students라는 Google 스프레드시트.\n\n\n\n\nread_sheet()의 첫 번째 인수는 읽을 파일의 URL이며 티블을 반환합니다:https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w. 이러한 URL은 작업하기에 유쾌하지 않으므로 ID로 시트를 식별하고 싶을 때가 많습니다.\n\ngs4_deauth()\n\n\nstudents_sheet_id &lt;- \"1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w\"\nstudents &lt;- read_sheet(students_sheet_id)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range Sheet1.\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE   \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;list&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          &lt;dbl&gt; \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          &lt;dbl&gt; \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch &lt;dbl&gt; \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NULL&gt;\n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch &lt;chr&gt; \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          &lt;dbl&gt;\n\nread_excel()에서 했던 것처럼 열 이름, NA 문자열, 열 유형을 read_sheet()에 제공할 수 있습니다.\n\nstudents &lt;- read_sheet(\n  students_sheet_id,\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = \"dcccc\"\n)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range 2:10000000.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n여기서 열 유형을 짧은 코드를 사용하여 약간 다르게 정의했음에 유의하세요. 예를 들어 “dcccc”는 “double, character, character, character, character”를 나타냅니다.\nGoogle 스프레드시트에서 개별 시트를 읽을 수도 있습니다. penguins Google 스프레드시트에서 “Torgersen Island” 시트를 읽어보겠습니다:\n\npenguins_sheet_id &lt;- \"1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY\"\nread_sheet(penguins_sheet_id, sheet = \"Torgersen Island\")\n#&gt; ✔ Reading from penguins.\n#&gt; ✔ Range ''Torgersen Island''.\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;list&gt;         &lt;list&gt;        &lt;list&gt;           \n#&gt; 1 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 2 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 3 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 4 Adelie  Torgersen &lt;chr [1]&gt;      &lt;chr [1]&gt;     &lt;chr [1]&gt;        \n#&gt; 5 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 6 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;list&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nsheet_names()를 사용하여 Google 스프레드시트 내의 모든 시트 목록을 얻을 수 있습니다:\n\nsheet_names(penguins_sheet_id)\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\n마지막으로 read_excel()과 마찬가지로 read_sheet()에서 range를 정의하여 Google 스프레드시트의 일부를 읽을 수 있습니다. 아래에서는 gs4_example() 함수를 사용하여 googlesheets4 패키지와 함께 제공되는 예제 Google 스프레드시트를 찾습니다.\n\ndeaths_url &lt;- gs4_example(\"deaths\")\ndeaths &lt;- read_sheet(deaths_url, range = \"A5:F15\")\n#&gt; ✔ Reading from deaths.\n#&gt; ✔ Range A5:F15.\ndeaths\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.3.4 구글 스프레드시트에 쓰기\nwrite_sheet()를 사용하여 R에서 Google 스프레드시트로 쓸 수 있습니다. 첫 번째 인수는 쓸 데이터 프레임이고 두 번째 인수는 쓸 Google 스프레드시트의 이름(또는 다른 식별자)입니다:\n\nwrite_sheet(bake_sale, ss = \"bake-sale\")\n\nGoogle 스프레드시트 내의 특정 (워크)시트에 데이터를 쓰려면 sheet 인수로 지정할 수도 있습니다.\n\nwrite_sheet(bake_sale, ss = \"bake-sale\", sheet = \"Sales\")\n\n\n20.3.5 인증(Authentication)\nGoogle 계정으로 인증하지 않고 gs4_deauth()를 사용하여 공개 Google 스프레드시트에서 읽을 수 있지만, 비공개 시트를 읽거나 시트에 쓰려면 googlesheets4가 여러분의 Google 스프레드시트를 보고 관리할 수 있도록 인증이 필요합니다.\n인증이 필요한 시트를 읽으려고 시도하면 googlesheets4는 웹 브라우저로 안내하여 Google 계정에 로그인하고 Google 스프레드시트로 대신 작업할 수 있는 권한을 부여하라는 메시지를 표시합니다. 그러나 특정 Google 계정, 인증 범위 등을 지정하려면 gs4_auth()를 사용하여 수행할 수 있습니다. 예: gs4_auth(email = \"mine@example.com\")은 특정 이메일과 연결된 토큰을 강제로 사용합니다. 자세한 인증 정보는 googlesheets4 인증 비네트 https://googlesheets4.tidyverse.org/articles/auth.html을 읽어보는 것을 추천합니다.\n\n20.3.6 연습문제\n\n이 장의 앞부분에 있는 students 데이터셋을 Excel과 Google 스프레드시트에서 읽되 read_excel() 및 read_sheet() 함수에 추가 인수를 제공하지 마세요. 결과 R 데이터 프레임이 정확히 동일합니까? 그렇지 않다면 어떻게 다릅니까?\nhttps://pos.it/r4ds-survey에서 survey라는 제목의 Google 스프레드시트를 읽되 survey_id는 문자 변수로, n_pets는 수치형 변수로 읽으세요.\n\nhttps://pos.it/r4ds-roster에서 roster라는 제목의 Google 스프레드시트를 읽으세요. 결과 데이터 프레임의 이름은 roster여야 하며 다음과 같아야 합니다.\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>스프레드시트</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#요약",
    "href": "spreadsheets.html#요약",
    "title": "20  스프레드시트",
    "section": "\n20.4 요약",
    "text": "20.4 요약\nMicrosoft Excel과 Google 스프레드시트는 가장 널리 사용되는 두 가지 스프레드시트 시스템입니다. R에서 Excel 및 Google 스프레드시트 파일에 저장된 데이터와 직접 상호 작용할 수 있는 것은 엄청난 능력입니다! 이 장에서는 readxl 패키지의 read_excel()을 사용하여 Excel에서, googlesheets4 패키지의 read_sheet()를 사용하여 Google 스프레드시트에서 R로 데이터를 읽는 방법을 배웠습니다. 이 함수들은 서로 매우 유사하게 작동하며 열 이름, NA 문자열, 읽어들이는 파일 상단에서 건너뛸 행 등을 지정하기 위한 유사한 인수를 가지고 있습니다. 또한 두 함수 모두 스프레드시트에서 단일 시트를 읽을 수 있게 해줍니다.\n반면 Excel 파일에 쓰는 것은 다른 패키지와 함수(writexl::write_xlsx())가 필요한 반면, Google 스프레드시트에는 googlesheets4 패키지의 write_sheet()를 사용하여 쓸 수 있습니다.\n다음 장에서는 다른 데이터 소스인 데이터베이스와 해당 소스에서 R로 데이터를 읽는 방법에 대해 배울 것입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>스프레드시트</span>"
    ]
  },
  {
    "objectID": "databases.html",
    "href": "databases.html",
    "title": "21  데이터베이스",
    "section": "",
    "text": "21.1 소개\n방대한 양의 데이터가 데이터베이스에 저장되어 있으므로 데이터베이스에 액세스하는 방법을 아는 것은 필수적입니다. 때때로 누군가에게 스냅샷을 .csv로 다운로드해 달라고 요청할 수 있지만, 이것은 금방 고통스러워집니다. 변경해야 할 때마다 다른 사람과 소통해야 하기 때문입니다. 필요할 때 필요한 데이터를 얻기 위해 데이터베이스에 직접 접근할 수 있어야 합니다.\n이 장에서는 먼저 DBI 패키지의 기본 사항을 배웁니다. DBI 패키지를 사용하여 데이터베이스에 연결한 다음 SQL1 쿼리로 데이터를 검색하는 방법을 배웁니다. Structured Query Language의 약자인 SQL은 데이터베이스의 공용어이며 모든 데이터 과학자가 배워야 할 중요한 언어입니다. 그렇긴 하지만 우리는 SQL로 시작하지 않고 대신 dplyr 코드를 SQL로 변환할 수 있는 dbplyr을 가르칠 것입니다. 그것을 SQL의 가장 중요한 기능 중 일부를 가르치는 방법으로 사용할 것입니다. 이 장이 끝날 때까지 SQL 마스터가 되지는 않겠지만 가장 중요한 구성 요소를 식별하고 그 기능을 이해할 수 있게 될 것입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#소개",
    "href": "databases.html#소개",
    "title": "21  데이터베이스",
    "section": "",
    "text": "21.1.1 선수 지식\n이 장에서는 DBI와 dbplyr을 소개합니다. DBI는 데이터베이스에 연결하고 SQL을 실행하는 저수준 인터페이스입니다. dbplyr은 dplyr 코드를 SQL 쿼리로 변환한 다음 DBI로 실행하는 고수준 인터페이스입니다.\n\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#데이터베이스-기초",
    "href": "databases.html#데이터베이스-기초",
    "title": "21  데이터베이스",
    "section": "\n21.2 데이터베이스 기초",
    "text": "21.2 데이터베이스 기초\n가장 단순한 수준에서 데이터베이스를 데이터베이스 용어로 테이블(tables) 이라고 하는 데이터 프레임 모음으로 생각할 수 있습니다. 데이터 프레임과 마찬가지로 데이터베이스 테이블은 열의 모든 값이 동일한 유형인 명명된 열의 모음입니다. 데이터 프레임과 데이터베이스 테이블 사이에는 세 가지 높은 수준의 차이점이 있습니다:\n\n데이터베이스 테이블은 디스크에 저장되며 임의로 클 수 있습니다. 데이터 프레임은 메모리에 저장되며 근본적으로 제한되어 있습니다(비록 그 제한이 많은 문제에 대해 여전히 충분히 크지만).\n데이터베이스 테이블에는 거의 항상 인덱스가 있습니다. 책의 색인과 마찬가지로 데이터베이스 인덱스를 사용하면 모든 단일 행을 볼 필요 없이 관심 있는 행을 빠르게 찾을 수 있습니다. 데이터 프레임과 티블에는 인덱스가 없지만 data.table에는 있으며, 이것이 data.table이 빠른 이유 중 하나입니다.\n대부분의 고전적인 데이터베이스는 기존 데이터를 분석하는 것이 아니라 데이터를 신속하게 수집하는 데 최적화되어 있습니다. 이러한 데이터베이스는 데이터가 R과 같이 열별로 저장되는 것이 아니라 행별로 저장되기 때문에 행 지향(row-oriented) 이라고 합니다. 더 최근에는 기존 데이터를 훨씬 더 빠르게 분석할 수 있는 열 지향(column-oriented) 데이터베이스가 많이 개발되었습니다.\n\n데이터베이스는 데이터베이스 관리 시스템(줄여서 DBMS)에 의해 실행되며, 세 가지 기본 형태가 있습니다:\n\n\n클라이언트-서버 DBMS는 강력한 중앙 서버에서 실행되며, 여러분은 컴퓨터(클라이언트)에서 연결합니다. 조직 내의 여러 사람과 데이터를 공유하는 데 좋습니다. 널리 사용되는 클라이언트-서버 DBMS에는 PostgreSQL, MariaDB, SQL Server, Oracle이 있습니다.\nSnowflake, Amazon RedShift, Google BigQuery와 같은 클라우드 DBMS는 클라이언트-서버 DBMS와 유사하지만 클라우드에서 실행됩니다. 즉, 매우 큰 데이터셋을 쉽게 처리할 수 있으며 필요에 따라 더 많은 컴퓨팅 리소스를 자동으로 제공할 수 있습니다.\nSQLite 또는 duckdb와 같은 인-프로세스(In-process) DBMS는 전적으로 컴퓨터에서 실행됩니다. 여러분이 주 사용자인 대규모 데이터셋으로 작업하는 데 좋습니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#데이터베이스-연결",
    "href": "databases.html#데이터베이스-연결",
    "title": "21  데이터베이스",
    "section": "\n21.3 데이터베이스 연결",
    "text": "21.3 데이터베이스 연결\nR에서 데이터베이스에 연결하려면 한 쌍의 패키지를 사용합니다:\n\n데이터베이스에 연결하고, 데이터를 업로드하고, SQL 쿼리를 실행하는 등의 일반적인 함수 집합을 제공하는 DBI(database interface)를 항상 사용합니다.\n연결하려는 DBMS에 맞춤화된 패키지도 사용합니다. 이 패키지는 일반 DBI 명령을 해당 DBMS에 필요한 세부 사항으로 변환합니다. 일반적으로 각 DBMS마다 패키지가 하나씩 있습니다. 예를 들어 PostgreSQL용 RPostgres, MySQL용 RMariaDB입니다.\n\nDBMS에 맞는 특정 패키지를 찾을 수 없는 경우 일반적으로 odbc 패키지를 대신 사용할 수 있습니다. 이것은 많은 DBMS에서 지원하는 ODBC 프로토콜을 사용합니다. odbc는 ODBC 드라이버도 설치하고 odbc 패키지에 드라이버 위치를 알려줘야 하므로 설정이 조금 더 필요합니다.\n구체적으로 DBI::dbConnect()를 사용하여 데이터베이스 연결을 생성합니다. 첫 번째 인수는 DBMS2를 선택하고, 두 번째 및 후속 인수는 연결 방법(즉, 위치 및 액세스에 필요한 자격 증명)을 설명합니다. 다음 코드는 몇 가지 전형적인 예를 보여줍니다:\n\ncon &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(), \n  username = \"foo\"\n)\ncon &lt;- DBI::dbConnect(\n  RPostgres::Postgres(), \n  hostname = \"databases.mycompany.com\", \n  port = 1234\n)\n\n연결의 정확한 세부 사항은 DBMS마다 많이 다르므로 안타깝게도 여기서 모든 세부 사항을 다룰 수는 없습니다. 즉, 스스로 조사를 좀 해야 합니다. 일반적으로 팀의 다른 데이터 과학자에게 물어보거나 DBA(Database Administrator)에게 이야기할 수 있습니다. 초기 설정은 올바르게 하기 위해 약간의 조작(그리고 아마도 약간의 구글링)이 필요할 수 있지만 일반적으로 한 번만 수행하면 됩니다.\n\n21.3.1 이 책에서\n클라이언트-서버나 클라우드 DBMS를 설정하는 것은 이 책에서는 고통스러운 일이 될 것이므로 대신 R 패키지 내에 전적으로 존재하는 인-프로세스 DBMS인 duckdb를 사용할 것입니다. DBI의 마법 덕분에 duckdb와 다른 DBMS를 사용하는 유일한 차이점은 데이터베이스에 연결하는 방법뿐입니다. 따라서 이 코드를 쉽게 실행할 수 있을 뿐만 아니라 배운 내용을 쉽게 가져와 다른 곳에 적용할 수 있으므로 가르치기에 좋습니다.\nduckdb에 연결하는 것은 특히 간단합니다. 기본값이 R을 종료할 때 삭제되는 임시 데이터베이스를 생성하기 때문입니다. R을 다시 시작할 때마다 깨끗한 상태에서 시작한다는 것을 보장하므로 학습에 좋습니다:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\n\nduckdb는 데이터 과학자의 요구에 매우 부합하도록 설계된 고성능 데이터베이스입니다. 시작하기 매우 쉽지만 기가바이트의 데이터를 매우 빠른 속도로 처리할 수도 있기 때문에 여기서 사용합니다. 실제 데이터 분석 프로젝트에 duckdb를 사용하려면 dbdir 인수를 제공하여 영구 데이터베이스를 만들고 저장할 위치를 duckdb에 알려줘야 합니다. 프로젝트(Chapter 6)를 사용하고 있다고 가정하면 현재 프로젝트의 duckdb 디렉터리에 저장하는 것이 합리적입니다:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), dbdir = \"duckdb\")\n\n\n21.3.2 데이터 로드\n이것은 새 데이터베이스이므로 데이터를 추가하는 것으로 시작해야 합니다. 여기서는 DBI::dbWriteTable()을 사용하여 ggplot2의 mpg 및 diamonds 데이터셋을 추가합니다. dbWriteTable()의 가장 간단한 사용법에는 데이터베이스 연결, 데이터베이스에 생성할 테이블 이름, 데이터 프레임의 세 가지 인수가 필요합니다.\n\ndbWriteTable(con, \"mpg\", ggplot2::mpg)\ndbWriteTable(con, \"diamonds\", ggplot2::diamonds)\n\n실제 프로젝트에서 duckdb를 사용하는 경우 duckdb_read_csv() 및 duckdb_register_arrow()에 대해 배우는 것을 강력히 추천합니다. 이것들은 데이터를 먼저 R로 로드하지 않고도 duckdb로 직접 데이터를 빠르게 로드할 수 있는 강력하고 성능이 뛰어난 방법을 제공합니다. 또한 Section 26.4.1 에서 여러 파일을 데이터베이스로 로드하는 유용한 기술을 보여줄 것입니다.\n\n21.3.3 DBI 기초\ndbListTables()는 데이터베이스의 모든 테이블을 나열3하고 dbReadTable()은 테이블의 내용을 검색하는 등 몇 가지 다른 DBI 함수를 사용하여 데이터가 올바르게 로드되었는지 확인할 수 있습니다.\n\ndbListTables(con)\n#&gt; [1] \"diamonds\" \"mpg\"\n\ncon |&gt; \n  dbReadTable(\"diamonds\") |&gt; \n  as_tibble()\n#&gt; # A tibble: 53,940 × 10\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # ℹ 53,934 more rows\n\ndbReadTable()은 data.frame을 반환하므로 예쁘게 인쇄되도록 as_tibble()을 사용하여 티블로 변환합니다.\n이미 SQL을 알고 있다면 dbGetQuery()를 사용하여 데이터베이스에서 쿼리를 실행한 결과를 얻을 수 있습니다:\n\nsql &lt;- \"\n  SELECT carat, cut, clarity, color, price \n  FROM diamonds \n  WHERE price &gt; 15000\n\"\nas_tibble(dbGetQuery(con, sql))\n#&gt; # A tibble: 1,655 × 5\n#&gt;   carat cut       clarity color price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1  1.54 Premium   VS2     E     15002\n#&gt; 2  1.19 Ideal     VVS1    F     15005\n#&gt; 3  2.1  Premium   SI1     I     15007\n#&gt; 4  1.69 Ideal     SI1     D     15011\n#&gt; 5  1.5  Very Good VVS2    G     15013\n#&gt; 6  1.73 Very Good VS1     G     15014\n#&gt; # ℹ 1,649 more rows\n\nSQL을 한 번도 본 적이 없더라도 걱정하지 마세요! 곧 더 자세히 배우게 될 것입니다. 하지만 주의 깊게 읽으면 diamonds 데이터셋의 5개 열과 price가 15,000보다 큰 모든 행을 선택한다고 추측할 수 있습니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#dbplyr-기초",
    "href": "databases.html#dbplyr-기초",
    "title": "21  데이터베이스",
    "section": "\n21.4 dbplyr 기초",
    "text": "21.4 dbplyr 기초\n이제 데이터베이스에 연결하고 일부 데이터를 로드했으므로 dbplyr에 대해 배우기 시작할 수 있습니다. dbplyr은 dplyr 백엔드입니다. 즉, dplyr 코드를 계속 작성하지만 백엔드가 이를 다르게 실행한다는 의미입니다. 여기서 dbplyr은 SQL로 변환합니다. 다른 백엔드로는 data.table로 변환하는 dtplyr과 여러 코어에서 코드를 실행하는 multidplyr이 있습니다.\ndbplyr을 사용하려면 먼저 tbl()을 사용하여 데이터베이스 테이블을 나타내는 객체를 생성해야 합니다:\n\ndiamonds_db &lt;- tbl(con, \"diamonds\")\ndiamonds_db\n#&gt; # Source:   table&lt;diamonds&gt; [?? x 10]\n#&gt; # Database: DuckDB 1.4.3 [root@Darwin 25.1.0:R 4.5.0/:memory:]\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # ℹ more rows\n\n\n\n\n\n\n\n데이터베이스와 상호 작용하는 두 가지 다른 일반적인 방법이 있습니다. 첫째, 많은 기업 데이터베이스는 매우 커서 모든 테이블을 정리하려면 계층 구조가 필요합니다. 이 경우 관심 있는 테이블을 선택하기 위해 스키마 또는 카탈로그와 스키마를 제공해야 할 수 있습니다:\n\ndiamonds_db &lt;- tbl(con, in_schema(\"sales\", \"diamonds\"))\ndiamonds_db &lt;- tbl(con, in_catalog(\"north_america\", \"sales\", \"diamonds\"))\n\n다른 때는 자신의 SQL 쿼리를 시작점으로 사용하고 싶을 수 있습니다:\n\ndiamonds_db &lt;- tbl(con, sql(\"SELECT * FROM diamonds\"))\n\n\n\n\n이 객체는 게으릅니다(lazy). dplyr 동사를 사용해도 dplyr은 아무 작업도 수행하지 않습니다. 수행하려는 작업 순서를 기록하고 필요할 때만 수행합니다. 예를 들어 다음 파이프라인을 살펴보세요:\n\nbig_diamonds_db &lt;- diamonds_db |&gt; \n  filter(price &gt; 15000) |&gt; \n  select(carat:clarity, price)\n\nbig_diamonds_db\n#&gt; # Source:   SQL [?? x 5]\n#&gt; # Database: DuckDB 1.4.3 [root@Darwin 25.1.0:R 4.5.0/:memory:]\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # ℹ more rows\n\n상단에 DBMS 이름이 인쇄되고 열 수는 알려주지만 일반적으로 행 수는 알 수 없기 때문에 이 객체가 데이터베이스 쿼리를 나타낸다는 것을 알 수 있습니다. 총 행 수를 찾으려면 일반적으로 전체 쿼리를 실행해야 하는데, 이는 우리가 피하려고 하는 것이기 때문입니다.\nshow_query()라는 dplyr 함수로 생성된 SQL 코드를 볼 수 있습니다. dplyr을 알고 있다면 SQL을 배우는 좋은 방법입니다! dplyr 코드를 작성하고 dbplyr이 SQL로 변환하게 한 다음 두 언어가 어떻게 일치하는지 파악해 보세요.\n\nbig_diamonds_db |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT carat, cut, color, clarity, price\n#&gt; FROM diamonds\n#&gt; WHERE (price &gt; 15000.0)\n\n모든 데이터를 R로 다시 가져오려면 collect()를 호출합니다. 뒤에서 이것은 SQL을 생성하고 dbGetQuery()를 호출하여 데이터를 얻은 다음 결과를 티블로 변환합니다:\n\nbig_diamonds &lt;- big_diamonds_db |&gt; \n  collect()\nbig_diamonds\n#&gt; # A tibble: 1,655 × 5\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # ℹ 1,649 more rows\n\n일반적으로 dbplyr을 사용하여 데이터베이스에서 원하는 데이터를 선택하고 아래 설명된 변환을 사용하여 기본 필터링 및 집계를 수행합니다. 그런 다음 R 고유의 함수로 데이터를 분석할 준비가 되면 collect()를 사용하여 메모리 내 티블을 얻고 순수 R 코드로 작업을 계속합니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#sql",
    "href": "databases.html#sql",
    "title": "21  데이터베이스",
    "section": "\n21.5 SQL",
    "text": "21.5 SQL\n이 장의 나머지 부분에서는 dbplyr의 렌즈를 통해 SQL을 조금 가르칠 것입니다. 다소 전통적이지 않은 SQL 소개이지만 기본 사항을 빠르게 파악하는 데 도움이 되기를 바랍니다. 다행히도 개념의 많은 부분이 동일하므로 dplyr을 이해한다면 SQL을 빠르게 배울 수 있습니다.\nnycflights13 패키지의 오랜 친구인 flights와 planes를 사용하여 dplyr과 SQL 간의 관계를 탐색할 것입니다. dbplyr에는 nycflights13의 테이블을 데이터베이스로 복사하는 함수가 함께 제공되므로 이 데이터셋들을 학습 데이터베이스로 가져오기가 쉽습니다:\n\ndbplyr::copy_nycflights13(con)\n#&gt; Creating table: airlines\n#&gt; Creating table: airports\n#&gt; Creating table: flights\n#&gt; Creating table: planes\n#&gt; Creating table: weather\nflights &lt;- tbl(con, \"flights\")\nplanes &lt;- tbl(con, \"planes\")\n\n\n21.5.1 SQL 기초\nSQL의 최상위 구성 요소를 문(statements) 이라고 합니다. 일반적인 문에는 새 테이블 정의를 위한 CREATE, 데이터 추가를 위한 INSERT, 데이터 검색을 위한 SELECT가 포함됩니다. 데이터 과학자로서 거의 독점적으로 사용할 것이기 때문에 SELECT 문, 즉 쿼리(queries) 에 집중할 것입니다.\n쿼리는 절(clauses) 로 구성됩니다. 중요한 5가지 절은 SELECT, FROM, WHERE, ORDER BY, GROUP BY입니다. 모든 쿼리에는 SELECT4 및 FROM5 절이 있어야 하며 가장 간단한 쿼리는 지정된 테이블의 모든 열을 선택하는 SELECT * FROM table입니다. 이것이 dbplyr이 순수한 테이블에 대해 생성하는 것입니다:\n\nflights |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM flights\nplanes |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM planes\n\nWHERE와 ORDER BY는 포함되는 행과 정렬 방법을 제어합니다:\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  arrange(dep_delay) |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH')\n#&gt; ORDER BY dep_delay\n\nGROUP BY는 쿼리를 요약으로 변환하여 집계가 발생하도록 합니다:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(dep_delay = mean(dep_delay, na.rm = TRUE)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT dest, AVG(dep_delay) AS dep_delay\n#&gt; FROM flights\n#&gt; GROUP BY dest\n\ndplyr 동사와 SELECT 절 사이에는 두 가지 중요한 차이점이 있습니다:\n\nSQL에서는 대소문자가 중요하지 않습니다: select, SELECT, 심지어 SeLeCt라고 쓸 수도 있습니다. 이 책에서는 테이블이나 변수 이름과 구별하기 위해 SQL 키워드를 대문자로 쓰는 일반적인 관례를 따를 것입니다.\nSQL에서는 순서가 중요합니다: 항상 SELECT, FROM, WHERE, GROUP BY, ORDER BY 순서로 절을 작성해야 합니다. 혼란스럽게도 이 순서는 절이 실제로 평가되는 방식과 일치하지 않습니다. 실제 평가는 FROM, 그 다음 WHERE, GROUP BY, SELECT, ORDER BY 순입니다.\n\n다음 섹션에서는 각 절을 더 자세히 살펴봅니다.\n\n\n\n\n\n\nSQL은 표준이지만 매우 복잡하며 어떤 데이터베이스도 이를 정확히 따르지 않습니다. 이 책에서 중점적으로 다룰 주요 구성 요소는 DBMS 간에 매우 유사하지만 사소한 변형이 많이 있습니다. 다행히 dbplyr은 이 문제를 처리하도록 설계되었으며 데이터베이스마다 다른 변환을 생성합니다. 완벽하지는 않지만 지속적으로 개선되고 있으며 문제가 발생하면 GitHub에 문제를 제기하여 더 잘할 수 있도록 도울 수 있습니다.\n\n\n\n\n21.5.2 SELECT\nSELECT 절은 쿼리의 일꾼이며 select(), mutate(), rename(), relocate()와 다음 섹션에서 배울 summarize()와 동일한 작업을 수행합니다.\nselect(), rename(), relocate()는 이름과 함께 열이 나타나는 위치(나타나는 경우)에만 영향을 미치므로 SELECT로 매우 직접적으로 변환됩니다:\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\"\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  rename(year_built = year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\" AS year_built\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  relocate(manufacturer, model, .before = type) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, manufacturer, model, \"type\", \"year\"\n#&gt; FROM planes\n\n이 예제는 SQL이 이름 바꾸기를 수행하는 방법도 보여줍니다. SQL 용어로 이름 바꾸기는 별칭(aliasing) 이라고 하며 AS로 수행됩니다. mutate()와 달리 이전 이름이 왼쪽에 있고 새 이름이 오른쪽에 있다는 점에 유의하세요.\n\n\n\n\n\n\n위의 예제에서 \"year\"와 \"type\"이 큰따옴표로 묶여 있음을 주목하세요. 이는 duckdb의 예약어이므로 dbplyr은 열/테이블 이름과 SQL 연산자 간의 잠재적 혼란을 피하기 위해 인용부호를 붙입니다.\n다른 데이터베이스로 작업할 때 duckdb와 같은 소수의 클라이언트 패키지만 모든 예약어를 알고 있으므로 안전을 위해 모든 것을 인용하기 때문에 모든 변수 이름이 인용된 것을 볼 수 있습니다.\nSELECT \"tailnum\", \"type\", \"manufacturer\", \"model\", \"year\"\nFROM \"planes\"\n다른 데이터베이스 시스템은 인용부호 대신 역따옴표(backticks)를 사용합니다:\nSELECT `tailnum`, `type`, `manufacturer`, `model`, `year`\nFROM `planes`\n\n\n\nmutate()에 대한 변환도 마찬가지로 간단합니다. 각 변수는 SELECT의 새 표현식이 됩니다:\n\nflights |&gt; \n  mutate(\n    speed = distance / (air_time / 60)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*, distance / (air_time / 60.0) AS speed\n#&gt; FROM flights\n\nSection 21.6 에서 개별 구성 요소(예: /)의 변환으로 다시 돌아올 것입니다.\n\n21.5.3 FROM\nFROM 절은 데이터 소스를 정의합니다. 지금은 단일 테이블만 사용하고 있기 때문에 당분간은 별로 흥미롭지 않을 것입니다. 조인 함수를 다루게 되면 더 복잡한 예제를 보게 될 것입니다.\n\n21.5.4 GROUP BY\ngroup_by()는 GROUP BY6 절로 변환되고 summarize()는 SELECT 절로 변환됩니다:\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(\n    n = n(),\n    avg_price = mean(price, na.rm = TRUE)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n, AVG(price) AS avg_price\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n\nSection 21.6 에서 n()과 mean()의 변환에 무슨 일이 일어나고 있는지 다시 다룰 것입니다.\n\n21.5.5 WHERE\nfilter()는 WHERE 절로 변환됩니다:\n\nflights |&gt; \n  filter(dest == \"IAH\" | dest == \"HOU\") |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH' OR dest = 'HOU')\n\nflights |&gt; \n  filter(arr_delay &gt; 0 & arr_delay &lt; 20) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (arr_delay &gt; 0.0 AND arr_delay &lt; 20.0)\n\n여기서 주목해야 할 몇 가지 중요한 세부 사항이 있습니다:\n\n\n|는 OR가 되고 &는 AND가 됩니다.\nSQL은 ==가 아니라 비교에 =를 사용합니다. SQL에는 할당이 없으므로 혼동할 가능성이 없습니다.\nSQL은 \"\"가 아니라 문자열에 ''만 사용합니다. SQL에서 \"\"는 R의 ``와 같이 변수를 식별하는 데 사용됩니다.\n\n또 다른 유용한 SQL 연산자는 IN으로 R의 %in%와 매우 유사합니다:\n\nflights |&gt; \n  filter(dest %in% c(\"IAH\", \"HOU\")) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest IN ('IAH', 'HOU'))\n\nSQL은 NA 대신 NULL을 사용합니다. NULL은 NA와 비슷하게 작동합니다. 주요 차이점은 비교 및 산술에서 “전염성”이 있지만 요약할 때는 조용히 삭제된다는 것입니다. dbplyr은 처음 접할 때 이 동작에 대해 상기시켜 줍니다:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(delay = mean(arr_delay))\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB 1.4.3 [root@Darwin 25.1.0:R 4.5.0/:memory:]\n#&gt;   dest   delay\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 CLT    7.36 \n#&gt; 2 MDW   12.4  \n#&gt; 3 HOU    7.18 \n#&gt; 4 SDF   12.7  \n#&gt; 5 LAS    0.258\n#&gt; 6 PHX    2.10 \n#&gt; # ℹ more rows\n\nNULL이 작동하는 방식에 대해 더 알고 싶다면 Markus Winand의 “The Three-Valued Logic of SQL”을 읽어보세요.\n일반적으로 R에서 NA에 사용하는 함수를 사용하여 NULL로 작업할 수 있습니다:\n\nflights |&gt; \n  filter(!is.na(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (NOT((dep_delay IS NULL)))\n\n이 SQL 쿼리는 dbplyr의 단점 중 하나를 보여줍니다. SQL이 정확하지만 직접 손으로 쓰는 것만큼 간단하지 않을 수 있습니다. 이 경우 괄호를 생략하고 읽기 쉬운 특수 연산자를 사용할 수 있습니다:\nWHERE \"dep_delay\" IS NOT NULL\n방금 생성한 변수를 filter()하면 dbplyr은 WHERE 절이 아니라 HAVING 절을 생성합니다. 이것은 SQL의 특징 중 하나입니다. WHERE는 SELECT 및 GROUP BY 전에 평가되므로 SQL에는 그 후에 평가되는 또 다른 절이 필요합니다.\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(n = n()) |&gt; \n  filter(n &gt; 100) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n#&gt; HAVING (COUNT(*) &gt; 100.0)\n\n\n21.5.6 ORDER BY\n행 정렬은 arrange()에서 ORDER BY 절로의 간단한 변환을 포함합니다:\n\nflights |&gt; \n  arrange(year, month, day, desc(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; ORDER BY \"year\", \"month\", \"day\", dep_delay DESC\n\ndesc()가 DESC로 변환되는 것을 주목하세요. 이것은 이름이 SQL에서 직접 영감을 받은 많은 dplyr 함수 중 하나입니다.\n\n21.5.7 하위 쿼리(Subqueries)\n때로는 dplyr 파이프라인을 단일 SELECT 문으로 변환할 수 없어서 하위 쿼리를 사용해야 할 때가 있습니다. 하위 쿼리는 일반적인 테이블 대신 FROM 절에서 데이터 소스로 사용되는 쿼리일 뿐입니다.\ndbplyr은 일반적으로 SQL의 한계를 해결하기 위해 하위 쿼리를 사용합니다. 예를 들어 SELECT 절의 표현식은 방금 생성된 열을 참조할 수 없습니다. 즉, 다음 (바보 같은) dplyr 파이프라인은 두 단계로 발생해야 합니다. 첫 번째(내부) 쿼리는 year1을 계산하고 두 번째(외부) 쿼리는 year2를 계산할 수 있습니다.\n\nflights |&gt; \n  mutate(\n    year1 = year + 1,\n    year2 = year1 + 1\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*, year1 + 1.0 AS year2\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n\n방금 생성한 변수를 filter()하려고 시도한 경우에도 이를 볼 수 있습니다. WHERE가 SELECT 뒤에 쓰여지더라도 그 전에 평가된다는 것을 기억하세요. 따라서 이 (바보 같은) 예제에서는 하위 쿼리가 필요합니다:\n\nflights |&gt; \n  mutate(year1 = year + 1) |&gt; \n  filter(year1 == 2014) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n#&gt; WHERE (year1 = 2014.0)\n\n때때로 dbplyr은 해당 변환을 최적화하는 방법을 아직 모르기 때문에 필요하지 않은 곳에 하위 쿼리를 생성합니다. dbplyr이 시간이 지남에 따라 개선됨에 따라 이러한 경우는 드물어지겠지만 아마도 결코 사라지지는 않을 것입니다.\n\n21.5.8 조인\ndplyr의 조인에 익숙하다면 SQL 조인도 매우 유사합니다. 간단한 예는 다음과 같습니다:\n\nflights |&gt; \n  left_join(planes |&gt; rename(year_built = year), join_by(tailnum)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   flights.*,\n#&gt;   planes.\"year\" AS year_built,\n#&gt;   \"type\",\n#&gt;   manufacturer,\n#&gt;   model,\n#&gt;   engines,\n#&gt;   seats,\n#&gt;   speed,\n#&gt;   engine\n#&gt; FROM flights\n#&gt; LEFT JOIN planes\n#&gt;   ON (flights.tailnum = planes.tailnum)\n\n여기서 주목해야 할 주요 사항은 구문입니다. SQL 조인은 FROM 절의 하위 절을 사용하여 추가 테이블을 가져오고 ON을 사용하여 테이블이 어떻게 관련되어 있는지 정의합니다.\n이러한 함수에 대한 dplyr의 이름은 SQL과 밀접하게 연결되어 있어 inner_join(), right_join(), full_join()에 해당하는 SQL을 쉽게 추측할 수 있습니다:\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nINNER JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nRIGHT JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nFULL JOIN planes ON (flights.tailnum = planes.tailnum)\n데이터베이스의 데이터로 작업할 때 많은 조인이 필요할 가능성이 큽니다. 데이터베이스 테이블은 종종 고도로 정규화된 형태로 저장되어 각 “사실”이 한 곳에 저장되고 분석을 위해 완전한 데이터셋을 유지하려면 기본 키와 외래 키로 연결된 복잡한 테이블 네트워크를 탐색해야 하기 때문입니다. 이 시나리오에 직면하면 Tobias Schieferdecker, Kirill Müller, Darko Bergant의 dm 패키지가 생명의 은인이 될 것입니다. DBA가 종종 제공하는 제약 조건을 사용하여 테이블 간의 연결을 자동으로 결정하고, 연결을 시각화하여 무슨 일이 일어나고 있는지 볼 수 있게 하며, 한 테이블을 다른 테이블에 연결하는 데 필요한 조인을 생성할 수 있습니다.\n\n21.5.9 기타 동사\ndbplyr은 또한 distinct(), slice_*(), intersect()와 같은 다른 동사와 pivot_longer() 및 pivot_wider()와 같은 점점 늘어나는 tidyr 함수 선택을 변환합니다. 현재 사용 가능한 전체 세트를 보는 가장 쉬운 방법은 dbplyr 웹사이트를 방문하는 것입니다: https://dbplyr.tidyverse.org/reference/.\n\n21.5.10 연습문제\n\ndistinct()는 무엇으로 변환됩니까? head()는 어떻습니까?\n\n다음 SQL 쿼리가 각각 수행하는 작업을 설명하고 dbplyr을 사용하여 다시 만들어 보세요.\nSELECT * \nFROM flights\nWHERE dep_delay &lt; arr_delay\n\nSELECT *, distance / (air_time / 60) AS speed\nFROM flights",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-sql-expressions",
    "href": "databases.html#sec-sql-expressions",
    "title": "21  데이터베이스",
    "section": "\n21.6 함수 변환",
    "text": "21.6 함수 변환\n지금까지는 dplyr 동사가 쿼리 절로 변환되는 방식의 큰 그림에 초점을 맞추었습니다. 이제 조금 더 확대하여 개별 열에서 작동하는 R 함수의 변환에 대해 이야기해 보겠습니다. 예를 들어 summarize()에서 mean(x)를 사용하면 어떻게 될까요?\n무슨 일이 일어나고 있는지 확인하는 데 도움이 되도록 summarize() 또는 mutate()를 실행하고 생성된 SQL을 보여주는 몇 가지 작은 도우미 함수를 사용할 것입니다. 이렇게 하면 몇 가지 변형을 탐색하고 요약과 변환이 어떻게 다를 수 있는지 쉽게 확인할 수 있습니다.\n\nsummarize_query &lt;- function(df, ...) {\n  df |&gt; \n    summarize(...) |&gt; \n    show_query()\n}\nmutate_query &lt;- function(df, ...) {\n  df |&gt; \n    mutate(..., .keep = \"none\") |&gt; \n    show_query()\n}\n\n몇 가지 요약을 살펴보겠습니다! 아래 코드를 보면 mean()과 같은 일부 요약 함수는 비교적 간단한 변환을 가지는 반면 median()과 같은 다른 함수는 훨씬 더 복잡하다는 것을 알 수 있습니다. 복잡성은 일반적으로 통계에서는 일반적이지만 데이터베이스에서는 덜 일반적인 작업에 대해 더 높습니다.\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  summarize_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n    median = median(arr_delay, na.rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by \"year\" and \"month\". You can override\n#&gt; using the `.groups` argument.\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) AS mean,\n#&gt;   MEDIAN(arr_delay) AS median\n#&gt; FROM flights\n#&gt; GROUP BY \"year\", \"month\", \"day\"\n\n요약 함수를 mutate() 내부에서 사용하면 소위 윈도우(window) 함수로 전환해야 하기 때문에 변환이 더 복잡해집니다. SQL에서는 일반 집계 함수 뒤에 OVER를 추가하여 윈도우 함수로 변환합니다:\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  mutate_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) OVER (PARTITION BY \"year\", \"month\", \"day\") AS mean\n#&gt; FROM flights\n\nSQL에서 GROUP BY 절은 요약에만 사용되므로 여기서 그룹화가 GROUP BY 절에서 OVER로 이동했음을 볼 수 있습니다.\n윈도우 함수에는 각각 “이전” 또는 “다음” 값을 보는 lead() 및 lag()와 같이 앞이나 뒤를 보는 모든 함수가 포함됩니다:\n\nflights |&gt; \n  group_by(dest) |&gt;  \n  arrange(time_hour) |&gt; \n  mutate_query(\n    lead = lead(arr_delay),\n    lag = lag(arr_delay)\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   dest,\n#&gt;   LEAD(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lead,\n#&gt;   LAG(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lag\n#&gt; FROM flights\n#&gt; ORDER BY time_hour\n\n여기서 데이터를 arrange()하는 것이 중요합니다. SQL 테이블에는 고유한 순서가 없기 때문입니다. 실제로 arrange()를 사용하지 않으면 매번 다른 순서로 행을 다시 얻을 수 있습니다! 윈도우 함수의 경우 정렬 정보가 반복된다는 점에 유의하세요. 기본 쿼리의 ORDER BY 절은 윈도우 함수에 자동으로 적용되지 않습니다.\n또 다른 중요한 SQL 함수는 CASE WHEN입니다. 이것은 직접 영감을 준 dplyr 함수인 if_else() 및 case_when()의 변환으로 사용됩니다. 다음은 몇 가지 간단한 예입니다:\n\nflights |&gt; \n  mutate_query(\n    description = if_else(arr_delay &gt; 0, \"delayed\", \"on-time\")\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE WHEN (arr_delay &gt; 0.0) THEN 'delayed' WHEN NOT (arr_delay &gt; 0.0) THEN 'on-time' END AS description\n#&gt; FROM flights\nflights |&gt; \n  mutate_query(\n    description = \n      case_when(\n        arr_delay &lt; -5 ~ \"early\", \n        arr_delay &lt; 5 ~ \"on-time\",\n        arr_delay &gt;= 5 ~ \"late\"\n      )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt; -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt; 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt;= 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\nCASE WHEN은 R에서 SQL로 직접 변환되지 않는 다른 함수에도 사용됩니다. 이에 대한 좋은 예는 cut()입니다:\n\nflights |&gt; \n  mutate_query(\n    description =  cut(\n      arr_delay, \n      breaks = c(-Inf, -5, 5, Inf), \n      labels = c(\"early\", \"on-time\", \"late\")\n    )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt;= -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt;= 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt; 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\ndbplyr은 일반적인 문자열 및 날짜-시간 조작 함수도 변환하며, vignette(\"translation-function\", package = \"dbplyr\")에서 자세히 알아볼 수 있습니다. dbplyr의 변환은 확실히 완벽하지 않으며 아직 변환되지 않은 R 함수가 많지만 dbplyr은 대부분의 시간 동안 사용할 함수를 놀라울 정도로 잘 다룹니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#요약",
    "href": "databases.html#요약",
    "title": "21  데이터베이스",
    "section": "\n21.7 요약",
    "text": "21.7 요약\n이 장에서는 데이터베이스의 데이터에 액세스하는 방법을 배웠습니다. 익숙한 dplyr 코드를 작성하면 자동으로 SQL로 변환되는 dplyr “백엔드”인 dbplyr에 집중했습니다. 그 변환을 사용하여 SQL을 조금 가르쳤습니다. SQL은 데이터를 다루는 데 가장 일반적으로 사용되는 언어이며 SQL을 조금 알면 R을 사용하지 않는 다른 데이터 담당자와 소통하기가 더 쉬워지므로 SQL을 배우는 것이 중요합니다.\n이 장을 마쳤고 SQL에 대해 더 배우고 싶다면 두 가지 추천 사항이 있습니다:\n\nRenée M. P. Teate의 SQL for Data Scientists는 데이터 과학자의 요구에 맞춰 특별히 설계된 SQL 입문서이며 실제 조직에서 마주칠 가능성이 높은 고도로 상호 연결된 데이터의 예를 포함합니다.\nAnthony DeBarros의 Practical SQL은 데이터 저널리스트(설득력 있는 이야기를 전달하는 전문 데이터 과학자)의 관점에서 작성되었으며 데이터를 데이터베이스로 가져오고 자체 DBMS를 실행하는 것에 대해 더 자세히 다룹니다.\n\n다음 장에서는 대용량 데이터 작업을 위한 또 다른 dplyr 백엔드인 arrow에 대해 배울 것입니다. Arrow는 디스크의 대용량 파일 작업용으로 설계되었으며 데이터베이스의 자연스러운 보완재입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "databases.html#footnotes",
    "href": "databases.html#footnotes",
    "title": "21  데이터베이스",
    "section": "",
    "text": "SQL은 “에스-큐-엘” 또는 “시퀄”로 발음합니다.↩︎\n일반적으로 이것은 클라이언트 패키지에서 사용하는 유일한 함수이므로 library()로 전체 패키지를 로드하는 대신 ::를 사용하여 해당 함수 하나만 꺼내는 것을 권장합니다.↩︎\n적어도 볼 수 있는 권한이 있는 모든 테이블입니다.↩︎\n헷갈리게도 문맥에 따라 SELECT는 문이거나 절입니다. 이 혼란을 피하기 위해 일반적으로 SELECT 문 대신 SELECT 쿼리를 사용합니다.↩︎\n엄밀히 말하면 SELECT 1+1과 같은 쿼리를 작성하여 기본 계산을 수행할 수 있으므로 SELECT만 필요합니다. 하지만 데이터로 작업하려면(항상 그렇듯이!) FROM 절도 필요합니다.↩︎\n우연이 아닙니다. dplyr 함수 이름은 SQL 절에서 영감을 받았습니다.↩︎",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>데이터베이스</span>"
    ]
  },
  {
    "objectID": "arrow.html",
    "href": "arrow.html",
    "title": "22  Arrow",
    "section": "",
    "text": "22.1 소개\nCSV 파일은 사람이 읽기 쉽게 설계되었습니다. 매우 간단하고 모든 도구에서 읽을 수 있기 때문에 좋은 교환 형식입니다. 하지만 CSV 파일은 그리 효율적이지 않습니다. 데이터를 R로 읽어들이기 위해 꽤 많은 작업을 수행해야 하기 때문입니다. 이 장에서는 강력한 대안인 파켓(parquet) 형식에 대해 배울 것입니다. 이는 빅 데이터 시스템에서 널리 사용되는 오픈 표준 기반 형식입니다.\n우리는 파켓 파일을 대규모 데이터셋의 효율적인 분석 및 전송을 위해 설계된 다국어 도구 상자인 Apache Arrow와 결합할 것입니다. 익숙한 dplyr 구문을 사용하여 메모리보다 큰 데이터셋을 분석할 수 있는 dplyr 백엔드를 제공하는 arrow 패키지를 통해 Apache Arrow를 사용할 것입니다. 추가적인 이점으로 arrow는 매우 빠릅니다. 이 장의 뒷부분에서 몇 가지 예를 보게 될 것입니다.\narrow와 dbplyr 모두 dplyr 백엔드를 제공하므로 언제 각각을 사용해야 하는지 궁금할 수 있습니다. 많은 경우 데이터가 이미 데이터베이스나 파켓 파일에 있으므로 있는 그대로 작업하고 싶을 것이므로 선택은 이미 결정되어 있습니다. 하지만 자신의 데이터(아마도 CSV 파일)로 시작하는 경우 데이터베이스에 로드하거나 파켓으로 변환할 수 있습니다. 일반적으로 무엇이 가장 잘 작동할지 알기 어려우므로 분석 초기 단계에서는 두 가지를 모두 시도해보고 자신에게 가장 잘 맞는 것을 선택하는 것이 좋습니다.\n(이 장의 초기 버전을 기여해 준 Danielle Navarro에게 큰 감사를 드립니다.)",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#introduction",
    "href": "arrow.html#introduction",
    "title": "22  Arrow",
    "section": "",
    "text": "22.1.1 Prerequisites\nIn this chapter, we’ll continue to use the tidyverse, particularly dplyr, but we’ll pair it with the arrow package which is designed specifically for working with large data.\n\nlibrary(tidyverse)\nlibrary(arrow)\n\nLater in the chapter, we’ll also see some connections between arrow and duckdb, so we’ll also need dbplyr and duckdb.\n\nlibrary(dbplyr, warn.conflicts = FALSE)\nlibrary(duckdb)\n#&gt; Loading required package: DBI",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#getting-the-data",
    "href": "arrow.html#getting-the-data",
    "title": "22  Arrow",
    "section": "\n22.2 Getting the data",
    "text": "22.2 Getting the data\nWe begin by getting a dataset worthy of these tools: a dataset of item checkouts from Seattle public libraries, available online at data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6. This dataset contains 41,389,465 rows that tell you how many times each book was checked out each month from April 2005 to October 2022.\nThe following code will get you a cached copy of the data. The data is a 9GB CSV file, so it will take some time to download. I highly recommend using curl::multi_download() to get very large files as it’s built for exactly this purpose: it gives you a progress bar and it can resume the download if its interrupted.\n\ndir.create(\"data\", showWarnings = FALSE)\n\ncurl::multi_download(\n  \"https://r4ds.s3.us-west-2.amazonaws.com/seattle-library-checkouts.csv\",\n  \"data/seattle-library-checkouts.csv\",\n  resume = TRUE\n)\n#&gt; # A tibble: 1 × 10\n#&gt;   success status_code resumefrom url                    destfile        error\n#&gt;   &lt;lgl&gt;         &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;\n#&gt; 1 TRUE            200          0 https://r4ds.s3.us-we… data/seattle-l… &lt;NA&gt; \n#&gt; # ℹ 4 more variables: type &lt;chr&gt;, modified &lt;dttm&gt;, time &lt;dbl&gt;,\n#&gt; #   headers &lt;list&gt;",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#opening-a-dataset",
    "href": "arrow.html#opening-a-dataset",
    "title": "22  Arrow",
    "section": "\n22.3 Opening a dataset",
    "text": "22.3 Opening a dataset\nLet’s start by taking a look at the data. At 9 GB, this file is large enough that we probably don’t want to load the whole thing into memory. A good rule of thumb is that you usually want at least twice as much memory as the size of the data, and many laptops top out at 16 GB. This means we want to avoid read_csv() and instead use the arrow::open_dataset():\n\nseattle_csv &lt;- open_dataset(\n  sources = \"data/seattle-library-checkouts.csv\", \n  col_types = schema(ISBN = string()),\n  format = \"csv\"\n)\n\nWhat happens when this code is run? open_dataset() will scan a few thousand rows to figure out the structure of the dataset. The ISBN column contains blank values for the first 80,000 rows, so we have to specify the column type to help arrow work out the data structure. Once the data has been scanned by open_dataset(), it records what it’s found and stops; it will only read further rows as you specifically request them. This metadata is what we see if we print seattle_csv:\n\nseattle_csv\n#&gt; FileSystemDataset with 1 csv file\n#&gt; UsageClass: string\n#&gt; CheckoutType: string\n#&gt; MaterialType: string\n#&gt; CheckoutYear: int64\n#&gt; CheckoutMonth: int64\n#&gt; Checkouts: int64\n#&gt; Title: string\n#&gt; ISBN: string\n#&gt; Creator: string\n#&gt; Subjects: string\n#&gt; Publisher: string\n#&gt; PublicationYear: string\n\nThe first line in the output tells you that seattle_csv is stored locally on-disk as a single CSV file; it will only be loaded into memory as needed. The remainder of the output tells you the column type that arrow has imputed for each column.\nWe can see what’s actually in with glimpse(). This reveals that there are ~41 million rows and 12 columns, and shows us a few values.\n\nseattle_csv |&gt; glimpse()\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 41,389,465 rows x 12 columns\n#&gt; $ UsageClass      &lt;string&gt; \"Physical\", \"Physical\", \"Digital\", \"Physical\", \"Ph…\n#&gt; $ CheckoutType    &lt;string&gt; \"Horizon\", \"Horizon\", \"OverDrive\", \"Horizon\", \"Hor…\n#&gt; $ MaterialType    &lt;string&gt; \"BOOK\", \"BOOK\", \"EBOOK\", \"BOOK\", \"SOUNDDISC\", \"BOO…\n#&gt; $ CheckoutYear     &lt;int64&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 20…\n#&gt; $ CheckoutMonth    &lt;int64&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n#&gt; $ Checkouts        &lt;int64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 3, 2,…\n#&gt; $ Title           &lt;string&gt; \"Super rich : a guide to having it all / Russell S…\n#&gt; $ ISBN            &lt;string&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#&gt; $ Creator         &lt;string&gt; \"Simmons, Russell\", \"Barclay, James, 1965-\", \"Tim …\n#&gt; $ Subjects        &lt;string&gt; \"Self realization, Conduct of life, Attitude Psych…\n#&gt; $ Publisher       &lt;string&gt; \"Gotham Books,\", \"Pyr,\", \"Random House, Inc.\", \"Di…\n#&gt; $ PublicationYear &lt;string&gt; \"c2011.\", \"2010.\", \"2015\", \"2005.\", \"c2004.\", \"c20…\n\nWe can start to use this dataset with dplyr verbs, using collect() to force arrow to perform the computation and return some data. For example, this code tells us the total number of checkouts per year:\n\nseattle_csv |&gt; \n  group_by(CheckoutYear) |&gt; \n  summarise(Checkouts = sum(Checkouts)) |&gt; \n  arrange(CheckoutYear) |&gt; \n  collect()\n#&gt; # A tibble: 18 × 2\n#&gt;   CheckoutYear Checkouts\n#&gt;          &lt;int&gt;     &lt;int&gt;\n#&gt; 1         2005   3798685\n#&gt; 2         2006   6599318\n#&gt; 3         2007   7126627\n#&gt; 4         2008   8438486\n#&gt; 5         2009   9135167\n#&gt; 6         2010   8608966\n#&gt; # ℹ 12 more rows\n\nThanks to arrow, this code will work regardless of how large the underlying dataset is. But it’s currently rather slow: on Hadley’s computer, it took ~10s to run. That’s not terrible given how much data we have, but we can make it much faster by switching to a better format.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#sec-parquet",
    "href": "arrow.html#sec-parquet",
    "title": "22  Arrow",
    "section": "\n22.4 파켓(Parquet) 형식",
    "text": "22.4 파켓(Parquet) 형식\n이 데이터를 더 쉽게 다루기 위해 파켓 파일 형식으로 전환하고 여러 파일로 나누어 보겠습니다. 다음 섹션에서는 먼저 파켓과 파티셔닝(partitioning)을 소개한 다음 배운 내용을 시애틀 도서관 데이터에 적용해 보겠습니다.\n\n22.4.1 파켓의 장점\nCSV와 마찬가지로 파켓은 사각형 데이터에 사용되지만, 모든 파일 에디터로 읽을 수 있는 텍스트 형식이 아니라 빅 데이터의 요구 사항에 맞춰 특별히 설계된 맞춤형 이진 형식입니다. 이것은 다음을 의미합니다:\n\n파켓 파일은 일반적으로 동일한 CSV 파일보다 작습니다. 파켓은 파일 크기를 낮게 유지하기 위해 효율적인 인코딩에 의존하며 파일 압축을 지원합니다. 디스크에서 메모리로 이동할 데이터가 적기 때문에 파켓 파일을 빠르게 만드는 데 도움이 됩니다.\n파켓 파일은 풍부한 유형 시스템을 가지고 있습니다. Section 7.3 에서 이야기했듯이 CSV 파일은 열 유형에 대한 정보를 제공하지 않습니다. 예를 들어 CSV 리더는 \"08-10-2022\"를 문자열로 파싱해야 할지 날짜로 파싱해야 할지 추측해야 합니다. 반면 파켓 파일은 데이터와 함께 유형을 기록하는 방식으로 데이터를 저장합니다.\n파켓 파일은 “열 지향(column-oriented)”입니다. 이는 R의 데이터 프레임과 마찬가지로 열별로 구성되어 있음을 의미합니다. 이것은 행별로 구성된 CSV 파일에 비해 데이터 분석 작업에서 일반적으로 더 나은 성능을 제공합니다.\n파켓 파일은 “청크(chunked)”되어 있어 파일의 다른 부분을 동시에 작업할 수 있고, 운이 좋으면 일부 청크를 완전히 건너뛸 수도 있습니다.\n\n파켓 파일에는 한 가지 주요 단점이 있습니다. 더 이상 “사람이 읽을 수 없다”는 것입니다. 즉, readr::read_file()을 사용하여 파켓 파일을 보면 횡설수설하는 무더기만 보이게 됩니다.\n\n22.4.2 파티셔닝(Partitioning)\n데이터셋이 점점 더 커짐에 따라 모든 데이터를 단일 파일에 저장하는 것은 점점 더 고통스러워지며, 대규모 데이터셋을 여러 파일에 나누어 저장하는 것이 종종 유용합니다. 이 구조화가 지능적으로 수행되면 많은 분석에 파일의 일부만 필요하기 때문에 성능이 크게 향상될 수 있습니다.\n데이터셋을 파티셔닝하는 방법에 대한 확고한 규칙은 없습니다. 결과는 데이터, 액세스 패턴 및 데이터를 읽는 시스템에 따라 달라집니다. 자신의 상황에 가장 적합한 파티셔닝을 찾기 전에 약간의 실험이 필요할 수 있습니다. 대략적인 지침으로 arrow는 20MB보다 작고 2GB보다 큰 파일을 피하고 10,000개 이상의 파일을 생성하는 파티션을 피할 것을 권장합니다. 또한 필터링의 기준이 되는 변수로 파티셔닝해야 합니다. 곧 보게 되겠지만, 그렇게 하면 arrow가 관련 파일만 읽음으로써 많은 작업을 건너뛸 수 있습니다.\n\n22.4.3 시애틀 도서관 데이터 다시 쓰기\n실제 상황에서 어떻게 작동하는지 보기 위해 이러한 아이디어를 시애틀 도서관 데이터에 적용해 보겠습니다. 일부 분석에서는 최근 데이터만 보고 싶어할 가능성이 높고 연도별로 파티셔닝하면 적당한 크기의 18개 청크가 생성되므로 CheckoutYear로 파티셔닝하겠습니다.\n데이터를 다시 쓰기 위해 dplyr::group_by()를 사용하여 파티션을 정의한 다음 arrow::write_dataset()을 사용하여 파티션을 디렉터리에 저장합니다. write_dataset()에는 두 가지 중요한 인수가 있습니다: 파일을 생성할 디렉터리와 사용할 형식입니다.\n\npq_path &lt;- \"data/seattle-library-checkouts\"\n\n\nseattle_csv |&gt;\n  group_by(CheckoutYear) |&gt;\n  write_dataset(path = pq_path, format = \"parquet\")\n\n이 작업은 실행하는 데 약 1분 정도 걸립니다. 곧 보게 되겠지만 이는 향후 작업을 훨씬 더 빠르게 만들어 보상받는 초기 투자입니다.\n방금 생성한 내용을 살펴보겠습니다:\n\ntibble(\n  files = list.files(pq_path, recursive = TRUE),\n  size_MB = file.size(file.path(pq_path, files)) / 1024^2\n)\n#&gt; # A tibble: 18 × 2\n#&gt;   files                            size_MB\n#&gt;   &lt;chr&gt;                              &lt;dbl&gt;\n#&gt; 1 CheckoutYear=2005/part-0.parquet    108.\n#&gt; 2 CheckoutYear=2006/part-0.parquet    161.\n#&gt; 3 CheckoutYear=2007/part-0.parquet    175.\n#&gt; 4 CheckoutYear=2008/part-0.parquet    192.\n#&gt; 5 CheckoutYear=2009/part-0.parquet    211.\n#&gt; 6 CheckoutYear=2010/part-0.parquet    219.\n#&gt; # ℹ 12 more rows\n\n우리의 단일 9GB CSV 파일이 18개의 파켓 파일로 다시 쓰여졌습니다. 파일 이름은 Apache Hive 프로젝트에서 사용하는 “자기 설명적(self-describing)” 관례를 사용합니다. Hive 스타일 파티션은 폴더 이름을 “key=value” 관례로 지정하므로 짐작하셨겠지만 CheckoutYear=2005 디렉터리에는 CheckoutYear가 2005년인 모든 데이터가 포함되어 있습니다. 각 파일은 100MB에서 300MB 사이이며 총 크기는 이제 약 4GB로 원래 CSV 파일 크기의 절반보다 약간 큽니다. 파켓이 훨씬 더 효율적인 형식이므로 예상한 결과입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#using-dplyr-with-arrow",
    "href": "arrow.html#using-dplyr-with-arrow",
    "title": "22  Arrow",
    "section": "\n22.5 Using dplyr with arrow",
    "text": "22.5 Using dplyr with arrow\nNow we’ve created these parquet files, we’ll need to read them in again. We use open_dataset() again, but this time we give it a directory:\n\nseattle_pq &lt;- open_dataset(pq_path)\n\nNow we can write our dplyr pipeline. For example, we could count the total number of books checked out in each month for the last five years:\n\nquery &lt;- seattle_pq |&gt; \n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear, CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(CheckoutYear, CheckoutMonth)\n\nWriting dplyr code for arrow data is conceptually similar to dbplyr, Chapter 21: you write dplyr code, which is automatically transformed into a query that the Apache Arrow C++ library understands, which is then executed when you call collect(). If we print out the query object we can see a little information about what we expect Arrow to return when the execution takes place:\n\nquery\n#&gt; FileSystemDataset (query)\n#&gt; CheckoutYear: int32\n#&gt; CheckoutMonth: int64\n#&gt; TotalCheckouts: int64\n#&gt; \n#&gt; * Grouped by CheckoutYear\n#&gt; * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#&gt; See $.data for the source Arrow object\n\nAnd we can get the results by calling collect():\n\nquery |&gt; collect()\n#&gt; # A tibble: 58 × 3\n#&gt; # Groups:   CheckoutYear [5]\n#&gt;   CheckoutYear CheckoutMonth TotalCheckouts\n#&gt;          &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n#&gt; 1         2018             1         355101\n#&gt; 2         2018             2         309813\n#&gt; 3         2018             3         344487\n#&gt; 4         2018             4         330988\n#&gt; 5         2018             5         318049\n#&gt; 6         2018             6         341825\n#&gt; # ℹ 52 more rows\n\nLike dbplyr, arrow only understands some R expressions, so you may not be able to write exactly the same code you usually would. However, the list of operations and functions supported is fairly extensive and continues to grow; find a complete list of currently supported functions in ?acero.\n\n22.5.1 Performance\nLet’s take a quick look at the performance impact of switching from CSV to parquet. First, let’s time how long it takes to calculate the number of books checked out in each month of 2021, when the data is stored as a single large csv:\n\nseattle_csv |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;  11.951   1.297  11.387\n\nNow let’s use our new version of the dataset in which the Seattle library checkout data has been partitioned into 18 smaller parquet files:\n\nseattle_pq |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;   0.263   0.058   0.063\n\nThe ~100x speedup in performance is attributable to two factors: the multi-file partitioning, and the format of individual files:\n\nPartitioning improves performance because this query uses CheckoutYear == 2021 to filter the data, and arrow is smart enough to recognize that it only needs to read 1 of the 18 parquet files.\nThe parquet format improves performance by storing data in a binary format that can be read more directly into memory. The column-wise format and rich metadata means that arrow only needs to read the four columns actually used in the query (CheckoutYear, MaterialType, CheckoutMonth, and Checkouts).\n\nThis massive difference in performance is why it pays off to convert large CSVs to parquet!\n\n22.5.2 Using duckdb with arrow\nThere’s one last advantage of parquet and arrow — it’s very easy to turn an arrow dataset into a DuckDB database (Chapter 21) by calling arrow::to_duckdb():\n\nseattle_pq |&gt; \n  to_duckdb() |&gt;\n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutYear)) |&gt;\n  collect()\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # A tibble: 5 × 2\n#&gt;   CheckoutYear TotalCheckouts\n#&gt;          &lt;int&gt;          &lt;dbl&gt;\n#&gt; 1         2022        2431502\n#&gt; 2         2021        2266438\n#&gt; 3         2020        1241999\n#&gt; 4         2019        3931688\n#&gt; 5         2018        3987569\n\nThe neat thing about to_duckdb() is that the transfer doesn’t involve any memory copying, and speaks to the goals of the arrow ecosystem: enabling seamless transitions from one computing environment to another.\n\n22.5.3 Exercises\n\nFigure out the most popular book each year.\nWhich author has the most books in the Seattle library system?\nHow has checkouts of books vs ebooks changed over the last 10 years?",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#summary",
    "href": "arrow.html#summary",
    "title": "22  Arrow",
    "section": "\n22.6 Summary",
    "text": "22.6 Summary\nIn this chapter, you’ve been given a taste of the arrow package, which provides a dplyr backend for working with large on-disk datasets. It can work with CSV files, and it’s much much faster if you convert your data to parquet. Parquet is a binary data format that’s designed specifically for data analysis on modern computers. Far fewer tools can work with parquet files compared to CSV, but its partitioned, compressed, and columnar structure makes it much more efficient to analyze.\nNext up you’ll learn about your first non-rectangular data source, which you’ll handle using tools provided by the tidyr package. We’ll focus on data that comes from JSON files, but the general principles apply to tree-like data regardless of its source.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "rectangling.html",
    "href": "rectangling.html",
    "title": "23  계층적 데이터",
    "section": "",
    "text": "23.1 소개\n이 장에서는 데이터 직사각형화(rectangling) 기술을 배울 것입니다. 이는 근본적으로 계층적이거나 트리 형태인 데이터를 행과 열로 구성된 직사각형 데이터 프레임으로 변환하는 것입니다. 계층적 데이터는 놀라울 정도로 흔하며, 특히 웹에서 가져온 데이터로 작업할 때 더욱 그렇기 때문에 이 작업은 중요합니다.\n직사각형화에 대해 배우려면 먼저 계층적 데이터를 가능하게 하는 데이터 구조인 리스트에 대해 배워야 합니다. 그런 다음 두 가지 중요한 tidyr 함수인 tidyr::unnest_longer()와 tidyr::unnest_wider()를 배울 것입니다. 그 후 실제 문제를 해결하기 위해 이 간단한 함수들을 반복해서 적용하는 몇 가지 사례 연구를 보여줄 것입니다. 마지막으로 계층적 데이터셋의 가장 빈번한 소스이자 웹에서 데이터 교환을 위한 일반적인 형식인 JSON에 대해 이야기하며 마무리하겠습니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "rectangling.html#소개",
    "href": "rectangling.html#소개",
    "title": "23  계층적 데이터",
    "section": "",
    "text": "23.1.1 선수 지식\n이 장에서는 tidyverse의 핵심 멤버인 tidyr의 많은 함수를 사용할 것입니다. 또한 직사각형화 연습을 위한 흥미로운 데이터셋을 제공하는 repurrrsive를 사용하고, 마지막으로 JSON 파일을 R 리스트로 읽기 위해 jsonlite를 사용할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(repurrrsive)\nlibrary(jsonlite)",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "rectangling.html#리스트lists",
    "href": "rectangling.html#리스트lists",
    "title": "23  계층적 데이터",
    "section": "\n23.2 리스트(Lists)",
    "text": "23.2 리스트(Lists)\n지금까지 정수, 숫자, 문자, 날짜-시간 및 팩터와 같은 단순한 벡터를 포함하는 데이터 프레임으로 작업했습니다. 이러한 벡터는 동질적(homogeneous), 즉 모든 요소가 동일한 데이터 유형이기 때문에 단순합니다. 다른 유형의 요소를 동일한 벡터에 저장하려면 list()로 생성하는 리스트(list) 가 필요합니다:\n\nx1 &lt;- list(1:4, \"a\", TRUE)\nx1\n#&gt; [[1]]\n#&gt; [1] 1 2 3 4\n#&gt; \n#&gt; [[2]]\n#&gt; [1] \"a\"\n#&gt; \n#&gt; [[3]]\n#&gt; [1] TRUE\n\n리스트의 구성 요소 또는 자식(children) 의 이름을 지정하는 것이 종종 편리한데, 이는 티블의 열 이름을 지정하는 것과 같은 방식으로 할 수 있습니다:\n\nx2 &lt;- list(a = 1:2, b = 1:3, c = 1:4)\nx2\n#&gt; $a\n#&gt; [1] 1 2\n#&gt; \n#&gt; $b\n#&gt; [1] 1 2 3\n#&gt; \n#&gt; $c\n#&gt; [1] 1 2 3 4\n\n이러한 매우 단순한 리스트의 경우에도 인쇄하면 꽤 많은 공간을 차지합니다. 유용한 대안은 내용보다는 구조(structure)의 압축된 표시를 생성하는 str()입니다:\n\nstr(x1)\n#&gt; List of 3\n#&gt;  $ : int [1:4] 1 2 3 4\n#&gt;  $ : chr \"a\"\n#&gt;  $ : logi TRUE\nstr(x2)\n#&gt; List of 3\n#&gt;  $ a: int [1:2] 1 2\n#&gt;  $ b: int [1:3] 1 2 3\n#&gt;  $ c: int [1:4] 1 2 3 4\n\n보시다시피 str()은 리스트의 각 자식을 별도의 줄에 표시합니다. 이름이 있으면 이름을 표시하고, 그 다음 유형의 약어, 그 다음 처음 몇 개의 값을 표시합니다.\n\n23.2.1 계층 구조(Hierarchy)\n리스트는 다른 리스트를 포함하여 모든 유형의 객체를 포함할 수 있습니다. 이로 인해 계층적(트리 형태) 구조를 나타내기에 적합합니다:\n\nx3 &lt;- list(list(1, 2), list(3, 4))\nstr(x3)\n#&gt; List of 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 1\n#&gt;   ..$ : num 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 3\n#&gt;   ..$ : num 4\n\n이것은 평면 벡터를 생성하는 c()와 눈에 띄게 다릅니다:\n\nc(c(1, 2), c(3, 4))\n#&gt; [1] 1 2 3 4\n\nx4 &lt;- c(list(1, 2), list(3, 4))\nstr(x4)\n#&gt; List of 4\n#&gt;  $ : num 1\n#&gt;  $ : num 2\n#&gt;  $ : num 3\n#&gt;  $ : num 4\n\n리스트가 복잡해짐에 따라 계층 구조를 한눈에 볼 수 있게 해주는 str()이 더 유용해집니다:\n\nx5 &lt;- list(1, list(2, list(3, list(4, list(5)))))\nstr(x5)\n#&gt; List of 2\n#&gt;  $ : num 1\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 2\n#&gt;   ..$ :List of 2\n#&gt;   .. ..$ : num 3\n#&gt;   .. ..$ :List of 2\n#&gt;   .. .. ..$ : num 4\n#&gt;   .. .. ..$ :List of 1\n#&gt;   .. .. .. ..$ : num 5\n\n리스트가 훨씬 더 크고 복잡해지면 결국 str()도 실패하기 시작하고 View()1로 전환해야 합니다. Figure 23.1 는 View(x5)를 호출한 결과를 보여줍니다. 뷰어는 리스트의 최상위 수준만 보여주는 것으로 시작하지만, Figure 23.2 처럼 구성 요소를 대화식으로 확장하여 더 많은 내용을 볼 수 있습니다. RStudio는 또한 Figure 23.3 처럼 해당 요소에 액세스하는 데 필요한 코드를 보여줍니다. 이 코드가 어떻게 작동하는지는 Section 27.3 에서 다시 다룰 것입니다.\n\n\n\n\n\n\n\nFigure 23.1: RStudio 뷰를 사용하면 복잡한 리스트를 대화식으로 탐색할 수 있습니다. 뷰어는 리스트의 최상위 수준만 보여주며 열립니다.\n\n\n\n\n\n\n\n\n\n\n\nFigure 23.2: 오른쪽을 가리키는 삼각형을 클릭하면 리스트의 해당 구성 요소가 확장되어 그 자식들도 볼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\nFigure 23.3: 관심 있는 데이터에 도달할 때까지 이 작업을 필요한 만큼 반복할 수 있습니다. 왼쪽 하단 모서리에 유의하세요: 리스트의 요소를 클릭하면 RStudio가 그것에 액세스하는 데 필요한 부분집합 코드를 제공합니다. 이 경우 x5[[2]][[2]][[2]]입니다.\n\n\n\n\n\n23.2.2 리스트 열(List-columns)\n리스트는 티블 내부에도 존재할 수 있으며, 이를 리스트 열이라고 부릅니다. 리스트 열은 일반적으로 티블에 속하지 않을 객체를 티블에 배치할 수 있게 해주기 때문에 유용합니다. 특히 리스트 열은 tidymodels 생태계에서 많이 사용되는데, 모델 출력이나 리샘플링과 같은 것들을 데이터 프레임에 저장할 수 있게 해주기 때문입니다.\n다음은 리스트 열의 간단한 예입니다:\n\ndf &lt;- tibble(\n  x = 1:2, \n  y = c(\"a\", \"b\"),\n  z = list(list(1, 2), list(3, 4, 5))\n)\ndf\n#&gt; # A tibble: 2 × 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n#&gt; 2     2 b     &lt;list [3]&gt;\n\n티블 안의 리스트라고 해서 특별한 점은 없으며, 다른 열과 똑같이 작동합니다:\n\ndf |&gt; \n  filter(x == 1)\n#&gt; # A tibble: 1 × 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n\n리스트 열로 계산하는 것은 더 어렵지만, 그것은 일반적으로 리스트로 계산하는 것이 더 어렵기 때문입니다. 이에 대해서는 Chapter 26 에서 다시 다룰 것입니다. 이 장에서는 리스트 열을 일반 변수로 중첩 해제(unnesting)하여 기존 도구를 사용할 수 있도록 하는 데 집중할 것입니다.\n기본 인쇄 방법은 내용의 대략적인 요약만 표시합니다. 리스트 열은 임의로 복잡할 수 있으므로 인쇄하는 좋은 방법이 없습니다. 그 내용을 보고 싶다면 리스트 열 하나만 뽑아내어 위에서 배운 기술 중 하나를 적용해야 합니다. 예: df |&gt; pull(z) |&gt; str() 또는 df |&gt; pull(z) |&gt; View().\n\n\n\n\n\n\nNote기본 R\n\n\n\n리스트를 data.frame의 열에 넣는 것은 가능하지만, data.frame()이 리스트를 열의 리스트로 취급하기 때문에 훨씬 더 까다롭습니다:\n\ndata.frame(x = list(1:3, 3:5))\n#&gt;   x.1.3 x.3.5\n#&gt; 1     1     3\n#&gt; 2     2     4\n#&gt; 3     3     5\n\n리스트 I()로 감싸서 data.frame()이 리스트를 행의 리스트로 취급하도록 강제할 수 있지만, 결과가 특별히 잘 인쇄되지는 않습니다:\n\ndata.frame(\n  x = I(list(1:2, 3:5)), \n  y = c(\"1, 2\", \"3, 4, 5\")\n)\n#&gt;         x       y\n#&gt; 1    1, 2    1, 2\n#&gt; 2 3, 4, 5 3, 4, 5\n\n티블에서 리스트 열을 사용하는 것이 더 쉬운데, tibble()이 리스트를 벡터처럼 취급하고 인쇄 방법이 리스트를 염두에 두고 설계되었기 때문입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "rectangling.html#중첩-해제unnesting",
    "href": "rectangling.html#중첩-해제unnesting",
    "title": "23  계층적 데이터",
    "section": "\n23.3 중첩 해제(Unnesting)",
    "text": "23.3 중첩 해제(Unnesting)\n리스트와 리스트 열의 기초를 배웠으니 이제 어떻게 일반 행과 열로 되돌릴 수 있는지 알아봅시다. 여기서는 기본 아이디어를 얻을 수 있도록 매우 간단한 샘플 데이터를 사용할 것입니다. 다음 섹션에서는 실제 데이터로 전환하겠습니다.\n리스트 열은 일반적으로 명명된 것과 이름이 없는 것의 두 가지 기본 형태가 있습니다. 자식이 이름이 있는(named) 경우, 모든 행에서 동일한 이름을 갖는 경향이 있습니다. 예를 들어 df1에서 리스트 열 y의 모든 요소는 a와 b라는 이름의 두 요소를 갖습니다. 이름이 있는 리스트 열은 자연스럽게 열로 중첩 해제됩니다: 각 명명된 요소는 새로운 명명된 열이 됩니다.\n\ndf1 &lt;- tribble(\n  ~x, ~y,\n  1, list(a = 11, b = 12),\n  2, list(a = 21, b = 22),\n  3, list(a = 31, b = 32),\n)\n\n자식이 이름이 없는(unnamed) 경우, 요소의 수는 행마다 다른 경향이 있습니다. 예를 들어 df2에서 리스트 열 y의 요소는 이름이 없고 길이가 1에서 3까지 다양합니다. 이름이 없는 리스트 열은 자연스럽게 행으로 중첩 해제됩니다: 각 자식에 대해 하나의 행을 얻게 됩니다.\n\ndf2 &lt;- tribble(\n  ~x, ~y,\n  1, list(11, 12, 13),\n  2, list(21),\n  3, list(31, 32),\n)\n\ntidyr은 이 두 가지 경우를 위해 unnest_wider()와 unnest_longer()라는 두 가지 함수를 제공합니다. 다음 섹션에서 작동 방식을 설명합니다.\n\n23.3.1 unnest_wider()\n\ndf1처럼 각 행이 동일한 이름을 가진 동일한 수의 요소를 가지고 있을 때, unnest_wider()를 사용하여 각 구성 요소를 자체 열에 넣는 것이 자연스럽습니다:\n\ndf1 |&gt; \n  unnest_wider(y)\n#&gt; # A tibble: 3 × 3\n#&gt;       x     a     b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\n기본적으로 새 열의 이름은 전적으로 리스트 요소의 이름에서 가져오지만, names_sep 인수를 사용하여 열 이름과 요소 이름을 결합하도록 요청할 수 있습니다. 이는 반복되는 이름의 모호함을 해결하는 데 유용합니다.\n\ndf1 |&gt; \n  unnest_wider(y, names_sep = \"_\")\n#&gt; # A tibble: 3 × 3\n#&gt;       x   y_a   y_b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\n\n23.3.2 unnest_longer()\n\n각 행에 이름이 없는 리스트가 포함된 경우, unnest_longer()를 사용하여 각 요소를 자체 행에 넣는 것이 가장 자연스럽습니다:\n\ndf2 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 6 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11\n#&gt; 2     1    12\n#&gt; 3     1    13\n#&gt; 4     2    21\n#&gt; 5     3    31\n#&gt; 6     3    32\n\ny 내부의 각 요소에 대해 x가 어떻게 복제되는지 주목하세요: 리스트 열 내부의 각 요소에 대해 하나의 출력 행을 얻습니다. 하지만 다음 예제처럼 요소 중 하나가 비어 있으면 어떻게 될까요?\n\ndf6 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1, 2),\n  \"b\", list(3),\n  \"c\", list()\n)\ndf6 |&gt; unnest_longer(y)\n#&gt; # A tibble: 3 × 2\n#&gt;   x         y\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 a         1\n#&gt; 2 a         2\n#&gt; 3 b         3\n\n출력에서 행이 0개가 되므로 행이 사실상 사라집니다. 해당 행을 보존하여 y에 NA를 추가하고 싶다면 keep_empty = TRUE를 설정하세요.\n\n23.3.3 일관성 없는 유형\n서로 다른 유형의 벡터를 포함하는 리스트 열을 중첩 해제하면 어떻게 될까요? 예를 들어 리스트 열 y에 두 개의 숫자, 문자, 논리형이 포함된 다음 데이터셋을 예로 들어보겠습니다. 이들은 일반적으로 단일 열에 섞일 수 없습니다.\n\ndf4 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1),\n  \"b\", list(\"a\", TRUE, 5)\n)\n\nunnest_longer()는 행의 수를 변경하면서 항상 열의 집합을 변경하지 않은 상태로 유지합니다. 그렇다면 어떤 일이 벌어질까요? unnest_longer()는 어떻게 y에 있는 모든 것을 유지하면서 5개의 행을 생성할까요?\n\ndf4 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 4 × 2\n#&gt;   x     y        \n#&gt;   &lt;chr&gt; &lt;list&gt;   \n#&gt; 1 a     &lt;dbl [1]&gt;\n#&gt; 2 b     &lt;chr [1]&gt;\n#&gt; 3 b     &lt;lgl [1]&gt;\n#&gt; 4 b     &lt;dbl [1]&gt;\n\n보시다시피 출력에는 리스트 열이 포함되어 있지만 리스트 열의 모든 요소에는 단일 요소가 포함되어 있습니다. unnest_longer()가 벡터의 공통 유형을 찾을 수 없기 때문에 원래 유형을 리스트 열에 유지합니다. 이것이 모든 열의 요소가 동일한 유형이어야 한다는 계명을 어기는 것인지 궁금할 수 있습니다. 그렇지 않습니다: 내용이 다른 유형이더라도 모든 요소는 리스트입니다.\n일관성 없는 유형을 다루는 것은 어렵고 세부 사항은 문제의 정확한 성격과 목표에 달려 있지만, 아마도 Chapter 26 의 도구가 필요할 것입니다.\n\n23.3.4 기타 함수\ntidyr에는 이 책에서 다루지 않을 몇 가지 다른 유용한 직사각형화 함수가 있습니다:\n\n\nunnest_auto()는 리스트 열의 구조를 기반으로 unnest_longer()와 unnest_wider() 중에서 자동으로 선택합니다. 빠른 탐색에는 좋지만, 궁극적으로는 데이터가 어떻게 구성되어 있는지 이해하도록 강제하지 않고 코드를 이해하기 어렵게 만들기 때문에 좋지 않은 생각입니다.\n\nunnest()는 행과 열을 모두 확장합니다. 리스트 열에 데이터 프레임과 같은 2차원 구조가 포함된 경우에 유용합니다. 이 책에서는 보지 못하겠지만 tidymodels 생태계를 사용한다면 만날 수도 있습니다.\n\n이러한 함수들은 다른 사람의 코드를 읽거나 더 드문 직사각형화 문제에 직면했을 때 접할 수 있으므로 알고 있는 것이 좋습니다.\n\n23.3.5 연습문제\n\ndf2와 같은 이름이 없는 리스트 열에 unnest_wider()를 사용하면 어떻게 됩니까? 이제 어떤 인수가 필요합니까? 결측값은 어떻게 됩니까?\ndf1과 같은 이름이 있는 리스트 열에 unnest_longer()를 사용하면 어떻게 됩니까? 출력에서 어떤 추가 정보를 얻습니까? 그 추가 세부 정보를 어떻게 억제할 수 있습니까?\n\n때때로 값이 정렬된 여러 리스트 열이 있는 데이터 프레임을 만나게 됩니다. 예를 들어 다음 데이터 프레임에서 y와 z의 값은 정렬되어 있습니다(즉, y와 z는 행 내에서 항상 같은 길이를 가지며, y의 첫 번째 값은 z의 첫 번째 값에 해당합니다). 이 데이터 프레임에 두 번의 unnest_longer() 호출을 적용하면 어떻게 됩니까? x와 y 사이의 관계를 어떻게 보존할 수 있습니까? (힌트: 문서를 주의 깊게 읽으세요).\n\ndf4 &lt;- tribble(\n  ~x, ~y, ~z,\n  \"a\", list(\"y-a-1\", \"y-a-2\"), list(\"z-a-1\", \"z-a-2\"),\n  \"b\", list(\"y-b-1\", \"y-b-2\", \"y-b-3\"), list(\"z-b-1\", \"z-b-2\", \"z-b-3\")\n)",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "rectangling.html#사례-연구",
    "href": "rectangling.html#사례-연구",
    "title": "23  계층적 데이터",
    "section": "\n23.4 사례 연구",
    "text": "23.4 사례 연구\n위에서 사용한 간단한 예제와 실제 데이터의 주요 차이점은 실제 데이터에는 일반적으로 여러 번의 unnest_longer() 및/또는 unnest_wider() 호출이 필요한 여러 수준의 중첩이 포함되어 있다는 것입니다. 이를 실제로 보여주기 위해 이 섹션에서는 repurrrsive 패키지의 데이터셋을 사용하여 세 가지 실제 직사각형화 과제를 해결합니다.\n\n23.4.1 매우 넓은 데이터\ngh_repos부터 시작하겠습니다. 이것은 GitHub API를 사용하여 검색된 GitHub 저장소 컬렉션에 대한 데이터가 포함된 리스트입니다. 매우 깊게 중첩된 리스트이므로 이 책에서 구조를 보여주기가 어렵습니다. 계속하기 전에 View(gh_repos)로 직접 탐색해 보는 것을 추천합니다.\ngh_repos는 리스트이지만 우리의 도구는 리스트 열과 함께 작동하므로 먼저 티블에 넣는 것으로 시작하겠습니다. 나중에 설명할 이유 때문에 이 열을 json이라고 부릅니다.\n\nrepos &lt;- tibble(json = gh_repos)\nrepos\n#&gt; # A tibble: 6 × 1\n#&gt;   json       \n#&gt;   &lt;list&gt;     \n#&gt; 1 &lt;list [30]&gt;\n#&gt; 2 &lt;list [30]&gt;\n#&gt; 3 &lt;list [30]&gt;\n#&gt; 4 &lt;list [26]&gt;\n#&gt; 5 &lt;list [30]&gt;\n#&gt; 6 &lt;list [30]&gt;\n\n이 티블에는 gh_repos의 각 자식에 대해 하나씩 6개의 행이 포함되어 있습니다. 각 행에는 26개 또는 30개의 행이 있는 이름이 없는 리스트가 포함되어 있습니다. 이들은 이름이 없으므로 각 자식을 자체 행에 넣기 위해 unnest_longer()로 시작하겠습니다:\n\nrepos |&gt; \n  unnest_longer(json)\n#&gt; # A tibble: 176 × 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [68]&gt;\n#&gt; 2 &lt;named list [68]&gt;\n#&gt; 3 &lt;named list [68]&gt;\n#&gt; 4 &lt;named list [68]&gt;\n#&gt; 5 &lt;named list [68]&gt;\n#&gt; 6 &lt;named list [68]&gt;\n#&gt; # ℹ 170 more rows\n\n처음에는 상황이 개선되지 않은 것처럼 보일 수 있습니다: 행은 더 많아졌지만(6개 대신 176개) json의 각 요소는 여전히 리스트입니다. 하지만 중요한 차이점이 있습니다: 이제 각 요소가 이름이 있는 리스트이므로 unnest_wider()를 사용하여 각 요소를 자체 열에 넣을 수 있습니다:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) \n#&gt; # A tibble: 176 × 68\n#&gt;         id name        full_name         owner        private html_url       \n#&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;list&gt;       &lt;lgl&gt;   &lt;chr&gt;          \n#&gt; 1 61160198 after       gaborcsardi/after &lt;named list&gt; FALSE   https://github…\n#&gt; 2 40500181 argufy      gaborcsardi/argu… &lt;named list&gt; FALSE   https://github…\n#&gt; 3 36442442 ask         gaborcsardi/ask   &lt;named list&gt; FALSE   https://github…\n#&gt; 4 34924886 baseimports gaborcsardi/base… &lt;named list&gt; FALSE   https://github…\n#&gt; 5 61620661 citest      gaborcsardi/cite… &lt;named list&gt; FALSE   https://github…\n#&gt; 6 33907457 clisymbols  gaborcsardi/clis… &lt;named list&gt; FALSE   https://github…\n#&gt; # ℹ 170 more rows\n#&gt; # ℹ 62 more variables: description &lt;chr&gt;, fork &lt;lgl&gt;, url &lt;chr&gt;, …\n\n작동은 했지만 결과가 약간 압도적입니다: 열이 너무 많아서 티블이 전부 인쇄하지도 못할 정도입니다! names()로 모두 볼 수 있으며, 여기서는 처음 10개를 살펴봅니다:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  names() |&gt; \n  head(10)\n#&gt;  [1] \"id\"          \"name\"        \"full_name\"   \"owner\"       \"private\"    \n#&gt;  [6] \"html_url\"    \"description\" \"fork\"        \"url\"         \"forks_url\"\n\n흥미로워 보이는 것 몇 개를 뽑아보겠습니다:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description)\n#&gt; # A tibble: 176 × 4\n#&gt;         id full_name               owner             description             \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;list&gt;            &lt;chr&gt;                   \n#&gt; 1 61160198 gaborcsardi/after       &lt;named list [17]&gt; Run Code in the Backgro…\n#&gt; 2 40500181 gaborcsardi/argufy      &lt;named list [17]&gt; Declarative function ar…\n#&gt; 3 36442442 gaborcsardi/ask         &lt;named list [17]&gt; Friendly CLI interactio…\n#&gt; 4 34924886 gaborcsardi/baseimports &lt;named list [17]&gt; Do we get warnings for …\n#&gt; 5 61620661 gaborcsardi/citest      &lt;named list [17]&gt; Test R package and repo…\n#&gt; 6 33907457 gaborcsardi/clisymbols  &lt;named list [17]&gt; Unicode symbols for CLI…\n#&gt; # ℹ 170 more rows\n\n이것을 사용하여 gh_repos가 어떻게 구성되었는지 거꾸로 이해할 수 있습니다: 각 자식은 자신이 만든 최대 30개의 GitHub 저장소 리스트를 포함하는 GitHub 사용자였습니다.\nowner는 또 다른 리스트 열이며 이름이 있는 리스트를 포함하므로 unnest_wider()를 사용하여 값을 가져올 수 있습니다:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner)\n#&gt; Error in `unnest_wider()`:\n#&gt; ! Can't duplicate names between the affected columns and the original\n#&gt;   data.\n#&gt; ✖ These names are duplicated:\n#&gt;   ℹ `id`, from `owner`.\n#&gt; ℹ Use `names_sep` to disambiguate using the column name.\n#&gt; ℹ Or use `names_repair` to specify a repair strategy.\n\n이런, 이 리스트 열에도 id 열이 포함되어 있고 동일한 데이터 프레임에 두 개의 id 열을 가질 수 없습니다. 제안된 대로 names_sep을 사용하여 문제를 해결해 보겠습니다:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner, names_sep = \"_\")\n#&gt; # A tibble: 176 × 20\n#&gt;         id full_name               owner_login owner_id owner_avatar_url     \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;                \n#&gt; 1 61160198 gaborcsardi/after       gaborcsardi   660288 https://avatars.gith…\n#&gt; 2 40500181 gaborcsardi/argufy      gaborcsardi   660288 https://avatars.gith…\n#&gt; 3 36442442 gaborcsardi/ask         gaborcsardi   660288 https://avatars.gith…\n#&gt; 4 34924886 gaborcsardi/baseimports gaborcsardi   660288 https://avatars.gith…\n#&gt; 5 61620661 gaborcsardi/citest      gaborcsardi   660288 https://avatars.gith…\n#&gt; 6 33907457 gaborcsardi/clisymbols  gaborcsardi   660288 https://avatars.gith…\n#&gt; # ℹ 170 more rows\n#&gt; # ℹ 15 more variables: owner_gravatar_id &lt;chr&gt;, owner_url &lt;chr&gt;, …\n\n이렇게 하면 또 다른 넓은 데이터셋이 생성되지만, owner에 저장소를 “소유”한 사람에 대한 많은 추가 데이터가 포함되어 있음을 알 수 있습니다.\n\n23.4.2 관계형 데이터\n중첩된 데이터는 때때로 우리가 보통 여러 데이터 프레임에 분산시킬 데이터를 나타내는 데 사용됩니다. 예를 들어 왕좌의 게임(Game of Thrones) 책과 TV 시리즈에 등장하는 인물에 대한 데이터가 포함된 got_chars를 예로 들어보겠습니다. gh_repos와 마찬가지로 리스트이므로 먼저 티블의 리스트 열로 변환하는 것으로 시작합니다:\n\nchars &lt;- tibble(json = got_chars)\nchars\n#&gt; # A tibble: 30 × 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [18]&gt;\n#&gt; 2 &lt;named list [18]&gt;\n#&gt; 3 &lt;named list [18]&gt;\n#&gt; 4 &lt;named list [18]&gt;\n#&gt; 5 &lt;named list [18]&gt;\n#&gt; 6 &lt;named list [18]&gt;\n#&gt; # ℹ 24 more rows\n\njson 열에는 이름이 있는 요소가 포함되어 있으므로 먼저 넓게 만드는 것으로 시작하겠습니다:\n\nchars |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 30 × 18\n#&gt;   url                    id name            gender culture    born           \n#&gt;   &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          \n#&gt; 1 https://www.anapio…  1022 Theon Greyjoy   Male   \"Ironborn\" \"In 278 AC or …\n#&gt; 2 https://www.anapio…  1052 Tyrion Lannist… Male   \"\"         \"In 273 AC, at…\n#&gt; 3 https://www.anapio…  1074 Victarion Grey… Male   \"Ironborn\" \"In 268 AC or …\n#&gt; 4 https://www.anapio…  1109 Will            Male   \"\"         \"\"             \n#&gt; 5 https://www.anapio…  1166 Areo Hotah      Male   \"Norvoshi\" \"In 257 AC or …\n#&gt; 6 https://www.anapio…  1267 Chett           Male   \"\"         \"At Hag's Mire\"\n#&gt; # ℹ 24 more rows\n#&gt; # ℹ 12 more variables: died &lt;chr&gt;, alive &lt;lgl&gt;, titles &lt;list&gt;, …\n\n그리고 읽기 쉽게 몇 개의 열을 선택합니다:\n\ncharacters &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, name, gender, culture, born, died, alive)\ncharacters\n#&gt; # A tibble: 30 × 7\n#&gt;      id name              gender culture    born              died           \n#&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          \n#&gt; 1  1022 Theon Greyjoy     Male   \"Ironborn\" \"In 278 AC or 27… \"\"             \n#&gt; 2  1052 Tyrion Lannister  Male   \"\"         \"In 273 AC, at C… \"\"             \n#&gt; 3  1074 Victarion Greyjoy Male   \"Ironborn\" \"In 268 AC or be… \"\"             \n#&gt; 4  1109 Will              Male   \"\"         \"\"                \"In 297 AC, at…\n#&gt; 5  1166 Areo Hotah        Male   \"Norvoshi\" \"In 257 AC or be… \"\"             \n#&gt; 6  1267 Chett             Male   \"\"         \"At Hag's Mire\"   \"In 299 AC, at…\n#&gt; # ℹ 24 more rows\n#&gt; # ℹ 1 more variable: alive &lt;lgl&gt;\n\n이 데이터셋에는 많은 리스트 열도 포함되어 있습니다:\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list))\n#&gt; # A tibble: 30 × 8\n#&gt;      id titles    aliases    allegiances books     povBooks tvSeries playedBy\n#&gt;   &lt;int&gt; &lt;list&gt;    &lt;list&gt;     &lt;list&gt;      &lt;list&gt;    &lt;list&gt;   &lt;list&gt;   &lt;list&gt;  \n#&gt; 1  1022 &lt;chr [2]&gt; &lt;chr [4]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 2  1052 &lt;chr [2]&gt; &lt;chr [11]&gt; &lt;chr [1]&gt;   &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 3  1074 &lt;chr [2]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 4  1109 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [1]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 5  1166 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 6  1267 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; # ℹ 24 more rows\n\ntitles 열을 살펴보겠습니다. 이름이 없는 리스트 열이므로 행으로 중첩 해제합니다:\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles)\n#&gt; # A tibble: 59 × 2\n#&gt;      id titles                                              \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # ℹ 53 more rows\n\n이 데이터는 필요에 따라 인물 데이터에 조인하기 쉬울 것이기 때문에 자체 테이블에서 볼 수 있을 것이라고 예상할 수 있습니다. 그렇게 해보겠습니다. 약간의 정리가 필요합니다: 빈 문자열을 포함하는 행을 제거하고, 각 행에 이제 단일 제목만 포함되므로 titles를 title로 이름을 바꿉니다.\n\ntitles &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles) |&gt; \n  filter(titles != \"\") |&gt; \n  rename(title = titles)\ntitles\n#&gt; # A tibble: 52 × 2\n#&gt;      id title                                               \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # ℹ 46 more rows\n\n각 리스트 열에 대해 이와 같은 테이블을 만든 다음, 필요에 따라 조인을 사용하여 인물 데이터와 결합하는 것을 상상할 수 있습니다.\n\n23.4.3 깊게 중첩된 데이터\n매우 깊게 중첩되어 있어 반복적인 unnest_wider() 및 unnest_longer() 호출이 필요한 리스트 열인 gmaps_cities로 이 사례 연구를 마무리하겠습니다. 이것은 5개의 도시 이름과 구글의 지오코딩 API를 사용하여 해당 위치를 확인한 결과가 포함된 두 개의 열로 된 티블입니다:\n\ngmaps_cities\n#&gt; # A tibble: 5 × 2\n#&gt;   city       json            \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [2]&gt;\n#&gt; 2 Washington &lt;named list [2]&gt;\n#&gt; 3 New York   &lt;named list [2]&gt;\n#&gt; 4 Chicago    &lt;named list [2]&gt;\n#&gt; 5 Arlington  &lt;named list [2]&gt;\n\njson은 내부 이름이 있는 리스트 열이므로 unnest_wider()로 시작합니다:\n\ngmaps_cities |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 5 × 3\n#&gt;   city       results    status\n#&gt;   &lt;chr&gt;      &lt;list&gt;     &lt;chr&gt; \n#&gt; 1 Houston    &lt;list [1]&gt; OK    \n#&gt; 2 Washington &lt;list [2]&gt; OK    \n#&gt; 3 New York   &lt;list [1]&gt; OK    \n#&gt; 4 Chicago    &lt;list [1]&gt; OK    \n#&gt; 5 Arlington  &lt;list [2]&gt; OK\n\n이렇게 하면 status와 results를 얻게 됩니다. 상태가 모두 OK이므로 상태 열은 삭제하겠습니다. 실제 분석에서는 status != \"OK\"인 모든 행을 캡처하고 무엇이 잘못되었는지 파악하고 싶을 것입니다. results는 하나 또는 두 개의 요소를 가진 이름이 없는 리스트이므로(이유는 곧 알게 될 것입니다) 행으로 중첩 해제합니다:\n\ngmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results)\n#&gt; # A tibble: 7 × 2\n#&gt;   city       results         \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [5]&gt;\n#&gt; 2 Washington &lt;named list [5]&gt;\n#&gt; 3 Washington &lt;named list [5]&gt;\n#&gt; 4 New York   &lt;named list [5]&gt;\n#&gt; 5 Chicago    &lt;named list [5]&gt;\n#&gt; 6 Arlington  &lt;named list [5]&gt;\n#&gt; # ℹ 1 more row\n\n이제 results는 이름이 있는 리스트이므로 unnest_wider()를 사용합니다:\n\nlocations &lt;- gmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\nlocations\n#&gt; # A tibble: 7 × 6\n#&gt;   city       address_components formatted_address   geometry        \n#&gt;   &lt;chr&gt;      &lt;list&gt;             &lt;chr&gt;               &lt;list&gt;          \n#&gt; 1 Houston    &lt;list [4]&gt;         Houston, TX, USA    &lt;named list [4]&gt;\n#&gt; 2 Washington &lt;list [2]&gt;         Washington, USA     &lt;named list [4]&gt;\n#&gt; 3 Washington &lt;list [4]&gt;         Washington, DC, USA &lt;named list [4]&gt;\n#&gt; 4 New York   &lt;list [3]&gt;         New York, NY, USA   &lt;named list [4]&gt;\n#&gt; 5 Chicago    &lt;list [4]&gt;         Chicago, IL, USA    &lt;named list [4]&gt;\n#&gt; 6 Arlington  &lt;list [4]&gt;         Arlington, TX, USA  &lt;named list [4]&gt;\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 2 more variables: place_id &lt;chr&gt;, types &lt;list&gt;\n\n이제 왜 두 도시가 두 개의 결과를 얻었는지 알 수 있습니다: Washington은 워싱턴 주와 워싱턴 DC 모두와 일치했고, Arlington은 버지니아 주 알링턴과 텍사스 주 알링턴과 일치했습니다.\n여기서부터 갈 수 있는 몇 가지 다른 방향이 있습니다. geometry 리스트 열에 저장된 일치 항목의 정확한 위치를 확인하고 싶을 수 있습니다:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry)\n#&gt; # A tibble: 7 × 6\n#&gt;   city       formatted_address   bounds           location     location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;       &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: viewport &lt;list&gt;\n\n그러면 새로운 bounds(직사각형 영역)와 location(점)을 얻게 됩니다. location을 중첩 해제하여 위도(lat)와 경도(lng)를 볼 수 있습니다:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  unnest_wider(location)\n#&gt; # A tibble: 7 × 7\n#&gt;   city       formatted_address   bounds             lat    lng location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt;  29.8  -95.4 APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt;  47.8 -121.  APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt;  38.9  -77.0 APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt;  40.7  -74.0 APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt;  41.9  -87.6 APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt;  32.7  -97.1 APPROXIMATE  \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: viewport &lt;list&gt;\n\n경계(bounds)를 추출하려면 몇 단계가 더 필요합니다:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  # 관심 있는 변수에 집중\n  select(!location:viewport) |&gt;\n  unnest_wider(bounds)\n#&gt; # A tibble: 7 × 4\n#&gt;   city       formatted_address   northeast        southwest       \n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;          \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; # ℹ 1 more row\n\n그런 다음 southwest와 northeast(직사각형의 모서리)의 이름을 변경하여 names_sep을 사용하여 짧으면서도 기억하기 쉬운 이름을 만들 수 있습니다:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  select(!location:viewport) |&gt;\n  unnest_wider(bounds) |&gt; \n  rename(ne = northeast, sw = southwest) |&gt; \n  unnest_wider(c(ne, sw), names_sep = \"_\") \n#&gt; # A tibble: 7 × 6\n#&gt;   city       formatted_address   ne_lat ne_lng sw_lat sw_lng\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Houston    Houston, TX, USA      30.1  -95.0   29.5  -95.8\n#&gt; 2 Washington Washington, USA       49.0 -117.    45.5 -125. \n#&gt; 3 Washington Washington, DC, USA   39.0  -76.9   38.8  -77.1\n#&gt; 4 New York   New York, NY, USA     40.9  -73.7   40.5  -74.3\n#&gt; 5 Chicago    Chicago, IL, USA      42.0  -87.5   41.6  -87.9\n#&gt; 6 Arlington  Arlington, TX, USA    32.8  -97.0   32.6  -97.2\n#&gt; # ℹ 1 more row\n\nunnest_wider()에 변수 이름 벡터를 제공하여 두 열을 동시에 중첩 해제하는 방법에 유의하세요.\n관심 있는 구성 요소에 도달하는 경로를 발견했다면 또 다른 tidyr 함수인 hoist()를 사용하여 직접 추출할 수 있습니다:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  hoist(\n    geometry,\n    ne_lat = c(\"bounds\", \"northeast\", \"lat\"),\n    sw_lat = c(\"bounds\", \"southwest\", \"lat\"),\n    ne_lng = c(\"bounds\", \"northeast\", \"lng\"),\n    sw_lng = c(\"bounds\", \"southwest\", \"lng\"),\n  )\n\n이러한 사례 연구가 실제 직사각형화에 대한 흥미를 유발했다면 vignette(\"rectangling\", package = \"tidyr\")에서 몇 가지 예제를 더 볼 수 있습니다.\n\n23.4.4 연습문제\n\ngh_repos가 언제 생성되었는지 대략적으로 추정해 보세요. 왜 날짜를 대략적으로만 추정할 수 있습니까?\n각 소유자가 많은 저장소를 가질 수 있기 때문에 gh_repo의 owner 열에는 중복된 정보가 많이 포함되어 있습니다. 각 소유자에 대해 하나의 행을 포함하는 owners 데이터 프레임을 구성할 수 있습니까? (힌트: distinct()가 list-cols와 함께 작동합니까?)\ntitles에 사용된 단계를 따라 왕좌의 게임 인물들의 별칭(aliases), 충성(allegiances), 책(books) 및 TV 시리즈(TV series)에 대한 유사한 테이블을 만드세요.\n\n다음 코드를 한 줄씩 설명하세요. 왜 흥미롭습니까? 왜 got_chars에서는 작동하지만 일반적으로는 작동하지 않을 수 있습니까?\n\ntibble(json = got_chars) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list)) |&gt; \n  pivot_longer(\n    where(is.list), \n    names_to = \"name\", \n    values_to = \"value\"\n  ) |&gt;  \n  unnest_longer(value)\n\n\ngmaps_cities에서 address_components에는 무엇이 들어 있습니까? 왜 행마다 길이가 다릅니까? 그것을 파악하기 위해 적절하게 중첩 해제하세요. (힌트: types는 항상 두 개의 요소를 포함하는 것으로 보입니다. unnest_longer()보다 unnest_wider()가 작업하기 더 쉬운가요?)",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "rectangling.html#json",
    "href": "rectangling.html#json",
    "title": "23  계층적 데이터",
    "section": "\n23.5 JSON",
    "text": "23.5 JSON\n이전 섹션의 모든 사례 연구는 야생에서 수집된 JSON에서 가져온 것입니다. JSON은 javascript object notation의 약자로 대부분의 웹 API가 데이터를 반환하는 방식입니다. JSON과 R의 데이터 유형은 꽤 비슷하지만 완벽한 1대1 매핑은 아니므로 문제가 발생할 경우를 대비해 JSON에 대해 조금 이해하는 것이 중요합니다.\n\n23.5.1 데이터 유형\nJSON은 인간이 아니라 기계가 쉽게 읽고 쓸 수 있도록 설계된 간단한 형식입니다. 6가지 주요 데이터 유형이 있습니다. 그중 4개는 스칼라(scalar)입니다:\n\n가장 간단한 유형은 null(null)로 R의 NA와 같은 역할을 합니다. 데이터의 부재를 나타냅니다.\n\n문자열(string) 은 R의 문자열과 매우 유사하지만 항상 큰따옴표를 사용해야 합니다.\n\n숫자(number) 는 R의 숫자와 유사합니다: 정수(예: 123), 소수(예: 123.45) 또는 지수(예: 1.23e3) 표기법을 사용할 수 있습니다. JSON은 Inf, -Inf 또는 NaN을 지원하지 않습니다.\n\n불리언(boolean) 은 R의 TRUE 및 FALSE와 유사하지만 소문자 true 및 false를 사용합니다.\n\nJSON의 문자열, 숫자 및 불리언은 R의 문자형, 수치형 및 논리형 벡터와 매우 유사합니다. 주요 차이점은 JSON의 스칼라는 단일 값만 나타낼 수 있다는 것입니다. 여러 값을 나타내려면 나머지 두 가지 유형인 배열과 객체 중 하나를 사용해야 합니다.\n배열과 객체는 모두 R의 리스트와 유사합니다. 차이점은 이름이 있는지 여부입니다. 배열(array) 은 이름이 없는 리스트와 같으며 []로 씁니다. 예를 들어 [1, 2, 3]은 3개의 숫자를 포함하는 배열이고, [null, 1, \"string\", false]는 null, 숫자, 문자열 및 불리언을 포함하는 배열입니다. 객체(object) 는 이름이 있는 리스트와 같으며 {}로 씁니다. 이름(JSON 용어로는 키)은 문자열이므로 따옴표로 둘러싸야 합니다. 예를 들어 {\"x\": 1, \"y\": 2}는 x를 1에, y를 2에 매핑하는 객체입니다.\nJSON에는 날짜나 날짜-시간을 나타내는 기본 방법이 없으므로 종종 문자열로 저장되며, 올바른 데이터 구조로 변환하려면 readr::parse_date() 또는 readr::parse_datetime()을 사용해야 합니다. 마찬가지로 JSON에서 부동 소수점 숫자를 나타내는 규칙은 약간 부정확하므로 때때로 문자열에 저장된 숫자를 발견할 수도 있습니다. 올바른 변수 유형을 얻기 위해 필요에 따라 readr::parse_double()을 적용하세요.\n\n23.5.2 jsonlite\nJSON을 R 데이터 구조로 변환하려면 Jeroen Ooms가 만든 jsonlite 패키지를 권장합니다. 여기서는 두 가지 jsonlite 함수인 read_json()과 parse_json()만 사용합니다. 실제 생활에서는 디스크에서 JSON 파일을 읽기 위해 read_json()을 사용하게 될 것입니다. 예를 들어 repurrrsive 패키지는 gh_user에 대한 소스를 JSON 파일로 제공하며 read_json()으로 읽을 수 있습니다:\n\n# 패키지 내부의 json 파일 경로:\ngh_users_json()\n#&gt; [1] \"/Users/jinhwan/Library/R/arm64/4.5/library/repurrrsive/extdata/gh_users.json\"\n\n# read_json()으로 읽기\ngh_users2 &lt;- read_json(gh_users_json())\n\n# 이전에 사용하던 데이터와 동일한지 확인\nidentical(gh_users, gh_users2)\n#&gt; [1] TRUE\n\n이 책에서는 parse_json()도 사용하는데, JSON을 포함하는 문자열을 인수로 받기 때문에 간단한 예제를 생성하는 데 좋기 때문입니다. 시작하기 위해 숫자 하나로 시작하여 배열에 몇 개의 숫자를 넣고, 그 배열을 객체에 넣는 세 가지 간단한 JSON 데이터셋이 있습니다:\n\nstr(parse_json('1'))\n#&gt;  int 1\nstr(parse_json('[1, 2, 3]'))\n#&gt; List of 3\n#&gt;  $ : int 1\n#&gt;  $ : int 2\n#&gt;  $ : int 3\nstr(parse_json('{\"x\": [1, 2, 3]}'))\n#&gt; List of 1\n#&gt;  $ x:List of 3\n#&gt;   ..$ : int 1\n#&gt;   ..$ : int 2\n#&gt;   ..$ : int 3\n\njsonlite에는 fromJSON()이라는 또 다른 중요한 함수가 있습니다. 여기서는 사용하지 않는데, 자동 단순화(simplifyVector = TRUE)를 수행하기 때문입니다. 이것은 특히 간단한 경우에 잘 작동하지만, 무슨 일이 일어나는지 정확히 알 수 있고 가장 복잡한 중첩 구조를 더 쉽게 처리할 수 있도록 직접 직사각형화를 수행하는 것이 더 낫다고 생각합니다.\n\n23.5.3 직사각형화 프로세스 시작하기\n대부분의 경우 JSON 파일은 최상위 배열 하나를 포함합니다. 여러 “것”(예: 여러 페이지, 여러 레코드 또는 여러 결과)에 대한 데이터를 제공하도록 설계되었기 때문입니다. 이 경우 각 요소가 행이 되도록 tibble(json)으로 직사각형화를 시작합니다:\n\njson &lt;- '[\n  {\"name\": \"John\", \"age\": 34},\n  {\"name\": \"Susan\", \"age\": 27}\n]'\ndf &lt;- tibble(json = parse_json(json))\ndf\n#&gt; # A tibble: 2 × 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n#&gt; 2 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 2 × 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\n더 드문 경우로, JSON 파일이 하나의 “것”을 나타내는 최상위 JSON 객체 하나로 구성되는 경우가 있습니다. 이 경우 티블에 넣기 전에 리스트로 감싸서 직사각형화 프로세스를 시작해야 합니다.\n\njson &lt;- '{\n  \"status\": \"OK\", \n  \"results\": [\n    {\"name\": \"John\", \"age\": 34},\n    {\"name\": \"Susan\", \"age\": 27}\n ]\n}\n'\ndf &lt;- tibble(json = list(parse_json(json)))\ndf\n#&gt; # A tibble: 1 × 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 × 3\n#&gt;   status name    age\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 OK     John     34\n#&gt; 2 OK     Susan    27\n\n대안으로 파싱된 JSON 내부를 파고들어 실제로 관심 있는 부분부터 시작할 수 있습니다:\n\ndf &lt;- tibble(results = parse_json(json)$results)\ndf |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 × 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\n\n23.5.4 연습문제\n\n\n아래의 df_col과 df_row를 직사각형화하세요. 이들은 JSON에서 데이터 프레임을 인코딩하는 두 가지 방법을 나타냅니다.\n\njson_col &lt;- parse_json('\n  {\n    \"x\": [\"a\", \"x\", \"z\"],\n    \"y\": [10, null, 3]\n  }\n')\njson_row &lt;- parse_json('\n  [\n    {\"x\": \"a\", \"y\": 10},\n    {\"x\": \"x\", \"y\": null},\n    {\"x\": \"z\", \"y\": 3}\n  ]\n')\n\ndf_col &lt;- tibble(json = list(json_col)) \ndf_row &lt;- tibble(json = json_row)",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "rectangling.html#요약",
    "href": "rectangling.html#요약",
    "title": "23  계층적 데이터",
    "section": "\n23.6 요약",
    "text": "23.6 요약\n이 장에서는 리스트가 무엇인지, JSON 파일에서 어떻게 리스트를 생성할 수 있는지, 그리고 그것들을 어떻게 직사각형 데이터 프레임으로 변환하는지 배웠습니다. 놀랍게도 리스트 요소를 행에 넣기 위한 unnest_longer()와 리스트 요소를 열에 넣기 위한 unnest_wider()라는 두 개의 새로운 함수만 필요했습니다. 리스트 열이 얼마나 깊게 중첩되어 있는지는 중요하지 않습니다. 이 두 함수를 반복해서 호출하기만 하면 됩니다.\nJSON은 웹 API가 반환하는 가장 일반적인 데이터 형식입니다. 웹사이트에 API가 없지만 웹사이트에서 원하는 데이터를 볼 수 있다면 어떻게 될까요? 그것이 다음 장의 주제입니다: 웹 스크래핑, 즉 HTML 웹페이지에서 데이터를 추출하는 것입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "rectangling.html#footnotes",
    "href": "rectangling.html#footnotes",
    "title": "23  계층적 데이터",
    "section": "",
    "text": "이것은 RStudio 기능입니다.↩︎",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>계층적 데이터</span>"
    ]
  },
  {
    "objectID": "webscraping.html",
    "href": "webscraping.html",
    "title": "24  웹 스크래핑",
    "section": "",
    "text": "24.1 소개\n이 장에서는 rvest를 사용한 웹 스크래핑의 기초를 소개합니다. 웹 스크래핑은 웹페이지에서 데이터를 추출하는 데 매우 유용한 도구입니다. 일부 웹사이트는 API(데이터를 JSON으로 반환하는 구조화된 HTTP 요청 세트)를 제공하며, 이는 Chapter 23 의 기술을 사용하여 처리합니다. 가능하면 API를 사용해야 합니다1. 일반적으로 더 신뢰할 수 있는 데이터를 제공하기 때문입니다. 그러나 불행히도 웹 API 프로그래밍은 이 책의 범위를 벗어납니다. 대신, 사이트가 API를 제공하는지 여부와 관계없이 작동하는 기술인 스크래핑을 가르칩니다.\n이 장에서는 HTML의 기초를 다루기 전에 먼저 스크래핑의 윤리와 법적 측면에 대해 논의할 것입니다. 그런 다음 페이지의 특정 요소를 찾기 위한 CSS 선택자의 기초와 rvest 함수를 사용하여 HTML에서 텍스트와 속성의 데이터를 가져와 R로 옮기는 방법을 배울 것입니다. 그 후 두 가지 사례 연구와 동적 웹사이트에 대한 짧은 논의로 마무리하기 전에, 스크래핑하려는 페이지에 어떤 CSS 선택자가 필요한지 파악하는 몇 가지 기술을 논의할 것입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#소개",
    "href": "webscraping.html#소개",
    "title": "24  웹 스크래핑",
    "section": "",
    "text": "24.1.1 선수 지식\n이 장에서는 rvest에서 제공하는 도구에 초점을 맞출 것입니다. rvest는 tidyverse의 멤버이지만 핵심 멤버는 아니므로 명시적으로 로드해야 합니다. 스크래핑한 데이터를 다루는 데 일반적으로 유용하므로 전체 tidyverse도 로드할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(rvest)",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#스크래핑-윤리-및-법적-측면",
    "href": "webscraping.html#스크래핑-윤리-및-법적-측면",
    "title": "24  웹 스크래핑",
    "section": "\n24.2 스크래핑 윤리 및 법적 측면",
    "text": "24.2 스크래핑 윤리 및 법적 측면\n웹 스크래핑을 수행하는 데 필요한 코드를 논의하기 전에, 그렇게 하는 것이 합법적이고 윤리적인지 여부에 대해 이야기해야 합니다. 전반적으로 이 두 가지와 관련하여 상황은 복잡합니다.\n법적 측면은 거주 지역에 따라 크게 달라집니다. 그러나 일반적인 원칙으로서 데이터가 공개적이고, 비개인적이며, 사실적이라면 괜찮을 가능성이 높습니다2. 이 세 가지 요소는 아래에서 논의할 것처럼 사이트의 이용 약관, 개인 식별 정보 및 저작권과 연결되어 있기 때문에 중요합니다.\n데이터가 공개적이지 않거나, 비개인적이지 않거나, 사실적이지 않거나, 특히 돈을 벌기 위해 데이터를 스크래핑하는 경우 변호사와 상담해야 합니다. 어떤 경우이든 스크래핑하는 페이지를 호스팅하는 서버의 리소스를 존중해야 합니다. 가장 중요한 것은 많은 페이지를 스크래핑하는 경우 각 요청 사이에 잠시 기다려야 한다는 것입니다. 그렇게 하는 한 가지 쉬운 방법은 Dmytro Perepolkin이 만든 polite 패키지를 사용하는 것입니다. 요청 사이에 자동으로 일시 중지하고 결과를 캐시하므로 동일한 페이지를 두 번 요청하지 않습니다.\n\n24.2.1 서비스 약관\n자세히 살펴보면 많은 웹사이트의 페이지 어딘가에 “이용 약관” 또는 “서비스 약관” 링크가 포함되어 있음을 알 수 있으며, 해당 페이지를 자세히 읽어보면 사이트가 웹 스크래핑을 명시적으로 금지하고 있음을 발견하는 경우가 많습니다. 이러한 페이지는 회사가 매우 광범위한 주장을 하는 법적 토지 강탈이 되는 경향이 있습니다. 가능한 한 이러한 서비스 약관을 존중하는 것이 예의이지만, 모든 주장을 곧이곧대로 받아들이지는 마세요.\n미국 법원은 웹사이트 하단에 서비스 약관을 배치하는 것만으로는 귀하가 그에 구속되기에 충분하지 않다고 일반적으로 판결했습니다(예: HiQ Labs v. LinkedIn). 일반적으로 서비스 약관에 구속되려면 계정 생성이나 확인란 선택과 같은 명시적인 조치를 취해야 합니다. 이것이 데이터가 공개적인지 여부가 중요한 이유입니다. 액세스하는 데 계정이 필요하지 않다면 서비스 약관에 구속될 가능성이 낮습니다. 그러나 법원이 명시적으로 동의하지 않더라도 서비스 약관을 집행할 수 있다고 판결한 유럽에서는 상황이 다소 다릅니다.\n\n24.2.2 개인 식별 정보\n데이터가 공개적이더라도 이름, 이메일 주소, 전화번호, 생년월일 등과 같은 개인 식별 정보를 스크래핑할 때는 매우 주의해야 합니다. 유럽은 이러한 데이터의 수집 또는 저장에 대해 특히 엄격한 법률(GDPR)을 가지고 있으며, 거주 지역에 관계없이 윤리적 수렁에 빠질 가능성이 높습니다. 예를 들어, 2016년에 한 연구 그룹은 데이팅 사이트인 OkCupid에서 약 70,000명의 공개 프로필 정보(예: 사용자 이름, 나이, 성별, 위치 등)를 스크래핑하여 익명화 시도 없이 이 데이터를 공개적으로 출시했습니다. 연구원들은 데이터가 이미 공개되어 있었기 때문에 이에 문제가 없다고 느꼈지만, 이 작업은 데이터셋에 정보가 공개된 사용자의 식별 가능성에 대한 윤리적 우려로 인해 널리 비난받았습니다. 작업에 개인 식별 정보 스크래핑이 포함된 경우 OkCupid 연구3와 개인 식별 정보의 획득 및 출시와 관련된 의심스러운 연구 윤리를 가진 유사한 연구에 대해 읽어보는 것을 강력히 추천합니다.\n\n24.2.3 저작권\n마지막으로 저작권법에 대해서도 걱정해야 합니다. 저작권법은 복잡하지만 무엇이 보호되는지 정확히 설명하는 미국 법률을 살펴볼 가치가 있습니다: “[…] 모든 유형의 표현 매체에 고정된 저자의 독창적인 저작물, []”. 그런 다음 문학 저작물, 음악 저작물, 영화 등과 같이 적용되는 특정 범주를 설명합니다. 저작권 보호에서 눈에 띄게 빠진 것은 데이터입니다. 즉, 스크래핑을 사실(facts)로 제한하는 한 저작권 보호는 적용되지 않습니다. (하지만 유럽에는 데이터베이스를 보호하는 별도의 “sui generis” 권리가 있음에 유의하세요.)\n간단한 예로 미국에서는 재료 목록과 지침은 저작권으로 보호될 수 없으므로 저작권은 레시피를 보호하는 데 사용될 수 없습니다. 하지만 그 레시피 목록에 실질적인 새로운 문학적 내용이 수반된다면 그것은 저작권으로 보호될 수 있습니다. 이것이 인터넷에서 레시피를 찾을 때 항상 앞에 그렇게 많은 내용이 있는 이유입니다.\n독창적인 콘텐츠(텍스트나 이미지 등)를 스크래핑해야 하는 경우에도 여전히 공정 이용 원칙(doctrine of fair use)에 따라 보호받을 수 있습니다. 공정 이용은 고정된 규칙은 아니지만 여러 요소를 따져봅니다. 연구 또는 비상업적 목적으로 데이터를 수집하고 스크래핑하는 내용을 필요한 것만으로 제한하는 경우 적용될 가능성이 더 높습니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#html-기초",
    "href": "webscraping.html#html-기초",
    "title": "24  웹 스크래핑",
    "section": "\n24.3 HTML 기초",
    "text": "24.3 HTML 기초\n웹페이지를 스크래핑하려면 먼저 웹페이지를 설명하는 언어인 HTML에 대해 조금 이해해야 합니다. HTML은 HyperText Markup Language의 약자로 다음과 같이 생겼습니다:\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;페이지 제목&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='first'&gt;제목&lt;/h1&gt;\n  &lt;p&gt;일부 텍스트 및 &lt;b&gt;일부 굵은 텍스트.&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\nHTML은 시작 태그(예: &lt;tag&gt;), 선택적 속성(id='first'), 종료 태그4(예: &lt;/tag&gt;) 및 내용(시작 태그와 종료 태그 사이의 모든 것)으로 구성된 요소(elements) 에 의해 형성된 계층 구조를 가집니다.\n&lt;와 &gt;는 시작 및 종료 태그에 사용되므로 직접 작성할 수 없습니다. 대신 HTML 이스케이프인 &gt;(보다 큼)와 &lt;(보다 작음)를 사용해야 합니다. 그리고 이러한 이스케이프는 &를 사용하므로 리터럴 앰퍼샌드를 원한다면 &amp;로 이스케이프해야 합니다. 다양한 가능한 HTML 이스케이프가 있지만 rvest가 자동으로 처리해 주므로 너무 걱정할 필요는 없습니다.\n웹 스크래핑이 가능한 이유는 스크래핑하려는 데이터가 포함된 대부분의 페이지가 일반적으로 일관된 구조를 가지고 있기 때문입니다.\n\n24.3.1 요소(Elements)\n100개 이상의 HTML 요소가 있습니다. 가장 중요한 것들은 다음과 같습니다:\n\n모든 HTML 페이지는 &lt;html&gt; 요소 내에 있어야 하며 두 개의 자식을 가져야 합니다: 페이지 제목과 같은 문서 메타데이터를 포함하는 &lt;head&gt;와 브라우저에서 보는 내용을 포함하는 &lt;body&gt;입니다.\n&lt;h1&gt;(제목 1), &lt;section&gt;(섹션), &lt;p&gt;(단락) 및 &lt;ol&gt;(순서가 있는 목록)과 같은 블록 태그는 페이지의 전반적인 구조를 형성합니다.\n&lt;b&gt;(굵게), &lt;i&gt;(기울임꼴) 및 &lt;a&gt;(링크)와 같은 인라인 태그는 블록 태그 내부의 텍스트 형식을 지정합니다.\n\n처음 보는 태그를 만나면 약간의 구글링으로 그 역할을 찾을 수 있습니다. 시작하기 좋은 또 다른 장소는 웹 프로그래밍의 거의 모든 측면을 설명하는 MDN 웹 문서입니다.\n대부분의 요소는 시작 태그와 종료 태그 사이에 내용을 가질 수 있습니다. 이 내용은 텍스트이거나 더 많은 요소일 수 있습니다. 예를 들어 다음 HTML은 한 단어가 굵게 표시된 텍스트 단락을 포함합니다.\n&lt;p&gt;\n  안녕! 내 &lt;b&gt;이름&lt;/b&gt;은 해들리야.\n&lt;/p&gt;\n자식(children) 은 포함된 요소이므로 위의 &lt;p&gt; 요소는 하나의 자식인 &lt;b&gt; 요소를 가집니다. &lt;b&gt; 요소는 자식이 없지만 내용(텍스트 “이름”)을 가집니다.\n\n24.3.2 속성(Attributes)\n태그는 name1='value1' name2='value2'와 같이 생긴 이름이 지정된 속성을 가질 수 있습니다. 가장 중요한 두 가지 속성은 id와 class로, CSS(Cascading Style Sheets)와 함께 사용되어 페이지의 시각적 모양을 제어합니다. 이들은 페이지에서 데이터를 스크래핑할 때 종종 유용합니다. 속성은 링크의 목적지(&lt;a&gt; 요소의 href 속성)와 이미지의 소스(&lt;img&gt; 요소의 src 속성)를 기록하는 데에도 사용됩니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#데이터-추출",
    "href": "webscraping.html#데이터-추출",
    "title": "24  웹 스크래핑",
    "section": "\n24.4 데이터 추출",
    "text": "24.4 데이터 추출\n스크래핑을 시작하려면 스크래핑하려는 페이지의 URL이 필요하며 이는 일반적으로 웹 브라우저에서 복사할 수 있습니다. 그런 다음 read_html()을 사용하여 해당 페이지의 HTML을 R로 읽어들여야 합니다. 이는 xml_document5 객체를 반환하며, 이를 rvest 함수를 사용하여 조작하게 됩니다:\n\nhtml &lt;- read_html(\"http://rvest.tidyverse.org/\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html lang=\"en\"&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n    &lt;a href=\"#container\" class=\"visually-hidden-focusable\"&gt;Ski ...\n\nrvest에는 HTML을 인라인으로 작성할 수 있게 해주는 함수도 포함되어 있습니다. 이 장에서 다양한 rvest 함수가 간단한 예제와 함께 어떻게 작동하는지 가르치기 위해 이 함수를 자주 사용할 것입니다.\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;이것은 단락입니다&lt;/p&gt;\n  &lt;ul&gt;\n    &lt;li&gt;이것은 글머리 기호 목록입니다&lt;/li&gt;\n  &lt;/ul&gt;\n\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n&lt;p&gt;이것은 단락입니다&lt;/p&gt;\\n  &lt;ul&gt;\\n&lt;li&gt;이것은 글머리 기호 목록입니다&lt;/li&gt;\\n  &lt;/ul&gt;\\n ...\n\n이제 R에 HTML이 있으므로 관심 있는 데이터를 추출할 차례입니다. 먼저 관심 있는 요소를 식별할 수 있게 해주는 CSS 선택자와 거기서 데이터를 추출하는 데 사용할 수 있는 rvest 함수에 대해 배우게 될 것입니다. 그런 다음 몇 가지 특수 도구가 있는 HTML 표에 대해 짧게 다룰 것입니다.\n\n24.4.1 요소 찾기\nCSS는 Cascading Style Sheets의 약자로 HTML 문서의 시각적 스타일을 정의하기 위한 도구입니다. CSS에는 CSS 선택자(selectors) 라고 불리는 페이지의 요소를 선택하기 위한 미니어처 언어가 포함되어 있습니다. CSS 선택자는 HTML 요소를 찾기 위한 패턴을 정의하며, 추출하려는 요소를 설명하는 간결한 방법을 제공하므로 스크래핑에 유용합니다.\nSection 24.5 에서 CSS 선택자에 대해 더 자세히 다루겠지만, 다행히 다음 세 가지만으로도 많은 것을 할 수 있습니다:\n\np는 모든 &lt;p&gt; 요소를 선택합니다.\n.title은 class가 “title”인 모든 요소를 선택합니다.\n#title은 id 속성이 “title”과 같은 요소를 선택합니다. id 속성은 문서 내에서 고유해야 하므로 이는 항상 단일 요소만 선택합니다.\n\n간단한 예제로 이 선택자들을 시도해 봅시다:\n\nhtml &lt;- minimal_html(\"\n  &lt;h1&gt;이것은 제목입니다&lt;/h1&gt;\n  &lt;p id='first'&gt;이것은 단락입니다&lt;/p&gt;\n  &lt;p class='important'&gt;이것은 중요한 단락입니다&lt;/p&gt;\n\")\n\nhtml_elements()를 사용하여 선택자와 일치하는 모든 요소를 찾으세요:\n\nhtml |&gt; html_elements(\"p\")\n#&gt; {xml_nodeset (2)}\n#&gt; [1] &lt;p id=\"first\"&gt;이것은 단락입니다&lt;/p&gt;\n#&gt; [2] &lt;p class=\"important\"&gt;이것은 중요한 단락입니다&lt;/p&gt;\nhtml |&gt; html_elements(\".important\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p class=\"important\"&gt;이것은 중요한 단락입니다&lt;/p&gt;\nhtml |&gt; html_elements(\"#first\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p id=\"first\"&gt;이것은 단락입니다&lt;/p&gt;\n\n또 다른 중요한 함수는 html_element()로, 항상 입력과 동일한 수의 출력을 반환합니다. 전체 문서에 적용하면 첫 번째 일치 항목을 제공합니다:\n\nhtml |&gt; html_element(\"p\")\n#&gt; {html_node}\n#&gt; &lt;p id=\"first\"&gt;\n\n일치하는 요소가 없는 선택자를 사용할 때 html_element()와 html_elements() 사이에는 중요한 차이점이 있습니다. html_elements()는 길이가 0인 벡터를 반환하는 반면, html_element()는 결측값을 반환합니다. 이것은 곧 중요해질 것입니다.\n\nhtml |&gt; html_elements(\"b\")\n#&gt; {xml_nodeset (0)}\nhtml |&gt; html_element(\"b\")\n#&gt; {xml_missing}\n#&gt; &lt;NA&gt;\n\n\n24.4.2 중첩 선택\n대부분의 경우 html_elements()와 html_element()를 함께 사용하게 되는데, 일반적으로 관측값이 될 요소를 식별하기 위해 html_elements()를 사용한 다음 변수가 될 요소를 찾기 위해 html_element()를 사용합니다. 간단한 예제를 사용하여 이를 실제로 살펴보겠습니다. 여기에는 스타워즈(StarWars)의 네 캐릭터에 대한 정보가 포함된 순서가 없는 목록(&lt;ul&gt;)이 있습니다:\n\nhtml &lt;- minimal_html(\"\n  &lt;ul&gt;\n    &lt;li&gt;&lt;b&gt;C-3PO&lt;/b&gt;는 &lt;span class='weight'&gt;167 kg&lt;/span&gt;인 &lt;i&gt;드로이드&lt;/i&gt;입니다&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R4-P17&lt;/b&gt;은 &lt;i&gt;드로이드&lt;/i&gt;입니다&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R2-D2&lt;/b&gt;는 &lt;span class='weight'&gt;96 kg&lt;/span&gt;인 &lt;i&gt;드로이드&lt;/i&gt;입니다&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;Yoda&lt;/b&gt;는 &lt;span class='weight'&gt;66 kg&lt;/span&gt;입니다&lt;/li&gt;\n  &lt;/ul&gt;\n\")\n\nhtml_elements()를 사용하여 각 요소가 서로 다른 캐릭터에 해당하는 벡터를 만들 수 있습니다:\n\ncharacters &lt;- html |&gt; html_elements(\"li\")\ncharacters\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;li&gt;\\n&lt;b&gt;C-3PO&lt;/b&gt;는 &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;인 &lt;i&gt;드로이드&lt;/i&gt;입니다 ...\n#&gt; [2] &lt;li&gt;\\n&lt;b&gt;R4-P17&lt;/b&gt;은 &lt;i&gt;드로이드&lt;/i&gt;입니다&lt;/li&gt;\n#&gt; [3] &lt;li&gt;\\n&lt;b&gt;R2-D2&lt;/b&gt;는 &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;인 &lt;i&gt;드로이드&lt;/i&gt;입니다&lt; ...\n#&gt; [4] &lt;li&gt;\\n&lt;b&gt;Yoda&lt;/b&gt;는 &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;입니다&lt;/li&gt;\n\n각 캐릭터의 이름을 추출하기 위해 html_element()를 사용합니다. html_elements()의 출력에 적용될 때 요소당 하나의 응답을 반환하는 것이 보장되기 때문입니다:\n\ncharacters |&gt; html_element(\"b\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;b&gt;C-3PO&lt;/b&gt;\n#&gt; [2] &lt;b&gt;R4-P17&lt;/b&gt;\n#&gt; [3] &lt;b&gt;R2-D2&lt;/b&gt;\n#&gt; [4] &lt;b&gt;Yoda&lt;/b&gt;\n\nhtml_element()와 html_elements()의 구별은 이름에 대해서는 중요하지 않지만 몸무게에 대해서는 중요합니다. 몸무게 &lt;span&gt;이 없더라도 각 캐릭터에 대해 하나의 몸무게를 얻고 싶습니다. 그것이 html_element()가 하는 일입니다:\n\ncharacters |&gt; html_element(\".weight\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;\n#&gt; [2] NA\n#&gt; [3] &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;\n#&gt; [4] &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\n\nhtml_elements()는 characters의 자식인 모든 몸무게 &lt;span&gt;을 찾습니다. 이들 중 세 개만 있으므로 이름과 몸무게 사이의 연결을 잃게 됩니다:\n\ncharacters |&gt; html_elements(\".weight\")\n#&gt; {xml_nodeset (3)}\n#&gt; [1] &lt;span class=\"weight\"&gt;167 kg&lt;/span&gt;\n#&gt; [2] &lt;span class=\"weight\"&gt;96 kg&lt;/span&gt;\n#&gt; [3] &lt;span class=\"weight\"&gt;66 kg&lt;/span&gt;\n\n이제 관심 있는 요소를 선택했으므로 텍스트 내용이나 일부 속성에서 데이터를 추출해야 합니다.\n\n24.4.3 텍스트와 속성\nhtml_text2()6는 HTML 요소의 일반 텍스트 내용을 추출합니다:\n\ncharacters |&gt; \n  html_element(\"b\") |&gt; \n  html_text2()\n#&gt; [1] \"C-3PO\"  \"R4-P17\" \"R2-D2\"  \"Yoda\"\n\ncharacters |&gt; \n  html_element(\".weight\") |&gt; \n  html_text2()\n#&gt; [1] \"167 kg\" NA       \"96 kg\"  \"66 kg\"\n\n모든 이스케이프가 자동으로 처리된다는 점에 유의하세요. HTML 이스케이프는 소스 HTML에서만 볼 수 있으며 rvest에서 반환된 데이터에서는 볼 수 없습니다.\nhtml_attr()는 속성에서 데이터를 추출합니다:\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Cat'&gt;고양이&lt;/a&gt;&lt;/p&gt;\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Dog'&gt;개&lt;/a&gt;&lt;/p&gt;\n\")\n\nhtml |&gt; \n  html_elements(\"p\") |&gt; \n  html_element(\"a\") |&gt; \n  html_attr(\"href\")\n#&gt; [1] \"https://en.wikipedia.org/wiki/Cat\" \"https://en.wikipedia.org/wiki/Dog\"\n\nhtml_attr()는 항상 문자열을 반환하므로 숫자나 날짜를 추출하는 경우 사후 처리를 좀 해야 합니다.\n\n24.4.4 표(Tables)\n운이 좋다면 데이터가 이미 HTML 표에 저장되어 있을 것이고, 단순히 그 표에서 읽어오기만 하면 될 것입니다. 브라우저에서 표를 인식하는 것은 대개 간단합니다: 행과 열의 직사각형 구조를 가질 것이며, Excel과 같은 도구에 복사해서 붙여넣을 수 있습니다.\nHTML 표는 4개의 주요 요소로 구성됩니다: &lt;table&gt;, &lt;tr&gt;(표 행), &lt;th&gt;(표 머리글) 및 &lt;td&gt;(표 데이터). 여기에 두 개의 열과 세 개의 행이 있는 간단한 HTML 표가 있습니다:\n\nhtml &lt;- minimal_html(\"\n  &lt;table class='mytable'&gt;\n    &lt;tr&gt;&lt;th&gt;x&lt;/th&gt;   &lt;th&gt;y&lt;/th&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;1.5&lt;/td&gt; &lt;td&gt;2.7&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;4.9&lt;/td&gt; &lt;td&gt;1.3&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;7.2&lt;/td&gt; &lt;td&gt;8.1&lt;/td&gt;&lt;/tr&gt;\n  &lt;/table&gt;\n\")\n\nrvest는 이런 종류의 데이터를 읽는 방법을 아는 함수인 html_table()을 제공합니다. 페이지에서 찾은 각 표에 대해 하나의 티블을 포함하는 리스트를 반환합니다. 추출하려는 표를 식별하기 위해 html_element()를 사용하세요:\n\nhtml |&gt; \n  html_element(\".mytable\") |&gt; \n  html_table()\n#&gt; # A tibble: 3 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   1.5   2.7\n#&gt; 2   4.9   1.3\n#&gt; 3   7.2   8.1\n\nx와 y가 자동으로 숫자로 변환된 것을 주목하세요. 이 자동 변환이 항상 작동하는 것은 아니므로 더 복잡한 시나리오에서는 convert = FALSE로 이를 끄고 직접 변환을 수행하고 싶을 수 있습니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#sec-css-selectors",
    "href": "webscraping.html#sec-css-selectors",
    "title": "24  웹 스크래핑",
    "section": "\n24.5 올바른 선택자 찾기",
    "text": "24.5 올바른 선택자 찾기\n데이터에 필요한 선택자를 파악하는 것이 일반적으로 문제의 가장 어려운 부분입니다. 구체적(즉, 관심 없는 것은 선택하지 않음)이면서 민감한(즉, 관심 있는 모든 것을 선택함) 선택자를 찾기 위해 종종 실험을 좀 해야 합니다. 많은 시행착오는 프로세스의 정상적인 부분입니다! 이 프로세스를 돕기 위해 사용할 수 있는 두 가지 주요 도구가 있습니다: SelectorGadget과 브라우저의 개발자 도구입니다.\nSelectorGadget은 제공한 긍정적 예제와 부정적 예제를 기반으로 CSS 선택자를 자동으로 생성하는 자바스크립트 북마클릿입니다. 항상 작동하는 것은 아니지만 작동할 때는 마법 같습니다! https://rvest.tidyverse.org/articles/selectorgadget.html을 읽거나 Mine의 비디오 https://www.youtube.com/watch?v=PetWV5g1Xsc를 시청하여 SelectorGadget을 설치하고 사용하는 방법을 배울 수 있습니다.\n모든 현대 브라우저에는 개발자를 위한 툴킷이 함께 제공되지만, 일반 브라우저가 아니더라도 크롬(Chrome)을 권장합니다: 웹 개발자 도구가 가장 뛰어나고 즉시 사용할 수 있기 때문입니다. 페이지의 요소를 마우스 오른쪽 버튼으로 클릭하고 검사(Inspect)를 클릭합니다. 그러면 방금 클릭한 요소를 중심으로 전체 HTML 페이지의 확장 가능한 뷰가 열립니다. 이를 사용하여 페이지를 탐색하고 어떤 선택자가 작동할지 감을 잡을 수 있습니다. class와 id 속성은 종종 페이지의 시각적 구조를 형성하는 데 사용되므로 찾고 있는 데이터를 추출하기 위한 좋은 도구가 되므로 특히 주의를 기울이세요.\n요소(Elements) 뷰 내에서 요소를 마우스 오른쪽 버튼으로 클릭하고 Copy as Selector를 선택하여 관심 있는 요소를 고유하게 식별할 선택자를 생성할 수도 있습니다.\nSelectorGadget이나 크롬 개발자 도구가 이해할 수 없는 CSS 선택자를 생성했다면 CSS 선택자를 평범한 영어로 번역해주는 Selectors Explained를 시도해 보세요. 이 작업을 자주 하게 된다면 일반적으로 CSS 선택자에 대해 더 많이 배우고 싶을 것입니다. 재미있는 CSS dinner 튜토리얼부터 시작하여 MDN 웹 문서를 참조하는 것을 추천합니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#종합하기",
    "href": "webscraping.html#종합하기",
    "title": "24  웹 스크래핑",
    "section": "\n24.6 종합하기",
    "text": "24.6 종합하기\n웹사이트 몇 군데를 스크래핑하기 위해 이 모든 것을 종합해 봅시다. 이 예제들이 실행할 때 더 이상 작동하지 않을 위험이 있습니다. 이것이 웹 스크래핑의 근본적인 과제입니다. 사이트 구조가 변경되면 스크래핑 코드를 변경해야 합니다.\n\n24.6.1 스타워즈(StarWars)\nrvest는 vignette(\"starwars\")에 매우 간단한 예제를 포함하고 있습니다. 이것은 최소한의 HTML을 가진 간단한 페이지이므로 시작하기에 좋은 곳입니다. 지금 해당 페이지로 이동하여 “요소 검사”를 사용하여 스타워즈 영화 제목인 제목 중 하나를 검사해 보시길 권장합니다. 키보드나 마우스를 사용하여 HTML 계층 구조를 탐색하고 각 영화에서 사용되는 공유 구조에 대한 감을 잡을 수 있는지 확인해 보세요.\n각 영화가 다음과 같은 공유 구조를 가지고 있음을 볼 수 있을 것입니다:\n&lt;section&gt;\n  &lt;h2 data-id=\"1\"&gt;The Phantom Menace&lt;/h2&gt;\n  &lt;p&gt;Released: 1999-05-19&lt;/p&gt;\n  &lt;p&gt;Director: &lt;span class=\"director\"&gt;George Lucas&lt;/span&gt;&lt;/p&gt;\n  \n  &lt;div class=\"crawl\"&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n  &lt;/div&gt;\n&lt;/section&gt;\n우리의 목표는 이 데이터를 title, year, director, intro 변수를 가진 7행 데이터 프레임으로 변환하는 것입니다. 먼저 HTML을 읽고 모든 &lt;section&gt; 요소를 추출하는 것으로 시작하겠습니다:\n\nurl &lt;- \"https://rvest.tidyverse.org/articles/starwars.html\"\nhtml &lt;- read_html(url)\n\nsection &lt;- html |&gt; html_elements(\"section\")\nsection\n#&gt; {xml_nodeset (7)}\n#&gt; [1] &lt;section&gt;&lt;h2 data-id=\"1\"&gt;\\nThe Phantom Menace\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [2] &lt;section&gt;&lt;h2 data-id=\"2\"&gt;\\nAttack of the Clones\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: ...\n#&gt; [3] &lt;section&gt;&lt;h2 data-id=\"3\"&gt;\\nRevenge of the Sith\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased:  ...\n#&gt; [4] &lt;section&gt;&lt;h2 data-id=\"4\"&gt;\\nA New Hope\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1977-05-2 ...\n#&gt; [5] &lt;section&gt;&lt;h2 data-id=\"5\"&gt;\\nThe Empire Strikes Back\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleas ...\n#&gt; [6] &lt;section&gt;&lt;h2 data-id=\"6\"&gt;\\nReturn of the Jedi\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [7] &lt;section&gt;&lt;h2 data-id=\"7\"&gt;\\nThe Force Awakens\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 20 ...\n\n이 코드는 해당 페이지에서 찾은 7편의 영화와 일치하는 7개의 요소를 검색하므로 section을 선택자로 사용하는 것이 좋음을 시사합니다. 데이터는 항상 텍스트에서 발견되므로 개별 요소를 추출하는 것은 간단합니다. 올바른 선택자를 찾기만 하면 됩니다:\n\nsection |&gt; html_element(\"h2\") |&gt; html_text2()\n#&gt; [1] \"The Phantom Menace\"      \"Attack of the Clones\"   \n#&gt; [3] \"Revenge of the Sith\"     \"A New Hope\"             \n#&gt; [5] \"The Empire Strikes Back\" \"Return of the Jedi\"     \n#&gt; [7] \"The Force Awakens\"\n\nsection |&gt; html_element(\".director\") |&gt; html_text2()\n#&gt; [1] \"George Lucas\"     \"George Lucas\"     \"George Lucas\"    \n#&gt; [4] \"George Lucas\"     \"Irvin Kershner\"   \"Richard Marquand\"\n#&gt; [7] \"J. J. Abrams\"\n\n각 구성 요소에 대해 이 작업을 완료하면 모든 결과를 티블로 묶을 수 있습니다:\n\ntibble(\n  title = section |&gt; \n    html_element(\"h2\") |&gt; \n    html_text2(),\n  released = section |&gt; \n    html_element(\"p\") |&gt; \n    html_text2() |&gt; \n    str_remove(\"Released: \") |&gt; \n    parse_date(),\n  director = section |&gt; \n    html_element(\".director\") |&gt; \n    html_text2(),\n  intro = section |&gt; \n    html_element(\".crawl\") |&gt; \n    html_text2()\n)\n#&gt; # A tibble: 7 × 4\n#&gt;   title                   released   director         intro                  \n#&gt;   &lt;chr&gt;                   &lt;date&gt;     &lt;chr&gt;            &lt;chr&gt;                  \n#&gt; 1 The Phantom Menace      1999-05-19 George Lucas     \"Turmoil has engulfed …\n#&gt; 2 Attack of the Clones    2002-05-16 George Lucas     \"There is unrest in th…\n#&gt; 3 Revenge of the Sith     2005-05-19 George Lucas     \"War! The Republic is …\n#&gt; 4 A New Hope              1977-05-25 George Lucas     \"It is a period of civ…\n#&gt; 5 The Empire Strikes Back 1980-05-17 Irvin Kershner   \"It is a dark time for…\n#&gt; 6 Return of the Jedi      1983-05-25 Richard Marquand \"Luke Skywalker has re…\n#&gt; # ℹ 1 more row\n\n나중에 분석에서 쉽게 사용할 수 있는 변수를 얻기 위해 released에 대해 처리를 조금 더 했습니다.\n\n24.6.2 IMDB 인기 영화\n다음 과제로 인터넷 영화 데이터베이스(IMDb)에서 상위 250개 영화를 추출하는 조금 더 까다로운 작업을 처리해 보겠습니다. 우리가 이 장을 썼을 때 페이지는 Figure 24.1 처럼 보였습니다.\n\n\n\n\n\n\n\nFigure 24.1: 2022-12-05에 찍은 IMDb 상위 영화 웹페이지의 스크린샷.\n\n\n\n\n이 데이터는 명확한 표 구조를 가지고 있으므로 html_table()로 시작할 가치가 있습니다:\n\nurl &lt;- \"https://web.archive.org/web/20220201012049/https://www.imdb.com/chart/top/\"\nhtml &lt;- read_html(url)\n\ntable &lt;- html |&gt; \n  html_element(\"table\") |&gt; \n  html_table()\ntable\n#&gt; # A tibble: 250 × 5\n#&gt;   ``    `Rank & Title`                    `IMDb Rating` `Your Rating`   ``   \n#&gt;   &lt;lgl&gt; &lt;chr&gt;                                     &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt;\n#&gt; 1 NA    \"1.\\n      The Shawshank Redempt…           9.2 \"12345678910\\n… NA   \n#&gt; 2 NA    \"2.\\n      The Godfather\\n      …           9.1 \"12345678910\\n… NA   \n#&gt; 3 NA    \"3.\\n      The Godfather: Part I…           9   \"12345678910\\n… NA   \n#&gt; 4 NA    \"4.\\n      The Dark Knight\\n    …           9   \"12345678910\\n… NA   \n#&gt; 5 NA    \"5.\\n      12 Angry Men\\n       …           8.9 \"12345678910\\n… NA   \n#&gt; 6 NA    \"6.\\n      Schindler's List\\n   …           8.9 \"12345678910\\n… NA   \n#&gt; # ℹ 244 more rows\n\n여기에는 몇 개의 빈 열이 포함되어 있지만 전반적으로 표의 정보를 잘 캡처합니다. 그러나 사용하기 쉽게 만들려면 처리를 좀 더 해야 합니다. 먼저 열의 이름을 작업하기 쉽게 바꾸고 순위(rank)와 제목(title)에 있는 불필요한 공백을 제거하겠습니다. 한 단계에서 이 두 열만 선택하고 이름을 바꾸기 위해 select()(rename() 대신)를 사용하여 이 작업을 수행할 것입니다. 그런 다음 줄바꿈과 추가 공백을 제거한 다음, separate_wider_regex()(Section 15.3.4 에서 배움)를 적용하여 제목, 연도 및 순위를 자체 변수로 뽑아내겠습니다.\n\nratings &lt;- table |&gt;\n  select(\n    rank_title_year = `Rank & Title`,\n    rating = `IMDb Rating`\n  ) |&gt; \n  mutate(\n    rank_title_year = str_replace_all(rank_title_year, \"\\n +\", \" \")\n  ) |&gt; \n  separate_wider_regex(\n    rank_title_year,\n    patterns = c(\n      rank = \"\\\\d+\", \"\\\\. \",\n      title = \".+\", \" +\\\\(\",\n      year = \"\\\\d+\", \"\\\\)\"\n    )\n  )\nratings\n#&gt; # A tibble: 250 × 4\n#&gt;   rank  title                    year  rating\n#&gt;   &lt;chr&gt; &lt;chr&gt;                    &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 1     The Shawshank Redemption 1994     9.2\n#&gt; 2 2     The Godfather            1972     9.1\n#&gt; 3 3     The Godfather: Part II   1974     9  \n#&gt; 4 4     The Dark Knight          2008     9  \n#&gt; 5 5     12 Angry Men             1957     8.9\n#&gt; 6 6     Schindler's List         1993     8.9\n#&gt; # ℹ 244 more rows\n\n대부분의 데이터가 표 셀에서 나오는 경우에도 여전히 원시 HTML을 살펴볼 가치가 있습니다. 그렇게 하면 속성 중 하나를 사용하여 약간의 추가 데이터를 더할 수 있다는 것을 발견하게 될 것입니다. 이것이 페이지 소스를 탐색하는 데 시간을 조금 투자할 가치가 있는 이유 중 하나입니다. 추가 데이터를 찾거나 약간 더 쉬운 파싱 경로를 찾을 수도 있습니다.\n\nhtml |&gt; \n  html_elements(\"td strong\") |&gt; \n  head() |&gt; \n  html_attr(\"title\")\n#&gt; [1] \"9.2 based on 2,536,415 user ratings\"\n#&gt; [2] \"9.1 based on 1,745,675 user ratings\"\n#&gt; [3] \"9.0 based on 1,211,032 user ratings\"\n#&gt; [4] \"9.0 based on 2,486,931 user ratings\"\n#&gt; [5] \"8.9 based on 749,563 user ratings\"  \n#&gt; [6] \"8.9 based on 1,295,705 user ratings\"\n\n이를 표 형식의 데이터와 결합하고 다시 separate_wider_regex()를 적용하여 관심 있는 데이터 조각을 추출할 수 있습니다:\n\nratings |&gt;\n  mutate(\n    rating_n = html |&gt; html_elements(\"td strong\") |&gt; html_attr(\"title\")\n  ) |&gt; \n  separate_wider_regex(\n    rating_n,\n    patterns = c(\n      \"[0-9.]+ based on \",\n      number = \"[0-9,]+\",\n      \" user ratings\"\n    )\n  ) |&gt; \n  mutate(\n    number = parse_number(number)\n  )\n#&gt; # A tibble: 250 × 5\n#&gt;   rank  title                    year  rating  number\n#&gt;   &lt;chr&gt; &lt;chr&gt;                    &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 1     The Shawshank Redemption 1994     9.2 2536415\n#&gt; 2 2     The Godfather            1972     9.1 1745675\n#&gt; 3 3     The Godfather: Part II   1974     9   1211032\n#&gt; 4 4     The Dark Knight          2008     9   2486931\n#&gt; 5 5     12 Angry Men             1957     8.9  749563\n#&gt; 6 6     Schindler's List         1993     8.9 1295705\n#&gt; # ℹ 244 more rows",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#동적-사이트",
    "href": "webscraping.html#동적-사이트",
    "title": "24  웹 스크래핑",
    "section": "\n24.7 동적 사이트",
    "text": "24.7 동적 사이트\n지금까지는 html_elements()가 브라우저에서 보는 내용을 반환하는 웹사이트에 집중하여 반환된 내용을 파싱하는 방법과 해당 정보를 깔끔한 데이터 프레임으로 구성하는 방법을 논의했습니다. 그러나 때때로 html_elements()와 친구들이 브라우저에서 보는 것과 전혀 다른 내용을 반환하는 사이트를 만나게 될 것입니다. 많은 경우 자바스크립트로 페이지 내용을 동적으로 생성하는 웹사이트를 스크래핑하려고 하기 때문입니다. rvest는 원시 HTML을 다운로드하고 자바스크립트를 실행하지 않기 때문에 현재는 이런 방식이 작동하지 않습니다.\n이런 유형의 사이트를 스크래핑하는 것은 여전히 가능하지만 rvest는 모든 자바스크립트 실행을 포함하여 웹 브라우저를 완전히 시뮬레이션하는 더 비용이 많이 드는 프로세스를 사용해야 합니다. 이 기능은 이 글을 쓰는 시점에는 사용할 수 없지만 우리가 적극적으로 작업 중인 기능이며 여러분이 이 글을 읽을 때쯤이면 사용할 수 있을 것입니다. 배경에서 실제로 크롬(Chrome) 브라우저를 실행하는 chromote 패키지를 사용하며, 사람이 텍스트를 입력하고 버튼을 클릭하는 것과 같이 사이트와 상호 작용할 수 있는 추가 도구를 제공합니다. 자세한 내용은 rvest 웹사이트를 확인하세요.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#요약",
    "href": "webscraping.html#요약",
    "title": "24  웹 스크래핑",
    "section": "\n24.8 요약",
    "text": "24.8 요약\n이 장에서는 웹페이지에서 데이터를 스크래핑하는 이유와 이유가 아닌 것, 그리고 방법에 대해 배웠습니다. 먼저 HTML의 기초와 특정 요소를 참조하기 위해 CSS 선택자를 사용하는 방법을 배웠고, 그런 다음 rvest 패키지를 사용하여 HTML에서 R로 데이터를 가져오는 방법을 배웠습니다. 그런 다음 두 가지 사례 연구로 웹 스크래핑을 시연했습니다: rvest 패키지 웹사이트에서 스타워즈 영화에 대한 데이터를 스크래핑하는 간단한 시나리오와 IMDB에서 상위 250개 영화를 스크래핑하는 더 복잡한 시나리오입니다.\n웹에서 데이터를 스크래핑하는 기술적 세부 사항은 특히 사이트를 다룰 때 복잡할 수 있지만, 법적 및 윤리적 고려 사항은 훨씬 더 복잡할 수 있습니다. 데이터를 스크래핑하기 전에 이 두 가지 모두에 대해 스스로 교육하는 것이 중요합니다.\n이로써 데이터가 있는 곳(스프레드시트, 데이터베이스, JSON 파일 및 웹사이트)에서 R의 깔끔한 형태로 데이터를 가져오는 기술을 배운 책의 가져오기(import) 파트가 끝납니다. 이제 새로운 주제인 프로그래밍 언어로서의 R을 최대한 활용하는 것으로 시선을 돌릴 때입니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "webscraping.html#footnotes",
    "href": "webscraping.html#footnotes",
    "title": "24  웹 스크래핑",
    "section": "",
    "text": "그리고 많은 인기 있는 API에는 이미 이를 래핑하는 CRAN 패키지가 있으므로 먼저 조사를 조금 해보세요!↩︎\n분명히 우리는 변호사가 아니며 이것은 법률 자문이 아닙니다. 하지만 이 주제에 대해 많은 것을 읽은 후 우리가 줄 수 있는 최선의 요약입니다.↩︎\nOkCupid 연구에 대한 기사 중 하나가 Wired에 게시되었습니다: https://www.wired.com/2016/05/okcupid-study-reveals-perils-big-data-science.↩︎\n여러 태그( &lt;p&gt; 및 &lt;li&gt; 포함)는 종료 태그가 필요하지 않지만 HTML 구조를 보기가 조금 더 쉽기 때문에 포함하는 것이 가장 좋다고 생각합니다.↩︎\n이 클래스는 xml2 패키지에서 가져옵니다. xml2는 rvest가 기반으로 하는 저수준 패키지입니다.↩︎\nrvest는 html_text()도 제공하지만 중첩된 HTML을 텍스트로 변환하는 작업을 더 잘 수행하므로 거의 항상 html_text2()를 사용해야 합니다.↩︎",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>웹 스크래핑</span>"
    ]
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "프로그램 (Program)",
    "section": "",
    "text": "책의 이 파트에서는 프로그래밍 기술을 향상시킬 것입니다. 프로그램은 모든 데이터 과학 작업을 위해 필요한 교차적인 기술입니다. 데이터 과학을 수행하려면 반드시 컴퓨터를 사용해야 합니다. 머릿속으로만 할 수 없으며, 연필과 종이로도 할 수 없습니다.\n\n\n\n\n\n\n\nFigure 1: 프로그래밍은 다른 모든 구성 요소들이 헤엄치는 물과 같습니다.\n\n\n\n\n프로그래밍은 코드를 생성하며, 코드는 소통의 도구입니다. 명백하게 코드는 컴퓨터에게 무엇을 하기를 원하는지 알려줍니다. 하지만 코드는 다른 사람들에게도 그 의미를 전달합니다. 수행하는 모든 프로젝트는 근본적으로 협력적이기 때문에 코드를 소통의 수단으로 생각하는 것이 중요합니다. 다른 사람들과 함께 작업하지 않더라도, 여러분은 분명히 미래의 자신과 함께 작업하게 될 것입니다! 명확한 코드를 작성하는 것은 다른 사람들(미래의 자신 포함)이 여러분이 왜 그런 방식으로 분석을 처리했는지 이해할 수 있게 하므로 중요합니다. 즉, 프로그래밍을 더 잘하게 된다는 것은 소통을 더 잘하게 된다는 것을 의미하기도 합니다. 시간이 흐르면서 여러분의 코드가 작성하기 쉬워질 뿐만 아니라 다른 사람들이 읽기에도 쉬워지기를 바랍니다.\n이어지는 세 장에서 프로그래밍 기술을 향상시키기 위한 기술들을 배우게 됩니다:\n\n복사해서 붙여넣기는 강력한 도구이지만, 두 번 이상 하는 것은 피해야 합니다. 코드에서 자신을 반복하는 것은 오류와 불일치를 쉽게 초래할 수 있기 때문에 위험합니다. 대신 25  함수 (Functions) 에서는 반복되는 tidyverse 코드를 추출하여 쉽게 재사용할 수 있게 해주는 함수(functions) 를 작성하는 방법을 배웁니다.\n함수는 반복되는 코드를 추출하지만, 종종 서로 다른 입력에 대해 동일한 작업을 반복해야 할 때가 있습니다. 유사한 작업을 반복해서 수행할 수 있게 해주는 반복(iteration) 도구가 필요합니다. 이러한 도구에는 26  반복 에서 배울 for 루프와 함수형 프로그래밍이 포함됩니다.\n다른 사람들이 작성한 코드를 더 많이 읽다 보면, tidyverse를 사용하지 않는 코드를 더 많이 보게 될 것입니다. 27  기본 R 필드 가이드 에서는 야생에서 보게 될 가장 중요한 기본(base) R 함수 중 일부를 배웁니다.\n\n이 장들의 목표는 데이터 과학을 위해 필요한 프로그래밍의 최소한을 가르치는 것입니다. 여기서의 내용을 마스터했다면, 프로그래밍 기술에 계속 투자하는 것을 강력히 추천합니다. 도움이 될 만한 두 권의 책을 썼습니다. Garrett Grolemund가 쓴 Hands on Programming with R은 프로그래밍 언어로서의 R에 대한 입문서이며, R이 첫 번째 프로그래밍 언어라면 시작하기에 훌륭한 장소입니다. Hadley Wickham이 쓴 Advanced R은 프로그래밍 언어인 R의 세부 사항을 깊이 파고듭니다. 기존 프로그래밍 경험이 있다면 시작하기에 훌륭한 장소이며, 이 장들의 아이디어를 내면화한 후의 훌륭한 다음 단계입니다.",
    "crumbs": [
      "프로그램 (Program)"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "25  함수 (Functions)",
    "section": "",
    "text": "25.1 소개\n데이터 과학자로서 영역을 넓히는 가장 좋은 방법 중 하나는 함수를 작성하는 것입니다. 함수를 사용하면 복사해서 붙여넣기보다 더 강력하고 일반적인 방식으로 일반적인 작업을 자동화할 수 있습니다. 함수를 작성하는 것은 복사해서 붙여넣기보다 네 가지 큰 장점이 있습니다:\n좋은 경험 법칙은 코드 블록을 두 번 이상 복사해서 붙여넣었을 때(즉, 동일한 코드의 사본이 세 개 있을 때) 함수 작성을 고려하는 것입니다. 이 장에서는 유용한 세 가지 유형의 함수에 대해 배웁니다:\n이러한 각 섹션에는 여러분이 보는 패턴을 일반화하는 데 도움이 되는 많은 예제가 포함되어 있습니다. 이 예제들은 트위터 사용자들의 도움 없이는 불가능했을 것이며, 댓글에 있는 링크를 따라가서 원래의 영감을 확인해 보기를 권장합니다. 또한 일반 함수와 플롯 함수에 대한 원래의 동기 부여 트윗을 읽어보면 더 많은 함수를 볼 수 있습니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>함수 (Functions)</span>"
    ]
  },
  {
    "objectID": "functions.html#소개",
    "href": "functions.html#소개",
    "title": "25  함수 (Functions)",
    "section": "",
    "text": "함수에 기억하기 쉬운 이름을 지정하여 코드를 더 쉽게 이해할 수 있게 할 수 있습니다.\n요구 사항이 변경되면 여러 곳이 아닌 한 곳에서만 코드를 업데이트하면 됩니다.\n복사해서 붙여넣을 때 발생할 수 있는 우발적인 실수(예: 한 곳에서는 변수 이름을 업데이트했지만 다른 곳에서는 업데이트하지 않음)를 없앨 수 있습니다.\n프로젝트 간에 작업을 재사용하기가 쉬워져 시간이 지남에 따라 생산성이 향상됩니다.\n\n\n\n벡터 함수: 하나 이상의 벡터를 입력으로 받아 벡터를 출력으로 반환합니다.\n데이터 프레임 함수: 데이터 프레임을 입력으로 받아 데이터 프레임을 출력으로 반환합니다.\n플롯 함수: 데이터 프레임을 입력으로 받아 플롯을 출력으로 반환합니다.\n\n\n\n25.1.1 선수 지식\ntidyverse의 다양한 함수들을 정리해 보겠습니다. 또한 함수와 함께 사용할 친숙한 데이터 소스로 nycflights13을 사용할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2\nlibrary(nycflights13)",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>함수 (Functions)</span>"
    ]
  },
  {
    "objectID": "functions.html#벡터-함수",
    "href": "functions.html#벡터-함수",
    "title": "25  함수 (Functions)",
    "section": "\n25.2 벡터 함수",
    "text": "25.2 벡터 함수\n벡터 함수로 시작하겠습니다: 하나 이상의 벡터를 받아 벡터 결과를 반환하는 함수입니다. 예를 들어, 이 코드를 보세요. 무엇을 하는 코드일까요?\n\ndf &lt;- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |&gt; mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(a, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(b, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a       b     c     d\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339  0.387  0.291 0    \n#&gt; 2 0.880 -0.613  0.611 0.557\n#&gt; 3 0     -0.0833 1     0.752\n#&gt; 4 0.795 -0.0822 0     1    \n#&gt; 5 1     -0.0952 0.580 0.394\n\n이것이 각 열의 범위를 0에서 1로 조정한다는 것을 알아낼 수 있을 것입니다. 하지만 실수를 발견했나요? Hadley가 이 코드를 작성할 때 복사해서 붙여넣는 과정에서 오류를 범했고 a를 b로 바꾸는 것을 잊었습니다. 이런 유형의 실수를 방지하는 것이 함수 작성법을 배워야 하는 아주 좋은 이유 중 하나입니다.\n\n25.2.1 함수 작성하기\n함수를 작성하려면 먼저 반복되는 코드를 분석하여 어떤 부분이 상수이고 어떤 부분이 변하는지 파악해야 합니다. 위의 코드를 가져와 mutate() 밖으로 꺼내면, 각 반복이 이제 한 줄이 되므로 패턴을 보기가 조금 더 쉽습니다:\n\n(a - min(a, na.rm = TRUE)) / (max(a, na.rm = TRUE) - min(a, na.rm = TRUE))\n(b - min(b, na.rm = TRUE)) / (max(b, na.rm = TRUE) - min(b, na.rm = TRUE))\n(c - min(c, na.rm = TRUE)) / (max(c, na.rm = TRUE) - min(c, na.rm = TRUE))\n(d - min(d, na.rm = TRUE)) / (max(d, na.rm = TRUE) - min(d, na.rm = TRUE))  \n\n이것을 좀 더 명확하게 하기 위해 변하는 부분을 █로 바꿀 수 있습니다:\n\n(█ - min(█, na.rm = TRUE)) / (max(█, na.rm = TRUE) - min(█, na.rm = TRUE))\n\n이것을 함수로 만들려면 세 가지가 필요합니다:\n\n이름(name). 여기서는 이 함수가 벡터를 0과 1 사이로 재조정하므로 rescale01을 사용할 것입니다.\n인수(arguments). 인수는 호출마다 변하는 것이며, 위의 분석에 따르면 하나만 있으면 됩니다. 수치형 벡터의 관례적인 이름이므로 x라고 부르겠습니다.\n본문(body). 본문은 모든 호출에서 반복되는 코드입니다.\n\n그런 다음 템플릿을 따라 함수를 만듭니다:\n\nname &lt;- function(arguments) {\n  body\n}\n\n이 경우 다음과 같이 됩니다:\n\nrescale01 &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\n이 시점에서 몇 가지 간단한 입력으로 테스트하여 로직을 올바르게 캡처했는지 확인할 수 있습니다:\n\nrescale01(c(-10, 0, 10))\n#&gt; [1] 0.0 0.5 1.0\nrescale01(c(1, 2, 3, NA, 5))\n#&gt; [1] 0.00 0.25 0.50   NA 1.00\n\n그런 다음 mutate() 호출을 다음과 같이 다시 쓸 수 있습니다:\n\ndf |&gt; mutate(\n  a = rescale01(a),\n  b = rescale01(b),\n  c = rescale01(c),\n  d = rescale01(d),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339 1     0.291 0    \n#&gt; 2 0.880 0     0.611 0.557\n#&gt; 3 0     0.530 1     0.752\n#&gt; 4 0.795 0.531 0     1    \n#&gt; 5 1     0.518 0.580 0.394\n\n(Chapter 26 에서는 across()를 사용하여 중복을 더욱 줄여 df |&gt; mutate(across(a:d, rescale01))만 있으면 되도록 하는 방법을 배울 것입니다).\n\n25.2.2 함수 개선하기\nrescale01() 함수가 불필요한 작업을 수행한다는 것을 알 수 있습니다. min()을 두 번, max()를 한 번 계산하는 대신 range()를 사용하여 한 단계로 최소값과 최대값을 모두 계산할 수 있습니다:\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\n또는 무한대 값이 포함된 벡터에서 이 함수를 시도해 볼 수도 있습니다:\n\nx &lt;- c(1:10, Inf)\nrescale01(x)\n#&gt;  [1]   0   0   0   0   0   0   0   0   0   0 NaN\n\n그 결과는 그리 유용하지 않으므로 range()에 무한대 값을 무시하도록 요청할 수 있습니다:\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE, finite = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nrescale01(x)\n#&gt;  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n#&gt;  [8] 0.7777778 0.8888889 1.0000000       Inf\n\n이러한 변경 사항은 함수의 중요한 이점을 보여줍니다: 반복되는 코드를 함수로 옮겼기 때문에 한 곳에서만 변경하면 됩니다.\n\n25.2.3 Mutate 함수\n이제 함수의 기본 개념을 알았으니 다양한 예제를 살펴보겠습니다. “mutate” 함수, 즉 입력과 길이가 같은 출력을 반환하므로 mutate() 및 filter() 내부에서 잘 작동하는 함수부터 살펴보겠습니다.\nrescale01()의 간단한 변형부터 시작하겠습니다. 벡터의 평균이 0이고 표준 편차가 1이 되도록 재조정하는 Z-점수를 계산하고 싶을 수 있습니다:\n\nz_score &lt;- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\n또는 간단한 case_when()을 감싸서 유용한 이름을 지정하고 싶을 수도 있습니다. 예를 들어, 이 clamp() 함수는 벡터의 모든 값이 최소값과 최대값 사이에 있도록 합니다:\n\nclamp &lt;- function(x, min, max) {\n  case_when(\n    x &lt; min ~ min,\n    x &gt; max ~ max,\n    .default = x\n  )\n}\n\nclamp(1:10, min = 3, max = 7)\n#&gt;  [1] 3 3 3 4 5 6 7 7 7 7\n\n물론 함수가 수치형 변수하고만 작업해야 하는 것은 아닙니다. 반복되는 문자열 조작을 수행하고 싶을 수도 있습니다. 첫 글자를 대문자로 만들고 싶을 수 있습니다:\n\nfirst_upper &lt;- function(x) {\n  str_sub(x, 1, 1) &lt;- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nfirst_upper(\"hello\")\n#&gt; [1] \"Hello\"\n\n또는 문자열을 숫자로 변환하기 전에 퍼센트 기호, 쉼표, 달러 기호를 제거하고 싶을 수도 있습니다:\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nclean_number &lt;- function(x) {\n  is_pct &lt;- str_detect(x, \"%\")\n  num &lt;- x |&gt; \n    str_remove_all(\"%\") |&gt; \n    str_remove_all(\",\") |&gt; \n    str_remove_all(fixed(\"$\")) |&gt; \n    as.numeric()\n  if_else(is_pct, num / 100, num)\n}\n\nclean_number(\"$12,300\")\n#&gt; [1] 12300\nclean_number(\"45%\")\n#&gt; [1] 0.45\n\n때때로 함수는 하나의 데이터 분석 단계에 매우 특화될 수 있습니다. 예를 들어, 결측값을 997, 998, 999로 기록하는 변수가 많은 경우 이를 NA로 바꾸는 함수를 작성하고 싶을 수 있습니다:\n\nfix_na &lt;- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\n단일 벡터를 취하는 예제에 집중했는데, 이것이 가장 일반적이라고 생각하기 때문입니다. 하지만 함수가 여러 벡터 입력을 받지 못할 이유는 없습니다.\n\n25.2.4 요약 함수\n벡터 함수의 또 다른 중요한 제품군은 요약 함수, 즉 summarize()에서 사용할 단일 값을 반환하는 함수입니다. 때로는 기본 인수 한두 개를 설정하는 것만으로도 충분할 수 있습니다:\n\ncommas &lt;- function(x) {\n  str_flatten(x, collapse = \", \", last = \" and \")\n}\n\ncommas(c(\"cat\", \"dog\", \"pigeon\"))\n#&gt; [1] \"cat, dog and pigeon\"\n\n또는 표준 편차를 평균으로 나누는 변동 계수와 같은 간단한 계산을 감쌀 수도 있습니다:\n\ncv &lt;- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n#&gt; [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n#&gt; [1] 0.5652554\n\n또는 기억하기 쉬운 이름을 지정하여 일반적인 패턴을 기억하기 쉽게 만들고 싶을 수도 있습니다:\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nn_missing &lt;- function(x) {\n  sum(is.na(x))\n} \n\n여러 벡터 입력을 받는 함수를 작성할 수도 있습니다. 예를 들어, 모델 예측과 실제 값을 비교하는 데 도움이 되는 평균 절대 백분율 오차(MAPE)를 계산하고 싶을 수 있습니다:\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nmape &lt;- function(actual, predicted) {\n  sum(abs((actual - predicted) / actual)) / length(actual)\n}\n\n\n\n\n\n\n\nNoteRStudio\n\n\n\n함수 작성을 시작하면 매우 유용한 두 가지 RStudio 단축키가 있습니다:\n\n작성한 함수의 정의를 찾으려면 함수 이름에 커서를 놓고 F2를 누르세요.\n함수로 빠르게 이동하려면 Ctrl + .을 눌러 퍼지 파일 및 함수 찾기를 열고 함수 이름의 처음 몇 글자를 입력하세요. 파일, Quarto 섹션 등으로 이동할 수도 있어 매우 편리한 탐색 도구입니다.\n\n\n\n\n25.2.5 연습문제\n\n\n다음 코드 조각들을 함수로 바꾸는 연습을 해보세요. 각 함수가 무엇을 하는지 생각해 보세요. 이름을 무엇으로 짓겠습니까? 인수가 몇 개 필요합니까?\n\nmean(is.na(x))\nmean(is.na(y))\nmean(is.na(z))\n\nx / sum(x, na.rm = TRUE)\ny / sum(y, na.rm = TRUE)\nz / sum(z, na.rm = TRUE)\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n\nrescale01()의 두 번째 변형에서는 무한대 값이 변경되지 않은 상태로 남습니다. -Inf는 0으로, Inf는 1로 매핑되도록 rescale01()을 다시 작성할 수 있습니까?\n생년월일 벡터가 주어지면 나이(년)를 계산하는 함수를 작성하세요.\n수치형 벡터의 분산과 왜도(skewness)를 계산하는 자신만의 함수를 작성하세요. 위키피디아 등에서 정의를 찾아볼 수 있습니다.\n동일한 길이의 두 벡터를 받아 두 벡터 모두에 NA가 있는 위치의 수를 반환하는 요약 함수 both_na()를 작성하세요.\n\n설명서를 읽고 다음 함수들이 무엇을 하는지 파악하세요. 매우 짧음에도 불구하고 왜 유용할까요?\n\nis_directory &lt;- function(x) {\n  file.info(x)$isdir\n}\nis_readable &lt;- function(x) {\n  file.access(x, 4) == 0\n}",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>함수 (Functions)</span>"
    ]
  },
  {
    "objectID": "functions.html#데이터-프레임-함수",
    "href": "functions.html#데이터-프레임-함수",
    "title": "25  함수 (Functions)",
    "section": "\n25.3 데이터 프레임 함수",
    "text": "25.3 데이터 프레임 함수\n벡터 함수는 dplyr 동사 내에서 반복되는 코드를 추출하는 데 유용합니다. 하지만 동사 자체를 반복하는 경우도 많으며, 특히 대규모 파이프라인 내에서 그렇습니다. 여러 동사를 여러 번 복사해서 붙여넣고 있다는 것을 알게 되면 데이터 프레임 함수 작성을 고려해 볼 수 있습니다. 데이터 프레임 함수는 dplyr 동사처럼 작동합니다: 데이터 프레임을 첫 번째 인수로 받고, 무엇을 할지 알려주는 추가 인수를 받고, 데이터 프레임이나 벡터를 반환합니다.\ndplyr 동사를 사용하는 함수를 작성할 수 있도록 하기 위해 먼저 간접 참조(indirection)의 어려움과 {{ }}를 사용한 감싸기(embracing)로 이를 극복하는 방법을 소개하겠습니다. 이 이론을 바탕으로, 무엇을 할 수 있는지 보여주는 다양한 예제를 보여드리겠습니다.\n\n25.3.1 간접 참조와 Tidy Evaluation\ndplyr 동사를 사용하는 함수를 작성하기 시작하면 간접 참조 문제에 빠르게 부딪힙니다. 아주 간단한 함수인 grouped_mean()으로 문제를 설명해 보겠습니다. 이 함수의 목표는 group_var로 그룹화된 mean_var의 평균을 계산하는 것입니다:\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by(group_var) |&gt; \n    summarize(mean(mean_var))\n}\n\n이것을 사용하려고 하면 오류가 발생합니다:\n\ndiamonds |&gt; grouped_mean(cut, carat)\n#&gt; Error in `group_by()`:\n#&gt; ! Must group by variables found in `.data`.\n#&gt; ✖ Column `group_var` is not found.\n\n문제를 좀 더 명확하게 하기 위해 가상의 데이터 프레임을 사용할 수 있습니다:\n\ndf &lt;- tibble(\n  mean_var = 1,\n  group_var = \"g\",\n  group = 1,\n  x = 10,\n  y = 100\n)\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\ndf |&gt; grouped_mean(group, y)\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\n\ngrouped_mean()을 어떻게 호출하든 df |&gt; group_by(group) |&gt; summarize(mean(x)) 또는 df |&gt; group_by(group) |&gt; summarize(mean(y)) 대신 항상 df |&gt; group_by(group_var) |&gt; summarize(mean(mean_var))를 수행합니다. 이것은 간접 참조의 문제이며, dplyr가 tidy evaluation을 사용하여 특별한 처리 없이 데이터 프레임 내부의 변수 이름을 참조할 수 있도록 하기 때문에 발생합니다.\nTidy evaluation은 변수가 어느 데이터 프레임에서 왔는지 말할 필요가 없으므로 데이터 분석을 매우 간결하게 만들어 주기 때문에 95%의 경우 훌륭합니다. 문맥상 명확하기 때문입니다. Tidy evaluation의 단점은 반복되는 tidyverse 코드를 함수로 감싸려고 할 때 발생합니다. 여기서는 group_by()와 summarize()에게 group_var와 mean_var를 변수 이름으로 취급하지 말고 대신 그 안을 들여다보고 우리가 실제로 사용하려는 변수를 찾도록 알려줄 방법이 필요합니다.\nTidy evaluation에는 감싸기(embracing) 🤗라는 이 문제에 대한 해결책이 포함되어 있습니다. 변수를 감싼다는 것은 중괄호로 감싸서(예: var) {{ var }}가 되도록 하는 것을 의미합니다. 변수를 감싸면 dplyr에게 인수를 리터럴 변수 이름이 아니라 인수 안에 저장된 값을 사용하도록 지시합니다. 무슨 일이 일어나고 있는지 기억하는 한 가지 방법은 {{ }}를 터널을 내려다보는 것으로 생각하는 것입니다 — {{ var }}는 dplyr 함수가 var라는 변수를 찾는 대신 var의 내부를 들여다보게 합니다.\n따라서 grouped_mean()이 작동하도록 하려면 group_var와 mean_var를 {{ }}로 감싸야 합니다:\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by({{ group_var }}) |&gt; \n    summarize(mean({{ mean_var }}))\n}\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   group `mean(x)`\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1        10\n\n성공입니다!\n\n25.3.2 언제 감싸야 할까요?\n따라서 데이터 프레임 함수 작성의 핵심 과제는 어떤 인수를 감싸야 하는지 파악하는 것입니다. 다행히도 문서에서 찾아볼 수 있기 때문에 쉽습니다 😄. 문서에서 찾아야 할 두 가지 용어가 있으며, 이는 tidy evaluation의 가장 일반적인 두 가지 하위 유형에 해당합니다:\n\n데이터 마스킹(Data-masking): 변수로 계산하는 arrange(), filter(), summarize()와 같은 함수에서 사용됩니다.\nTidy 선택(Tidy-selection): 변수를 선택하는 select(), relocate(), rename()과 같은 함수에서 사용됩니다.\n\n어떤 인수가 tidy evaluation을 사용하는지에 대한 직관은 많은 일반적인 함수에 대해 유효할 것입니다 — 계산할 수 있는지(예: x + 1) 또는 선택할 수 있는지(예: a:x) 생각해보세요.\n다음 섹션에서는 감싸기를 이해하고 나면 작성할 수 있는 유용한 함수들을 살펴보겠습니다.\n\n25.3.3 일반적인 사용 사례\n초기 데이터 탐색을 수행할 때 동일한 요약 세트를 일반적으로 수행하는 경우 도우미 함수로 감싸는 것을 고려할 수 있습니다:\n\nsummary6 &lt;- function(data, var) {\n  data |&gt; summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    mean = mean({{ var }}, na.rm = TRUE),\n    median = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_miss = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamonds |&gt; summary6(carat)\n#&gt; # A tibble: 1 × 6\n#&gt;     min  mean median   max     n n_miss\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1   0.2 0.798    0.7  5.01 53940      0\n\n(summarize()를 도우미로 감쌀 때마다 메시지를 피하고 데이터를 그룹화되지 않은 상태로 유지하기 위해 .groups = \"drop\"을 설정하는 것이 좋은 관행이라고 생각합니다.)\n이 함수의 좋은 점은 summarize()를 감싸기 때문에 그룹화된 데이터에 사용할 수 있다는 것입니다:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(carat)\n#&gt; # A tibble: 5 × 7\n#&gt;   cut         min  mean median   max     n n_miss\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair       0.22 1.05    1     5.01  1610      0\n#&gt; 2 Good       0.23 0.849   0.82  3.01  4906      0\n#&gt; 3 Very Good  0.2  0.806   0.71  4    12082      0\n#&gt; 4 Premium    0.2  0.892   0.86  4.01 13791      0\n#&gt; 5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\n또한 summarize에 대한 인수는 데이터 마스킹이므로 summary6()에 대한 var 인수도 마찬가지입니다. 즉, 계산된 변수도 요약할 수 있습니다:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(log10(carat))\n#&gt; # A tibble: 5 × 7\n#&gt;   cut          min    mean  median   max     n n_miss\n#&gt;   &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair      -0.658 -0.0273  0      0.700  1610      0\n#&gt; 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n#&gt; 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n#&gt; 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n#&gt; 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\n여러 변수를 요약하려면 Section 26.2 까지 기다려야 하며, 거기서 across() 사용법을 배우게 될 것입니다.\n또 다른 인기 있는 summarize() 도우미 함수는 비율도 계산하는 count()의 버전입니다:\n\n# https://twitter.com/Diabb6/status/1571635146658402309\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}\n\ndiamonds |&gt; count_prop(clarity)\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity     n   prop\n#&gt;   &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 I1        741 0.0137\n#&gt; 2 SI2      9194 0.170 \n#&gt; 3 SI1     13065 0.242 \n#&gt; 4 VS2     12258 0.227 \n#&gt; 5 VS1      8171 0.151 \n#&gt; 6 VVS2     5066 0.0939\n#&gt; # ℹ 2 more rows\n\n이 함수에는 df, var, sort의 세 가지 인수가 있으며, 모든 변수에 대해 데이터 마스킹을 사용하는 count()에 전달되므로 var만 감싸면 됩니다. 사용자가 자신의 값을 제공하지 않으면 기본적으로 FALSE가 되도록 sort에 기본값을 사용한다는 점에 유의하세요.\n또는 데이터의 하위 집합에 대해 변수의 정렬된 고유 값을 찾고 싶을 수도 있습니다. 필터링을 수행하기 위해 변수와 값을 제공하는 대신 사용자가 조건을 제공하도록 허용합니다:\n\nunique_where &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    distinct({{ var }}) |&gt; \n    arrange({{ var }})\n}\n\n# 12월의 모든 목적지 찾기\nflights |&gt; unique_where(month == 12, dest)\n#&gt; # A tibble: 96 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 ABQ  \n#&gt; 2 ALB  \n#&gt; 3 ATL  \n#&gt; 4 AUS  \n#&gt; 5 AVL  \n#&gt; 6 BDL  \n#&gt; # ℹ 90 more rows\n\n여기서는 filter()에 전달되기 때문에 condition을 감싸고, distinct()와 arrange()에 전달되기 때문에 var를 감쌉니다.\n이 모든 예제는 데이터 프레임을 첫 번째 인수로 받도록 만들었지만, 동일한 데이터로 반복적으로 작업하는 경우 하드코딩하는 것이 합리적일 수 있습니다. 예를 들어, 다음 함수는 항상 flights 데이터셋과 작동하며 time_hour, carrier, flight가 행을 식별할 수 있는 복합 기본 키를 형성하므로 항상 이를 선택합니다.\n\nsubset_flights &lt;- function(rows, cols) {\n  flights |&gt; \n    filter({{ rows }}) |&gt; \n    select(time_hour, carrier, flight, {{ cols }})\n}\n\n\n25.3.4 데이터 마스킹 대 Tidy 선택\n때때로 데이터 마스킹을 사용하는 함수 내부에서 변수를 선택하고 싶을 때가 있습니다. 예를 들어, 행에서 누락된 관측값의 수를 계산하는 count_missing()을 작성하고 싶다고 상상해 보세요. 다음과 같이 작성하려고 할 수 있습니다:\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by({{ group_vars }}) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; Error in `group_by()`:\n#&gt; ℹ In argument: `c(year, month, day)`.\n#&gt; Caused by error:\n#&gt; ! `c(year, month, day)` must be size 336776 or 1, not 1010328.\n\ngroup_by()는 tidy 선택이 아니라 데이터 마스킹을 사용하기 때문에 이것은 작동하지 않습니다. 데이터 마스킹 함수 내부에서 tidy 선택을 사용할 수 있게 해주는 편리한 pick() 함수를 사용하여 이 문제를 해결할 수 있습니다:\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n  )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; # A tibble: 365 × 4\n#&gt;    year month   day n_miss\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1  2013     1     1      4\n#&gt; 2  2013     1     2      8\n#&gt; 3  2013     1     3     10\n#&gt; 4  2013     1     4      6\n#&gt; 5  2013     1     5      3\n#&gt; 6  2013     1     6      1\n#&gt; # ℹ 359 more rows\n\npick()의 또 다른 편리한 사용법은 2차원 카운트 테이블을 만드는 것입니다. 여기서는 rows와 cols의 모든 변수를 사용하여 카운트한 다음 pivot_wider()를 사용하여 카운트를 그리드로 재배열합니다:\n\n# https://twitter.com/pollicipes/status/1571606508944719876\ncount_wide &lt;- function(data, rows, cols) {\n  data |&gt; \n    count(pick(c({{ rows }}, {{ cols }}))) |&gt; \n    pivot_wider(\n      names_from = {{ cols }}, \n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamonds |&gt; count_wide(c(clarity, color), cut)\n#&gt; # A tibble: 56 × 7\n#&gt;   clarity color  Fair  Good `Very Good` Premium Ideal\n#&gt;   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 I1      D         4     8           5      12    13\n#&gt; 2 I1      E         9    23          22      30    18\n#&gt; 3 I1      F        35    19          13      34    42\n#&gt; 4 I1      G        53    19          16      46    16\n#&gt; 5 I1      H        52    14          12      46    38\n#&gt; 6 I1      I        34     9           8      24    17\n#&gt; # ℹ 50 more rows\n\n예제는 주로 dplyr에 집중했지만 tidy evaluation은 tidyr의 기반이기도 하며, pivot_wider() 문서를 보면 names_from이 tidy 선택을 사용한다는 것을 알 수 있습니다.\n\n25.3.5 연습문제\n\n\nnycflights13의 데이터셋을 사용하여 다음을 수행하는 함수를 작성하세요:\n\n\n취소되었거나(is.na(arr_time)) 1시간 이상 지연된 모든 항공편을 찾습니다.\n\nflights |&gt; filter_severe()\n\n\n\n취소된 항공편 수와 1시간 이상 지연된 항공편 수를 계산합니다.\n\nflights |&gt; group_by(dest) |&gt; summarize_severe()\n\n\n\n취소되었거나 사용자가 제공한 시간 이상 지연된 모든 항공편을 찾습니다:\n\nflights |&gt; filter_severe(hours = 2)\n\n\n\n날씨를 요약하여 사용자가 제공한 변수의 최소, 평균, 최대를 계산합니다:\n\nweather |&gt; summarize_weather(temp)\n\n\n\n시계 시간(예: dep_time, arr_time 등)을 사용하는 사용자 제공 변수를 십진수 시간(즉, 시간 + (분 / 60))으로 변환합니다.\n\nflights |&gt; standardize_time(sched_dep_time)\n\n\n\n\n다음 각 함수에 대해 tidy evaluation을 사용하는 모든 인수를 나열하고 데이터 마스킹을 사용하는지 tidy 선택을 사용하는지 설명하세요: distinct(), count(), group_by(), rename_with(), slice_min(), slice_sample().\n\n다음 함수를 일반화하여 카운트할 변수를 원하는 수만큼 제공할 수 있도록 하세요.\n\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>함수 (Functions)</span>"
    ]
  },
  {
    "objectID": "functions.html#플롯-함수",
    "href": "functions.html#플롯-함수",
    "title": "25  함수 (Functions)",
    "section": "\n25.4 플롯 함수",
    "text": "25.4 플롯 함수\n데이터 프레임을 반환하는 대신 플롯을 반환하고 싶을 수도 있습니다. 다행히도 aes()가 데이터 마스킹 함수이기 때문에 ggplot2에서도 동일한 기술을 사용할 수 있습니다. 예를 들어, 많은 히스토그램을 만들고 있다고 상상해 보세요:\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.05)\n\n이것을 히스토그램 함수로 감쌀 수 있다면 좋지 않을까요? aes()가 데이터 마스킹 함수이고 감싸야 한다는 것을 알면 아주 쉽습니다:\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\nhistogram()은 ggplot2 플롯을 반환하므로 원하는 경우 추가 구성 요소를 계속 추가할 수 있습니다. |&gt;에서 +로 전환해야 한다는 점만 기억하세요:\n\ndiamonds |&gt; \n  histogram(carat, 0.1) +\n  labs(x = \"Size (in carats)\", y = \"Number of diamonds\")\n\n\n25.4.1 더 많은 변수\n더 많은 변수를 혼합하는 것은 간단합니다. 예를 들어, 매끄러운 선과 직선을 겹쳐서 데이터셋이 선형인지 여부를 눈으로 확인하는 쉬운 방법을 원할 수 있습니다:\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nlinearity_check &lt;- function(df, x, y) {\n  df |&gt;\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\nstarwars |&gt; \n  filter(mass &lt; 1000) |&gt; \n  linearity_check(mass, height)\n\n\n\n\n\n\n\n또는 오버플로팅이 문제가 되는 매우 큰 데이터셋의 경우 색상이 지정된 산점도에 대한 대안을 원할 수도 있습니다:\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\nhex_plot &lt;- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |&gt; \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # make border same color as fill\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamonds |&gt; hex_plot(carat, price, depth)\n\n\n\n\n\n\n\n\n25.4.2 다른 tidyverse와 결합하기\n가장 유용한 도우미 중 일부는 데이터 조작과 ggplot2를 약간 결합합니다. 예를 들어, fct_infreq()를 사용하여 막대를 빈도 순서대로 자동으로 정렬하는 수직 막대 차트를 만들고 싶을 수 있습니다. 막대 차트가 수직이므로 가장 높은 값이 맨 위에 오도록 일반적인 순서를 반전시켜야 합니다:\n\nsorted_bars &lt;- function(df, var) {\n  df |&gt; \n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |&gt;\n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamonds |&gt; sorted_bars(clarity)\n\n\n\n\n\n\n\n여기서는 사용자 제공 데이터를 기반으로 변수 이름을 생성하기 때문에 :=(흔히 “바다코끼리 연산자”라고 함)라는 새로운 연산자를 사용해야 합니다. 변수 이름은 =의 왼쪽에 오지만 R의 구문은 단일 리터럴 이름을 제외하고는 = 왼쪽에 어떤 것도 허용하지 않습니다. 이 문제를 해결하기 위해 tidy evaluation이 =와 정확히 동일한 방식으로 취급하는 특수 연산자 :=를 사용합니다.\n또는 데이터의 일부에 대해서만 막대 플롯을 쉽게 그리고 싶을 수도 있습니다:\n\nconditional_bars &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamonds |&gt; conditional_bars(cut == \"Good\", clarity)\n\n\n\n\n\n\n\n창의력을 발휘하여 다른 방식으로 데이터 요약을 표시할 수도 있습니다. https://gist.github.com/GShotwell/b19ef520b6d56f61a830fabb3454965b에서 멋진 응용 프로그램을 찾을 수 있습니다; 축 레이블을 사용하여 가장 높은 값을 표시합니다. ggplot2에 대해 더 많이 알게 될수록 함수의 힘은 계속 커질 것입니다.\n더 복잡한 경우인 생성한 플롯에 레이블을 지정하는 것으로 마무리하겠습니다.\n\n25.4.3 레이블 지정\n앞서 보여드린 히스토그램 함수를 기억하시나요?\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\n출력에 사용된 변수와 빈 너비로 레이블을 지정할 수 있다면 좋지 않을까요? 그렇게 하려면 tidy evaluation의 이면으로 들어가서 아직 이야기하지 않은 패키지인 rlang의 함수를 사용해야 합니다. rlang은 tidy evaluation(및 기타 많은 유용한 도구)을 구현하기 때문에 tidyverse의 거의 모든 다른 패키지에서 사용되는 저수준 패키지입니다.\n레이블 지정 문제를 해결하기 위해 rlang::englue()를 사용할 수 있습니다. 이것은 str_glue()와 유사하게 작동하므로 { }로 감싸진 모든 값은 문자열에 삽입됩니다. 하지만 적절한 변수 이름을 자동으로 삽입하는 {{ }}도 이해합니다:\n\nhistogram &lt;- function(df, var, binwidth) {\n  label &lt;- rlang::englue(\"A histogram of {{var}} with binwidth {binwidth}\")\n  \n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = label)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\nggplot2 플롯에서 문자열을 제공하려는 다른 모든 곳에서 동일한 접근 방식을 사용할 수 있습니다.\n\n25.4.4 연습문제\n아래 단계를 점진적으로 구현하여 풍부한 플롯 함수를 만드세요:\n\n데이터셋과 x, y 변수가 주어지면 산점도를 그립니다.\n최적 적합선(즉, 표준 오차가 없는 선형 모델)을 추가합니다.\n제목을 추가합니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>함수 (Functions)</span>"
    ]
  },
  {
    "objectID": "functions.html#스타일",
    "href": "functions.html#스타일",
    "title": "25  함수 (Functions)",
    "section": "\n25.5 스타일",
    "text": "25.5 스타일\nR은 함수나 인수의 이름이 무엇이든 상관하지 않지만 이름은 사람에게 큰 차이를 만듭니다. 이상적으로는 함수 이름이 짧으면서도 함수가 하는 일을 명확하게 떠올리게 해야 합니다. 어렵습니다! 하지만 RStudio의 자동 완성을 사용하면 긴 이름을 쉽게 입력할 수 있으므로 짧은 것보다는 명확한 것이 낫습니다.\n일반적으로 함수 이름은 동사여야 하고 인수는 명사여야 합니다. 몇 가지 예외가 있습니다: 함수가 매우 잘 알려진 명사를 계산하거나(즉, mean()이 compute_mean()보다 낫습니다) 객체의 일부 속성에 액세스하는 경우(즉, coef()가 get_coefficients()보다 낫습니다) 명사가 괜찮습니다. 최선의 판단을 사용하고 나중에 더 나은 이름을 알아내면 함수 이름을 바꾸는 것을 두려워하지 마세요.\n\n# 너무 짧음\nf()\n\n# 동사가 아니거나 설명적이지 않음\nmy_awesome_function()\n\n# 길지만 명확함\nimpute_missing()\ncollapse_years()\n\nR은 함수에서 공백을 사용하는 방식에 대해서도 상관하지 않지만 미래의 독자는 상관할 것입니다. Chapter 4 의 규칙을 계속 따르세요. 또한 function() 뒤에는 항상 중괄호({})가 와야 하며 내용은 두 칸 더 들여써야 합니다. 이렇게 하면 왼쪽 여백을 훑어보면서 코드의 계층 구조를 더 쉽게 볼 수 있습니다.\n\n# 추가적인 두 칸 공백 누락\ndensity &lt;- function(color, facets, binwidth = 0.1) {\ndiamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\n# 파이프가 잘못 들여쓰기됨\ndensity &lt;- function(color, facets, binwidth = 0.1) {\n  diamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\n보시다시피 {{ }} 안에는 공백을 추가하는 것을 권장합니다. 이렇게 하면 뭔가 특이한 일이 일어나고 있다는 것이 매우 분명해집니다.\n\n25.5.1 연습문제\n\n\n다음 두 함수의 소스 코드를 읽고 어떤 역할을 하는지 파악한 다음 더 나은 이름을 브레인스토밍하세요.\n\nf1 &lt;- function(string, prefix) {\n  str_sub(string, 1, str_length(prefix)) == prefix\n}\n\nf3 &lt;- function(x, y) {\n  rep(y, length.out = length(x))\n}\n\n\n최근에 작성한 함수를 가져와서 5분 동안 더 나은 이름과 인수에 대해 브레인스토밍하세요.\nrnorm(), dnorm() 등보다 norm_r(), norm_d() 등이 더 나은 이유를 설명하세요. 반대의 경우도 설명하세요. 이름을 어떻게 더 명확하게 만들 수 있습니까?",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>함수 (Functions)</span>"
    ]
  },
  {
    "objectID": "functions.html#요약",
    "href": "functions.html#요약",
    "title": "25  함수 (Functions)",
    "section": "\n25.6 요약",
    "text": "25.6 요약\n이 장에서는 벡터 생성, 데이터 프레임 생성 또는 플롯 생성이라는 세 가지 유용한 시나리오에 대한 함수를 작성하는 방법을 배웠습니다. 그 과정에서 많은 예제를 보았는데, 이를 통해 창의력이 발휘되고 함수가 분석 코드에 도움이 될 수 있는 위치에 대한 아이디어를 얻었기를 바랍니다.\n우리는 함수를 시작하기 위한 최소한의 것만 보여주었으며 배워야 할 것이 훨씬 더 많습니다. 더 배울 수 있는 몇 가지 장소는 다음과 같습니다:\n\nTidy evaluation을 사용한 프로그래밍에 대해 자세히 알아보려면 dplyr로 프로그래밍하기 및 tidyr로 프로그래밍하기에서 유용한 레시피를 확인하고 데이터 마스킹이란 무엇이며 왜 {{가 필요한가?에서 이론에 대해 자세히 알아보세요.\nggplot2 코드의 중복을 줄이는 방법에 대해 자세히 알아보려면 ggplot2 책의 ggplot2로 프로그래밍하기 장을 읽어보세요.\n함수 스타일에 대한 더 많은 조언은 tidyverse 스타일 가이드를 참조하세요.\n\n다음 장에서는 코드 중복을 줄이는 추가 도구를 제공하는 반복(iteration)에 대해 알아보겠습니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>함수 (Functions)</span>"
    ]
  },
  {
    "objectID": "iteration.html",
    "href": "iteration.html",
    "title": "26  반복",
    "section": "",
    "text": "26.1 소개\n이 장에서는 서로 다른 객체에 대해 동일한 작업을 반복적으로 수행하는 반복(iteration)을 위한 도구들을 배울 것입니다. R에서의 반복은 다른 프로그래밍 언어와는 다소 다르게 보이는 경향이 있는데, 이는 많은 부분이 암시적으로 처리되어 무료로 제공되기 때문입니다. 예를 들어, R에서 수치형 벡터 x를 두 배로 만들고 싶다면 그냥 2 * x라고 쓰면 됩니다. 대부분의 다른 언어에서는 for 루프 같은 것을 사용하여 x의 각 요소를 명시적으로 두 배로 만들어야 합니다.\n이 책은 이미 여러 “것”들에 대해 동일한 작업을 수행하는 작지만 강력한 도구들을 몇 가지 소개했습니다:\n이제 다른 함수를 입력으로 받는 함수를 중심으로 구축되었기 때문에 종종 함수형 프로그래밍(functional programming) 도구라고 불리는 좀 더 일반적인 도구들을 배울 때입니다. 함수형 프로그래밍을 배우는 것은 자칫 추상적으로 흐를 수 있지만, 이 장에서는 세 가지 일반적인 작업인 여러 열 수정하기, 여러 파일 읽기, 여러 객체 저장하기에 집중하여 구체적으로 다루겠습니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>반복</span>"
    ]
  },
  {
    "objectID": "iteration.html#소개",
    "href": "iteration.html#소개",
    "title": "26  반복",
    "section": "",
    "text": "facet_wrap() 및 facet_grid()는 각 하위 집합에 대해 플롯을 그립니다.\n\ngroup_by()와 summarize()를 함께 사용하면 각 하위 집합에 대한 요약 통계를 계산합니다.\n\nunnest_wider() 및 unnest_longer()는 리스트 열의 각 요소에 대해 새로운 행과 열을 생성합니다.\n\n\n\n26.1.1 선수 지식\n이 장에서는 tidyverse의 핵심 멤버인 dplyr과 purrr에서 제공하는 도구들에 집중하겠습니다. dplyr은 이미 보셨겠지만, purrr는 처음입니다. 이 장에서는 몇 가지 purrr 함수만 사용할 예정이지만, 프로그래밍 기술을 향상시키고 싶다면 탐색해 보기에 아주 좋은 패키지입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>반복</span>"
    ]
  },
  {
    "objectID": "iteration.html#sec-across",
    "href": "iteration.html#sec-across",
    "title": "26  반복",
    "section": "\n26.2 여러 열 수정하기",
    "text": "26.2 여러 열 수정하기\n다음과 같은 간단한 티블이 있고, 모든 열의 관측값 개수를 세고 중앙값을 계산하고 싶다고 가정해 봅시다.\n\nset.seed(1014)\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\n복사해서 붙여넣기를 사용하여 할 수 있습니다:\n\ndf |&gt; summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\n하지만 이것은 코드 블록을 두 번 이상 복사해서 붙여넣지 말라는 우리의 경험 법칙을 어기는 것이며, 열이 수십 개 또는 수백 개라면 매우 지루해질 것임을 상상할 수 있습니다. 대신 across()를 사용할 수 있습니다:\n\ndf |&gt; summarize(\n  n = n(),\n  across(a:d, median),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nacross()에는 특히 중요한 세 가지 인수가 있으며, 다음 섹션들에서 자세히 다루겠습니다. across()를 사용할 때마다 처음 두 개를 사용하게 될 것입니다. 첫 번째 인수 .cols는 반복할 열을 지정하고, 두 번째 인수 .fns는 각 열에 대해 수행할 작업을 지정합니다. 출력 열의 이름을 추가로 제어해야 할 때는 .names 인수를 사용할 수 있으며, 이는 mutate()와 함께 across()를 사용할 때 특히 중요합니다. 또한 filter()와 함께 작동하는 두 가지 중요한 변형인 if_any()와 if_all()에 대해서도 논의할 것입니다.\n\n26.2.1 .cols로 열 선택하기\nacross()의 첫 번째 인수 .cols는 변환할 열을 선택합니다. 이것은 select()와 동일한 사양을 사용하므로(Section 3.3.2), starts_with() 및 ends_with()와 같은 함수를 사용하여 이름에 따라 열을 선택할 수 있습니다.\nacross()에 특히 유용한 두 가지 추가 선택 기술이 있습니다: everything()과 where()입니다. everything()은 간단합니다. (그룹화되지 않은) 모든 열을 선택합니다:\n\nset.seed(1014)\ndf &lt;- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median))\n#&gt; # A tibble: 2 × 5\n#&gt;     grp      a      b       c       d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1     1 -0.244 -0.522 -0.0974 -0.251 \n#&gt; 2     2 -0.247  0.468  0.112   0.0700\n\n그룹화 열(여기서는 grp)은 summarize()에 의해 자동으로 보존되므로 across()에 포함되지 않습니다.\nwhere()를 사용하면 유형에 따라 열을 선택할 수 있습니다:\n\n\nwhere(is.numeric)은 모든 수치형 열을 선택합니다.\n\nwhere(is.character)는 모든 문자열 열을 선택합니다.\n\nwhere(is.Date)는 모든 날짜 열을 선택합니다.\n\nwhere(is.POSIXct)는 모든 날짜-시간 열을 선택합니다.\n\nwhere(is.logical)은 모든 논리형 열을 선택합니다.\n\n다른 선택자들과 마찬가지로 부울 대수와 결합할 수 있습니다. 예를 들어 !where(is.numeric)은 수치형이 아닌 모든 열을 선택하고, starts_with(\"a\") & where(is.logical)은 이름이 “a”로 시작하는 모든 논리형 열을 선택합니다.\n\n26.2.2 단일 함수 호출하기\nacross()의 두 번째 인수는 각 열이 어떻게 변환될지를 정의합니다. 위의 간단한 경우처럼 단일 기존 함수가 될 수도 있습니다. 이것은 R의 꽤 특별한 기능입니다. 우리는 한 함수(median, mean, str_flatten, …)를 다른 함수(across)에 전달하고 있습니다. 이것이 R을 함수형 프로그래밍 언어로 만드는 기능 중 하나입니다.\n여기서 중요한 점은 이 함수를 across()에 전달하여 across()가 호출할 수 있게 하는 것이지, 우리가 직접 호출하는 것이 아니라는 점입니다. 즉, 함수 이름 뒤에 ()가 오면 안 됩니다. 이를 잊어버리면 오류가 발생합니다:\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median()))\n#&gt; Error in `summarize()`:\n#&gt; ℹ In argument: `across(everything(), median())`.\n#&gt; Caused by error in `median.default()`:\n#&gt; ! argument \"x\" is missing, with no default\n\n이 오류는 입력 없이 함수를 호출하려고 했기 때문에 발생합니다. 예:\n\nmedian()\n#&gt; Error in median.default(): argument \"x\" is missing, with no default\n\n\n26.2.3 여러 함수 호출하기\n더 복잡한 경우에는 추가 인수를 제공하거나 여러 변환을 수행하고 싶을 수 있습니다. 간단한 예로 이 문제의 동기를 부여해 보겠습니다. 데이터에 결측값이 있으면 어떻게 될까요? median()은 결측값을 전파하여 최적이 아닌 출력을 제공합니다:\n\nset.seed(1014)\nrnorm_na &lt;- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss &lt;- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |&gt; \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b     c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    NA    NA    NA 0.413     5\n\n이 결측값들을 제거하기 위해 na.rm = TRUE를 median()에 전달할 수 있다면 좋을 것입니다. 그렇게 하려면 median()을 직접 호출하는 대신, 원하는 인수로 median()을 호출하는 새 함수를 만들어야 합니다:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;        a      b      c     d     n\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 -0.703 -0.265 -0.522 0.413     5\n\n이것은 약간 장황하므로, R에는 편리한 단축키가 있습니다. 이런 일회용 또는 익명(anonymous)1 함수의 경우 function을 \\2로 바꿀 수 있습니다:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\n어느 경우든 across()는 실질적으로 다음 코드로 확장됩니다:\n\ndf_miss |&gt; \n  summarize(\n    a = median(a, na.rm = TRUE),\n    b = median(b, na.rm = TRUE),\n    c = median(c, na.rm = TRUE),\n    d = median(d, na.rm = TRUE),\n    n = n()\n  )\n\nmedian()에서 결측값을 제거할 때, 얼마나 많은 값이 제거되었는지도 알 수 있으면 좋을 것입니다. across()에 두 개의 함수를 제공하여 이를 알아낼 수 있습니다. 하나는 중앙값을 계산하고 다른 하나는 결측값의 개수를 세는 것입니다. .fns에 명명된 리스트를 사용하여 여러 함수를 제공합니다:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1   -0.703        1   -0.265        1   -0.522        2    0.413        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\n자세히 보시면, 열 이름이 {.col}_{.fn}과 같은 glue 사양(Section 14.3.2)을 사용하여 지정되었다는 것을 직감할 수 있을 것입니다. 여기서 .col은 원래 열의 이름이고 .fn은 함수의 이름입니다. 이것은 우연이 아닙니다! 다음 섹션에서 배우게 되겠지만, .names 인수를 사용하여 자신만의 glue 사양을 제공할 수 있습니다.\n\n26.2.4 열 이름\nacross()의 결과는 .names 인수에 제공된 사양에 따라 이름이 지정됩니다. 함수 이름이 먼저 오게 하고 싶다면 직접 지정할 수 있습니다3:\n\ndf_miss |&gt; \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1   -0.703        1   -0.265        1   -0.522        2    0.413        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\n.names 인수는 mutate()와 함께 across()를 사용할 때 특히 중요합니다. 기본적으로 across()의 출력에는 입력과 동일한 이름이 지정됩니다. 즉, mutate() 내부의 across()는 기존 열을 대체합니다. 예를 들어, 여기서는 coalesce()를 사용하여 NA를 0으로 바꿉니다:\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n#&gt; # A tibble: 5 × 4\n#&gt;          a      b      c        d\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 -0.00557 -0.283 -1.86  -0.783  \n#&gt; 2  0.255   -0.247 -0.522 -0.00289\n#&gt; 3 -1.40    -0.554  0.512  0.413  \n#&gt; 4 -2.44    -0.244  0      0.724  \n#&gt; 5  0        0      0      2.35\n\n대신 새 열을 만들고 싶다면 .names 인수를 사용하여 출력에 새 이름을 지정할 수 있습니다:\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0), .names = \"{.col}_na_zero\")\n  )\n#&gt; # A tibble: 5 × 8\n#&gt;          a      b      c        d a_na_zero b_na_zero c_na_zero d_na_zero\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 -0.00557 -0.283 -1.86  -0.783    -0.00557    -0.283    -1.86   -0.783  \n#&gt; 2  0.255   -0.247 -0.522 -0.00289   0.255      -0.247    -0.522  -0.00289\n#&gt; 3 -1.40    -0.554  0.512  0.413    -1.40       -0.554     0.512   0.413  \n#&gt; 4 -2.44    -0.244 NA      0.724    -2.44       -0.244     0       0.724  \n#&gt; 5 NA       NA     NA      2.35      0           0         0       2.35\n\n\n26.2.5 필터링\nacross()는 summarize() 및 mutate()와 훌륭한 조화를 이루지만 filter()와 함께 사용하기에는 더 어색합니다. 일반적으로 여러 조건을 | 또는 &로 결합하기 때문입니다. across()가 여러 논리형 열을 만드는 데 도움이 될 수 있다는 것은 분명하지만, 그 다음에는 어떻게 해야 할까요? 그래서 dplyr은 if_any()와 if_all()이라는 across()의 두 가지 변형을 제공합니다:\n\n# df_miss |&gt; filter(is.na(a) | is.na(b) | is.na(c) | is.na(d)) 와 동일\ndf_miss |&gt; filter(if_any(a:d, is.na))\n#&gt; # A tibble: 2 × 4\n#&gt;       a      b     c     d\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 -2.44 -0.244    NA 0.724\n#&gt; 2 NA    NA        NA 2.35\n\n# df_miss |&gt; filter(is.na(a) & is.na(b) & is.na(c) & is.na(d)) 와 동일\ndf_miss |&gt; filter(if_all(a:d, is.na))\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n\n26.2.6 함수 내의 across()\n\nacross()는 여러 열에 대해 작업할 수 있게 해주기 때문에 프로그래밍하기에 특히 유용합니다. 예를 들어, Jacob Scott은 여러 lubridate 함수를 래핑하여 모든 날짜 열을 연, 월, 일 열로 확장하는 이 작은 도우미 함수를 사용합니다:\n\nexpand_dates &lt;- function(df) {\n  df |&gt; \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date &lt;- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |&gt; \n  expand_dates()\n#&gt; # A tibble: 2 × 5\n#&gt;   name  date       date_year date_month date_day\n#&gt;   &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 Amy   2009-08-03      2009          8        3\n#&gt; 2 Bob   2010-01-16      2010          1       16\n\nacross()는 또한 첫 번째 인수가 tidy-select를 사용하기 때문에 단일 인수에 여러 열을 쉽게 제공할 수 있습니다. Section 25.3.2 에서 논의한 대로 해당 인수를 감싸야 한다는 점만 기억하면 됩니다. 예를 들어, 이 함수는 기본적으로 수치형 열의 평균을 계산합니다. 하지만 두 번째 인수를 제공하여 선택한 열만 요약하도록 선택할 수 있습니다:\n\nsummarize_means &lt;- function(df, summary_vars = where(is.numeric)) {\n  df |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means()\n#&gt; # A tibble: 5 × 9\n#&gt;   cut       carat depth table price     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means(c(carat, x:z))\n#&gt; # A tibble: 5 × 6\n#&gt;   cut       carat     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  5.51  5.52  3.40 21551\n\n\n26.2.7 pivot_longer()와 비교\n계속 진행하기 전에 across()와 pivot_longer()(Section 5.3) 사이의 흥미로운 연결 고리를 짚고 넘어갈 가치가 있습니다. 많은 경우, 먼저 데이터를 피벗한 다음 열이 아닌 그룹별로 연산을 수행하여 동일한 계산을 수행할 수 있습니다. 예를 들어, 이 다중 함수 요약을 보세요:\n\ndf |&gt; \n  summarize(across(a:d, list(median = median, mean = mean)))\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\n피벗을 더 길게(longer) 한 다음 요약하여 동일한 값을 계산할 수 있습니다:\n\nlong &lt;- df |&gt; \n  pivot_longer(a:d) |&gt; \n  group_by(name) |&gt; \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n#&gt; # A tibble: 4 × 3\n#&gt;   name   median    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 a     -0.246  -0.0426\n#&gt; 2 b      0.155  -0.0656\n#&gt; 3 c      0.0480 -0.0297\n#&gt; 4 d     -0.193  -0.200\n\n그리고 across()와 동일한 구조를 원한다면 다시 피벗할 수 있습니다:\n\nlong |&gt; \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\n이것은 가끔 현재 across()로는 해결할 수 없는 문제에 부딪힐 때 유용한 기술입니다. 즉, 동시에 계산하려는 열 그룹이 있는 경우입니다. 예를 들어, 데이터 프레임에 값과 가중치가 모두 포함되어 있고 가중 평균을 계산하고 싶다고 가정해 봅시다:\n\nset.seed(1014)\ndf_paired &lt;- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n\n현재로서는 across()를 사용하여 이 작업을 수행할 수 있는 방법이 없지만4, pivot_longer()를 사용하면 비교적 간단합니다:\n\ndf_long &lt;- df_paired |&gt; \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n#&gt; # A tibble: 40 × 3\n#&gt;   group    val   wts\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 a     -1.40  0.290\n#&gt; 2 b     -1.86  0.461\n#&gt; 3 c      0.935 0.528\n#&gt; 4 d      2.76  0.709\n#&gt; 5 a      0.255 0.678\n#&gt; 6 b     -0.522 0.315\n#&gt; # ℹ 34 more rows\n\ndf_long |&gt; \n  group_by(group) |&gt; \n  summarize(mean = weighted.mean(val, wts))\n#&gt; # A tibble: 4 × 2\n#&gt;   group    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a     -0.207 \n#&gt; 2 b     -0.237 \n#&gt; 3 c      0.0208\n#&gt; 4 d      0.0655\n\n필요한 경우 pivot_wider()를 사용하여 이를 다시 원래 형태로 되돌릴 수 있습니다.\n\n26.2.8 연습문제\n\n\n다음을 수행하여 across() 기술을 연습하세요:\n\npalmerpenguins::penguins의 각 열에 있는 고유 값의 개수를 계산합니다.\nmtcars의 모든 열의 평균을 계산합니다.\ndiamonds를 cut, clarity, color로 그룹화한 다음 관측값 개수를 세고 각 수치형 열의 평균을 계산합니다.\n\n\nacross()에 함수 리스트를 사용하면서 이름을 지정하지 않으면 어떻게 됩니까? 출력 이름은 어떻게 지정됩니까?\n날짜 열이 확장된 후 자동으로 제거되도록 expand_dates()를 조정하세요. 인수를 감싸야(embrace) 합니까?\n\n이 함수 파이프라인의 각 단계가 무엇을 하는지 설명하세요. where()의 어떤 특별한 기능을 활용하고 있습니까?\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\nnycflights13::flights |&gt; show_missing(c(year, month, day))",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>반복</span>"
    ]
  },
  {
    "objectID": "iteration.html#여러-파일-읽기",
    "href": "iteration.html#여러-파일-읽기",
    "title": "26  반복",
    "section": "\n26.3 여러 파일 읽기",
    "text": "26.3 여러 파일 읽기\n이전 섹션에서는 dplyr::across()를 사용하여 여러 열에 대해 변환을 반복하는 방법을 배웠습니다. 이 섹션에서는 purrr::map()을 사용하여 디렉터리의 모든 파일에 대해 작업을 수행하는 방법을 배울 것입니다. 간단한 동기 부여로 시작하겠습니다. 읽고 싶은 엑셀 스프레드시트로 가득 찬 디렉터리가 있다고 가정해 봅시다5. 복사해서 붙여넣기를 사용하여 할 수 있습니다:\n\ndata2019 &lt;- readxl::read_excel(\"data/y2019.xlsx\")\ndata2020 &lt;- readxl::read_excel(\"data/y2020.xlsx\")\ndata2021 &lt;- readxl::read_excel(\"data/y2021.xlsx\")\ndata2022 &lt;- readxl::read_excel(\"data/y2022.xlsx\")\n\n그런 다음 dplyr::bind_rows()를 사용하여 모두 결합합니다:\n\ndata &lt;- bind_rows(data2019, data2020, data2021, data2022)\n\n이 작업은 파일이 4개가 아니라 수백 개라면 금방 지루해질 것임을 상상할 수 있습니다. 다음 섹션들에서는 이러한 종류의 작업을 자동화하는 방법을 보여줍니다. 세 가지 기본 단계가 있습니다: list.files()를 사용하여 디렉터리의 모든 파일을 나열한 다음, purrr::map()을 사용하여 각 파일을 리스트로 읽어 들인 다음, purrr::list_rbind()를 사용하여 이를 단일 데이터 프레임으로 결합합니다. 그런 다음 모든 파일에 대해 정확히 동일한 작업을 수행할 수 없는, 이질성이 증가하는 상황을 처리하는 방법에 대해 논의하겠습니다.\n\n26.3.1 디렉터리의 파일 나열하기\n이름에서 알 수 있듯이 list.files()는 디렉터리의 파일을 나열합니다. 거의 항상 다음 세 가지 인수를 사용하게 될 것입니다:\n\n첫 번째 인수 path는 살펴볼 디렉터리입니다.\npattern은 파일 이름을 필터링하는 데 사용되는 정규 표현식입니다. 가장 일반적인 패턴은 지정된 확장자를 가진 모든 파일을 찾기 위한 [.]xlsx$ 또는 [.]csv$와 같은 것입니다.\nfull.names는 디렉터리 이름을 출력에 포함할지 여부를 결정합니다. 거의 항상 이것을 TRUE로 설정하고 싶을 것입니다.\n\n우리의 동기 부여 예제를 구체화하기 위해, 이 책에는 gapminder 패키지의 데이터가 포함된 12개의 엑셀 스프레드시트가 있는 폴더가 있습니다. 이 폴더는 https://github.com/hadley/r4ds/tree/main/data/gapminder에서 찾을 수 있습니다. 각 파일에는 142개 국가에 대한 1년 치 데이터가 들어 있습니다. 적절한 list.files() 호출로 이를 모두 나열할 수 있습니다:\n\npaths &lt;- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\npaths\n#&gt;  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#&gt;  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#&gt;  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#&gt;  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#&gt;  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#&gt; [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n\n26.3.2 리스트\n이제 이 12개의 경로가 있으므로 read_excel()을 12번 호출하여 12개의 데이터 프레임을 얻을 수 있습니다:\n\ngapminder_1952 &lt;- readxl::read_excel(\"data/gapminder/1952.xlsx\")\ngapminder_1957 &lt;- readxl::read_excel(\"data/gapminder/1957.xlsx\")\ngapminder_1962 &lt;- readxl::read_excel(\"data/gapminder/1962.xlsx\")\n ...,\ngapminder_2007 &lt;- readxl::read_excel(\"data/gapminder/2007.xlsx\")\n\n하지만 각 시트를 자체 변수에 넣으면 몇 단계 후에 작업하기가 매우 어려워질 것입니다. 대신 단일 객체에 넣는 것이 작업하기 더 쉬울 것입니다. 리스트는 이 작업에 완벽한 도구입니다:\n\nfiles &lt;- list(\n  readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\n이제 리스트에 이 데이터 프레임들이 있으니, 어떻게 하나를 꺼낼까요? files[[i]]를 사용하여 i번째 요소를 추출할 수 있습니다:\n\nfiles[[3]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\n[[에 대해서는 Section 27.3 에서 더 자세히 다루겠습니다.\n\n26.3.3 purrr::map()과 list_rbind()\n\n해당 데이터 프레임들을 리스트에 “수동으로” 모으는 코드는 파일을 하나씩 읽는 코드만큼이나 입력하기 지루합니다. 다행히도 purrr::map()을 사용하여 paths 벡터를 훨씬 더 잘 활용할 수 있습니다. map()은 across()와 비슷하지만, 데이터 프레임의 각 열에 대해 작업을 수행하는 대신 벡터의 각 요소에 대해 작업을 수행합니다. map(x, f)는 다음의 단축 표현입니다:\n\nlist(\n  f(x[[1]]),\n  f(x[[2]]),\n  ...,\n  f(x[[n]])\n)\n\n따라서 map()을 사용하여 12개의 데이터 프레임 리스트를 얻을 수 있습니다:\n\nfiles &lt;- map(paths, readxl::read_excel)\nlength(files)\n#&gt; [1] 12\n\nfiles[[1]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 136 more rows\n\n(이것은 str()로 특히 간결하게 표시되지 않는 또 다른 데이터 구조이므로, RStudio에 로드하고 View()로 검사하고 싶을 수 있습니다.)\n이제 purrr::list_rbind()를 사용하여 해당 데이터 프레임 리스트를 단일 데이터 프레임으로 결합할 수 있습니다:\n\nlist_rbind(files)\n#&gt; # A tibble: 1,704 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n또는 파이프라인에서 두 단계를 한 번에 수행할 수도 있습니다:\n\npaths |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind()\n\nread_excel()에 추가 인수를 전달하고 싶다면 어떻게 할까요? across()와 동일한 기술을 사용합니다. 예를 들어, n_max = 1을 사용하여 데이터의 처음 몇 행만 엿보는 것이 종종 유용합니다:\n\npaths |&gt; \n  map(\\(path) readxl::read_excel(path, n_max = 1)) |&gt; \n  list_rbind()\n#&gt; # A tibble: 12 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Afghanistan Asia         30.3  9240934      821.\n#&gt; 3 Afghanistan Asia         32.0 10267083      853.\n#&gt; 4 Afghanistan Asia         34.0 11537966      836.\n#&gt; 5 Afghanistan Asia         36.1 13079460      740.\n#&gt; 6 Afghanistan Asia         38.4 14880372      786.\n#&gt; # ℹ 6 more rows\n\n이것은 무언가 빠져 있다는 것을 명확히 해줍니다. year 열이 없는데, 해당 값은 개별 파일이 아니라 경로에 기록되어 있기 때문입니다. 다음으로 이 문제를 해결해 보겠습니다.\n\n26.3.4 경로에 있는 데이터\n때로는 파일 이름 자체가 데이터이기도 합니다. 이 예제에서 파일 이름에는 연도가 포함되어 있는데, 이는 개별 파일 내부에는 기록되지 않습니다. 해당 열을 최종 데이터 프레임에 넣으려면 두 가지 작업을 수행해야 합니다:\n먼저, 경로 벡터의 이름을 지정합니다. 가장 쉬운 방법은 함수를 인수로 받을 수 있는 set_names() 함수를 사용하는 것입니다. 여기서는 basename()을 사용하여 전체 경로에서 파일 이름만 추출합니다:\n\npaths |&gt; set_names(basename)\n#&gt;                  1952.xlsx                  1957.xlsx \n#&gt; \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n#&gt;                  1962.xlsx                  1967.xlsx \n#&gt; \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n#&gt;                  1972.xlsx                  1977.xlsx \n#&gt; \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n#&gt;                  1982.xlsx                  1987.xlsx \n#&gt; \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n#&gt;                  1992.xlsx                  1997.xlsx \n#&gt; \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n#&gt;                  2002.xlsx                  2007.xlsx \n#&gt; \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n이 이름들은 모든 map 함수에 의해 자동으로 전달되므로, 데이터 프레임 리스트도 동일한 이름을 갖게 됩니다:\n\nfiles &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel)\n\n이렇게 하면 map() 호출은 다음의 단축 표현이 됩니다:\n\nfiles &lt;- list(\n  \"1952.xlsx\" = readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  \"1957.xlsx\" = readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  \"1962.xlsx\" = readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  \"2007.xlsx\" = readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\n또한 [[를 사용하여 이름으로 요소를 추출할 수 있습니다:\n\nfiles[[\"1962.xlsx\"]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\n그런 다음 list_rbind()의 names_to 인수를 사용하여 이름을 year라는 새 열에 저장하도록 지시한 다음, readr::parse_number()를 사용하여 문자열에서 숫자를 추출합니다.\n\npaths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n#&gt; # A tibble: 1,704 × 6\n#&gt;    year country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  1952 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2  1952 Albania     Europe       55.2  1282697     1601.\n#&gt; 3  1952 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4  1952 Angola      Africa       30.0  4232095     3521.\n#&gt; 5  1952 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6  1952 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n더 복잡한 경우에는 디렉터리 이름에 다른 변수가 저장되어 있거나, 파일 이름에 여러 데이터 비트가 포함되어 있을 수 있습니다. 이 경우 set_names()(인수 없이)를 사용하여 전체 경로를 기록한 다음, tidyr::separate_wider_delim()과 그 친구들을 사용하여 유용한 열로 변환하세요.\n\npaths |&gt; \n  set_names() |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |&gt; \n  separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n#&gt; # A tibble: 1,704 × 8\n#&gt;   dir       file  ext   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n#&gt; 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n#&gt; 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n\n26.3.5 작업 저장\n이제 멋지고 깔끔한 데이터 프레임을 얻기 위해 이 모든 노력을 기울였으니, 작업을 저장하기에 아주 좋은 시간입니다:\n\ngapminder &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n\nwrite_csv(gapminder, \"gapminder.csv\")\n\n이제 나중에 이 문제로 돌아올 때 단일 csv 파일을 읽어 들일 수 있습니다. 대규모의 풍부한 데이터셋의 경우 Section 22.4 에서 논의한 대로 .csv보다는 parquet를 사용하는 것이 더 나은 선택일 수 있습니다.\n프로젝트에서 작업하는 경우, 이런 종류의 데이터 준비 작업을 수행하는 파일을 0-cleanup.R과 같은 이름으로 부르는 것이 좋습니다. 파일 이름의 0은 이 파일이 다른 무엇보다 먼저 실행되어야 함을 암시합니다.\n입력 데이터 파일이 시간이 지남에 따라 변경된다면, 이런 종류의 데이터 정리 코드가 입력 파일 중 하나가 수정될 때마다 자동으로 다시 실행되도록 설정하는 targets와 같은 도구를 배워서 사용하는 것을 고려해 보세요.\n\n26.3.6 여러 번의 단순한 반복\n여기서는 데이터를 디스크에서 직접 로드했고, 운 좋게도 깔끔한 데이터셋을 얻었습니다. 대부분의 경우 추가적인 정리가 필요하며, 두 가지 기본 옵션이 있습니다. 복잡한 함수로 한 번의 반복을 수행하거나, 단순한 함수로 여러 번의 반복을 수행하는 것입니다. 우리의 경험상 대부분의 사람들은 먼저 한 번의 복잡한 반복을 시도하지만, 여러 번의 단순한 반복을 수행하는 것이 종종 더 좋습니다.\n예를 들어 여러 파일을 읽어 들이고, 결측값을 필터링하고, 피벗한 다음, 결합하고 싶다고 가정해 봅시다. 문제에 접근하는 한 가지 방법은 파일을 받아서 그 모든 단계를 수행하는 함수를 작성한 다음 map()을 한 번 호출하는 것입니다:\n\nprocess_file &lt;- function(path) {\n  df &lt;- read_csv(path)\n  \n  df |&gt; \n    filter(!is.na(id)) |&gt; \n    mutate(id = tolower(id)) |&gt; \n    pivot_longer(jan:dec, names_to = \"month\")\n}\n\npaths |&gt; \n  map(process_file) |&gt; \n  list_rbind()\n\n또는 process_file()의 각 단계를 모든 파일에 대해 수행할 수도 있습니다:\n\npaths |&gt; \n  map(read_csv) |&gt; \n  map(\\(df) df |&gt; filter(!is.na(id))) |&gt; \n  map(\\(df) df |&gt; mutate(id = tolower(id))) |&gt; \n  map(\\(df) df |&gt; pivot_longer(jan:dec, names_to = \"month\")) |&gt; \n  list_rbind()\n\n이 접근 방식을 권장하는 이유는 첫 번째 파일을 올바르게 만드는 데 집착하지 않고 나머지로 넘어갈 수 있기 때문입니다. 정리 및 청소 작업을 할 때 모든 데이터를 고려함으로써 전체적으로 생각하고 더 높은 품질의 결과를 얻을 가능성이 큽니다.\n이 특정 예제에서는 데이터 프레임들을 더 일찍 결합하여 또 다른 최적화를 할 수 있습니다. 그러면 일반적인 dplyr 동작에 의존할 수 있습니다:\n\npaths |&gt; \n  map(read_csv) |&gt; \n  list_rbind() |&gt; \n  filter(!is.na(id)) |&gt; \n  mutate(id = tolower(id)) |&gt; \n  pivot_longer(jan:dec, names_to = \"month\")\n\n\n26.3.7 이질적인 데이터\n불행히도 때로는 map()에서 list_rbind()로 바로 넘어갈 수 없는 경우가 있습니다. 데이터 프레임들이 너무 이질적이어서 list_rbind()가 실패하거나 별로 유용하지 않은 데이터 프레임을 생성하기 때문입니다. 이럴 때는 여전히 모든 파일을 로드하는 것부터 시작하는 것이 유용합니다:\n\nfiles &lt;- paths |&gt; \n  map(readxl::read_excel) \n\n그런 다음 데이터 프레임의 구조를 캡처하여 데이터 과학 기술로 탐색할 수 있게 하는 전략이 매우 유용합니다. 그렇게 하는 한 가지 방법은 각 열에 대해 한 행씩 있는 티블을 반환하는 이 편리한 df_types 함수6를 사용하는 것입니다:\n\ndf_types &lt;- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder)\n#&gt; # A tibble: 6 × 3\n#&gt;   col_name  col_type  n_miss\n#&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 year      double         0\n#&gt; 2 country   character      0\n#&gt; 3 continent character      0\n#&gt; 4 lifeExp   double         0\n#&gt; 5 pop       double         0\n#&gt; 6 gdpPercap double         0\n\n그런 다음 이 함수를 모든 파일에 적용하고, 차이점이 어디에 있는지 더 쉽게 볼 수 있도록 피벗을 수행할 수 있습니다. 예를 들어, 이를 통해 우리가 작업해 온 gapminder 스프레드시트가 모두 상당히 동질적임을 쉽게 확인할 수 있습니다:\n\nfiles |&gt; \n  map(df_types) |&gt; \n  list_rbind(names_to = \"file_name\") |&gt; \n  select(-n_miss) |&gt; \n  pivot_wider(names_from = col_name, values_from = col_type)\n#&gt; # A tibble: 12 × 6\n#&gt;   file_name country   continent lifeExp pop    gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1 1952.xlsx character character double  double double   \n#&gt; 2 1957.xlsx character character double  double double   \n#&gt; 3 1962.xlsx character character double  double double   \n#&gt; 4 1967.xlsx character character double  double double   \n#&gt; 5 1972.xlsx character character double  double double   \n#&gt; 6 1977.xlsx character character double  double double   \n#&gt; # ℹ 6 more rows\n\n파일 형식이 이질적이라면 성공적으로 병합하기 전에 추가 처리를 수행해야 할 수도 있습니다. 불행히도 이 부분은 여러분이 스스로 알아내도록 남겨두겠지만, map_if() 및 map_at()에 대해 읽어보는 것이 좋습니다. map_if()를 사용하면 값에 따라 리스트의 요소를 선택적으로 수정할 수 있고, map_at()을 사용하면 이름에 따라 요소를 선택적으로 수정할 수 있습니다.\n\n26.3.8 실패 처리\n때로는 데이터의 구조가 너무 엉망이라 단일 명령으로 모든 파일을 읽을 수조차 없을 때가 있습니다. 그러면 map()의 단점 중 하나를 만나게 됩니다. 즉, 전체가 성공하거나 실패한다는 것입니다. map()은 디렉터리의 모든 파일을 성공적으로 읽거나, 아니면 오류와 함께 실패하여 파일을 하나도 읽지 못합니다. 이것은 짜증 나는 일입니다. 왜 단 하나의 실패가 다른 모든 성공에 접근하는 것을 막아야 할까요?\n다행히 purrr에는 이 문제를 해결하기 위한 도우미인 possibly()가 있습니다. possibly()는 함수 연산자(function operator)로 알려져 있습니다. 함수를 인수로 받아 수정된 동작을 가진 함수를 반환합니다. 특히 possibly()는 함수가 오류를 발생시키는 대신 지정된 값을 반환하도록 변경합니다:\n\nfiles &lt;- paths |&gt; \n  map(possibly(\\(path) readxl::read_excel(path), NULL))\n\ndata &lt;- files |&gt; list_rbind()\n\n이것은 여기서 특히 잘 작동하는데, list_rbind()가 많은 tidyverse 함수와 마찬가지로 NULL을 자동으로 무시하기 때문입니다.\n이제 쉽게 읽을 수 있는 모든 데이터를 확보했으니, 일부 파일 로드에 실패한 이유와 그에 대해 무엇을 할지 알아내는 어려운 부분을 해결할 차례입니다. 먼저 실패한 경로들을 가져옵니다:\n\nfailed &lt;- map_vec(files, is.null)\npaths[failed]\n#&gt; character(0)\n\n그런 다음 실패한 각 파일에 대해 가져오기 함수를 다시 호출하여 무엇이 잘못되었는지 확인합니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>반복</span>"
    ]
  },
  {
    "objectID": "iteration.html#여러-출력-저장하기",
    "href": "iteration.html#여러-출력-저장하기",
    "title": "26  반복",
    "section": "\n26.4 여러 출력 저장하기",
    "text": "26.4 여러 출력 저장하기\n지난 섹션에서는 여러 파일을 단일 객체로 읽어 들이는 데 유용한 map()에 대해 배웠습니다. 이 섹션에서는 이제 그 반대 문제, 즉 하나 이상의 R 객체를 가져와서 하나 이상의 파일에 저장하는 방법을 살펴보겠습니다. 다음 세 가지 예제를 사용하여 이 과제를 탐구하겠습니다:\n\n여러 데이터 프레임을 하나의 데이터베이스에 저장하기.\n여러 데이터 프레임을 여러 .csv 파일에 저장하기.\n여러 플롯을 여러 .png 파일에 저장하기.\n\n\n26.4.1 데이터베이스에 쓰기\n때로는 한꺼번에 많은 파일로 작업할 때 모든 데이터를 메모리에 한 번에 올릴 수 없어서 map(files, read_csv)를 수행할 수 없는 경우가 있습니다. 이 문제를 처리하는 한 가지 접근 방식은 dbplyr을 사용하여 필요한 부분만 액세스할 수 있도록 데이터를 데이터베이스에 로드하는 것입니다.\n운이 좋다면 사용 중인 데이터베이스 패키지가 경로 벡터를 받아서 모두 데이터베이스에 로드하는 편리한 함수를 제공할 것입니다. duckdb의 duckdb_read_csv()가 그런 사례입니다:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nduckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\n이것은 여기서 잘 작동하겠지만, 우리는 csv 파일이 아니라 엑셀 스프레드시트를 가지고 있습니다. 그래서 “수동으로” 해야 할 것입니다. 수동으로 하는 법을 배우면 csv 파일 뭉치가 있고, 작업 중인 데이터베이스에 이를 모두 로드하는 단일 함수가 없는 경우에도 도움이 될 것입니다.\n먼저 데이터를 채울 테이블을 만드는 것부터 시작해야 합니다. 가장 쉬운 방법은 원하는 모든 열을 포함하지만 데이터는 샘플링된 정도만 포함하는 더미 데이터 프레임인 템플릿을 만드는 것입니다. gapminder 데이터의 경우, 단일 파일을 읽고 연도를 추가하여 해당 템플릿을 만들 수 있습니다:\n\ntemplate &lt;- readxl::read_excel(paths[[1]])\ntemplate$year &lt;- 1952\ntemplate\n#&gt; # A tibble: 142 × 6\n#&gt;   country     continent lifeExp      pop gdpPercap  year\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.  1952\n#&gt; 2 Albania     Europe       55.2  1282697     1601.  1952\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.  1952\n#&gt; 4 Angola      Africa       30.0  4232095     3521.  1952\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.  1952\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.  1952\n#&gt; # ℹ 136 more rows\n\n이제 데이터베이스에 연결하고 DBI::dbCreateTable()을 사용하여 템플릿을 데이터베이스 테이블로 바꿀 수 있습니다:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nDBI::dbCreateTable(con, \"gapminder\", template)\n\ndbCreateTable()은 template의 데이터를 사용하지 않고 변수 이름과 유형만 사용합니다. 따라서 지금 gapminder 테이블을 검사해 보면 비어 있지만, 우리가 예상하는 유형을 가진 필요한 변수들이 있는 것을 볼 수 있습니다:\n\ncon |&gt; tbl(\"gapminder\")\n#&gt; # Source:   table&lt;gapminder&gt; [?? x 6]\n#&gt; # Database: DuckDB 1.4.3 [root@Darwin 25.1.0:R 4.5.0/:memory:]\n#&gt; # ℹ 6 variables: country &lt;chr&gt;, continent &lt;chr&gt;, lifeExp &lt;dbl&gt;, pop &lt;dbl&gt;,\n#&gt; #   gdpPercap &lt;dbl&gt;, year &lt;dbl&gt;\n\n다음으로, 단일 파일 경로를 받아서 R로 읽어 들이고 그 결과를 gapminder 테이블에 추가하는 함수가 필요합니다. read_excel()을 DBI::dbAppendTable()과 결합하여 이를 수행할 수 있습니다:\n\nappend_file &lt;- function(path) {\n  df &lt;- readxl::read_excel(path)\n  df$year &lt;- parse_number(basename(path))\n  \n  DBI::dbAppendTable(con, \"gapminder\", df)\n}\n\n이제 paths의 각 요소에 대해 append_file()을 한 번씩 호출해야 합니다. map()으로도 가능합니다:\n\npaths |&gt; map(append_file)\n\n하지만 우리는 append_file()의 출력 결과에는 관심이 없으므로, map() 대신 walk()를 사용하는 것이 약간 더 좋습니다. walk()는 map()과 정확히 동일한 작업을 수행하지만 출력 결과는 버립니다:\n\npaths |&gt; walk(append_file)\n\n이제 테이블에 모든 데이터가 들어 있는지 확인할 수 있습니다:\n\ncon |&gt; \n  tbl(\"gapminder\") |&gt; \n  count(year)\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB 1.4.3 [root@Darwin 25.1.0:R 4.5.0/:memory:]\n#&gt;    year     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1967   142\n#&gt; 2  1952   142\n#&gt; 3  1977   142\n#&gt; 4  1987   142\n#&gt; 5  2007   142\n#&gt; 6  1962   142\n#&gt; # ℹ more rows\n\n\n26.4.2 csv 파일 쓰기\n각 그룹에 대해 하나씩 여러 csv 파일을 쓰려는 경우에도 동일한 기본 원칙이 적용됩니다. ggplot2::diamonds 데이터를 가져와서 각 clarity(투명도)별로 하나의 csv 파일을 저장하고 싶다고 가정해 봅시다. 먼저 그 개별 데이터셋들을 만들어야 합니다. 여러 가지 방법으로 할 수 있지만, 우리가 특히 좋아하는 방법은 group_nest()입니다.\n\nby_clarity &lt;- diamonds |&gt; \n  group_nest(clarity)\n\nby_clarity\n#&gt; # A tibble: 8 × 2\n#&gt;   clarity               data\n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n#&gt; 1 I1               [741 × 9]\n#&gt; 2 SI2            [9,194 × 9]\n#&gt; 3 SI1           [13,065 × 9]\n#&gt; 4 VS2           [12,258 × 9]\n#&gt; 5 VS1            [8,171 × 9]\n#&gt; 6 VVS2           [5,066 × 9]\n#&gt; # ℹ 2 more rows\n\n이것은 8개의 행과 2개의 열이 있는 새로운 티블을 제공합니다. clarity는 그룹화 변수이고, data는 각 고유한 clarity 값에 대해 하나의 티블을 포함하는 리스트 열입니다:\n\nby_clarity$data[[1]]\n#&gt; # A tibble: 741 × 9\n#&gt;   carat cut       color depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#&gt; 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#&gt; 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#&gt; 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#&gt; 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#&gt; 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#&gt; # ℹ 735 more rows\n\n여기서 mutate()와 str_glue()를 사용하여 출력 파일의 이름을 제공하는 열을 만들어 보겠습니다:\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity               data path             \n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n#&gt; 1 I1               [741 × 9] diamonds-I1.csv  \n#&gt; 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#&gt; 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#&gt; 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#&gt; 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#&gt; 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#&gt; # ℹ 2 more rows\n\n따라서 이 데이터 프레임들을 수동으로 저장한다면 다음과 같이 쓸 수 있을 것입니다:\n\nwrite_csv(by_clarity$data[[1]], by_clarity$path[[1]])\nwrite_csv(by_clarity$data[[2]], by_clarity$path[[2]])\nwrite_csv(by_clarity$data[[3]], by_clarity$path[[3]])\n...\nwrite_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])\n\n이것은 변하는 인수가 하나가 아니라 두 개이므로 이전의 map() 사용과는 조금 다릅니다. 즉, 첫 번째 인수와 두 번째 인수를 모두 변경하는 map2()라는 새로운 함수가 필요합니다. 그리고 이번에도 출력 결과에는 관심이 없으므로 map2() 대신 walk2()를 원합니다. 그러면 다음과 같습니다:\n\nwalk2(by_clarity$data, by_clarity$path, write_csv)\n\n\n26.4.3 플롯 저장하기\n동일한 기본 접근 방식을 사용하여 많은 플롯을 만들 수 있습니다. 먼저 원하는 플롯을 그리는 함수를 만들어 보겠습니다:\n\ncarat_histogram &lt;- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\n\n\n\n이제 map()을 사용하여 많은 플롯7과 최종 파일 경로의 리스트를 만들 수 있습니다:\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\n그런 다음 walk2()를 ggsave()와 함께 사용하여 각 플롯을 저장합니다:\n\nwalk2(\n  by_clarity$path,\n  by_clarity$plot,\n  \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n)\n\n이것은 다음의 단축 표현입니다:\n\nggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)\nggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)\nggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)\n...\nggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>반복</span>"
    ]
  },
  {
    "objectID": "iteration.html#요약",
    "href": "iteration.html#요약",
    "title": "26  반복",
    "section": "\n26.5 요약",
    "text": "26.5 요약\n이 장에서는 데이터 과학을 할 때 자주 발생하는 세 가지 문제, 즉 여러 열 조작하기, 여러 파일 읽기, 여러 출력 저장하기를 해결하기 위해 명시적 반복을 사용하는 방법을 살펴보았습니다. 하지만 일반적으로 반복은 슈퍼 파워입니다. 올바른 반복 기술을 알고 있다면 하나의 문제를 해결하는 것에서 모든 문제를 해결하는 것으로 쉽게 나아갈 수 있습니다. 이 장의 기술들을 마스터했다면, Advanced R의 함수형(Functionals) 장을 읽고 purrr 웹사이트를 참고하여 더 많은 내용을 배워보시기를 강력히 추천합니다.\n다른 언어의 반복문에 대해 많이 알고 있다면, 우리가 for 루프에 대해 논의하지 않은 것에 놀랐을 수도 있습니다. 그 이유는 R의 데이터 분석 지향적 특성이 반복 방식을 바꾸기 때문입니다. 대부분의 경우 기존의 관용구에 의존하여 각 열이나 각 그룹에 작업을 수행할 수 있습니다. 그럴 수 없는 경우에는 리스트의 각 요소에 작업을 수행하는 map()과 같은 함수형 프로그래밍 도구를 종종 사용할 수 있습니다. 하지만 야생에서 마주치는 코드에서는 for 루프를 보게 될 것이므로, 몇 가지 중요한 기본(base) R 도구를 논의하는 다음 장에서 이에 대해 배울 것입니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>반복</span>"
    ]
  },
  {
    "objectID": "iteration.html#footnotes",
    "href": "iteration.html#footnotes",
    "title": "26  반복",
    "section": "",
    "text": "익명인 이유는 &lt;-를 사용하여 명시적으로 이름을 지정하지 않았기 때문입니다. 프로그래머들은 이를 “람다 함수”라고도 부릅니다.↩︎\n오래된 코드에서는 ~ .x + 1과 같은 구문을 볼 수 있습니다. 이것은 익명 함수를 작성하는 또 다른 방법이지만 tidyverse 함수 내에서만 작동하며 항상 변수 이름 .x를 사용합니다. 우리는 이제 기본 구문인 \\(x) x + 1을 권장합니다.↩︎\n현재로서는 열의 순서를 변경할 수는 없지만, relocate() 등을 사용하여 나중에 재정렬할 수 있습니다.↩︎\n언젠가는 가능할 수도 있겠지만, 현재로서는 방법이 보이지 않습니다.↩︎\n대신 동일한 형식의 csv 파일 디렉터리가 있다면 Section 7.4 의 기술을 사용할 수 있습니다.↩︎\n이 함수의 작동 방식은 설명하지 않겠지만, 사용된 함수들의 문서를 찾아보면 알아낼 수 있을 것입니다.↩︎\nby_clarity$plot을 인쇄하여 조잡한 애니메이션을 얻을 수 있습니다. plots의 각 요소에 대해 하나의 플롯을 얻게 됩니다. 참고: 저에게는 이런 일이 일어나지 않았습니다.↩︎",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>반복</span>"
    ]
  },
  {
    "objectID": "base-R.html",
    "href": "base-R.html",
    "title": "27  기본 R 필드 가이드",
    "section": "",
    "text": "27.1 소개\n프로그래밍 섹션을 마무리하기 위해, 이 책에서 다루지 않은 가장 중요한 기본(base) R 함수들을 간단히 살펴보겠습니다. 이 도구들은 프로그래밍을 더 많이 할 때 특히 유용하며, 야생에서 만날 코드를 읽는 데 도움이 될 것입니다.\n이 시점에서 tidyverse만이 데이터 과학 문제를 해결하는 유일한 방법이 아니라는 점을 상기시키는 것이 좋겠습니다. 이 책에서 tidyverse를 가르치는 이유는 tidyverse 패키지들이 공통된 디자인 철학을 공유하여 함수 간의 일관성을 높이고 새로운 함수나 패키지를 배우고 사용하기 조금 더 쉽게 만들기 때문입니다. 기본 R을 사용하지 않고는 tidyverse를 사용할 수 없으므로, 패키지를 로드하기 위한 library(), 수치 요약을 위한 sum()과 mean(), 팩터, 날짜, POSIXct 데이터 유형, 그리고 물론 +, -, /, *, |, &, !와 같은 모든 기본 연산자에 이르기까지 이미 많은 기본 R 함수를 가르쳐 드렸습니다. 지금까지 우리가 집중하지 않았던 것은 기본 R 워크플로우이므로, 이 장에서는 그 중 몇 가지를 강조할 것입니다.\n이 책을 읽고 나면 기본 R, data.table 및 기타 패키지를 사용하여 동일한 문제에 대한 다른 접근 방식을 배우게 될 것입니다. 특히 StackOverflow를 사용하는 경우 다른 사람이 작성한 R 코드를 읽기 시작할 때 의심할 여지 없이 이러한 다른 접근 방식을 접하게 될 것입니다. 다양한 접근 방식을 혼합하여 코드를 작성하는 것은 100% 괜찮습니다. 다른 사람의 말에 휘둘리지 마세요!\n이 장에서는 [를 사용한 부분집합, [[와 $를 사용한 부분집합, apply 계열 함수, for 루프라는 네 가지 큰 주제에 중점을 둘 것입니다. 마지막으로 두 가지 필수 플롯 함수에 대해 간단히 설명하겠습니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#소개",
    "href": "base-R.html#소개",
    "title": "27  기본 R 필드 가이드",
    "section": "",
    "text": "27.1.1 선수 지식\n이 장은 기본 R에 중점을 두므로 실제 전제 조건은 없지만, 차이점 중 일부를 설명하기 위해 tidyverse를 로드할 것입니다.\n\nlibrary(tidyverse)\n#&gt; Warning: package 'ggplot2' was built under R version 4.5.2\n#&gt; Warning: package 'readr' was built under R version 4.5.2",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-many",
    "href": "base-R.html#sec-subset-many",
    "title": "27  기본 R 필드 가이드",
    "section": "\n27.2 [로 여러 요소 선택하기",
    "text": "27.2 [로 여러 요소 선택하기\n[는 벡터와 데이터 프레임에서 하위 구성 요소를 추출하는 데 사용되며 x[i] 또는 x[i, j]와 같이 호출됩니다. 이 섹션에서는 [의 힘을 소개합니다. 먼저 벡터와 함께 사용하는 방법을 보여준 다음, 데이터 프레임과 같은 2차원(2d) 구조로 동일한 원리가 어떻게 간단하게 확장되는지 보여줍니다. 그런 다음 다양한 dplyr 동사가 [의 특수한 경우임을 보여줌으로써 지식을 굳히는 데 도움을 줄 것입니다.\n\n27.2.1 벡터 부분집합하기\n벡터를 부분집합할 수 있는, 즉 x[i]에서 i가 될 수 있는 주요 유형은 다섯 가지입니다:\n\n\n양의 정수 벡터. 양의 정수로 부분집합하면 해당 위치의 요소가 유지됩니다:\n\nx &lt;- c(\"one\", \"two\", \"three\", \"four\", \"five\")\nx[c(3, 2, 5)]\n#&gt; [1] \"three\" \"two\"   \"five\"\n\n위치를 반복함으로써 실제로 입력보다 더 긴 출력을 만들 수 있으므로 “부분집합”이라는 용어는 다소 부적절할 수 있습니다.\n\nx[c(1, 1, 5, 5, 5, 2)]\n#&gt; [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\"\n\n\n\n음의 정수 벡터. 음수 값은 지정된 위치의 요소를 삭제합니다:\n\nx[c(-1, -3, -5)]\n#&gt; [1] \"two\"  \"four\"\n\n\n\n논리형 벡터. 논리형 벡터로 부분집합하면 TRUE 값에 해당하는 모든 값이 유지됩니다. 이것은 비교 함수와 함께 사용할 때 가장 유용합니다.\n\nx &lt;- c(10, 3, NA, 5, 8, 1, NA)\n\n# x의 모든 결측되지 않은 값\nx[!is.na(x)]\n#&gt; [1] 10  3  5  8  1\n\n# x의 모든 짝수(또는 결측!) 값\nx[x %% 2 == 0]\n#&gt; [1] 10 NA  8 NA\n\nfilter()와 달리 NA 인덱스는 출력에 NA로 포함됩니다.\n\n\n문자형 벡터. 명명된 벡터가 있는 경우 문자형 벡터로 부분집합할 수 있습니다:\n\nx &lt;- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n#&gt; xyz def \n#&gt;   5   2\n\n양의 정수로 부분집합하는 것과 마찬가지로 문자형 벡터를 사용하여 개별 항목을 복제할 수 있습니다.\n\n없음. 마지막 유형의 부분집합은 아무것도 없는 x[]이며, 이는 완전한 x를 반환합니다. 이것은 벡터를 부분집합하는 데는 유용하지 않지만, 곧 보게 되겠지만 티블과 같은 2차원 구조를 부분집합할 때 유용합니다.\n\n27.2.2 데이터 프레임 부분집합하기\n데이터 프레임과 함께 [를 사용할 수 있는 꽤 다양한 방법1이 있지만, 가장 중요한 방법은 df[rows, cols]로 행과 열을 독립적으로 선택하는 것입니다. 여기서 rows와 cols는 위에서 설명한 벡터입니다. 예를 들어 df[rows, ]와 df[, cols]는 행만 선택하거나 열만 선택하며, 빈 부분집합을 사용하여 다른 차원을 보존합니다.\n다음은 몇 가지 예입니다:\n\ndf &lt;- tibble(\n  x = 1:3, \n  y = c(\"a\", \"e\", \"f\"), \n  z = runif(3)\n)\n\n# 첫 번째 행과 두 번째 열 선택\ndf[1, 2]\n#&gt; # A tibble: 1 × 1\n#&gt;   y    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a\n\n# 모든 행과 x, y 열 선택\ndf[, c(\"x\" , \"y\")]\n#&gt; # A tibble: 3 × 2\n#&gt;       x y    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 a    \n#&gt; 2     2 e    \n#&gt; 3     3 f\n\n# `x`가 1보다 큰 행과 모든 열 선택\ndf[df$x &gt; 1, ]\n#&gt; # A tibble: 2 × 3\n#&gt;       x y         z\n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2 e     0.834\n#&gt; 2     3 f     0.601\n\n곧 $로 돌아오겠지만 문맥상 df$x가 무엇을 하는지 짐작할 수 있을 것입니다: df에서 x 변수를 추출합니다. 여기서 [는 tidy evaluation을 사용하지 않으므로 x 변수의 출처를 명시해야 하기 때문에 이것을 사용해야 합니다.\n[와 관련하여 티블과 데이터 프레임 사이에는 중요한 차이점이 있습니다. 이 책에서 우리는 주로 티블을 사용했는데, 티블은 데이터 프레임이지만 삶을 조금 더 쉽게 만들기 위해 일부 동작을 조정합니다. 대부분의 경우 “티블”과 “데이터 프레임”을 상호 교환적으로 사용할 수 있으므로 R의 내장 데이터 프레임에 특히 주의를 기울이고 싶을 때 data.frame이라고 쓸 것입니다. df가 data.frame인 경우 df[, cols]는 col이 단일 열을 선택하면 벡터를 반환하고 둘 이상의 열을 선택하면 데이터 프레임을 반환합니다. df가 티블이면 [는 항상 티블을 반환합니다.\n\ndf1 &lt;- data.frame(x = 1:3)\ndf1[, \"x\"]\n#&gt; [1] 1 2 3\n\ndf2 &lt;- tibble(x = 1:3)\ndf2[, \"x\"]\n#&gt; # A tibble: 3 × 1\n#&gt;       x\n#&gt;   &lt;int&gt;\n#&gt; 1     1\n#&gt; 2     2\n#&gt; 3     3\n\ndata.frame의 이러한 모호성을 피하는 한 가지 방법은 drop = FALSE를 명시적으로 지정하는 것입니다:\n\ndf1[, \"x\" , drop = FALSE]\n#&gt;   x\n#&gt; 1 1\n#&gt; 2 2\n#&gt; 3 3\n\n\n27.2.3 dplyr 등가물\n여러 dplyr 동사는 [의 특수한 경우입니다:\n\n\nfilter()는 결측값을 제외하도록 주의하면서 논리형 벡터로 행을 부분집합하는 것과 같습니다:\n\ndf &lt;- tibble(\n  x = c(2, 3, 1, 1, NA), \n  y = letters[1:5],\n  z = runif(5)\n)\ndf |&gt; filter(x &gt; 1)\n\n# 다음은 동일함\ndf[!is.na(df$x) & df$x &gt; 1, ]\n\n야생에서 흔히 볼 수 있는 또 다른 기술은 결측값을 삭제하는 부작용을 위해 which()를 사용하는 것입니다: df[which(df$x &gt; 1), ].\n\n\narrange()는 정수 벡터로 행을 부분집합하는 것과 같으며, 보통 order()로 생성됩니다:\n\ndf |&gt; arrange(x, y)\n\n# 다음은 동일함\ndf[order(df$x, df$y), ]\n\norder(decreasing = TRUE)를 사용하여 모든 열을 내림차순으로 정렬하거나 -rank(col)을 사용하여 개별적으로 열을 내림차순으로 정렬할 수 있습니다.\n\n\nselect()와 relocate()는 모두 문자형 벡터로 열을 부분집합하는 것과 비슷합니다:\n\ndf |&gt; select(x, z)\n\n# 다음은 동일함\ndf[, c(\"x\", \"z\")]\n\n\n\n기본 R은 subset()이라는 filter()와 select()2의 기능을 결합한 함수도 제공합니다:\n\ndf |&gt; \n  filter(x &gt; 1) |&gt; \n  select(y, z)\n#&gt; # A tibble: 2 × 2\n#&gt;   y           z\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a     0.157  \n#&gt; 2 b     0.00740\n\n\n# 다음은 동일함\ndf |&gt; subset(x &gt; 1, c(y, z))\n\n이 함수는 dplyr 구문의 많은 부분에 영감을 주었습니다.\n\n27.2.4 연습문제\n\n\n벡터를 입력으로 받아 다음을 반환하는 함수를 만드세요:\n\n짝수 위치에 있는 요소.\n마지막 값을 제외한 모든 요소.\n짝수 값만(결측값 없음).\n\n\nx[-which(x &gt; 0)]이 x[x &lt;= 0]과 같지 않은 이유는 무엇입니까? which()에 대한 문서를 읽고 실험을 통해 알아내세요.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-one",
    "href": "base-R.html#sec-subset-one",
    "title": "27  기본 R 필드 가이드",
    "section": "\n27.3 $와 [[로 단일 요소 선택하기",
    "text": "27.3 $와 [[로 단일 요소 선택하기\n많은 요소를 선택하는 [는 단일 요소를 추출하는 [[ 및 $와 짝을 이룹니다. 이 섹션에서는 [[와 $를 사용하여 데이터 프레임에서 열을 뽑아내는 방법을 보여주고, data.frame과 티블 간의 몇 가지 차이점에 대해 논의하며, 리스트와 함께 사용할 때 [와 [[의 중요한 차이점을 강조합니다.\n\n27.3.1 데이터 프레임\n[[와 $는 데이터 프레임에서 열을 추출하는 데 사용할 수 있습니다. [[는 위치나 이름으로 액세스할 수 있으며 $는 이름에 의한 액세스에 특화되어 있습니다:\n\ntb &lt;- tibble(\n  x = 1:4,\n  y = c(10, 4, 1, 21)\n)\n\n# 위치로\ntb[[1]]\n#&gt; [1] 1 2 3 4\n\n# 이름으로\ntb[[\"x\"]]\n#&gt; [1] 1 2 3 4\ntb$x\n#&gt; [1] 1 2 3 4\n\n또한 기본 R에서 mutate()에 해당하는 새로운 열을 만드는 데에도 사용할 수 있습니다:\n\ntb$z &lt;- tb$x + tb$y\ntb\n#&gt; # A tibble: 4 × 3\n#&gt;       x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    10    11\n#&gt; 2     2     4     6\n#&gt; 3     3     1     4\n#&gt; 4     4    21    25\n\ntransform(), with(), within()을 포함하여 새 열을 만드는 다른 여러 기본 R 접근 방식이 있습니다. Hadley는 https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf에 몇 가지 예제를 모았습니다.\n빠른 요약을 수행할 때 $를 직접 사용하는 것이 편리합니다. 예를 들어 가장 큰 다이아몬드의 크기나 cut의 가능한 값을 찾고 싶다면 summarize()를 사용할 필요가 없습니다:\n\nmax(diamonds$carat)\n#&gt; [1] 5.01\n\nlevels(diamonds$cut)\n#&gt; [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\ndplyr는 Chapter 3 에서 언급하지 않은 [[/$에 해당하는 pull()을 제공합니다. pull()은 변수 이름이나 변수 위치를 취하고 해당 열만 반환합니다. 즉, 위의 코드를 파이프를 사용하도록 다시 쓸 수 있습니다:\n\ndiamonds |&gt; pull(carat) |&gt; max()\n#&gt; [1] 5.01\n\ndiamonds |&gt; pull(cut) |&gt; levels()\n#&gt; [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\n\n27.3.2 티블\n$와 관련하여 티블과 기본 data.frame 사이에는 몇 가지 중요한 차이점이 있습니다. 데이터 프레임은 변수 이름의 접두사를 일치시키고(부분 일치라고 함) 열이 존재하지 않아도 불평하지 않습니다:\n\ndf &lt;- data.frame(x1 = 1)\ndf$x\n#&gt; [1] 1\ndf$z\n#&gt; NULL\n\n티블은 더 엄격합니다: 변수 이름을 정확히 일치시키며 액세스하려는 열이 존재하면 경고를 생성합니다:\n\ntb &lt;- tibble(x1 = 1)\n\ntb$x\n#&gt; Warning: Unknown or uninitialised column: `x`.\n#&gt; NULL\ntb$z\n#&gt; Warning: Unknown or uninitialised column: `z`.\n#&gt; NULL\n\n이런 이유로 우리는 때때로 티블이 게으르고 무뚝뚝하다고 농담합니다: 덜 일하고 더 많이 불평합니다.\n\n27.3.3 리스트\n[[와 $는 리스트 작업에도 정말 중요하며 [와 어떻게 다른지 이해하는 것이 중요합니다. l이라는 이름의 리스트로 차이점을 설명해 보겠습니다:\n\nl &lt;- list(\n  a = 1:3, \n  b = \"a string\", \n  c = pi,\n  d = list(-1, -5)\n)\n\n\n\n[는 하위 리스트를 추출합니다. 추출하는 요소의 수에 관계없이 결과는 항상 리스트입니다.\n\nstr(l[1:2])\n#&gt; List of 2\n#&gt;  $ a: int [1:3] 1 2 3\n#&gt;  $ b: chr \"a string\"\n\nstr(l[1])\n#&gt; List of 1\n#&gt;  $ a: int [1:3] 1 2 3\n\nstr(l[4])\n#&gt; List of 1\n#&gt;  $ d:List of 2\n#&gt;   ..$ : num -1\n#&gt;   ..$ : num -5\n\n벡터와 마찬가지로 논리형, 정수형 또는 문자형 벡터로 부분집합할 수 있습니다.\n\n\n[[와 $는 리스트에서 단일 구성 요소를 추출합니다. 그들은 리스트에서 계층 구조의 한 수준을 제거합니다.\n\nstr(l[[1]])\n#&gt;  int [1:3] 1 2 3\n\nstr(l[[4]])\n#&gt; List of 2\n#&gt;  $ : num -1\n#&gt;  $ : num -5\n\nstr(l$a)\n#&gt;  int [1:3] 1 2 3\n\n\n\n[와 [[의 차이점은 리스트의 경우 특히 중요합니다. [[는 리스트를 파고드는 반면 [는 새롭고 더 작은 리스트를 반환하기 때문입니다. 차이점을 기억하는 데 도움이 되도록 Figure 27.1 에 표시된 특이한 후추통을 살펴보세요. 이 후추통이 리스트 pepper라면 pepper[1]은 단일 후추 패킷이 들어 있는 후추통입니다. pepper[2]는 똑같이 보이지만 두 번째 패킷이 들어 있을 것입니다. pepper[1:2]는 두 개의 후추 패킷이 들어 있는 후추통일 것입니다. pepper[[1]]은 후추 패킷 자체를 추출합니다.\n\n\n\n\n\n\n\nFigure 27.1: (왼쪽) Hadley가 호텔 방에서 한 번 발견한 후추통. (가운데) pepper[1]. (오른쪽) pepper[[1]]\n\n\n\n\n데이터 프레임에 1차원 [를 사용할 때도 동일한 원칙이 적용됩니다: df[\"x\"]는 1열 데이터 프레임을 반환하고 df[[\"x\"]]는 벡터를 반환합니다.\n\n27.3.4 연습문제\n\n벡터의 길이보다 큰 양의 정수로 [[를 사용하면 어떻게 됩니까? 존재하지 않는 이름으로 부분집합하면 어떻게 됩니까?\npepper[[1]][1]은 무엇일까요? pepper[[1]][[1]]은 어떻습니까?",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#apply-계열",
    "href": "base-R.html#apply-계열",
    "title": "27  기본 R 필드 가이드",
    "section": "\n27.4 Apply 계열",
    "text": "27.4 Apply 계열\nChapter 26 에서 dplyr::across() 및 map 함수 계열과 같은 반복을 위한 tidyverse 기술을 배웠습니다. 이 섹션에서는 이들의 기본 등가물인 apply 계열에 대해 배울 것입니다. 이 문맥에서 apply와 map은 동의어입니다. “벡터의 각 요소에 함수를 매핑”하는 것을 “벡터의 각 요소에 함수를 적용(apply)”한다고 말할 수 있기 때문입니다. 여기서는 야생에서 이들을 인식할 수 있도록 이 계열에 대한 빠른 개요를 제공합니다.\n이 계열의 가장 중요한 멤버는 lapply()이며, 이는 purrr::map()3과 매우 유사합니다. 실제로 map()의 고급 기능을 사용하지 않았기 때문에 Chapter 26 의 모든 map() 호출을 lapply()로 바꿀 수 있습니다.\nacross()에 해당하는 정확한 기본 R 등가물은 없지만 lapply()와 함께 [를 사용하여 근접하게 할 수 있습니다. 이것이 작동하는 이유는 내부적으로 데이터 프레임이 열의 리스트이기 때문에 데이터 프레임에서 lapply()를 호출하면 각 열에 함수가 적용되기 때문입니다.\n\ndf &lt;- tibble(a = 1, b = 2, c = \"a\", d = \"b\", e = 4)\n\n# 먼저 수치형 열 찾기\nnum_cols &lt;- sapply(df, is.numeric)\nnum_cols\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\n# 그런 다음 lapply()로 각 열을 변환한 다음 원래 값을 대체\ndf[, num_cols] &lt;- lapply(df[, num_cols, drop = FALSE], \\(x) x * 2)\ndf\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b c     d         e\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2     4 a     b         8\n\n위의 코드는 새로운 함수 sapply()를 사용합니다. lapply()와 비슷하지만 항상 결과를 단순화하려고 시도하므로 이름에 s가 붙어 있습니다. 여기서는 리스트 대신 논리형 벡터를 생성합니다. 단순화가 실패하여 예상치 못한 유형을 제공할 수 있으므로 프로그래밍에는 사용하지 않는 것이 좋지만 대화형 사용에는 일반적으로 괜찮습니다. purrr에는 Chapter 26 에서 언급하지 않은 map_vec()이라는 유사한 함수가 있습니다.\n기본 R은 vapply()라는 sapply()의 더 엄격한 버전을 제공합니다. 이는 vector apply의 줄임말입니다. 이것은 예상되는 유형을 지정하는 추가 인수를 취하여 입력에 관계없이 동일한 방식으로 단순화가 발생하도록 합니다. 예를 들어 위의 sapply() 호출을 is.numeric()이 길이 1의 논리형 벡터를 반환할 것으로 예상한다고 지정하는 이 vapply()로 바꿀 수 있습니다:\n\nvapply(df, is.numeric, logical(1))\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\nsapply()와 vapply()의 구별은 함수 내부에 있을 때 정말 중요하지만(비정상적인 입력에 대한 함수의 견고성에 큰 차이를 만들기 때문입니다), 데이터 분석에서는 일반적으로 중요하지 않습니다.\napply 계열의 또 다른 중요한 멤버는 단일 그룹화된 요약을 계산하는 tapply()입니다:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize(price = mean(price))\n#&gt; # A tibble: 5 × 2\n#&gt;   cut       price\n#&gt;   &lt;ord&gt;     &lt;dbl&gt;\n#&gt; 1 Fair      4359.\n#&gt; 2 Good      3929.\n#&gt; 3 Very Good 3982.\n#&gt; 4 Premium   4584.\n#&gt; 5 Ideal     3458.\n\ntapply(diamonds$price, diamonds$cut, mean)\n#&gt;      Fair      Good Very Good   Premium     Ideal \n#&gt;  4358.758  3928.864  3981.760  4584.258  3457.542\n\n불행히도 tapply()는 결과를 명명된 벡터로 반환하므로 여러 요약 및 그룹화 변수를 데이터 프레임으로 수집하려면 약간의 체조가 필요합니다(이렇게 하지 않고 자유 부동 벡터로 작업하는 것은 확실히 가능하지만 경험상 작업이 지연될 뿐입니다). tapply() 또는 기타 기본 기술을 사용하여 다른 그룹화된 요약을 수행하는 방법을 보고 싶다면 Hadley가 gist에 몇 가지 기술을 모아두었습니다.\napply 계열의 마지막 멤버는 행렬 및 배열과 함께 작동하는 이름 그대로의 apply()입니다. 특히 lapply(df, something)을 수행하는 느리고 잠재적으로 위험한 방법인 apply(df, 2, something)을 주의하세요. 우리는 일반적으로 행렬이 아닌 데이터 프레임으로 작업하기 때문에 데이터 과학에서는 거의 나타나지 않습니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#for-루프",
    "href": "base-R.html#for-루프",
    "title": "27  기본 R 필드 가이드",
    "section": "\n27.5 for 루프",
    "text": "27.5 for 루프\nfor 루프는 apply 및 map 계열 모두 내부적으로 사용하는 반복의 기본 구성 요소입니다. for 루프는 더 경험이 많은 R 프로그래머가 됨에 따라 배워야 할 강력하고 일반적인 도구입니다. for 루프의 기본 구조는 다음과 같습니다:\n\nfor (element in vector) {\n  # 요소로 무언가를 수행\n}\n\nfor 루프의 가장 간단한 사용은 walk()와 동일한 효과를 얻는 것입니다: 리스트의 각 요소에 대해 부작용이 있는 함수를 호출합니다. 예를 들어, Section 26.4.1 에서 walk()를 사용하는 대신:\n\npaths |&gt; walk(append_file)\n\nfor 루프를 사용할 수 있었습니다:\n\nfor (path in paths) {\n  append_file(path)\n}\n\nfor 루프의 출력을 저장하려는 경우, 예를 들어 Chapter 26 에서와 같이 디렉토리의 모든 엑셀 파일을 읽으려는 경우 상황이 조금 더 까다로워집니다:\n\npaths &lt;- dir(\"data/gapminder\", pattern = \"\\\\.xlsx$\", full.names = TRUE)\nfiles &lt;- map(paths, readxl::read_excel)\n\n사용할 수 있는 몇 가지 다른 기술이 있지만, 출력이 어떻게 보일지 미리 명시하는 것이 좋습니다. 이 경우 paths와 길이가 같은 리스트를 원하므로 vector()로 만들 수 있습니다:\n\nfiles &lt;- vector(\"list\", length(paths))\n\n그런 다음 paths의 요소를 반복하는 대신 seq_along()을 사용하여 paths의 각 요소에 대한 하나의 인덱스를 생성하여 인덱스를 반복합니다:\n\nseq_along(paths)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12\n\n인덱스를 사용하는 것은 입력의 각 위치를 출력의 해당 위치와 연결할 수 있기 때문에 중요합니다:\n\nfor (i in seq_along(paths)) {\n  files[[i]] &lt;- readxl::read_excel(paths[[i]])\n}\n\n티블 리스트를 단일 티블로 결합하려면 do.call() + rbind()를 사용할 수 있습니다:\n\ndo.call(rbind, files)\n#&gt; # A tibble: 1,704 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n리스트를 만들고 진행하면서 결과를 저장하는 대신, 데이터 프레임을 조각별로 쌓아 올리는 더 간단한 접근 방식이 있습니다:\n\nout &lt;- NULL\nfor (path in paths) {\n  out &lt;- rbind(out, readxl::read_excel(path))\n}\n\n벡터가 매우 길어지면 매우 느려질 수 있으므로 이 패턴은 피하는 것이 좋습니다. 이것이 for 루프가 느리다는 지속적인 헛소문의 원인입니다: 루프가 아니라 벡터를 반복적으로 키우는 것이 느린 것입니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#플롯",
    "href": "base-R.html#플롯",
    "title": "27  기본 R 필드 가이드",
    "section": "\n27.6 플롯",
    "text": "27.6 플롯\n그렇지 않으면 tidyverse를 사용하지 않는 많은 R 사용자가 합리적인 기본값, 자동 범례, 현대적인 모양과 같은 유용한 기능 때문에 플롯을 위해 ggplot2를 선호합니다. 그러나 기본 R 플롯 함수는 매우 간결하기 때문에 여전히 유용할 수 있습니다 — 기본 탐색 플롯을 수행하는 데 입력이 거의 필요하지 않습니다.\n야생에서 볼 수 있는 두 가지 주요 유형의 기본 플롯은 각각 plot()과 hist()로 생성되는 산점도와 히스토그램입니다. 다음은 diamonds 데이터셋의 간단한 예입니다:\n# 왼쪽\nhist(diamonds$carat)\n\n# 오른쪽\nplot(diamonds$carat, diamonds$price)\n\n\n\n\n\n\n\n\n\n\n기본 플롯 함수는 벡터와 함께 작동하므로 $ 또는 다른 기술을 사용하여 데이터 프레임에서 열을 뽑아내야 합니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#요약",
    "href": "base-R.html#요약",
    "title": "27  기본 R 필드 가이드",
    "section": "\n27.7 요약",
    "text": "27.7 요약\n이 장에서는 부분집합 및 반복에 유용한 기본 R 함수들을 보여주었습니다. 책의 다른 곳에서 논의된 접근 방식과 비교할 때, 이러한 함수는 데이터 프레임과 일부 열 사양보다는 개별 벡터를 취하는 경향이 있기 때문에 “데이터 프레임” 풍미보다는 “벡터” 풍미가 더 강합니다. 이것은 종종 프로그래밍을 더 쉽게 만들므로 더 많은 함수를 작성하고 자신의 패키지를 작성하기 시작할 때 더 중요해집니다.\n이 장으로 책의 프로그래밍 섹션이 끝납니다. 여러분은 R을 사용하는 데이터 과학자가 될 뿐만 아니라 R로 프로그래밍할 수 있는 데이터 과학자가 되는 여정의 확실한 시작을 했습니다. 이 장들이 프로그래밍에 대한 관심을 불러일으켰고 이 책 밖에서 더 배우기를 고대하고 있기를 바랍니다.",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "base-R.html#footnotes",
    "href": "base-R.html#footnotes",
    "title": "27  기본 R 필드 가이드",
    "section": "",
    "text": "https://adv-r.hadley.nz/subsetting.html#subset-multiple을 읽어보고 데이터 프레임을 1차원 객체처럼 부분집합하는 방법과 행렬로 부분집합하는 방법을 확인하세요.↩︎\n하지만 그룹화된 데이터 프레임을 다르게 처리하지 않으며 starts_with()와 같은 선택 도우미 함수를 지원하지 않습니다.↩︎\n진행률 표시줄과 오류 발생 시 문제가 발생한 요소를 보고하는 것과 같은 편리한 기능만 없습니다.↩︎",
    "crumbs": [
      "프로그램 (Program)",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>기본 R 필드 가이드</span>"
    ]
  },
  {
    "objectID": "communicate.html",
    "href": "communicate.html",
    "title": "소통 (Communicate)",
    "section": "",
    "text": "지금까지 여러분은 데이터를 R로 가져오고, 분석하기 편리한 형태로 정리한 다음, 변형과 시각화를 통해 데이터를 이해하는 도구들을 배웠습니다. 하지만 분석 결과가 아무리 훌륭하더라도 다른 사람들에게 설명할 수 없다면 의미가 없습니다. 즉, 결과를 소통(communicate) 해야 합니다.\n\n\n\n\n\n\n\nFigure 1: 소통은 데이터 과학 프로세스의 마지막 부분입니다. 분석 결과를 다른 사람에게 전달할 수 없다면 분석이 아무리 훌륭하더라도 중요하지 않습니다.\n\n\n\n\n소통은 이어지는 두 장의 주제입니다:\n\n28  Quarto 에서는 산문, 코드, 결과를 통합하는 도구인 Quarto에 대해 배웁니다. Quarto를 분석가 간의 소통뿐만 아니라 분석가와 의사 결정권자 간의 소통에도 사용할 수 있습니다. Quarto 형식의 강력함 덕분에 동일한 문서를 두 가지 목적으로 모두 사용할 수도 있습니다.\n29  Quarto 형식 에서는 대시보드, 웹사이트, 책을 포함하여 Quarto를 사용하여 생성할 수 있는 다른 많은 종류의 출력에 대해 조금 배우게 됩니다.\n\n이 장들은 주로 소통의 기술적 메커니즘에 초점을 맞추며, 자신의 생각을 다른 사람에게 전달하는 정말 어려운 문제들을 다루지는 않습니다. 하지만 소통에 관한 훌륭한 책들이 많이 있으며, 각 장의 끝에서 안내해 드릴 것입니다.",
    "crumbs": [
      "소통 (Communicate)"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "28  Quarto",
    "section": "",
    "text": "28.1 소개\nQuarto는 코드, 결과, 산문을 결합하여 데이터 과학을 위한 통합 저작 프레임워크를 제공합니다. Quarto 문서는 완전히 재현 가능하며 PDF, Word 파일, 프레젠테이션 등과 같은 수십 가지 출력 형식을 지원합니다.\nQuarto 파일은 세 가지 방식으로 사용하도록 설계되었습니다:\nQuarto는 R 패키지가 아니라 명령줄 인터페이스 도구입니다. 즉, ?를 통해 도움말을 거의 이용할 수 없다는 의미입니다. 대신 이 장을 진행하면서, 그리고 나중에 Quarto를 사용할 때 Quarto 문서를 참조해야 합니다.\nR Markdown 사용자라면 “Quarto는 R Markdown과 매우 비슷하게 들리는데”라고 생각할 수 있습니다. 틀리지 않습니다! Quarto는 R Markdown 생태계(rmarkdown, bookdown, distill, xaringan 등)의 많은 패키지 기능을 하나의 일관된 시스템으로 통합할 뿐만 아니라 R 외에도 Python 및 Julia와 같은 여러 프로그래밍 언어에 대한 기본 지원으로 확장합니다. 어떤 의미에서 Quarto는 10년 동안 R Markdown 생태계를 확장하고 지원하면서 배운 모든 것을 반영합니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#소개",
    "href": "quarto.html#소개",
    "title": "28  Quarto",
    "section": "",
    "text": "분석 배후의 코드가 아니라 결론에 집중하고 싶은 의사 결정권자에게 소통하기 위해.\n결론뿐만 아니라 결론에 도달한 방법(즉, 코드)에도 관심이 있는 다른 데이터 과학자(미래의 자신 포함!)와 협업하기 위해.\n수행한 작업뿐만 아니라 생각했던 내용도 캡처할 수 있는 현대적인 실험실 노트로서 데이터 과학을 수행하는 환경으로.\n\n\n\n\n28.1.1 선수 지식\nQuarto 명령줄 인터페이스(Quarto CLI)가 필요하지만, 명시적으로 설치하거나 로드할 필요는 없습니다. RStudio가 필요할 때 자동으로 두 가지를 모두 수행하기 때문입니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#quarto-기초",
    "href": "quarto.html#quarto-기초",
    "title": "28  Quarto",
    "section": "\n28.2 Quarto 기초",
    "text": "28.2 Quarto 기초\n이것은 Quarto 파일입니다 – 확장자가 .qmd인 일반 텍스트 파일입니다:\n\n---\ntitle: \"다이아몬드 크기\"\ndate: 2022-09-12\nformat: html\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt;= 2.5)\n```\n\n우리는 `r nrow(diamonds)`개의 다이아몬드 데이터를 가지고 있습니다.\n그중 `r nrow(diamonds) - nrow(smaller)`개만이 2.5캐럿보다 큽니다.\n나머지의 분포는 아래와 같습니다:\n\n```{r}\n#| label: plot-smaller-diamonds\n#| echo: false\n\nsmaller |&gt; \n  ggplot(aes(x = carat)) + \n  geom_freqpoly(binwidth = 0.01)\n```\n\n여기에는 세 가지 중요한 유형의 콘텐츠가 포함되어 있습니다:\n\n\n---로 둘러싸인 (선택적) YAML 헤더.\n\n```로 둘러싸인 R 코드 청크.\n\n# heading 및 _italics_와 같은 간단한 텍스트 서식이 섞인 텍스트.\n\nFigure 28.1 은 코드와 출력이 인터리브된 노트북 인터페이스가 있는 RStudio의 .qmd 문서를 보여줍니다. Run 아이콘(청크 상단의 재생 버튼처럼 생김)을 클릭하거나 Cmd/Ctrl + Shift + Enter를 눌러 각 코드 청크를 실행할 수 있습니다. RStudio는 코드를 실행하고 결과를 코드와 함께 인라인으로 표시합니다.\n\n\n\n\n\n\n\nFigure 28.1: RStudio의 Quarto 문서. 코드와 출력이 문서에 인터리브되어 있으며, 플롯 출력이 코드 바로 아래에 나타납니다.\n\n\n\n\n문서에서 플롯과 출력을 보는 것이 마음에 들지 않고 RStudio의 콘솔 및 플롯 창을 사용하는 것을 선호한다면 “Render” 옆의 기어 아이콘을 클릭하고 Figure 28.2 에 표시된 대로 “Chunk Output in Console”로 전환할 수 있습니다.\n\n\n\n\n\n\n\nFigure 28.2: 플롯 창에 플롯 출력이 있는 RStudio의 Quarto 문서.\n\n\n\n\n모든 텍스트, 코드 및 결과가 포함된 전체 보고서를 생성하려면 “Render”를 클릭하거나 Cmd/Ctrl + Shift + K를 누르세요. quarto::quarto_render(\"diamond-sizes.qmd\")를 사용하여 프로그래밍 방식으로 수행할 수도 있습니다. 그러면 Figure 28.3 에 표시된 대로 뷰어 창에 보고서가 표시되고 HTML 파일이 생성됩니다.\n\n\n\n\n\n\n\nFigure 28.3: 뷰어 창에 렌더링된 문서가 있는 RStudio의 Quarto 문서.\n\n\n\n\n문서를 렌더링할 때 Quarto는 .qmd 파일을 knitr(https://yihui.org/knitr/)로 보내고, knitr는 모든 코드 청크를 실행하고 코드와 그 출력을 포함하는 새 마크다운(.md) 문서를 만듭니다. knitr에 의해 생성된 마크다운 파일은 pandoc(https://pandoc.org)에 의해 처리되어 완성된 파일을 만드는 역할을 합니다. 이 프로세스는 Figure 28.4 에 나와 있습니다. 이 2단계 워크플로우의 장점은 Chapter 29 에서 배우게 될 것처럼 매우 광범위한 출력 형식을 만들 수 있다는 것입니다.\n\n\n\n\n\n\n\nFigure 28.4: qmd에서 knitr, md, pandoc, 그리고 PDF, MS Word 또는 HTML 형식의 출력으로 이어지는 Quarto 워크플로우 다이어그램.\n\n\n\n\n자신만의 .qmd 파일로 시작하려면 메뉴 모음에서 File &gt; New File &gt; Quarto Document…를 선택하세요. RStudio는 Quarto의 주요 기능이 작동하는 방식을 상기시켜주는 유용한 콘텐츠로 파일을 미리 채우는 데 사용할 수 있는 마법사를 시작합니다.\n다음 섹션에서는 Quarto 문서의 세 가지 구성 요소인 마크다운 텍스트, 코드 청크, YAML 헤더에 대해 자세히 설명합니다.\n\n28.2.1 연습문제\n\nFile &gt; New File &gt; Quarto Document를 사용하여 새 Quarto 문서를 만드세요. 지침을 읽으세요. 청크를 개별적으로 실행하는 연습을 하세요. 그런 다음 적절한 버튼을 클릭하고 적절한 키보드 단축키를 사용하여 문서를 렌더링하세요. 코드를 수정하고 다시 실행하여 수정된 출력을 볼 수 있는지 확인하세요.\n세 가지 내장 형식인 HTML, PDF, Word 각각에 대해 하나의 새 Quarto 문서를 만드세요. 세 문서를 각각 렌더링하세요. 출력은 어떻게 다릅니까? 입력은 어떻게 다릅니까? (PDF 출력을 빌드하려면 LaTeX를 설치해야 할 수 있습니다. 필요한 경우 RStudio가 알려줄 것입니다.)",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#비주얼-에디터",
    "href": "quarto.html#비주얼-에디터",
    "title": "28  Quarto",
    "section": "\n28.3 비주얼 에디터",
    "text": "28.3 비주얼 에디터\nRStudio의 비주얼 에디터는 Quarto 문서를 작성하기 위한 WYSIWYM 인터페이스를 제공합니다. 내부적으로 Quarto 문서(.qmd 파일)의 산문은 일반 텍스트 파일 서식을 지정하기 위한 가벼운 규칙 집합인 Markdown으로 작성됩니다. 실제로 Quarto는 테이블, 인용, 상호 참조, 각주, div/span, 정의 목록, 속성, 원시 HTML/TeX 등을 포함한 Pandoc 마크다운(Quarto가 이해하는 약간 확장된 버전의 Markdown)을 사용하며 코드 셀 실행 및 출력 인라인 보기를 지원합니다. Markdown은 읽고 쓰기 쉽도록 설계되었지만 Section 28.4 에서 볼 수 있듯이 여전히 새로운 구문을 배워야 합니다. 따라서 .qmd 파일과 같은 계산 문서가 처음이지만 Google Docs나 MS Word와 같은 도구를 사용한 경험이 있는 경우 RStudio에서 Quarto를 시작하는 가장 쉬운 방법은 비주얼 에디터입니다.\n비주얼 에디터에서는 메뉴 모음의 버튼을 사용하여 이미지, 표, 상호 참조 등을 삽입하거나 포괄적인 ⌘ + / 또는 Ctrl + / 단축키를 사용하여 거의 모든 것을 삽입할 수 있습니다. 줄의 시작 부분에 있는 경우(Figure 28.5 에 표시된 대로) /만 입력하여 단축키를 호출할 수도 있습니다.\n\n\n\n\n\n\n\nFigure 28.5: Quarto 비주얼 에디터.\n\n\n\n\n이미지 삽입 및 표시 방식 사용자 정의도 비주얼 에디터로 용이하게 수행할 수 있습니다. 클립보드의 이미지를 비주얼 에디터에 직접 붙여넣거나(그러면 RStudio가 프로젝트 디렉토리에 해당 이미지의 사본을 배치하고 링크함) 비주얼 에디터의 Insert &gt; Figure / Image 메뉴를 사용하여 삽입할 이미지를 찾아보거나 URL을 붙여넣을 수 있습니다. 또한 동일한 메뉴를 사용하여 이미지 크기를 조정하고 캡션, 대체 텍스트 및 링크를 추가할 수 있습니다.\n비주얼 에디터에는 여기에 나열하지 않은 더 많은 기능이 있으며, 작성 경험을 쌓으면서 유용하게 사용할 수 있습니다.\n가장 중요한 점은 비주얼 에디터가 콘텐츠를 서식과 함께 표시하지만 내부적으로는 콘텐츠를 일반 Markdown으로 저장하며 비주얼 에디터와 소스 에디터 사이를 전환하며 두 도구 중 하나를 사용하여 콘텐츠를 보고 편집할 수 있다는 것입니다.\n\n28.3.1 연습문제\n\n비주얼 에디터를 사용하여 Figure 28.5 의 문서를 다시 만드세요.\n비주얼 에디터를 사용하여 Insert 메뉴와 무엇이든 삽입 도구를 사용하여 코드 청크를 삽입하세요.\n비주얼 에디터를 사용하여 다음 방법을 알아내세요:\n\n각주 추가.\n수평선 추가.\n인용구 블록 추가.\n\n\n비주얼 에디터에서 Insert &gt; Citation으로 이동하여 Welcome to the Tidyverse 논문에 대한 인용을 DOI(디지털 객체 식별자) 10.21105/joss.01686을 사용하여 삽입하세요. 문서를 렌더링하고 참조가 문서에 어떻게 나타나는지 관찰하세요. 문서의 YAML에서 어떤 변화를 관찰할 수 있습니까?",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-source-editor",
    "href": "quarto.html#sec-source-editor",
    "title": "28  Quarto",
    "section": "\n28.4 소스 에디터",
    "text": "28.4 소스 에디터\n비주얼 에디터의 도움 없이 RStudio의 소스 에디터를 사용하여 Quarto 문서를 편집할 수도 있습니다. 비주얼 에디터가 Google docs와 같은 도구로 작성한 경험이 있는 사람들에게 친숙하게 느껴진다면, 소스 에디터는 R 스크립트나 R Markdown 문서를 작성한 경험이 있는 사람들에게 친숙하게 느껴질 것입니다. 소스 에디터는 일반 텍스트에서 이러한 오류를 잡는 것이 더 쉬운 경우가 많으므로 Quarto 구문 오류를 디버깅하는 데 유용할 수 있습니다.\n아래 가이드는 소스 에디터에서 Quarto 문서를 작성하기 위해 Pandoc의 Markdown을 사용하는 방법을 보여줍니다.\n\n## Text formatting\n\n*italic* **bold** ~~strikeout~~ `code`\n\nsuperscript^2^ subscript~2~\n\n[underline]{.underline} [small caps]{.smallcaps}\n\n## Headings\n\n# 1st Level Header\n\n## 2nd Level Header\n\n### 3rd Level Header\n\n## Lists\n\n-   Bulleted list item 1\n\n-   Item 2\n\n    -   Item 2a\n\n    -   Item 2b\n\n1.  Numbered list item 1\n\n2.  Item 2.\n    The numbers are incremented automatically in the output.\n\n## Links and images\n\n&lt;http://example.com&gt;\n\n[linked phrase](http://example.com)\n\n![optional caption text](quarto.png){fig-alt=\"Quarto logo and the word quarto spelled in small case letters\"}\n\n## Tables\n\n| First Header | Second Header |\n|--------------|---------------|\n| Content Cell | Content Cell  |\n| Content Cell | Content Cell  |\n\n이것들을 배우는 가장 좋은 방법은 단순히 시도해 보는 것입니다. 며칠이 걸리겠지만 곧 제2의 천성이 되어 생각할 필요가 없게 될 것입니다. 잊어버린 경우 Help &gt; Markdown Quick Reference를 통해 편리한 참조 시트를 얻을 수 있습니다.\n\n28.4.1 연습문제\n\n간단한 이력서를 만들어 배운 내용을 연습하세요. 제목은 이름이어야 하며, (적어도) 교육 또는 고용에 대한 제목을 포함해야 합니다. 각 섹션에는 직업/학위의 글머리 기호 목록이 포함되어야 합니다. 연도를 굵게 강조하세요.\n\n소스 에디터와 Markdown 빠른 참조를 사용하여 다음 방법을 알아내세요:\n\n각주 추가.\n수평선 추가.\n인용구 블록 추가.\n\n\nhttps://github.com/hadley/r4ds/tree/main/quarto에서 diamond-sizes.qmd의 내용을 로컬 R Quarto 문서에 복사하여 붙여넣으세요. 실행할 수 있는지 확인한 다음, 가장 눈에 띄는 특징을 설명하는 텍스트를 빈도 다각형 뒤에 추가하세요.\nGoogle doc이나 MS Word에서 문서를 만들거나(또는 이전에 만든 문서를 찾아서) 제목, 하이퍼링크, 서식이 있는 텍스트 등과 같은 콘텐츠를 넣으세요. 이 문서의 내용을 복사하여 비주얼 에디터의 Quarto 문서에 붙여넣으세요. 그런 다음 소스 에디터로 전환하여 소스 코드를 검사하세요.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#코드-청크",
    "href": "quarto.html#코드-청크",
    "title": "28  Quarto",
    "section": "\n28.5 코드 청크",
    "text": "28.5 코드 청크\nQuarto 문서 내에서 코드를 실행하려면 청크를 삽입해야 합니다. 세 가지 방법이 있습니다:\n\n키보드 단축키 Cmd + Option + I / Ctrl + Alt + I.\n에디터 도구 모음의 “Insert” 버튼 아이콘.\n청크 구분 기호 ```{r} 및 ```를 수동으로 입력.\n\n키보드 단축키를 배우는 것을 추천합니다. 장기적으로 많은 시간을 절약해 줄 것입니다!\n이제 알게 되어 좋아하게 되었기를 바라는 키보드 단축키 Cmd/Ctrl + Enter를 사용하여 코드를 계속 실행할 수 있습니다. 그러나 청크에는 새로운 키보드 단축키가 있습니다: Cmd/Ctrl + Shift + Enter는 청크의 모든 코드를 실행합니다. 청크를 함수처럼 생각하세요. 청크는 비교적 독립적이어야 하며 단일 작업에 집중해야 합니다.\n다음 섹션에서는 ```{r}로 구성되고 뒤에 선택적 청크 레이블과 #|로 표시된 각 줄에 있는 다양한 기타 청크 옵션이 오는 청크 헤더에 대해 설명합니다.\n\n28.5.1 청크 레이블\n청크에는 선택적 레이블을 지정할 수 있습니다. 예:\n\n```{r}\n#| label: simple-addition\n1 + 1\n```\n#&gt; [1] 2\n\n이것은 세 가지 장점이 있습니다:\n\n\n스크립트 에디터 왼쪽 하단의 드롭다운 코드 탐색기를 사용하여 특정 청크로 더 쉽게 이동할 수 있습니다:\n\n\n\n\n\n\n\n\n\n청크에 의해 생성된 그래픽은 다른 곳에서 사용하기 더 쉬운 유용한 이름을 갖게 됩니다. 이에 대해서는 Section 28.6 에서 자세히 설명합니다.\n캐시된 청크의 네트워크를 설정하여 실행할 때마다 비용이 많이 드는 계산을 다시 수행하지 않도록 할 수 있습니다. 이에 대해서는 Section 28.8 에서 자세히 설명합니다.\n\n청크 레이블은 짧지만 기억에 남아야 하며 공백을 포함해서는 안 됩니다. 단어를 구분할 때는 밑줄(_) 대신 대시(-)를 사용하고 청크 레이블에 다른 특수 문자를 사용하지 않는 것이 좋습니다.\n일반적으로 원하는 대로 청크에 레이블을 지정할 수 있지만 특별한 동작을 부여하는 청크 이름이 하나 있습니다: setup. 노트북 모드에 있을 때 setup이라는 이름의 청크는 다른 코드가 실행되기 전에 한 번 자동으로 실행됩니다.\n또한 청크 레이블은 중복될 수 없습니다. 각 청크 레이블은 고유해야 합니다.\n\n28.5.2 청크 옵션\n청크 출력은 청크 헤더에 제공되는 필드인 옵션으로 사용자 정의할 수 있습니다. Knitr는 코드 청크를 사용자 정의하는 데 사용할 수 있는 거의 60개의 옵션을 제공합니다. 여기서는 자주 사용하는 가장 중요한 청크 옵션을 다룰 것입니다. 전체 목록은 https://yihui.org/knitr/options에서 볼 수 있습니다.\n가장 중요한 옵션 세트는 코드 블록이 실행되는지 여부와 완성된 보고서에 삽입되는 결과를 제어합니다:\n\neval: false는 코드가 평가되는 것을 방지합니다. (그리고 분명히 코드가 실행되지 않으면 결과가 생성되지 않습니다). 이것은 예제 코드를 표시하거나 각 줄을 주석 처리하지 않고 큰 코드 블록을 비활성화하는 데 유용합니다.\ninclude: false는 코드를 실행하지만 최종 문서에 코드나 결과를 표시하지 않습니다. 보고서를 어지럽히고 싶지 않은 설정 코드에 이것을 사용하세요.\necho: false는 코드가 완성된 파일에 나타나지 않도록 방지하지만 결과는 나타납니다. 기본 R 코드를 보고 싶어하지 않는 사람들을 대상으로 보고서를 작성할 때 이것을 사용하세요.\nmessage: false 또는 warning: false는 메시지나 경고가 완성된 파일에 나타나지 않도록 방지합니다.\nresults: hide는 인쇄된 출력을 숨깁니다; fig-show: hide는 플롯을 숨깁니다.\nerror: true는 코드가 오류를 반환하더라도 렌더링을 계속하도록 합니다. 이것은 보고서의 최종 버전에 포함하고 싶은 경우는 거의 없지만, .qmd 내부에서 정확히 무슨 일이 일어나고 있는지 디버깅해야 하는 경우 매우 유용할 수 있습니다. R을 가르치고 의도적으로 오류를 포함하려는 경우에도 유용합니다. 기본값인 error: false는 문서에 오류가 하나라도 있으면 렌더링이 실패하도록 합니다.\n\n이러한 각 청크 옵션은 #| 뒤에 청크 헤더에 추가됩니다. 예를 들어, 다음 청크에서는 eval이 false로 설정되어 있으므로 결과가 인쇄되지 않습니다.\n\n```{r}\n#| label: simple-multiplication\n#| eval: false\n2 * 2\n```\n\n다음 표는 각 옵션이 억제하는 출력 유형을 요약합니다:\n\n\n\n\n\n\n\n\n\n\n\nOption\nRun code\nShow code\nOutput\nPlots\nMessages\nWarnings\n\n\n\neval: false\nX\n\nX\nX\nX\nX\n\n\ninclude: false\n\nX\nX\nX\nX\nX\n\n\necho: false\n\nX\n\n\n\n\n\n\nresults: hide\n\n\nX\n\n\n\n\n\nfig-show: hide\n\n\n\nX\n\n\n\n\nmessage: false\n\n\n\n\nX\n\n\n\nwarning: false\n\n\n\n\n\nX\n\n\n\n28.5.3 전역 옵션\nknitr로 더 많은 작업을 수행하면 기본 청크 옵션 중 일부가 필요에 맞지 않아 변경하고 싶을 때가 있습니다.\n문서 YAML의 execute 아래에 선호하는 옵션을 추가하여 이를 수행할 수 있습니다. 예를 들어, 코드는 볼 필요가 없고 결과와 서술만 필요한 청중을 위해 보고서를 준비하는 경우 문서 수준에서 echo: false를 설정할 수 있습니다. 그렇게 하면 기본적으로 코드가 숨겨지므로 의도적으로 표시하도록 선택한 청크(echo: true 사용)만 표시됩니다. message: false 및 warning: false를 설정하는 것을 고려할 수 있지만, 그러면 최종 문서에 메시지가 표시되지 않기 때문에 문제를 디버깅하기가 더 어려워집니다.\ntitle: \"My report\"\nexecute:\n  echo: false\nQuarto는 다국어(R뿐만 아니라 Python, Julia 등과 같은 다른 언어와도 작동)로 설계되었으므로, 문서 실행 수준에서는 모든 knitr 옵션을 사용할 수 없습니다. 일부 옵션은 knitr에서만 작동하고 Quarto가 다른 언어로 코드를 실행하는 데 사용하는 다른 엔진(예: Jupyter)에서는 작동하지 않기 때문입니다. 그러나 knitr 필드 아래, opts_chunk 아래에서 문서에 대한 전역 옵션으로 이것들을 설정할 수 있습니다. 예를 들어, 책과 튜토리얼을 작성할 때 우리는 다음과 같이 설정합니다:\ntitle: \"Tutorial\"\nknitr:\n  opts_chunk:\n    comment: \"#&gt;\"\n    collapse: true\n이것은 우리가 선호하는 주석 형식을 사용하고 코드와 출력이 밀접하게 얽혀 있도록 합니다.\n\n28.5.4 인라인 코드\nQuarto 문서에 R 코드를 삽입하는 또 다른 방법이 있습니다: 텍스트에 직접 `r `을 사용합니다. 텍스트에서 데이터의 속성을 언급할 때 매우 유용할 수 있습니다. 예를 들어, 장의 시작 부분에서 사용된 예제 문서에는 다음이 있었습니다:\n\nWe have data about `r nrow(diamonds)` diamonds. Only `r nrow(diamonds) - nrow(smaller)` are larger than 2.5 carats. The distribution of the remainder is shown below:\n\n보고서가 렌더링되면 이러한 계산 결과가 텍스트에 삽입됩니다:\n\nWe have data about 53940 diamonds. Only 126 are larger than 2.5 carats. The distribution of the remainder is shown below:\n\n텍스트에 숫자를 삽입할 때 format()은 당신의 친구입니다. digits 수를 설정하여 터무니없는 정밀도로 인쇄하지 않도록 하고, 숫자를 더 읽기 쉽게 만들기 위해 big.mark를 설정할 수 있습니다. 이것들을 도우미 함수로 결합할 수 있습니다:\n\ncomma &lt;- function(x) format(x, digits = 2, big.mark = \",\")\ncomma(3452345)\n#&gt; [1] \"3,452,345\"\ncomma(.12358124331)\n#&gt; [1] \"0.12\"\n\n\n28.5.5 연습문제\n\n다이아몬드 크기가 컷, 색상 및 투명도에 따라 어떻게 달라지는지 탐구하는 섹션을 추가하세요. R을 모르는 사람을 위해 보고서를 작성하고 있다고 가정하고 각 청크에 echo: false를 설정하는 대신 전역 옵션을 설정하세요.\nhttps://github.com/hadley/r4ds/tree/main/quarto에서 diamond-sizes.qmd를 다운로드하세요. 가장 중요한 속성을 표시하는 표를 포함하여 가장 큰 20개의 다이아몬드를 설명하는 섹션을 추가하세요.\ndiamonds-sizes.qmd를 수정하여 label_comma()를 사용하여 보기 좋게 포맷된 출력을 생성하세요. 또한 2.5캐럿보다 큰 다이아몬드의 비율을 포함하세요.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-figures",
    "href": "quarto.html#sec-figures",
    "title": "28  Quarto",
    "section": "\n28.6 그림",
    "text": "28.6 그림\nQuarto 문서의 그림은 임베디드(예: PNG 또는 JPEG 파일)되거나 코드 청크의 결과로 생성될 수 있습니다.\n외부 파일의 이미지를 삽입하려면 RStudio의 비주얼 에디터에서 Insert 메뉴를 사용하고 Figure / Image를 선택하세요. 그러면 삽입할 이미지를 찾아보고 대체 텍스트나 캡션을 추가하고 크기를 조정할 수 있는 메뉴가 팝업됩니다. 비주얼 에디터에서 클립보드의 이미지를 문서에 붙여넣기만 하면 RStudio가 해당 이미지의 사본을 프로젝트 폴더에 배치합니다.\n그림을 생성하는 코드 청크(예: ggplot() 호출 포함)를 포함하면 결과 그림이 Quarto 문서에 자동으로 포함됩니다.\n\n28.6.1 그림 크기 조정\nQuarto에서 그래픽의 가장 큰 과제는 그림의 크기와 모양을 올바르게 만드는 것입니다. 그림 크기를 제어하는 다섯 가지 주요 옵션이 있습니다: fig-width, fig-height, fig-asp, out-width 및 out-height. 이미지 크기 조정은 두 가지 크기(R이 생성한 그림의 크기와 출력 문서에 삽입되는 크기)와 크기를 지정하는 여러 방법(즉, 높이, 너비, 가로세로 비율: 셋 중 두 개 선택)이 있기 때문에 까다롭습니다.\n다섯 가지 옵션 중 세 가지를 권장합니다:\n\n플롯은 너비가 일관적일 때 미적으로 더 보기 좋은 경향이 있습니다. 이를 강제하려면 기본값에서 fig-width: 6 (6”) 및 fig-asp: 0.618 (황금비)을 설정하세요. 그런 다음 개별 청크에서 fig-asp만 조정하세요.\n\nout-width로 출력 크기를 제어하고 출력 문서 본문 너비의 백분율로 설정하세요. out-width: \"70%\" 및 fig-align: center를 제안합니다.\n이렇게 하면 플롯이 너무 많은 공간을 차지하지 않으면서 숨 쉴 공간을 줍니다.\n\n여러 플롯을 한 행에 넣으려면 두 플롯의 경우 layout-ncol을 2로, 세 플롯의 경우 3 등으로 설정하세요. 이렇게 하면 layout-ncol이 2인 경우 각 플롯에 대해 out-width가 사실상 “50%”로 설정되고 layout-ncol이 3인 경우 “33%” 등으로 설정됩니다. 설명하려는 내용(예: 데이터 표시 또는 플롯 변형 표시)에 따라 아래에서 설명하는 것처럼 fig-width를 조정할 수도 있습니다.\n\n플롯의 텍스트를 읽기 위해 눈을 가늘게 뜨고 봐야 한다면 fig-width를 조정해야 합니다. fig-width가 최종 문서에서 렌더링되는 그림 크기보다 크면 텍스트가 너무 작아집니다. fig-width가 작으면 텍스트가 너무 커집니다. 문서의 fig-width와 최종 너비 사이의 올바른 비율을 파악하기 위해 약간의 실험을 해야 할 때가 많습니다. 원리를 설명하기 위해 다음 세 플롯은 각각 4, 6, 8의 fig-width를 가집니다:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n모든 그림에서 글꼴 크기가 일관되도록 하려면 out-width를 설정할 때마다 기본 out-width와 동일한 비율을 유지하도록 fig-width도 조정해야 합니다. 예를 들어 기본 fig-width가 6이고 out-width가 “70%”인 경우 out-width: \"50%\"로 설정할 때 fig-width를 4.3(6 * 0.5 / 0.7)으로 설정해야 합니다.\n그림 크기 조정 및 스케일링은 예술이자 과학이며 올바르게 수행하려면 반복적인 시행착오 접근 방식이 필요할 수 있습니다. 플롯 스케일링 제어하기 블로그 게시물에서 그림 크기 조정에 대해 자세히 알아볼 수 있습니다.\n\n28.6.2 기타 중요한 옵션\n이 책에서처럼 코드와 텍스트를 섞을 때 fig-show: hold를 설정하여 플롯이 코드 뒤에 표시되도록 할 수 있습니다. 이것은 큰 코드 블록을 설명과 함께 나누도록 강제하는 즐거운 부작용이 있습니다.\n플롯에 캡션을 추가하려면 fig-cap을 사용하세요. Quarto에서 이것은 그림을 인라인에서 “플로팅(floating)”으로 변경합니다.\nPDF 출력을 생성하는 경우 기본 그래픽 유형은 PDF입니다. PDF는 고품질 벡터 그래픽이므로 좋은 기본값입니다. 그러나 수천 개의 점을 표시하는 경우 매우 크고 느린 플롯을 생성할 수 있습니다. 이 경우 fig-format: \"png\"를 설정하여 PNG 사용을 강제하세요. 품질은 약간 낮지만 훨씬 더 컴팩트합니다.\n다른 청크에 일상적으로 레이블을 지정하지 않더라도 그림을 생성하는 코드 청크에는 이름을 지정하는 것이 좋습니다. 청크 레이블은 디스크의 그래픽 파일 이름을 생성하는 데 사용되므로 청크 이름을 지정하면 플롯을 골라내고 다른 상황(예: 이메일에 단일 플롯을 빠르게 넣으려는 경우)에서 재사용하기가 훨씬 쉽습니다.\n\n28.6.3 연습문제\n\n비주얼 에디터에서 diamond-sizes.qmd를 열고 다이아몬드 이미지를 찾아 복사하여 문서에 붙여넣으세요. 이미지를 두 번 클릭하고 캡션을 추가하세요. 이미지 크기를 조정하고 문서를 렌더링하세요. 이미지가 현재 작업 디렉토리에 어떻게 저장되는지 관찰하세요.\n\ndiamond-sizes.qmd에서 플롯을 생성하는 코드 청크의 레이블을 접두사 fig-로 시작하도록 편집하고 청크 옵션 fig-cap으로 그림에 캡션을 추가하세요. 그런 다음 코드 청크 위의 텍스트를 편집하여 Insert &gt; Cross Reference로 그림에 대한 상호 참조를 추가하세요.\n다음 청크 옵션을 한 번에 하나씩 사용하여 그림의 크기를 변경하고 문서를 렌더링한 다음 그림이 어떻게 변하는지 설명하세요.\n\nfig-width: 10\nfig-height: 3\nout-width: \"100%\"\nout-width: \"20%\"",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#표",
    "href": "quarto.html#표",
    "title": "28  Quarto",
    "section": "\n28.7 표",
    "text": "28.7 표\n그림과 마찬가지로 Quarto 문서에 두 가지 유형의 표를 포함할 수 있습니다. Quarto 문서에서 직접(표 삽입 메뉴 사용) 만드는 마크다운 표일 수도 있고 코드 청크의 결과로 생성된 표일 수도 있습니다. 이 섹션에서는 후자, 즉 계산을 통해 생성된 표에 초점을 맞출 것입니다.\n기본적으로 Quarto는 콘솔에서 보는 것처럼 데이터 프레임과 행렬을 인쇄합니다:\n\nmtcars[1:5, ]\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n추가 서식이 지정된 데이터가 표시되기를 원한다면 knitr::kable() 함수를 사용할 수 있습니다. 아래 코드는 Table 28.1 을 생성합니다.\n\nknitr::kable(mtcars[1:5, ], )\n\n\nTable 28.1: knitr kable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\n\n\n표를 사용자 정의할 수 있는 다른 방법을 보려면 ?knitr::kable 설명서를 읽어보세요. 더 깊은 사용자 정의를 위해서는 gt, huxtable, reactable, kableExtra, xtable, stargazer, pander, tables, ascii 패키지를 고려해 보세요. 각각은 R 코드에서 서식이 지정된 표를 반환하기 위한 도구 세트를 제공합니다.\n\n28.7.1 연습문제\n\n비주얼 에디터에서 diamond-sizes.qmd를 열고 코드 청크를 삽입한 다음 diamonds 데이터 프레임의 처음 5행을 보여주는 knitr::kable()이 있는 표를 추가하세요.\n대신 gt::gt()로 같은 표를 표시하세요.\n접두사 tbl-로 시작하는 청크 레이블을 추가하고 청크 옵션 tbl-cap으로 표에 캡션을 추가하세요. 그런 다음 코드 청크 위의 텍스트를 편집하여 Insert &gt; Cross Reference로 표에 대한 상호 참조를 추가하세요.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-caching",
    "href": "quarto.html#sec-caching",
    "title": "28  Quarto",
    "section": "\n28.8 캐싱",
    "text": "28.8 캐싱\n일반적으로 문서의 각 렌더링은 완전히 깨끗한 상태에서 시작합니다. 이것은 모든 중요한 계산을 코드로 캡처했음을 보장하기 때문에 재현성에 좋습니다. 그러나 시간이 오래 걸리는 계산이 있는 경우 고통스러울 수 있습니다. 해결책은 cache: true입니다.\n표준 YAML 옵션을 사용하여 문서의 모든 계산 결과를 캐싱하기 위해 문서 수준에서 Knitr 캐시를 활성화할 수 있습니다:\n---\ntitle: \"My Document\"\nexecute: \n  cache: true\n---\n또한 특정 청크의 계산 결과를 캐싱하기 위해 청크 수준에서 캐싱을 활성화할 수도 있습니다:\n\n```{r}\n#| cache: true\n# 시간이 오래 걸리는 계산 코드...\n```\n\n설정되면 청크의 출력을 디스크의 특별한 이름의 파일에 저장합니다. 후속 실행에서 knitr는 코드가 변경되었는지 확인하고 변경되지 않았으면 캐시된 결과를 재사용합니다.\n캐싱 시스템은 주의해서 사용해야 합니다. 기본적으로 종속성이 아닌 코드에만 기반하기 때문입니다. 예를 들어, 여기서 processed_data 청크는 raw-data 청크에 의존합니다:\n``` {{r}}\n#| label: raw-data\n#| cache: true\nrawdata &lt;- readr::read_csv(\"a_very_large_file.csv\")\n```\n``` {{r}}\n#| label: processed_data\n#| cache: true\nprocessed_data &lt;- rawdata |&gt; \n  filter(!is.na(import_var)) |&gt; \n  mutate(new_variable = complicated_transformation(x, y, z))\n```\nprocessed_data 청크를 캐싱한다는 것은 dplyr 파이프라인이 변경되면 다시 실행되지만 read_csv() 호출이 변경되면 다시 실행되지 않음을 의미합니다. dependson 청크 옵션으로 이 문제를 피할 수 있습니다:\n``` {{r}}\n#| label: processed-data\n#| cache: true\n#| dependson: \"raw-data\"\nprocessed_data &lt;- rawdata |&gt; \n  filter(!is.na(import_var)) |&gt; \n  mutate(new_variable = complicated_transformation(x, y, z))\n```\ndependson은 캐시된 청크가 의존하는 모든 청크의 문자 벡터를 포함해야 합니다. Knitr는 종속성 중 하나가 변경된 것을 감지할 때마다 캐시된 청크의 결과를 업데이트합니다.\nknitr 캐싱은 .qmd 파일 내의 변경 사항만 추적하기 때문에 a_very_large_file.csv가 변경되어도 청크가 업데이트되지 않습니다. 해당 파일의 변경 사항도 추적하려면 cache.extra 옵션을 사용할 수 있습니다. 이것은 변경될 때마다 캐시를 무효화하는 임의의 R 표현식입니다. 사용하기 좋은 함수는 file.mtime()입니다: 마지막으로 수정된 시간을 반환합니다. 그러면 다음과 같이 쓸 수 있습니다:\n``` {{r}}\n#| label: raw-data\n#| cache: true\n#| cache.extra: !expr file.mtime(\"a_very_large_file.csv\")\nrawdata &lt;- readr::read_csv(\"a_very_large_file.csv\")\n```\n우리는 David Robinson의 조언에 따라 청크 이름을 지정했습니다: 각 청크는 생성하는 기본 객체의 이름을 따서 명명됩니다. 이렇게 하면 dependson 사양을 이해하기 더 쉬워집니다.\n캐싱 전략이 점점 더 복잡해짐에 따라 정기적으로 knitr::clean_cache()로 모든 캐시를 지우는 것이 좋습니다.\n\n28.8.1 연습문제\n\n\nd가 c와 b에 의존하고 b와 c 모두 a에 의존하는 청크 네트워크를 설정하세요. 각 청크가 lubridate::now()를 인쇄하고 cache: true를 설정한 다음 캐싱에 대한 이해를 확인하세요.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#문제-해결",
    "href": "quarto.html#문제-해결",
    "title": "28  Quarto",
    "section": "\n28.9 문제 해결",
    "text": "28.9 문제 해결\nQuarto 문서 문제 해결은 더 이상 대화형 R 환경에 있지 않기 때문에 어려울 수 있으며 몇 가지 새로운 요령을 배워야 합니다. 또한 오류는 Quarto 문서 자체의 문제이거나 Quarto 문서 내의 R 코드 문제일 수 있습니다.\n코드 청크가 있는 문서에서 흔히 발생하는 오류 중 하나는 중복된 청크 레이블이며, 코드 청크를 복사하여 붙여넣는 워크플로우를 사용하는 경우 특히 만연합니다. 이 문제를 해결하려면 중복된 레이블 중 하나를 변경하기만 하면 됩니다.\n오류가 문서의 R 코드로 인한 것이라면 가장 먼저 시도해야 할 것은 대화형 세션에서 문제를 재현하는 것입니다. R을 다시 시작한 다음 Code 메뉴의 Run region 아래에서 “Run all chunks”를 실행하거나 키보드 단축키 Ctrl + Alt + R을 사용하세요. 운이 좋다면 문제가 재현되어 대화형으로 무슨 일이 일어나고 있는지 파악할 수 있습니다.\n도움이 되지 않는다면 대화형 환경과 Quarto 환경 사이에 뭔가 다른 점이 있는 것입니다. 옵션을 체계적으로 탐색해야 합니다. 가장 흔한 차이점은 작업 디렉토리입니다: Quarto의 작업 디렉토리는 파일이 있는 디렉토리입니다. 청크에 getwd()를 포함하여 작업 디렉토리가 예상한 것인지 확인하세요.\n다음으로 버그를 유발할 수 있는 모든 것을 브레인스토밍하세요. R 세션과 Quarto 세션에서 동일한지 체계적으로 확인해야 합니다. 가장 쉬운 방법은 문제를 일으키는 청크에 error: true를 설정한 다음 print()와 str()을 사용하여 설정이 예상대로인지 확인하는 것입니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#yaml-헤더",
    "href": "quarto.html#yaml-헤더",
    "title": "28  Quarto",
    "section": "\n28.10 YAML 헤더",
    "text": "28.10 YAML 헤더\nYAML 헤더의 매개변수를 조정하여 다른 많은 “전체 문서” 설정을 제어할 수 있습니다. YAML이 무엇을 의미하는지 궁금할 수 있습니다: “YAML Ain’t Markup Language”의 약자로, 사람이 읽고 쓰기 쉬운 방식으로 계층적 데이터를 표현하도록 설계되었습니다. Quarto는 이를 사용하여 출력의 많은 세부 사항을 제어합니다. 여기서는 자체 포함 문서, 문서 매개변수, 참고 문헌의 세 가지를 논의하겠습니다.\n\n28.10.1 자체 포함\nHTML 문서는 일반적으로 여러 외부 종속성(예: 이미지, CSS 스타일 시트, 자바스크립트 등)을 가지며, 기본적으로 Quarto는 이러한 종속성을 .qmd 파일과 같은 디렉토리의 _files 폴더에 배치합니다. HTML 파일을 호스팅 플랫폼(예: QuartoPub, https://quartopub.com/)에 게시하면 이 디렉토리의 종속성이 문서와 함께 게시되므로 게시된 보고서에서 사용할 수 있습니다. 그러나 보고서를 동료에게 이메일로 보내려면 모든 종속성을 포함하는 단일 자체 포함 HTML 문서를 선호할 수 있습니다. embed-resources 옵션을 지정하여 이를 수행할 수 있습니다:\nformat:\n  html:\n    embed-resources: true\n결과 파일은 브라우저에서 올바르게 표시하기 위해 외부 파일이나 인터넷 액세스가 필요하지 않도록 자체 포함됩니다.\n\n28.10.2 매개변수\nQuarto 문서에는 보고서를 렌더링할 때 값을 설정할 수 있는 하나 이상의 매개변수가 포함될 수 있습니다. 매개변수는 다양한 주요 입력에 대해 고유한 값으로 동일한 보고서를 다시 렌더링하려는 경우 유용합니다. 예를 들어 지점별 판매 보고서, 학생별 시험 결과 또는 국가별 인구 통계 요약을 생성할 수 있습니다. 하나 이상의 매개변수를 선언하려면 params 필드를 사용하세요.\n이 예제에서는 my_class 매개변수를 사용하여 표시할 자동차 클래스를 결정합니다:\n\n---\nformat: html\nparams:\n  my_class: \"suv\"\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nclass &lt;- mpg |&gt; filter(class == params$my_class)\n```\n\n# `r params$my_class`의 연비\n\n```{r}\n#| message: false\n\nggplot(class, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n```\n\n보시다시피 매개변수는 코드 청크 내에서 params라는 읽기 전용 리스트로 사용할 수 있습니다.\n원자 벡터를 YAML 헤더에 직접 쓸 수 있습니다. 매개변수 값 앞에 !expr를 붙여 임의의 R 표현식을 실행할 수도 있습니다. 이것은 날짜/시간 매개변수를 지정하는 좋은 방법입니다.\nparams:\n  start: !expr lubridate::ymd(\"2015-01-01\")\n  snapshot: !expr lubridate::ymd_hms(\"2015-01-01 12:30:00\")\n\n28.10.3 참고 문헌 및 인용\nQuarto는 여러 스타일의 인용 및 참고 문헌을 자동으로 생성할 수 있습니다. Quarto 문서에 인용 및 참고 문헌을 추가하는 가장 간단한 방법은 RStudio의 비주얼 에디터를 사용하는 것입니다.\n비주얼 에디터를 사용하여 인용을 추가하려면 Insert &gt; Citation으로 이동하세요. 인용은 다양한 소스에서 삽입할 수 있습니다:\n\nDOI (디지털 객체 식별자) 참조.\nZotero 개인 또는 그룹 라이브러리.\nCrossref, DataCite 또는 PubMed 검색.\n문서 참고 문헌(문서 디렉토리의 .bib 파일)\n\n내부적으로 시각적 모드는 인용에 대해 표준 Pandoc 마크다운 표현(예: [@citation])을 사용합니다.\n처음 세 가지 방법 중 하나를 사용하여 인용을 추가하면 비주얼 에디터가 자동으로 bibliography.bib 파일을 만들고 참조를 추가합니다. 또한 문서 YAML에 bibliography 필드를 추가합니다. 참조를 더 추가하면 이 파일이 인용으로 채워집니다. BibLaTeX, BibTeX, EndNote, Medline을 포함한 많은 일반적인 참고 문헌 형식을 사용하여 이 파일을 직접 편집할 수도 있습니다.\n소스 에디터의 .qmd 파일 내에 인용을 생성하려면 ‘@’ + 참고 문헌 파일의 인용 식별자로 구성된 키를 사용하세요. 그런 다음 인용을 대괄호 안에 넣으세요. 몇 가지 예는 다음과 같습니다:\n여러 인용을 `;`로 구분: Blah blah [@smith04; @doe99].\n\n대괄호 안에 임의의 주석 추가: \nBlah blah [see @doe99, pp. 33-35; also @smith04, ch. 1].\n\n대괄호를 제거하여 텍스트 내 인용 생성: @smith04 \nsays blah, or @smith04 [p. 33] says blah.\n\n인용 앞에 `-`를 추가하여 저자 이름 억제: \nSmith says blah [-@smith04].\nQuarto가 파일을 렌더링할 때 참고 문헌을 빌드하고 문서 끝에 추가합니다. 참고 문헌에는 참고 문헌 파일의 각 인용된 참조가 포함되지만 섹션 제목은 포함되지 않습니다. 결과적으로 # References 또는 # Bibliography와 같은 참고 문헌에 대한 섹션 제목으로 파일을 끝내는 것이 일반적입니다.\ncsl 필드에서 CSL(인용 스타일 언어) 파일을 참조하여 인용 및 참고 문헌의 스타일을 변경할 수 있습니다:\nbibliography: rmarkdown.bib\ncsl: apa.csl\nbibliography 필드와 마찬가지로 csl 파일에는 파일 경로가 포함되어야 합니다. 여기서는 csl 파일이 .qmd 파일과 같은 디렉토리에 있다고 가정합니다. 일반적인 참고 문헌 스타일에 대한 CSL 스타일 파일을 찾기에 좋은 곳은 https://github.com/citation-style-language/styles입니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#워크플로우",
    "href": "quarto.html#워크플로우",
    "title": "28  Quarto",
    "section": "\n28.11 워크플로우",
    "text": "28.11 워크플로우\n앞서 우리는 콘솔에서 대화형으로 작업한 다음 스크립트 에디터에서 작동하는 것을 캡처하는 R 코드를 캡처하기 위한 기본 워크플로우를 논의했습니다. Quarto는 콘솔과 스크립트 에디터를 하나로 묶어 대화형 탐색과 장기 코드 캡처 사이의 경계를 모호하게 만듭니다. Cmd/Ctrl + Shift + Enter로 편집하고 다시 실행하면서 청크 내에서 빠르게 반복할 수 있습니다. 만족하면 다음으로 이동하여 새 청크를 시작합니다.\nQuarto는 산문과 코드를 매우 긴밀하게 통합하기 때문에 중요합니다. 이것은 코드를 개발하고 생각을 기록할 수 있게 해주기 때문에 훌륭한 분석 노트북이 됩니다. 분석 노트북은 물리 과학의 고전적인 실험실 노트와 많은 동일한 목표를 공유합니다. 그것은:\n\n수행한 작업과 수행한 이유를 기록합니다. 기억력이 아무리 좋아도 수행한 작업을 기록하지 않으면 중요한 세부 사항을 잊어버릴 때가 올 것입니다. 잊지 않도록 적어 두세요!\n엄격한 사고를 지원합니다. 진행하면서 생각을 기록하고 계속해서 반성하면 강력한 분석을 내놓을 가능성이 더 큽니다. 이것은 나중에 분석을 작성하여 다른 사람들과 공유할 때도 시간을 절약해 줍니다.\n다른 사람들이 당신의 일을 이해하도록 돕습니다. 혼자서 데이터 분석을 하는 경우는 드물며, 종종 팀의 일원으로 일하게 됩니다. 실험실 노트는 수행한 작업뿐만 아니라 왜 그렇게 했는지 동료나 실험실 친구들과 공유하는 데 도움이 됩니다.\n\n실험실 노트를 효과적으로 사용하는 것에 대한 좋은 조언의 대부분은 분석 노트북으로도 번역될 수 있습니다. 우리는 우리 자신의 경험과 실험실 노트에 대한 Colin Purrington의 조언(https://colinpurrington.com/tips/lab-notebooks)을 바탕으로 다음 팁을 만들었습니다:\n\n각 노트북에 설명적인 제목, 기억하기 쉬운 파일 이름, 분석의 목표를 간략하게 설명하는 첫 번째 단락이 있는지 확인하세요.\n\nYAML 헤더 날짜 필드를 사용하여 노트북 작업을 시작한 날짜를 기록하세요:\ndate: 2016-08-23\n모호함이 없도록 ISO8601 YYYY-MM-DD 형식을 사용하세요. 평소에 날짜를 그렇게 쓰지 않더라도 사용하세요!\n\n분석 아이디어에 많은 시간을 할애했는데 막다른 골목으로 판명되더라도 삭제하지 마세요! 실패한 이유에 대한 짧은 메모를 작성하고 노트북에 남겨 두세요. 그러면 나중에 분석으로 다시 돌아올 때 같은 막다른 골목으로 가는 것을 피할 수 있습니다.\n일반적으로 데이터 입력은 R 외부에서 하는 것이 좋습니다. 하지만 데이터의 작은 스니펫을 기록해야 하는 경우 tibble::tribble()을 사용하여 명확하게 레이아웃하세요.\n데이터 파일에서 오류를 발견하면 직접 수정하지 말고 값을 수정하는 코드를 작성하세요. 수정한 이유를 설명하세요.\n하루를 마치기 전에 노트북을 렌더링할 수 있는지 확인하세요. 캐싱을 사용하는 경우 캐시를 지우세요. 그러면 코드가 아직 마음에 생생할 때 문제를 해결할 수 있습니다.\n코드를 장기적으로 재현 가능하게 하려면(즉, 다음 달이나 내년에 다시 실행할 수 있도록) 코드가 사용하는 패키지의 버전을 추적해야 합니다. 엄격한 접근 방식은 프로젝트 디렉토리에 패키지를 저장하는 renv(https://rstudio.github.io/renv/index.html)를 사용하는 것입니다. 빠르고 더러운 해킹은 sessionInfo()를 실행하는 청크를 포함하는 것입니다 — 이것은 오늘날 그대로 패키지를 쉽게 다시 만들 수는 없지만 적어도 무엇이었는지는 알 수 있습니다.\n경력 과정에서 아주, 아주, 아주 많은 분석 노트북을 만들게 될 것입니다. 나중에 다시 찾을 수 있도록 어떻게 정리하시겠습니까? 개별 프로젝트에 저장하고 좋은 명명 체계를 만드는 것을 추천합니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#요약",
    "href": "quarto.html#요약",
    "title": "28  Quarto",
    "section": "\n28.12 요약",
    "text": "28.12 요약\n이 장에서는 코드와 산문을 한곳에 포함하는 재현 가능한 계산 문서를 작성하고 게시하기 위한 Quarto를 소개했습니다. 비주얼 에디터나 소스 에디터로 RStudio에서 Quarto 문서를 작성하는 방법, 코드 청크가 작동하는 방식과 옵션을 사용자 정의하는 방법, Quarto 문서에 그림과 표를 포함하는 방법, 계산을 위한 캐싱 옵션에 대해 배웠습니다. 또한 자체 포함 또는 매개변수화된 문서를 만들기 위해 YAML 헤더 옵션을 조정하는 방법과 인용 및 참고 문헌을 포함하는 방법에 대해 배웠습니다. 또한 몇 가지 문제 해결 및 워크플로우 팁을 제공했습니다.\n이 소개는 Quarto를 시작하기에 충분하지만 아직 배워야 할 것이 훨씬 더 많습니다. Quarto는 아직 비교적 젊고 빠르게 성장하고 있습니다. 혁신을 파악하기 가장 좋은 곳은 공식 Quarto 웹사이트입니다: https://quarto.org.\n여기서 다루지 않은 두 가지 중요한 주제가 있습니다: 협업과 아이디어를 다른 사람들에게 정확하게 전달하는 세부 사항입니다. 협업은 현대 데이터 과학의 중요한 부분이며 Git 및 GitHub와 같은 버전 제어 도구를 사용하면 삶을 훨씬 더 쉽게 만들 수 있습니다. Jenny Bryan의 R 사용자를 위한 Git 및 GitHub에 대한 사용자 친화적인 소개인 “Happy Git with R”을 추천합니다. 이 책은 온라인에서 무료로 볼 수 있습니다: https://happygitwithr.com.\n또한 분석 결과를 명확하게 전달하기 위해 실제로 무엇을 써야 하는지에 대해서는 다루지 않았습니다. 글쓰기를 향상시키려면 Joseph M. Williams & Joseph Bizup의 Style: Lessons in Clarity and Grace 또는 George Gopen의 The Sense of Structure: Writing from the Reader’s Perspective를 읽는 것을 강력히 추천합니다. 두 책 모두 문장과 단락의 구조를 이해하고 글을 더 명확하게 만드는 도구를 제공하는 데 도움이 될 것입니다. (이 책들은 새 것으로 구입하면 꽤 비싸지만 많은 영어 수업에서 사용되므로 저렴한 중고 사본이 많이 있습니다). George Gopen은 또한 https://www.georgegopen.com/litigation-articles.html에 글쓰기에 대한 짧은 기사를 많이 가지고 있습니다. 변호사를 대상으로 하지만 거의 모든 것이 데이터 과학자에게도 적용됩니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html",
    "href": "quarto-formats.html",
    "title": "29  Quarto 형식",
    "section": "",
    "text": "29.1 소개\n지금까지 Quarto를 사용하여 HTML 문서를 생성하는 것을 보았습니다. 이 장에서는 Quarto로 생성할 수 있는 다른 많은 출력 유형 중 일부에 대해 간략하게 살펴봅니다.\n문서의 출력을 설정하는 방법은 두 가지가 있습니다:",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#소개",
    "href": "quarto-formats.html#소개",
    "title": "29  Quarto 형식",
    "section": "",
    "text": "YAML 헤더를 수정하여 영구적으로 설정:\ntitle: \"Diamond sizes\"\nformat: html\n\n\nquarto::quarto_render()를 직접 호출하여 일시적으로 설정:\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"docx\")\n\noutput_format 인수는 값 목록을 받을 수도 있으므로 프로그래밍 방식으로 여러 유형의 출력을 생성하려는 경우 유용합니다.\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = c(\"docx\", \"pdf\"))",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#출력-옵션",
    "href": "quarto-formats.html#출력-옵션",
    "title": "29  Quarto 형식",
    "section": "\n29.2 출력 옵션",
    "text": "29.2 출력 옵션\nQuarto는 광범위한 출력 형식을 제공합니다. 전체 목록은 https://quarto.org/docs/output-formats/all-formats.html에서 찾을 수 있습니다. 많은 형식이 일부 출력 옵션(예: 목차를 포함하기 위한 toc: true)을 공유하지만, 다른 형식은 형식에 특화된 옵션(예: code-fold: true는 HTML 출력의 경우 코드 청크를 &lt;details&gt; 태그로 축소하여 사용자가 요청할 때만 표시할 수 있게 하지만, PDF나 Word 문서에는 적용되지 않음)을 가집니다.\n기본 옵션을 재정의하려면 확장된 format 필드를 사용해야 합니다. 예를 들어 플로팅 목차가 있는 html을 렌더링하려면 다음과 같이 사용합니다:\nformat:\n  html:\n    toc: true\n    toc_float: true\n형식 목록을 제공하여 여러 출력으로 렌더링할 수도 있습니다:\nformat:\n  html:\n    toc: true\n    toc_float: true\n  pdf: default\n  docx: default\n기본 옵션을 재정의하고 싶지 않은 경우의 특별한 구문(pdf: default)에 유의하세요.\n문서의 YAML에 지정된 모든 형식으로 렌더링하려면 output_format = \"all\"을 사용할 수 있습니다.\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"all\")",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#문서",
    "href": "quarto-formats.html#문서",
    "title": "29  Quarto 형식",
    "section": "\n29.3 문서",
    "text": "29.3 문서\n이전 장에서는 기본 html 출력에 집중했습니다. 해당 테마에는 여러 가지 기본 변형이 있어 다양한 유형의 문서를 생성합니다. 예를 들어:\n\npdf는 설치가 필요한 오픈 소스 문서 레이아웃 시스템인 LaTeX를 사용하여 PDF를 만듭니다. 아직 없는 경우 RStudio가 알려줄 것입니다.\ndocx는 Microsoft Word(.docx) 문서용입니다.\nodt는 OpenDocument Text(.odt) 문서용입니다.\nrtf는 Rich Text Format(.rtf) 문서용입니다.\ngfm은 GitHub Flavored Markdown(.md) 문서용입니다.\nipynb는 Jupyter Notebooks(.ipynb)용입니다.\n\n의사 결정권자와 공유할 문서를 생성할 때 문서 YAML에서 전역 옵션을 설정하여 코드의 기본 표시를 끌 수 있다는 점을 기억하세요:\nexecute:\n  echo: false\nhtml 문서의 경우 또 다른 옵션은 코드 청크를 기본적으로 숨기지만 클릭하면 보이게 하는 것입니다:\nformat:\n  html:\n    code: true",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#프레젠테이션",
    "href": "quarto-formats.html#프레젠테이션",
    "title": "29  Quarto 형식",
    "section": "\n29.4 프레젠테이션",
    "text": "29.4 프레젠테이션\nQuarto를 사용하여 프레젠테이션을 생성할 수도 있습니다. Keynote나 PowerPoint와 같은 도구보다 시각적 제어는 덜하지만, R 코드의 결과를 프레젠테이션에 자동으로 삽입하면 엄청난 시간을 절약할 수 있습니다. 프레젠테이션은 콘텐츠를 슬라이드로 나누어 작동하며, 각 두 번째(##) 수준 헤더에서 새 슬라이드가 시작됩니다. 또한 첫 번째(#) 수준 헤더는 기본적으로 중앙에 배치되는 섹션 제목 슬라이드와 함께 새 섹션의 시작을 나타냅니다.\nQuarto는 다음을 포함하여 다양한 프레젠테이션 형식을 지원합니다:\n\nrevealjs - revealjs를 사용한 HTML 프레젠테이션\npptx - PowerPoint 프레젠테이션\nbeamer - LaTeX Beamer를 사용한 PDF 프레젠테이션.\n\nQuarto로 프레젠테이션을 만드는 방법에 대한 자세한 내용은 https://quarto.org/docs/presentations에서 읽을 수 있습니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#대화형-기능-interactivity",
    "href": "quarto-formats.html#대화형-기능-interactivity",
    "title": "29  Quarto 형식",
    "section": "\n29.5 대화형 기능 (Interactivity)",
    "text": "29.5 대화형 기능 (Interactivity)\n모든 HTML 문서와 마찬가지로 Quarto로 만든 HTML 문서에도 대화형 구성 요소가 포함될 수 있습니다. 여기서는 Quarto 문서에 대화형 기능을 포함하기 위한 두 가지 옵션인 htmlwidgets와 Shiny를 소개합니다.\n\n29.5.1 htmlwidgets\nHTML은 대화형 형식이며, 대화형 HTML 시각화를 생성하는 R 함수인 htmlwidgets를 사용하여 그 이점을 활용할 수 있습니다. 예를 들어 아래의 leaflet 지도를 살펴보세요. 웹에서 이 페이지를 보고 있다면 지도를 드래그하거나 확대/축소 등을 할 수 있습니다. 책에서는 그렇게 할 수 없으므로 Quarto가 자동으로 정적 스크린샷을 삽입해 줍니다.\n\nlibrary(leaflet)\nleaflet() |&gt;\n  setView(174.764, -36.877, zoom = 16) |&gt; \n  addTiles() |&gt;\n  addMarkers(174.764, -36.877, popup = \"Maungawhau\") \n\n\n\n\n\nhtmlwidgets의 장점은 이를 사용하기 위해 HTML이나 JavaScript에 대해 전혀 알 필요가 없다는 것입니다. 모든 세부 사항이 패키지 내부에 래핑되어 있으므로 걱정할 필요가 없습니다.\nhtmlwidgets를 제공하는 많은 패키지가 있으며 다음을 포함합니다:\n\n대화형 시계열 시각화를 위한 dygraphs.\n대화형 표를 위한 DT.\n대화형 3D 플롯을 위한 threejs.\n다이어그램(예: 순서도 및 간단한 노드-링크 다이어그램)을 위한 DiagrammeR.\n\nhtmlwidgets에 대해 더 자세히 알아보고 이를 제공하는 패키지의 전체 목록을 보려면 https://www.htmlwidgets.org를 방문하세요.\n\n29.5.2 Shiny\nhtmlwidgets는 클라이언트 측(client-side) 대화형 기능을 제공합니다 — 모든 상호 작용은 R과 독립적으로 브라우저에서 발생합니다. 한편으로는 R에 연결하지 않고도 HTML 파일을 배포할 수 있기 때문에 훌륭합니다. 그러나 이는 기본적으로 HTML과 JavaScript로 구현된 것들로만 할 수 있는 일을 제한합니다. 대안적인 접근 방식은 JavaScript가 아니라 R 코드를 사용하여 대화형 기능을 만들 수 있게 해주는 패키지인 shiny를 사용하는 것입니다.\nQuarto 문서에서 Shiny 코드를 호출하려면 YAML 헤더에 server: shiny를 추가하세요:\ntitle: \"Shiny Web App\"\nformat: html\nserver: shiny\n그런 다음 “input” 함수를 사용하여 문서에 대화형 구성 요소를 추가할 수 있습니다:\n\nlibrary(shiny)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\n\n\n\n\n\n\n\n\n\n또한 Shiny 서버에서 실행해야 하는 코드가 포함된 청크 옵션 context: server가 있는 코드 청크도 필요합니다.\n그런 다음 input$name 및 input$age로 값을 참조할 수 있으며, 이들을 사용하는 코드는 값이 변경될 때마다 자동으로 다시 실행됩니다.\nShiny 상호 작용은 서버 측(server-side) 에서 발생하기 때문에 여기에서 라이브 Shiny 앱을 보여드릴 수 없습니다. 즉, JavaScript를 모르고도 대화형 앱을 작성할 수 있지만, 이를 실행할 서버가 필요합니다. 이로 인해 물류적인 문제가 발생합니다: Shiny 앱을 온라인에서 실행하려면 Shiny 서버가 필요합니다. 자신의 컴퓨터에서 Shiny 앱을 실행할 때 Shiny는 자동으로 Shiny 서버를 설정해 주지만, 이러한 종류의 대화형 기능을 온라인에 게시하려면 공용 Shiny 서버가 필요합니다. 이것이 Shiny의 근본적인 트레이드오프입니다: R에서 할 수 있는 모든 것을 Shiny 문서에서 할 수 있지만, 누군가 R을 실행하고 있어야 합니다.\nShiny에 대해 더 배우고 싶다면 Hadley Wickham이 쓴 Mastering Shiny(https://mastering-shiny.org)를 읽어보시기를 권장합니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#웹사이트와-책",
    "href": "quarto-formats.html#웹사이트와-책",
    "title": "29  Quarto 형식",
    "section": "\n29.6 웹사이트와 책",
    "text": "29.6 웹사이트와 책\n약간의 추가 인프라를 사용하면 Quarto를 사용하여 완전한 웹사이트나 책을 생성할 수 있습니다:\n\n.qmd 파일을 단일 디렉토리에 넣습니다. index.qmd가 홈 페이지가 됩니다.\n\n사이트 탐색을 제공하는 _quarto.yml이라는 이름의 YAML 파일을 추가합니다. 이 파일에서 project 유형을 book 또는 website로 설정합니다. 예:\nproject:\n  type: book\n\n\n예를 들어 다음 _quarto.yml 파일은 세 개의 소스 파일인 index.qmd(홈 페이지), viridis-colors.qmd, terrain-colors.qmd로부터 웹사이트를 만듭니다.\n\nproject:\n  type: website\n\nwebsite:\n  title: \"A website on color scales\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: viridis-colors.qmd\n        text: Viridis colors\n      - href: terrain-colors.qmd\n        text: Terrain colors\n\n책에 필요한 _quarto.yml 파일도 매우 비슷하게 구성됩니다. 다음 예제는 세 가지 다른 출력(html, pdf, epub)으로 렌더링되는 4개의 장으로 구성된 책을 만드는 방법을 보여줍니다. 다시 한번 말씀드리지만 소스 파일은 .qmd 파일입니다.\n\nproject:\n  type: book\n\nbook:\n  title: \"A book on color scales\"\n  author: \"Jane Coloriste\"\n  chapters:\n    - index.qmd\n    - intro.qmd\n    - viridis-colors.qmd\n    - terrain-colors.qmd\n\nformat:\n  html:\n    theme: cosmo\n  pdf: default\n  epub: default\n\n웹사이트와 책에는 RStudio 프로젝트를 사용하는 것이 좋습니다. _quarto.yml 파일을 기반으로 RStudio는 작업 중인 프로젝트 유형을 인식하고, 웹사이트와 책을 렌더링하고 미리 보는 데 사용할 수 있는 Build 탭을 IDE에 추가합니다. 웹사이트와 책 모두 quarto::quarto_render()를 사용하여 렌더링할 수도 있습니다.\nQuarto 웹사이트에 대해서는 https://quarto.org/docs/websites, 책에 대해서는 https://quarto.org/docs/books에서 자세히 읽어보세요.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#기타-형식",
    "href": "quarto-formats.html#기타-형식",
    "title": "29  Quarto 형식",
    "section": "\n29.7 기타 형식",
    "text": "29.7 기타 형식\nQuarto는 더 많은 출력 형식을 제공합니다:\n\nQuarto Journal Templates를 사용하여 학술지 논문을 작성할 수 있습니다: https://quarto.org/docs/journals/templates.html.\nformat: ipynb를 사용하여 Quarto 문서를 Jupyter Notebook으로 출력할 수 있습니다: https://quarto.org/docs/reference/formats/ipynb.html.\n\n더 많은 형식 목록은 https://quarto.org/docs/output-formats/all-formats.html을 참조하세요.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#요약",
    "href": "quarto-formats.html#요약",
    "title": "29  Quarto 형식",
    "section": "\n29.8 요약",
    "text": "29.8 요약\n이 장에서는 정적 및 대화형 문서에서 프레젠테이션, 웹사이트 및 책에 이르기까지 Quarto로 결과를 전달하기 위한 다양한 옵션을 제시했습니다.\n이러한 다양한 형식으로 효과적인 소통을 하는 방법에 대해 더 자세히 배우려면 다음 리소스를 추천합니다:\n\n프레젠테이션 기술을 향상시키려면 Neal Ford, Matthew McCollough, Nathaniel Schutta가 쓴 Presentation Patterns를 시도해 보세요. 프레젠테이션을 개선하기 위해 적용할 수 있는 효과적인 패턴(낮은 수준과 높은 수준 모두) 세트를 제공합니다.\n학술 발표를 한다면 Leek group guide to giving talks가 마음에 드실 것입니다.\n우리는 직접 들어보지는 못했지만, Matt McGarrity의 대중 연설 온라인 강의에 대해 좋은 이야기를 들었습니다: https://www.coursera.org/learn/public-speaking.\n대시보드를 많이 만들고 있다면 Stephen Few의 Information Dashboard Design: The Effective Visual Communication of Data를 꼭 읽어보세요. 단지 예쁘기만 한 것이 아니라 정말로 유용한 대시보드를 만드는 데 도움이 될 것입니다.\n아이디어를 효과적으로 전달하는 것은 종종 그래픽 디자인에 대한 약간의 지식으로부터 이득을 얻습니다. Robin Williams의 The Non-Designer’s Design Book은 시작하기에 훌륭한 장소입니다.",
    "crumbs": [
      "소통 (Communicate)",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto 형식</span>"
    ]
  },
  {
    "objectID": "arrow.html#소개",
    "href": "arrow.html#소개",
    "title": "22  Arrow",
    "section": "",
    "text": "22.1.1 선수 지식\n이 장에서도 tidyverse, 특히 dplyr를 계속 사용하겠지만, 대용량 데이터 작업을 위해 특별히 설계된 arrow 패키지와 결합할 것입니다.\n\nlibrary(tidyverse)\nlibrary(arrow)\n\n이 장의 뒷부분에서는 arrow와 duckdb 사이의 몇 가지 연결 고리도 살펴볼 것이므로 dbplyr과 duckdb도 필요합니다.\n\nlibrary(dbplyr, warn.conflicts = FALSE)\nlibrary(duckdb)\n#&gt; Warning: package 'duckdb' was built under R version 4.5.2\n#&gt; Loading required package: DBI",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#데이터-가져오기",
    "href": "arrow.html#데이터-가져오기",
    "title": "22  Arrow",
    "section": "\n22.2 데이터 가져오기",
    "text": "22.2 데이터 가져오기\n이러한 도구에 걸맞은 데이터셋인 시애틀 공공 도서관의 아이템 대출 데이터셋을 가져오는 것으로 시작합니다. 이 데이터셋은 data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6에서 온라인으로 이용 가능합니다. 이 데이터셋에는 2005년 4월부터 2022년 10월까지 매달 각 책이 몇 번 대출되었는지를 알려주는 41,389,465개의 행이 포함되어 있습니다.\n다음 코드는 데이터의 캐시된 복사본을 가져옵니다. 데이터는 9GB CSV 파일이므로 다운로드하는 데 시간이 좀 걸립니다. 매우 큰 파일을 가져올 때는 이 목적을 위해 특별히 제작된 curl::multi_download()를 사용하는 것을 적극 추천합니다. 진행률 표시줄을 제공하고 중단된 경우 다운로드를 재개할 수 있기 때문입니다.\n\ndir.create(\"data\", showWarnings = FALSE)\n\ncurl::multi_download(\n  \"https://r4ds.s3.us-west-2.amazonaws.com/seattle-library-checkouts.csv\",\n  \"data/seattle-library-checkouts.csv\",\n  resume = TRUE\n)\n#&gt; # A tibble: 1 × 10\n#&gt;   success status_code resumefrom url                    destfile        error\n#&gt;   &lt;lgl&gt;         &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;\n#&gt; 1 TRUE            200          0 https://r4ds.s3.us-we… /Users/jinhwan… &lt;NA&gt; \n#&gt; # ℹ 4 more variables: type &lt;chr&gt;, modified &lt;dttm&gt;, time &lt;dbl&gt;,\n#&gt; #   headers &lt;list&gt;",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#데이터셋-열기",
    "href": "arrow.html#데이터셋-열기",
    "title": "22  Arrow",
    "section": "\n22.3 데이터셋 열기",
    "text": "22.3 데이터셋 열기\n데이터를 살펴보는 것부터 시작하겠습니다. 9GB인 이 파일은 메모리에 전체를 로드하고 싶지 않을 만큼 큽니다. 일반적인 경험 법칙으로 데이터 크기의 최소 두 배 이상의 메모리가 필요한데, 많은 노트북은 16GB가 한계입니다. 즉, read_csv()를 피하고 대신 arrow::open_dataset()을 사용하고 싶습니다:\n\nseattle_csv &lt;- open_dataset(\n  sources = \"data/seattle-library-checkouts.csv\", \n  col_types = schema(ISBN = string()),\n  format = \"csv\"\n)\n\n이 코드가 실행되면 어떻게 될까요? open_dataset()은 수천 개의 행을 스캔하여 데이터셋의 구조를 파악합니다. ISBN 열은 처음 80,000행 동안 빈 값을 포함하므로 arrow가 데이터 구조를 파악하는 데 도움이 되도록 열 유형을 지정해야 합니다. open_dataset()에 의해 데이터가 스캔되면 발견된 내용을 기록하고 멈춥니다. 사용자가 구체적으로 요청할 때만 추가 행을 읽습니다. 이 메타데이터는 seattle_csv를 인쇄하면 볼 수 있는 내용입니다:\n\nseattle_csv\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 12 columns\n#&gt; UsageClass: string\n#&gt; CheckoutType: string\n#&gt; MaterialType: string\n#&gt; CheckoutYear: int64\n#&gt; CheckoutMonth: int64\n#&gt; Checkouts: int64\n#&gt; Title: string\n#&gt; ISBN: string\n#&gt; Creator: string\n#&gt; Subjects: string\n#&gt; Publisher: string\n#&gt; PublicationYear: string\n\n출력의 첫 번째 줄은 seattle_csv가 로컬 디스크에 단일 CSV 파일로 저장되어 있음을 알려줍니다. 필요할 때만 메모리에 로드됩니다. 나머지 출력은 각 열에 대해 arrow가 추정한 열 유형을 알려줍니다.\nglimpse()로 실제로 무엇이 들어있는지 볼 수 있습니다. 약 4,100만 개의 행과 12개의 열이 있음을 보여주고 몇 가지 값을 보여줍니다.\n\nseattle_csv |&gt; glimpse()\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 41,389,465 rows x 12 columns\n#&gt; $ UsageClass      &lt;string&gt; \"Physical\", \"Physical\", \"Digital\", \"Physical\", \"Ph…\n#&gt; $ CheckoutType    &lt;string&gt; \"Horizon\", \"Horizon\", \"OverDrive\", \"Horizon\", \"Hor…\n#&gt; $ MaterialType    &lt;string&gt; \"BOOK\", \"BOOK\", \"EBOOK\", \"BOOK\", \"SOUNDDISC\", \"BOO…\n#&gt; $ CheckoutYear     &lt;int64&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 20…\n#&gt; $ CheckoutMonth    &lt;int64&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n#&gt; $ Checkouts        &lt;int64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 3, 2,…\n#&gt; $ Title           &lt;string&gt; \"Super rich : a guide to having it all / Russell S…\n#&gt; $ ISBN            &lt;string&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#&gt; $ Creator         &lt;string&gt; \"Simmons, Russell\", \"Barclay, James, 1965-\", \"Tim …\n#&gt; $ Subjects        &lt;string&gt; \"Self realization, Conduct of life, Attitude Psych…\n#&gt; $ Publisher       &lt;string&gt; \"Gotham Books,\", \"Pyr,\", \"Random House, Inc.\", \"Di…\n#&gt; $ PublicationYear &lt;string&gt; \"c2011.\", \"2010.\", \"2015\", \"2005.\", \"c2004.\", \"c20…\n\ndplyr 동사를 사용하여 이 데이터셋을 사용할 수 있으며, collect()를 사용하여 arrow가 계산을 수행하고 일부 데이터를 반환하도록 강제할 수 있습니다. 예를 들어, 이 코드는 연도별 총 대출 횟수를 알려줍니다:\n\nseattle_csv |&gt; \n  group_by(CheckoutYear) |&gt; \n  summarise(Checkouts = sum(Checkouts)) |&gt; \n  arrange(CheckoutYear) |&gt; \n  collect()\n#&gt; # A tibble: 18 × 2\n#&gt;   CheckoutYear Checkouts\n#&gt;          &lt;int&gt;     &lt;int&gt;\n#&gt; 1         2005   3798685\n#&gt; 2         2006   6599318\n#&gt; 3         2007   7126627\n#&gt; 4         2008   8438486\n#&gt; 5         2009   9135167\n#&gt; 6         2010   8608966\n#&gt; # ℹ 12 more rows\n\narrow 덕분에 이 코드는 기본 데이터셋이 아무리 크더라도 작동합니다. 하지만 현재는 다소 느립니다. 해들리의 컴퓨터에서 실행하는 데 약 10초가 걸렸습니다. 데이터 양을 고려하면 나쁘지 않지만 더 나은 형식으로 전환하여 훨씬 더 빠르게 만들 수 있습니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#arrow와-함께-dplyr-사용하기",
    "href": "arrow.html#arrow와-함께-dplyr-사용하기",
    "title": "22  Arrow",
    "section": "\n22.5 arrow와 함께 dplyr 사용하기",
    "text": "22.5 arrow와 함께 dplyr 사용하기\n이제 이 파켓 파일들을 만들었으므로 다시 읽어 들여야 합니다. 다시 open_dataset()을 사용하지만 이번에는 디렉터리를 제공합니다:\n\nseattle_pq &lt;- open_dataset(pq_path)\n\n이제 dplyr 파이프라인을 작성할 수 있습니다. 예를 들어 지난 5년 동안 매달 대출된 총 도서 수를 계산할 수 있습니다:\n\nquery &lt;- seattle_pq |&gt; \n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear, CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(CheckoutYear, CheckoutMonth)\n\narrow 데이터에 대한 dplyr 코드를 작성하는 것은 개념적으로 Chapter 21 의 dbplyr과 유사합니다. dplyr 코드를 작성하면 Apache Arrow C++ 라이브러리가 이해하는 쿼리로 자동으로 변환되고 collect()를 호출할 때 실행됩니다. query 객체를 인쇄하면 실행 시 Arrow가 반환할 것으로 예상되는 내용에 대한 약간의 정보를 볼 수 있습니다:\n\nquery\n#&gt; FileSystemDataset (query)\n#&gt; CheckoutYear: int32\n#&gt; CheckoutMonth: int64\n#&gt; TotalCheckouts: int64\n#&gt; \n#&gt; * Grouped by CheckoutYear\n#&gt; * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#&gt; See $.data for the source Arrow object\n\n그리고 collect()를 호출하여 결과를 얻을 수 있습니다:\n\nquery |&gt; collect()\n#&gt; # A tibble: 58 × 3\n#&gt; # Groups:   CheckoutYear [5]\n#&gt;   CheckoutYear CheckoutMonth TotalCheckouts\n#&gt;          &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n#&gt; 1         2018             1         355101\n#&gt; 2         2018             2         309813\n#&gt; 3         2018             3         344487\n#&gt; 4         2018             4         330988\n#&gt; 5         2018             5         318049\n#&gt; 6         2018             6         341825\n#&gt; # ℹ 52 more rows\n\ndbplyr과 마찬가지로 arrow는 일부 R 표현식만 이해하므로 평소 작성하던 것과 똑같은 코드를 작성하지 못할 수도 있습니다. 하지만 지원되는 연산 및 함수 목록은 상당히 광범위하며 계속 늘어나고 있습니다. 현재 지원되는 함수의 전체 목록은 ?acero에서 확인할 수 있습니다.\n\n22.5.1 성능\nCSV에서 파켓으로 전환할 때의 성능 영향을 빠르게 살펴보겠습니다. 먼저 데이터가 단일 대용량 CSV로 저장되어 있을 때 2021년 각 달에 대출된 도서 수를 계산하는 데 걸리는 시간을 측정해 보겠습니다:\n\nseattle_csv |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;  12.321   1.902  12.132\n\n이제 시애틀 도서관 대출 데이터가 18개의 작은 파켓 파일로 파티셔닝된 새 버전의 데이터셋을 사용해 보겠습니다:\n\nseattle_pq |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;   0.236   0.062   0.079\n\n약 100배의 성능 향상은 두 가지 요인, 즉 다중 파일 파티셔닝과 개별 파일의 형식에 기인합니다:\n\n파티셔닝은 성능을 향상시킵니다. 이 쿼리는 데이터를 필터링하기 위해 CheckoutYear == 2021을 사용하며, arrow는 18개의 파켓 파일 중 1개만 읽으면 된다는 것을 인식할 만큼 똑똑하기 때문입니다.\n파켓 형식은 데이터를 메모리에 더 직접적으로 읽을 수 있는 이진 형식으로 저장하여 성능을 향상시킵니다. 열 기반 형식과 풍부한 메타데이터는 arrow가 쿼리에 실제로 사용된 4개의 열(CheckoutYear, MaterialType, CheckoutMonth, Checkouts)만 읽으면 된다는 것을 의미합니다.\n\n이 엄청난 성능 차이가 대용량 CSV를 파켓으로 변환할 가치가 있는 이유입니다!\n\n22.5.2 arrow와 함께 duckdb 사용하기\n파켓과 arrow의 마지막 장점 하나는 arrow::to_duckdb()를 호출하여 arrow 데이터셋을 DuckDB 데이터베이스(Chapter 21)로 매우 쉽게 전환할 수 있다는 것입니다:\n\nseattle_pq |&gt; \n  to_duckdb() |&gt;\n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutYear)) |&gt;\n  collect()\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # A tibble: 5 × 2\n#&gt;   CheckoutYear TotalCheckouts\n#&gt;          &lt;int&gt;          &lt;dbl&gt;\n#&gt; 1         2022        2431502\n#&gt; 2         2021        2266438\n#&gt; 3         2020        1241999\n#&gt; 4         2019        3931688\n#&gt; 5         2018        3987569\n\nto_duckdb()의 멋진 점은 전송 과정에서 메모리 복사가 발생하지 않는다는 것이며, 이는 한 컴퓨팅 환경에서 다른 환경으로의 원활한 전환을 가능하게 하는 arrow 생태계의 목표를 잘 보여줍니다.\n\n22.5.3 연습문제\n\n매년 가장 인기 있는 책을 찾아보세요.\n시애틀 도서관 시스템에서 가장 많은 책을 보유한 작가는 누구입니까?\n지난 10년 동안 종이책 대 전자책의 대출은 어떻게 변했습니까?",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#요약",
    "href": "arrow.html#요약",
    "title": "22  Arrow",
    "section": "\n22.6 요약",
    "text": "22.6 요약\n이 장에서는 디스크의 대규모 데이터셋 작업을 위한 dplyr 백엔드를 제공하는 arrow 패키지를 맛보았습니다. CSV 파일과 함께 작업할 수 있으며, 데이터를 파켓으로 변환하면 훨씬 더 빠릅니다. 파켓은 현대 컴퓨터에서의 데이터 분석을 위해 특별히 설계된 이진 데이터 형식입니다. CSV에 비해 파켓 파일을 작업할 수 있는 도구는 훨씬 적지만, 파티셔닝, 압축 및 열 구조 덕분에 분석이 훨씬 더 효율적입니다.\n다음으로 tidyr 패키지에서 제공하는 도구를 사용하여 처리할 첫 번째 비정형 데이터 소스에 대해 배울 것입니다. JSON 파일에서 가져온 데이터에 초점을 맞추겠지만, 일반적인 원리는 소스에 관계없이 트리 구조의 데이터에 적용됩니다.",
    "crumbs": [
      "가져오기 (Import)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arrow</span>"
    ]
  }
]